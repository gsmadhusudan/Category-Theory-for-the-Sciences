<p>— title: Category Theory for the Sciences author: David I. Spivak rights: Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License language: en-US …</p>
<p></p>
<p>[Go to first, previous, <a href="copyright.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<p>Category Theory for the Sciences</p>
<p>David I. Spivak</p>
<p>The MIT Press<br />Cambridge, Massachusetts<br />London, England</p>
<p></p>
<p>[Go to first, previous, <a href="copyright.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="index.html">previous</a>, <a href="acknowledgments.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<p><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" alt="Creative Commons License" /></a><br /><em>Category Theory for the Sciences</em> by <a href="index.html">David I. Spivak</a> is licensed under a <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a> by the MIT Press.</p>
<p>MIT Press books may be purchased at special quantity discounts for business or sales promotional use. For information, please email <script type="text/javascript">
<!--
h='&#x6d;&#x69;&#116;&#112;&#114;&#x65;&#x73;&#x73;&#46;&#x6d;&#x69;&#116;&#46;&#x65;&#100;&#x75;';a='&#64;';n='&#x73;&#112;&#x65;&#x63;&#x69;&#x61;&#108;&#x73;&#x61;&#108;&#x65;&#x73;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'">'+e+'<\/'+'a'+'>');
// -->
</script><noscript>&#x73;&#112;&#x65;&#x63;&#x69;&#x61;&#108;&#x73;&#x61;&#108;&#x65;&#x73;&#32;&#x61;&#116;&#32;&#x6d;&#x69;&#116;&#112;&#114;&#x65;&#x73;&#x73;&#32;&#100;&#x6f;&#116;&#32;&#x6d;&#x69;&#116;&#32;&#100;&#x6f;&#116;&#32;&#x65;&#100;&#x75;</noscript>.</p>
<p><a href="http://lccn.loc.gov/2014007215">Library of Congress Cataloging-in-Publication Data</a></p>
<p>Spivak, David I., 1978– author.</p>
<p>Category theory for the sciences / David I. Spivak.</p>
<p>pages cm</p>
<p>Includes bibliographical references and index.</p>
<p>ISBN 978-0-262-02813-4 (hardcover : alk. paper) 1.<br />Science—Mathematical models. 2. Categories (Mathematics) I. Title.</p>
<p>Q175.32.M38S65 2014</p>
<p>512’.62—dc23</p>
<p>2014007215</p>
<p>10 9 8 7 6 5 4 3 2 1</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="index.html">previous</a>, <a href="acknowledgments.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="copyright.html">previous</a>, <a href="toc.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<h1 class="front-title"><strong>Acknowledgments</strong></h1>
<p>I would like to express my deep appreciation to the many scientists with whom I have worked over the past six years. It all started with Paea LePendu, who first taught me about databases when I was naively knocking on doors in the University of Oregon computer science department. This book would never have been written if Tristan Nguyen and Dave Balaban had not noticed my work and encouraged me to continue. Dave Balaban and Peter Gates have been my scientific partners since the beginning, working hard to understand what I am offering and working just as hard to help me understand all that I am missing. Peter Gates has deepened my understanding of data in profound ways.</p>
<p>I have also been tremendously lucky to know Haynes Miller, who made it possible for me to settle at MIT, with the help of Clark Barwick and Jacob Lurie. I knew that MIT would be the best place in the world for me to pursue this type of research, and it consistently lives up to expectation. Researchers like Markus Buehler and his graduate students Tristan Giesa and Dieter Brommer have been a pleasure to work with, and the many materials science examples scattered throughout this book are a testament to how much our work together has influenced my thinking.</p>
<p>I would also like to thank the collaborators and conversation partners with whom I have discussed subjects written about in this book. Besides the people mentioned previously, these include Steve Awodey, Allen Brown, Adam Chlipala, Carlo Curino, Dan Dugger, Henrik Forssell, David Gepner, Jason Gross, Bob Harper, Ralph Hutchison, Robert Kent, Jack Morava, Scott Morrison, David Platt, Joey Perricone, Dylan Rupel, Guarav Singh, Sam Shames, Nat Stapleton, Patrick Schultz, Ka Yu Tam, Ryan Wisnesky, Jesse Wolfson, and Elizabeth Wood.</p>
<p>I would like to thank Peter Kleinhenz and Peter Gates for reading an earlier version of this book and providing invaluable feedback before I began teaching the 18-S996 class at MIT in spring 2013. In particular, the first figure of the book, Figure <a href="chapter001.html#Fig_1-1">1.1</a>, is a slight alteration of a diagram Gates sent me to help motivate the book for scientists. I would also like to greatly thank the 18-S996 course grader Darij Grinberg, who not only was the best grader I have had in my 14 years of teaching, but gave me more comments than anyone else on the book itself. I would like to thank the students from the 18-S996 class at MIT who found typos, pointed out unclear explanations, and generally helped improve the book in many ways: Aaron Brookner, Leon Dimas, Dylan Erb, Deokhwan Kim, Taesoo Kim, Owen Lewis, Yair Shenfeld, and Adam Strandberg, among others. People outside the class, V. Galchin, K. Hofmeyr, D. McAdams, D. Holmes, C. McNally, P. O’Neill, and R. Harper, also contributed to finding errata and making improvements.</p>
<p>I’d also like to thank Marie Lufkin Lee, Marc Lowenthal, Katherine Almeida, and everyone else at MIT Press who helped get this book ready for publication. And thanks to Laura Baldwin, who helped me work through some painful LaTeX issues. The book is certainly far better than when I originally submitted it. I also appreciate the willingness of the Press to work with me in making a copy of this book publicly available.</p>
<p>Thanks also to my teacher Peter Ralston, who taught me to repeatedly question the obvious. My ability to commit to a project like this one and to see it to fruition has certainly been enhanced since I studied with him.</p>
<p>Finally, I acknowledge my appreciation for support from the O?ce of Naval Research and Air Force O?ce of Scientific Research<a href="acknowledgments.html#endnote_1"><sup>1</sup></a> without which this book would not have been remotely possible. I believe that the funding of basic research is an excellent way of ensuring that the United States remains a global leader in the years to come.</p>
<p>__________________</p>
<p><a href="acknowledgments.html#endnote_ref_1"><sup>1</sup></a>Grant numbers: N000140910466, N000141010841, N000141310260, FA9550-14-1-0031.</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="copyright.html">previous</a>, <a href="toc.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="copyright.html">previous</a>, <a href="chapter001.html">next</a> page;   contents;   <a href="bookindex.html">index</a>]</p>
<p></p>
<h1 class="front-title"><strong>Contents</strong></h1>
<p><a href="chapter001.html"><strong>1 Introduction</strong></a></p>
<p><a href="chapter001.html#lev_1-1">1.1 A brief history of category theory</a></p>
<p><a href="chapter001.html#lev_1-2">1.2 Intention of this book</a></p>
<p><a href="chapter001.html#lev_1-3">1.3 What is requested from the student</a></p>
<p><a href="chapter001.html#lev_1-4">1.4 Category theory references</a></p>
<p><a href="chapter002.html"><strong>2 The Category of Sets</strong></a></p>
<p><a href="chapter002.html#lev_2-1">2.1 Sets and functions</a></p>
<p><a href="chapter002.html#lev_2-2">2.2 Commutative diagrams</a></p>
<p><a href="chapter002.html#lev_2-3">2.3 Ologs</a></p>
<p><a href="chapter003.html"><strong>3 Fundamental Considerations in Set</strong></a></p>
<p><a href="chapter003.html#lev_3-1">3.1 Products and coproducts</a></p>
<p><a href="chapter003.html#lev_3-2">3.2 Finite limits in <strong>Set</strong></a></p>
<p><a href="chapter003.html#lev_3-3">3.3 Finite colimits in <strong>Set</strong></a></p>
<p><a href="chapter003.html#lev_3-4">3.4 Other notions in <strong>Set</strong></a></p>
<p><a href="chapter004.html"><strong>4 Categories and Functors, Without Admitting It</strong></a></p>
<p><a href="chapter004.html#lev_4-1">4.1 Monoids</a></p>
<p><a href="chapter004.html#lev_4-2">4.2 Groups</a></p>
<p><a href="chapter004.html#lev_4-3">4.3 Graphs</a></p>
<p><a href="chapter004.html#lev_4-4">4.4 Orders</a></p>
<p><a href="chapter004.html#lev_4-5">4.5 Databases: schemas and instances</a></p>
<p><a href="chapter005.html"><strong>5 Basic Category Theory</strong></a></p>
<p><a href="chapter005.html#lev_5-1">5.1 Categories and functors</a></p>
<p><a href="chapter005.html#lev_5-2">5.2 Common categories and functors from pure math</a></p>
<p><a href="chapter005.html#lev_5-3">5.3 Natural transformations</a></p>
<p><a href="chapter005.html#lev_5-4">5.4 Categories and schemas are equivalent, <strong>Cat</strong> » <strong>Sch</strong></a></p>
<p><a href="chapter006.html"><strong>6 Fundamental Considerations of Categories</strong></a></p>
<p><a href="chapter006.html#lev_6-1">6.1 Limits and colimits</a></p>
<p><a href="chapter006.html#lev_6-2">6.2 Other notions in <strong>Cat</strong></a></p>
<p><a href="chapter007.html"><strong>7 Categories at Work</strong></a></p>
<p><a href="chapter007.html#lev_7-1">7.1 Adjoint functors</a></p>
<p><a href="chapter007.html#lev_7-2">7.2 Categories of functors</a></p>
<p><a href="chapter007.html#lev_7-3">7.3 Monads</a></p>
<p><a href="chapter007.html#lev_7-4">7.4 Operads</a></p>
<p><a href="reference.html"><strong>References</strong></a></p>
<p><a href="bookindex.html"><strong>Index</strong></a></p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="toc.html">previous</a>, <a href="chapter002.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<h1 class="chapter-number"><a href="toc.html#chap-1"><strong>Chapter 1</strong></a></h1>
<h1 class="chapter-title"><a href="toc.html#chap-1"><strong>Introduction</strong></a></h1>
<p>The diagram in <a href="chapter001.html#Fig_1-1">Figure 1.1</a> is intended to evoke thoughts of the scientific method.</p>
<p><img src="images/Art_P1.jpg" alt="art" /></p>
<p><strong>Figure 1.1</strong></p>
<p>An observation analyzed by a person yields a hypothesis, which analyzed by a person produces a prediction, which motivates the specification of an experiment, which when executed results in an observation.</p>
<p>Its statements look valid, and a good graphic can be very useful for leading a reader through a story that the author wishes to tell.</p>
<p>But a graphic has the power to evoke feelings of understanding without really meaning much. The same is true for text: it is possible to use a language like English to express ideas that are never made rigorous or clear. When someone says, “I believe in free will,” what does she believe in? We may all have some concept of what she’s saying—something we can conceptually work with and discuss or argue about. But to what extent are we all discussing the same thing, the thing she intended to convey?</p>
<p>Science is about agreement. When we supply a convincing argument, the result of this convincing is agreement. When, in an experiment, the observation matches the hypothesis—success!—that is agreement. When my methods make sense to you, that is agreement. When practice does not agree with theory, that is disagreement. Agreement is the good stuff in science; it is the celebratory moment.</p>
<p>But it is easy to think we are in agreement, when we really are not. Modeling our thoughts on heuristics and graphics may be convenient for quick travel down the road, but we are liable to miss our turnoff at the first mile. The danger is in mistaking convenient conceptualizations for what is actually there. It is imperative that we have the ability at any time to ground in reality. What does that mean?</p>
<p>Data. Hard evidence. The physical world. It is here that science is grounded and heuristics evaporate. So let’s look again at <a href="chapter001.html#Fig_1-1">Figure 1.1</a>. It is intended to evoke an idea of how science is performed. Do hard evidence and data back up this theory? Can we set up an experiment to find out whether science is actually performed according to such a protocol? To do so we have to shake off the impressions evoked by the diagram and ask, What does this diagram intend to communicate?</p>
<p>In this book I will use a mathematical tool called <em>ologs</em>, or ontology logs, to give some structure to the kinds of ideas that are often communicated in graphics. Each olog inherently offers a framework in which to record data about the subject. More precisely, it encompasses a <em>database schema</em>, which means a system of interconnected tables that are initially empty but into which data can be entered. For example, consider the following olog:</p>
<p><img src="images/Art_P2.jpg" alt="art" /></p>
<p>This olog represents a framework in which to record data about objects held above the ground, their mass, their height, and a comparison (the question mark) between the number of seconds till they hit the ground and a certain real-valued function of their height. Ologs are discussed in detail throughout this book.</p>
<p><a href="chapter001.html#Fig_1-1">Figure 1.1</a> looks like an olog, but it does not conform to the rules laid out for ologs (see Section <a href="chapter002.html#lev_2-3">2.3</a>). In an olog, every arrow is intended to represent a mathematical function. It is difficult to imagine a function that takes in predictions and outputs experiments, but such a function is necessary in order for the arrow</p>
<p><img src="images/Art_eq1.jpg" alt="art" /></p>
<p>in <a href="chapter001.html#Fig_1-1">Figure 1.1</a> to make sense. To produce an experiment design from a prediction probably requires an expert, and even then the expert may be motivated to specify a different experiment on Tuesday than he is on Monday. But perhaps this criticism leads to a way forward. If we say that every arrow represents a function <em>when in the context of a specific expert who is actually doing the science at a specific time</em>, then <a href="chapter001.html#Fig_1-1">Figure 1.1</a> begins to make sense. In fact, the figure is reconsidered in Section <a href="chapter007.html#lev_7-3">7.3</a> (Example <a href="chapter007.html#Exa_7-3-3-10">7.3.3.10</a>), where background methodological context is discussed.</p>
<p>This book extols the virtues of a new branch of mathematics, <em>category theory</em>, which was invented for powerful communication of ideas between different fields and subfields within mathematics. By powerful communication of ideas I mean something precise. Different branches of mathematics can be formalized into categories. These categories can then be connected by functors. And the sense in which these functors provide powerful communication of ideas is that facts and theorems proven in one category can be transferred through a connecting functor to yield proofs of analogous theorems in another category. A functor is like a conductor of mathematical truth.</p>
<p>I believe that the language and tool set of category theory can be useful throughout science. We build scientific understanding by developing models, and category theory is the study of basic conceptual building blocks and how they cleanly fit together to make such models. Certain structures and conceptual frameworks show up again and again in our understanding of reality. No one would dispute that vector spaces are ubiquitous throughout the sciences. But so are hierarchies, symmetries, actions of agents on objects, data models, global behavior emerging as the aggregate of local behavior, self-similarity, and the effect of methodological context.</p>
<p>Some ideas are so common that our use of them goes virtually undetected, such as set-theoretic intersections. For example, when we speak of a material that is both lightweight and ductile, we are intersecting two sets. But what is the use of even mentioning this set-theoretic fact? The answer is that when we formalize our ideas, our understanding is clarified. Our ability to communicate with others is enhanced, and the possibility for developing new insights expands. And if we are ever to get to the point that we can input our ideas into computers, we will need to be able to formalize these ideas first.</p>
<p>It is my hope that this book will offer scientists a new vocabulary in which to think and communicate, and a new pipeline to the vast array of theorems that exist and are considered immensely powerful within mathematics. These theorems have not made their way into the world of science, but they are directly applicable there. Hierarchies are partial orders, symmetries are group elements, data models are categories, agent actions are monoid actions, local-to-global principles are sheaves, self-similarity is modeled by operads, context can be modeled by monads. All of these will be discussed in the book.</p>
<h1 id="lev_1-1" class="level1"><a href="toc.html#Rlev_1-1"><strong>1.1   A brief history of category theory</strong></a></h1>
<p>The paradigm shift brought on by Einstein’s theory of relativity led to a widespread realization that there is no single perspective from which to view the world. There is no background framework that we need to find; there are infinitely many different frameworks and perspectives, and the real power lies in being able to translate between them. It is in this historical context that category theory got its start.<sup><a href="chapter001.html#endnote_1">1</a></sup></p>
<p>Category theory was invented in the early 1940s by Samuel Eilenberg and Saunders Mac Lane. It was specifically designed to bridge what may appear to be two quite different fields: topology and algebra. Topology is the study of abstract shapes such as 7-dimensional spheres; algebra is the study of abstract equations such as <em>y</em><sup>2</sup><em>z</em> = <em>x</em><sup>3</sup> − <em>xz</em><sup>2</sup>. People had already created important and useful links (e.g., cohomology theory) between these fields, but Eilenberg and Mac Lane needed to precisely compare different links with one another. To do so they first needed to boil down and extract the fundamental nature of these two fields. But in doing so, the ideas they worked out amounted to a framework that fit not only topology and algebra, but many other mathematical disciplines as well.</p>
<p>At first category theory was little more than a deeply clarifying language for existing difficult mathematical ideas. However, in 1957 Alexander Grothendieck used category theory to build new mathematical machinery (new cohomology theories) that granted unprecedented insight into the behavior of algebraic equations. Since that time, categories have been built specifically to zoom in on particular features of mathematical subjects and study them with a level of acuity that is unavailable elsewhere.</p>
<p>Bill Lawvere saw category theory as a new foundation for all mathematical thought. Mathematicians had been searching for foundations in the nineteenth century and were reasonably satisfied with set theory as <em>the foundation</em>. But Lawvere showed that the category of sets is simply one category with certain nice properties, not necessarily the center of the mathematical universe. He explained how whole algebraic theories can be viewed as examples of a single system. He and others went on to show that higher-order logic was beautifully captured in the setting of category theory (more specifically toposes). It is here also that Grothendieck and his school worked out major results in algebraic geometry.</p>
<p>In 1980, Joachim Lambek showed that the types and programs used in computer science form a specific kind of category. This provided a new semantics for talking about programs, allowing people to investigate how programs combine and compose to create other programs, without caring about the specifics of implementation. Eugenio Moggi brought the category-theoretic notion of monads into computer science to encapsulate ideas that up to that point were considered outside the realm of such theory.</p>
<p>It is difficult to explain the clarity and beauty brought to category theory by people like Daniel Kan and André Joyal. They have each repeatedly extracted the essence of a whole mathematical subject to reveal and formalize a stunningly simple yet extremely powerful pattern of thinking, revolutionizing how mathematics is done.</p>
<p>All this time, however, category theory was consistently seen by much of the mathematical community as ridiculously abstract. But in the twenty-first century it has finally come to find healthy respect within the larger community of pure mathematics. It is the language of choice for graduate-level algebra and topology courses, and in my opinion will continue to establish itself as the basic framework in which to think about and express mathematical ideas.</p>
<p>As mentioned, category theory has branched out into certain areas of science as well. Baez and Dolan [6] have shown its value in making sense of quantum physics, it is well established in computer science, and it has found proponents in several other fields as well. But to my mind, we are at the very beginning of its venture into scientific methodology. Category theory was invented as a bridge, and it will continue to serve in that role.</p>
<h1 id="lev_1-2" class="level1"><a href="toc.html#Rlev_1-2"><strong>1.2   Intention of this book</strong></a></h1>
<p>The world of <em>applied mathematics</em> is much smaller than the world of <em>applicable mathematics</em>. As mentioned, this book is intended to create a bridge between the vast array of mathematical concepts that are used daily by mathematicians to describe all manner of phenomena that arise in our studies and the models and frameworks of scientific disciplines such as physics, computation, and neuroscience.</p>
<p>For the pure mathematician I try to prove that concepts such as categories, functors, natural transformations, limits, colimits, functor categories, sheaves, monads, and operads—concepts that are often considered too abstract even for math majors—can be communicated to scientists with no math background beyond linear algebra. If this material is as teachable as I think, it means that category theory is not esoteric but well aligned with ideas that already make sense to the scientific mind. Note, however, that this book is example-based rather than proof-based, so it may not be suitable as a reference for students of pure mathematics.</p>
<p>For the scientist I try to prove the claim that category theory includes a formal treatment of conceptual structures that the scientist sees often, perhaps without realizing that there is well-oiled mathematical machinery to be employed. A major topics is the structure of information itself: how data is made meaningful by its connections, both internal and outreaching, to other data.<sup><a href="chapter001.html#endnote_2">2</a></sup> Note, however, that this book should certainly not be taken as a reference on scientific matters themselves. One should assume that any account of physics, materials science, chemistry, and so on, has been oversimplified. The intention is to give a flavor of how category theory may help model scientific ideas, not to explain those ideas in a serious way.</p>
<p>Data gathering is ubiquitous in science. Giant databases are currently being mined for unknown patterns, but in fact there are many (many) known patterns that simply have not been catalogued. Consider the well-known case of medical records. In the early twenty-first century, it is often the case that a patient’s medical history is known by various doctor’s offices but quite inadequately shared among them. Sharing medical records often means faxing a handwritten note or a filled-in house-created form from one office to another.</p>
<p>Similarly, in science there exists substantial expertise making brilliant connections between concepts, but this expertise is conveyed in silos of English prose known as journal articles. Every scientific journal article has a methods section, but it is almost impossible to read a methods section and subsequently repeat the experiment—the English language is inadequate to precisely and concisely convey what is being done.</p>
<p>The first thought I wish to convey in this book is that reusable methodologies can be formalized and that doing so is inherently valuable. Consider the following analogy. Suppose one wants to add up the area of a region in space (or the area under a curve). One breaks the region down into small squares, each with area <em>A</em>, and then counts the number of squares, say <em>n</em>. One multiplies these numbers together and says that the region has an area of about <em>nA</em>. To obtain a more precise and accurate result, one repeats the process with half-size squares. This methodology can be used for any area-finding problem (of which there are more than a first-year calculus student generally realizes) and thus it deserves to be formalized. But once we have formalized this methodology, it can be taken to its limit, resulting in integration by Riemann sums. Formalizing the problem can lead to powerful techniques that were unanticipated at the outset.</p>
<p>I intend to show that category theory is incredibly efficient as a language for experimental design patterns, introducing formality while remaining flexible. It forms a rich and tightly woven conceptual fabric that allows the scientist to maneuver between different perspectives whenever the need arises. Once she weaves that fabric into her own line of research, she has an ability to think about models in a way that simply would not occur without it. Moreover, putting ideas into the language of category theory forces a person to clarify her assumptions. This is highly valuable both for the researcher and for her audience.</p>
<p>What must be recognized in order to find value in this book is that conceptual chaos is a major problem. Creativity demands clarity of thinking, and to think clearly about a subject requires an organized understanding of how its pieces fit together. Organization and clarity also lead to better communication with others. Academics often say they are paid to think and understand, but that is not the whole truth. They are paid to think, understand, and <em>communicate their findings</em>. Universal languages for science, such as calculus and differential equations, matrices, or simply graphs and pie charts, already exist, and they grant us a cultural cohesiveness that makes scientific research worthwhile. In this book I attempt to show that category theory can be similarly useful in describing complex scientific understandings.</p>
<h1 id="lev_1-3" class="level1"><a href="toc.html#Rlev_1-3"><strong>1.3   What is requested from the student</strong></a></h1>
<p>The only way to learn mathematics is by doing exercises. One does not get fit by merely looking at a treadmill or become a chef by merely reading cookbooks, and one does not learn math by watching someone else do it. There are about 300 exercises in this book. Some of them have solutions in the text, others have solutions that can only be accessed by professors teaching the class.</p>
<p>A good student can also make up his own exercises or simply play around with the material. This book often uses databases as an entry to category theory. If one wishes to explore categorical database software, FQL (functorial query language) is a great place to start. It may also be useful in solving some of the exercises.</p>
<h1 id="lev_1-4" class="level1"><a href="toc.html#Rlev_1-4"><strong>1.4   Category theory references</strong></a></h1>
<p>I wrote this book because the available books on category theory are almost all written for mathematicians (the rest are written for computer scientists). One book, <em>Conceptual Mathematics</em> by Lawvere and Schanuel [24], offers category theory to a wider audience, but its style is not appropriate for a course or as a reference. Still, it is very well written and clear.</p>
<p>The bible of category theory is <em>Categories for the Working Mathematician</em> by Mac Lane [29]. But as the title suggests, it was written for working mathematicians and would be opaque to my target audience. However, once a person has read the present book, Mac Lane’s book may become a valuable reference.</p>
<p>Other good books include Awodey’s <em>Category theory</em> [4], a recent gentle introduction by Simmons [37], and Barr and Wells’s <em>Category Theory for Computing Science</em>, [11]. A paper by Brown and Porter, ‘‘Category Theory: an abstract setting for analogy and comparison” [9] is more in line with the style of this book, only much shorter. Online, I find Wikipedia [46] and a site called <em>nLab</em> [34] to be quite useful.</p>
<p>This book attempts to explain category theory by examples and exercises rather than by theorems and proofs. I hope this approach will be valuable to the working scientist.</p>
<p>__________________</p>
<p><a href="chapter001.html#endnote_ref_1"><sup>1</sup></a>The following history of category theory is far too brief and perhaps reflects more of the author’s aesthetic than any kind of objective truth. References are Kromer [19], Marquis [30], and Landry and Marquis [22].</p>
<p><a href="chapter001.html#endnote_ref_2"><sup>2</sup></a>The word <em>data</em> is generally considered to be the plural form of the word <em>datum</em>. However, individual datum elements are only useful when they are organized into structures (e.g., if one were to shuffle the cells in a spreadsheet, most would consider the data to be destroyed). It is the whole organized structure that really houses the information; the data must be in formation in order to be useful. Thus I use the word <em>data</em> as a collective noun (akin to <em>sand</em>); it bridges the divide between the <em>individual datum elements</em> (akin to grains of sand) and the <em>data set</em> (akin to a sand pile).</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="toc.html">previous</a>, <a href="chapter002.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter001.html">previous</a>, <a href="chapter003.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<h1 class="chapter-number"><a href="toc.html#chap-2"><strong>Chapter 2</strong></a></h1>
<h1 class="chapter-title"><a href="toc.html#chap-2"><strong>The Category of Sets</strong></a></h1>
<p>The theory of sets was invented as a foundation for all of mathematics. The notion of sets and functions serves as a basis on which to build intuition about categories in general. This chapter gives examples of sets and functions and then discusses commutative diagrams. Ologs are then introduced, allowing us to use the language of category theory to speak about real world concepts. All this material is basic set theory, but it can also be taken as an investigation of the <em>category of sets</em>, which is denoted <strong>Set</strong>.</p>
<h1 id="lev_2-1" class="level1"><a href="toc.html#Rlev_2-1"><strong>2.1   Sets and functions</strong></a></h1>
<p>People have always found it useful to put things into bins.</p>
<p><img src="images/Art_eq2.jpg" alt="art" /></p>
<p>The study of sets is the study of things in bins.</p>
<h2 id="lev_2-1-1" class="level2"><strong>2.1.1   Sets</strong></h2>
<p>You probably have an innate understanding of what a set is. We can think of a set <em>X</em> as a collection of <em>elements x</em> ∈ <em>X</em>, each of which is recognizable as being in <em>X</em> and such that for each pair of named elements <em>x</em>, <em>x</em>′ ∈ <em>X</em> we can tell if <em>x</em> = <em>x</em>′ or not.<sup><a href="chapter002.html#endnote_1">1</a></sup> The set of pendulums is the collection of things we agree to call pendulums, each of which is recognizable as being a pendulum, and for any two people pointing at pendulums we can tell if they’re pointing at the same pendulum or not.</p>
<p><img src="images/Art_P3.jpg" alt="art" /></p>
<p><strong>Figure 2.1</strong> A set <em>X</em> with nine elements, and a set <em>Y</em> with no elements, <em>Y</em> = ∅.</p>
<p><em>Notation</em> 2.1.1.1. The symbol ∅ denotes the set with no elements (see <a href="chapter002.html#Fig_2-1">Figure 2.1</a>), which can also be written as { }. The symbol ℕ denotes the set of natural numbers:</p>
<p>ℕ≔{0, 1, 2, 3, 4, …, 877,…}.   (2.1)</p>
<p>The symbol ℤ denotes the set of integers, which contains both the natural numbers and their negatives,</p>
<p>ℤ≔{…,−551,…,−2,−1,0,1,2,…}.   (2.2)</p>
<p>If <em>A</em> and <em>B</em> are sets, we say that <em>A</em> is a <em>subset</em> of <em>B</em>, and write <em>A</em> ⊆ <em>B</em>, if every element of <em>A</em> is an element of <em>B</em>. So we have ℕ ⊆ ℤ. Checking the definition, one sees that for any set <em>A</em>, we have (perhaps uninteresting) subsets ∅ ⊆ <em>A</em> and <em>A</em> ⊆ <em>A</em>. We can use <em>set-builder notation</em> to denote subsets. For example, the set of even integers can be written {<em>n</em> ∈ ℤ | <em>n</em> is even}. The set of integers greater than 2 can be written in many ways, such as</p>
<p>{n∈ℤ|n&gt;2}or{n∈ℕ|n&gt;2}or{n∈ℕ|n⩾3}.</p>
<p>The symbol ∃ means “there exists.” So we could write the set of even integers as</p>
<p>{n∈ℤ|n is even}={n∈ℤ|∃m∈ℤ such that 2m=n}.</p>
<p>The symbol ∃! means “there exists a unique.” So the statement “∃!<em>x</em> ∈ ℝ such that <em>x</em><sup>2</sup> = 0” means that there is one and only one number whose square is 0. Finally, the symbol ∀ means “for all.” So the statement “∀<em>m</em> ∈ ℕ ∃<em>n</em> ∈ ℕ such that <em>m</em> &lt; <em>n</em>” means that for every number there is a bigger one.</p>
<p>As you may have noticed in defining ℕ and ℤ in (<a href="chapter002.html#lev_2-1">2.1</a>) and (<a href="chapter002.html#lev_2-2">2.2</a>), we use the colon-equals notation “<em>A</em> ≔ <em>XY Z</em>” to mean something like “define <em>A</em> to be <em>XY Z</em>.” That is, a colon-equals declaration does not denote a fact of nature (like 2 + 2 = 4) but a choice of the writer.</p>
<p>We also often discuss a certain set with one element, denoted {☺}, as well as the familiar set of real numbers, ℝ, and some variants such as ℝ<sub>⩾0</sub> ≔ {<em>x</em> ∈ ℝ | <em>x</em> ⩾ 0}.</p>
<p><em>Exercise</em> 2.1.1.2.</p>
<p>Let <em>A</em> ≔ {1, 2, 3}. What are all the subsets of <em>A</em>? Hint: There are eight.</p>
<p>A set can have other sets as elements. For example, the set</p>
<p>X≔{{1,2},{4},{1,3,6}}</p>
<p>has three elements, each of which is a set.</p>
<h2 id="lev_2-1-2" class="level2"><strong>2.1.2   Functions</strong></h2>
<p>If <em>X</em> and <em>Y</em> are sets, then a <em>function f from X to Y</em>, denoted <em>f</em> : <em>X</em> → <em>Y</em>, is a mapping that sends each element <em>x</em> ∈ <em>X</em> to an element of <em>Y</em>, denoted <em>f</em>(<em>x</em>) ∈ <em>Y</em>. We call <em>X</em> the <em>domain</em> of the function <em>f</em>, and we call <em>Y</em> the <em>codomain</em> of <em>f</em>.</p>
<p><img src="images/Art_P4.jpg" alt="art" /></p>
<p><strong>Figure 2.2</strong> A function from a set <em>X</em> to a set <em>Y</em>.</p>
<p>Note that for every element <em>x</em> ∈ <em>X</em>, there is exactly one arrow emanating from <em>x</em>, but for an element <em>y</em> ∈ <em>Y</em>, there can be several arrows pointing to <em>y</em>, or there can be no arrows pointing to <em>y</em> (see <a href="chapter002.html#Fig_2-2">Figure 2.2</a>).</p>
<p><em>Slogan</em> 2.1.2.1.</p>
<p><em>Given a function f</em> : <em>X</em> → <em>Y, we think of X as a set of things, and Y as a set of bins. The function tells us in which bin to put each thing</em>.</p>
<p><em>Application</em> 2.1.2.2. In studying the mechanics of materials, one wishes to know how a material responds to tension. For example, a rubber band responds to tension differently than a spring does. To each material we can associate a force-extension curve, recording how much force the material carries when extended to various lengths. Once we fix a methodology for performing experiments, finding a material’s force-extension curve would ideally constitute a function from the set of materials to the set of curves.</p>
<p><em>Exercise</em> 2.1.2.3.</p>
<p>Here is a simplified account of how the brain receives light. The eye contains about 100 million photoreceptor (PR) cells. Each connects to a retinal ganglion (RG) cell. No PR cell connects to two different RG cells, but usually many PR cells can attach to a single RG cell.</p>
<p>Let <em>PR</em> denote the set of photoreceptor cells, and let <em>RG</em> denote the set of retinal ganglion cells.</p>
<p>a. According to the above account, does the connection pattern constitute a function <em>RG</em> → <em>PR</em>, a function <em>PR</em> → <em>RG</em>, or neither one?</p>
<p>b. Would you guess that the connection pattern that exists between other areas of the brain are function-like? Justify your answer.</p>
<p><em>Example</em> 2.1.2.4. Suppose that <em>X</em> is a set and <em>X</em>′ ⊆ <em>X</em> is a subset. Then we can consider the function <em>X</em>′ → <em>X</em> given by sending every element of <em>X</em>′ to “itself” as an element of <em>X</em>. For example, if <em>X</em> = {<em>a</em>, <em>b</em>, <em>c</em>, <em>d</em>, <em>e</em>, <em>f</em>} and <em>X</em>′ = {<em>b</em>, <em>d</em>, <em>e</em>}, then <em>X</em>′ ⊆ <em>X</em>. We turn that into the function <em>X</em>′ → <em>X</em> given by <em>b</em> ↦ <em>b</em>, <em>d</em> ↦ <em>d</em>, <em>e</em> ↦ <em>e</em>.<sup><a href="chapter002.html#endnote_2">2</a></sup></p>
<p>As a matter of notation, we may sometimes say the following: Let <em>X</em> be a set, and let <em>i</em> : <em>X</em>′ ⊆ <em>X</em> be a subset. Here we are making clear that <em>X</em>′ is a subset of <em>X</em>, but that <em>i</em> is the name of the associated function.</p>
<p><em>Exercise</em> 2.1.2.5.</p>
<p>Let <em>f</em> : ℕ → ℕ be the function that sends every natural number to its square, e.g., <em>f</em>(6) = 36. First fill in the blanks, then answer a question.</p>
<p>a. 2 ↦ ________</p>
<p>b. 0 ↦ ________</p>
<p>c. −2 ↦ ________</p>
<p>d. 5 ↦ ________</p>
<p>e. Consider the symbol → and the symbol ↦. What is the difference between how these two symbols are used so far in this book?</p>
<p>Given a function <em>f</em> : <em>X</em> → <em>Y</em>, the elements of <em>Y</em> that have at least one arrow pointing to them are said to be <em>in the image</em> of <em>f</em>; that is, we have</p>
<p>im(f)≔{y∈Y|∃x∈X such that f(x)=y}.   (2.3)</p>
<p>The image of a function <em>f</em> is always a subset of its codomain, im(<em>f</em>) ⊆ <em>Y</em>.</p>
<p><em>Exercise</em> 2.1.2.6.</p>
<p>If <em>f</em> : <em>X</em> → <em>Y</em> is depicted by <a href="chapter002.html#Fig_2-2">Figure 2.2</a>, write its image, im(<em>f</em>) as a set.</p>
<p>Given a function <em>f</em> : <em>X</em> → <em>Y</em> and a function <em>g</em> : <em>Y</em> → <em>Z</em>, where the codomain of <em>f</em> is the same set as the domain of <em>g</em> (namely, <em>Y</em>), we say that <em>f</em> and <em>g</em> are <em>composable</em></p>
<p>X→fY→gZ.</p>
<p>The <em>composition of f and g</em> is denoted by <em>g</em> ○ <em>f</em> : <em>X</em> → <em>Z</em>. See <a href="chapter002.html#Fig_2-3">Figure 2.3</a>.</p>
<p><em>Slogan</em> 2.1.2.7.</p>
<p><em>Given composable functions</em> X→fY→gZ, <em>we have a way of putting every thing in X into a bin in Y, and we have a way of putting each bin from Y into a larger bin in Z. The composite, g</em> ○ <em>f</em> : <em>X</em> → <em>Z</em>, <em>is the resulting way that every thing in X is put into a bin in Z</em>.</p>
<p><em>Exercise</em> 2.1.2.8.</p>
<p><img src="images/Art_P5.jpg" alt="art" /></p>
<p><strong>Figure 2.3</strong> Functions <em>f</em> : <em>X</em> → <em>Y</em> and <em>g</em> : <em>Y</em> → <em>Z</em> compose to a function <em>g</em> ○ <em>f</em> : <em>X</em> → <em>Z</em> (follow the arrows).</p>
<p>If <em>A</em> ⊆ <em>X</em> is a subset, Example <a href="chapter002.html#Exa_2-1-2-4">2.1.2.4</a> showed how to think of it as a function <em>i</em> : <em>A</em> → <em>X</em>. Given a function <em>f</em> : <em>X</em> → <em>Y</em>, we can compose A→iX→fY and get a function <em>f</em> ○ <em>i</em>: <em>A</em> → <em>Y</em>. The image of this function is denoted</p>
<p>f(A)≔im(f○i),</p>
<p>see (<a href="chapter002.html#lev_2-3">2.3</a>) for the definition of image.</p>
<p>Let <em>X</em> = <em>Y</em> ≔ ℤ, let <em>A</em> ≔ {−1, 0, 1, 2, 3} ⊆ <em>X</em>, and let <em>f</em> : <em>X</em> → <em>Y</em> be given by <em>f</em>(<em>x</em>) = <em>x</em><sup>2</sup>. What is the image set <em>f</em>(<em>A</em>)?</p>
<p><em>Solution</em> 2.1.2.8.</p>
<p>By definition of image (see (<a href="chapter002.html#lev_2-3">2.3</a>), we have</p>
<p>f(A)={y∈ℤ|∃a∈A such that f○i(a)=y}.</p>
<p>Since <em>A</em> = {−1, 0, 1, 2, 3} and since <em>i</em>(<em>a</em>) = <em>a</em> for all <em>a</em> ∈ <em>A</em>, we have <em>f</em>(<em>A</em>) = {0, 1, 4, 9}. Note that an element of a set can only be in the set once; even though <em>f</em>(−1) = <em>f</em>(1) = 1, we need only mention 1 once in <em>f</em>(<em>A</em>). In other words, if a student has an answer such as {1, 0, 1, 4, 9}, this suggests a minor confusion.</p>
<p><em>Notation</em> 2.1.2.9. Let <em>X</em> be a set and <em>x</em> ∈ <em>X</em> an element. There is a function {☺} → <em>X</em> that sends ☺ ↦ <em>x</em>. We say that this function <em>represents x</em> ∈ <em>X</em>. We may denote it <em>x</em>: {☺} → <em>X</em>.</p>
<p><em>Exercise</em> 2.1.2.10.</p>
<p>Let <em>X</em> be a set, let <em>x</em> ∈ <em>X</em> be an element, and let <em>x</em>: {☺} → <em>X</em> be the function representing it. Given a function <em>f</em> : <em>X</em> → <em>Y</em>, what is <em>f</em> ○ <em>x</em>?</p>
<p><em>Remark</em> 2.1.2.11. Suppose given sets <em>A</em>, <em>B</em>, <em>C</em> and functions A→fB→gC. The <em>classical order</em> for writing their composition has been used so far, namely, <em>g</em> ○ <em>f</em> : <em>A</em> → <em>C</em>. For any element <em>a</em> ∈ <em>A</em>, we write <em>g</em> ○ <em>f</em>(<em>a</em>) to mean <em>g</em>(<em>f</em>(<em>a</em>)). This means “do <em>g</em> to whatever results from doing <em>f</em> to <em>a</em>.”</p>
<p>However, there is another way to write this composition, called <em>diagrammatic order</em>. Instead of <em>g</em> ○ <em>f</em>, we would write <em>f</em>; <em>g</em> : <em>A</em> → <em>C</em>, meaning “do <em>f</em>, then do <em>g</em>.” Given an element <em>a</em> ∈ <em>A</em>, represented by <em>a</em>: {☺} → <em>A</em>, we have an element <em>a</em>; <em>f</em>; <em>g</em>.</p>
<p>Let <em>X</em> and <em>Y</em> be sets. We write Hom<strong><sub>Set</sub></strong>(<em>X</em>, <em>Y</em>) to denote the set of functions <em>X</em> → <em>Y</em>.<sup><a href="chapter002.html#endnote_3">3</a></sup> Note that two functions <em>f</em>, <em>g</em> : <em>X</em> → <em>Y</em> are equal if and only if for every element <em>x</em> ∈ <em>X</em>, we have <em>f</em>(<em>x</em>) = <em>g</em>(<em>x</em>).</p>
<p><em>Exercise</em> 2.1.2.12.</p>
<p>Let <em>A</em> = {1, 2, 3, 4, 5} and <em>B</em> = {<em>x</em>, <em>y</em>}.</p>
<p>a. How many elements does Hom<strong><sub>Set</sub></strong>(<em>A</em>, <em>B</em>) have?</p>
<p>b. How many elements does Hom<strong><sub>Set</sub></strong>(<em>B</em>, <em>A</em>) have?</p>
<p><em>Exercise</em> 2.1.2.13.</p>
<p>a. Find a set <em>A</em> such that for all sets <em>X</em> there is exactly one element in Hom<strong><sub>Set</sub></strong>(<em>X</em>, <em>A</em>). Hint: Draw a picture of proposed <em>A</em>’s and <em>X</em>’s. How many dots should be in <em>A</em>?</p>
<p>b. Find a set <em>B</em> such that for all sets <em>X</em> there is exactly one element in Hom<strong><sub>Set</sub></strong>(<em>B</em>, <em>X</em>).</p>
<p><em>Solution</em> 2.1.2.13.</p>
<p>a. Here is one: <em>A</em> ≔ {☺}. (Here is another, <em>A</em> ≔ {48}, and another, <em>A</em> ≔ {<em>a</em><sub>1</sub>}).</p>
<p><img src="images/Art_P6.jpg" alt="art" /></p>
<p>Why? We are trying to count the number of functions <em>X</em> → <em>A</em>. Regardless of <em>X</em> and <em>A</em>, in order to give a function <em>X</em> → <em>A</em> one must answer the question, Where do I send <em>x</em>? several times, once for each element <em>x</em> ∈ <em>X</em>. Each element of <em>X</em> is sent to an element in <em>A</em>. For example, if <em>X</em> = {1, 2, 3}, then one asks three questions: Where do I send 1? Where do I send 2? Where do I send 3? When <em>A</em> has only one element, there is only one place to send each <em>x</em>. A function <em>X</em> → {☺} would be written 1 ↦ ☺, 2 ↦ ☺, 3 ↦ ☺. There is only one such function, so Hom<strong><sub>Set</sub></strong>(<em>X</em>, {☺}) has one element.</p>
<p>b. <em>B</em> = ∅ is the only possibility.</p>
<p><img src="images/Art_P7.jpg" alt="art" /></p>
<p>To give a function <em>B</em> → <em>X</em> one must answer the question, Where do I send <em>b</em>? for each <em>b</em> ∈ <em>B</em>. Because <em>B</em> has no elements, no questions must be answered in order to provide such a function. There is one way to answer all the necessary questions, because doing so is immediate (“vacuously satisfied”). It is like commanding John to “assign a letter grade to every person who is over 14 feet tall.” John is finished with his job the moment the command is given, and there is only one way for him to finish the job. So Hom<strong><sub>Set</sub></strong>(∅, <em>X</em>) has one element.</p>
<p>For any set <em>X</em>, we define the <em>identity function on X</em>, denoted</p>
<p>idX:X→X,</p>
<p>to be the function such that for all <em>x</em> ∈ <em>X</em>, we have id<em><sub>X</sub></em>(<em>x</em>) = <em>x</em>.</p>
<p><strong>Definition 2.1.2.14</strong> (Isomorphism). Let <em>X</em> and <em>Y</em> be sets. A function <em>f</em> : <em>X</em> → <em>Y</em> is called an <em>isomorphism</em>, denoted <em>f</em> : X→≅Y, if there exists a function <em>g</em> : <em>Y</em> → <em>X</em> such that <em>g</em> ○ <em>f</em> = id<em><sub>X</sub></em> and <em>f</em> ○ <em>g</em> = id<em><sub>Y</sub></em>.</p>
<p><img src="images/Art_P8.jpg" alt="art" /></p>
<p><strong>Figure 2.4</strong> An isomorphism X→≅Y.</p>
<p><img src="images/Art_P9.jpg" alt="art" /></p>
<p>In this case we also say that <em>f</em> is <em>invertible</em> and that <em>g</em> is <em>the inverse</em> of <em>f</em>. If there exists an isomorphism X→≅Y, we say that <em>X</em> and <em>Y</em> are <em>isomorphic</em> sets and may write <em>X</em> ≅ <em>Y</em>.</p>
<p><em>Example</em> 2.1.2.15. If <em>X</em> and <em>Y</em> are sets and <em>f</em> : <em>X</em> → <em>Y</em> is an isomorphism, then the analogue of <a href="chapter002.html#Fig_2-2">Figure 2.2</a> will look like a perfect matching, more often called a <em>one-to-one correspondence</em>. That means that no two arrows will hit the same element of <em>Y</em>, and every element of <em>Y</em> will be in the image. For example, <a href="chapter002.html#Fig_2-4">Figure 2.4</a> depicts an isomorphism X→≅Y between four element sets.</p>
<p><em>Application</em> 2.1.2.16. There is an isomorphism between the set Nuc<sub>DNA</sub> of nucleotides found in DNA and the set Nuc<sub>RNA</sub> of nucleotides found in RNA. Indeed, both sets have four elements, so there are 24 different isomorphisms. But only one is useful in biology. Before we say which one it is, let us say there is also an isomorphism Nuc<sub>DNA</sub> ≅ {<em>A</em>, <em>C</em>, <em>G</em>, <em>T</em>} and an isomorphism Nuc<sub>RNA</sub> ≅ {<em>A</em>, <em>C</em>, <em>G</em>, <em>U</em>}, and we will use the letters as abbreviations for the nucleotides.</p>
<p>The convenient isomorphism NucDNA→≅NucRNA is that given by RNA transcription; it sends</p>
<p>A↦U, C↦G, G↦C, T↦A.</p>
<p>(See also Application <a href="chapter005.html#App_5-1-2-21">5.1.2.21</a>.) There is also an isomorphism NucDNA→≅NucDNA (the matching in the double helix), given by</p>
<p>A↦T, C↦G, G↦C, T↦A.</p>
<p>Protein production can be modeled as a function from the set of 3-nucleotide sequences to the set of eukaryotic amino acids. However, it cannot be an isomorphism because there are 4<sup>3</sup> = 64 triplets of RNA nucleotides but only 21 eukaryotic amino acids.</p>
<p><em>Exercise</em> 2.1.2.17.</p>
<p>Let <em>n</em> ∈ ℕ be a natural number, and let <em>X</em> be a set with exactly <em>n</em> elements.</p>
<p>a. How many isomorphisms are there from <em>X</em> to itself?</p>
<p>b. Does your formula from part (a) hold when <em>n</em> = 0?</p>
<p><strong>Proposition 2.1.2.18</strong>. <em>The following facts hold about isomorphism</em>.</p>
<ol>
<li><em>Any set A is isomorphic to itself; i.e., there exists an isomorphism</em> A→≅A.</li>
<li><em>For any sets A and B, if A is isomorphic to B, then B is isomorphic to A</em>.</li>
<li><em>For any sets A, B, and C, if A is isomorphic to B, and B is isomorphic to C, then A is isomorphic to C.</em></li>
</ol>
<p><em>Proof</em>.     1. The identity function id<em><sub>A</sub></em>: <em>A</em> → <em>A</em> is invertible; its inverse is id<em><sub>A</sub></em> because id<em><sub>A</sub></em> ○ id<em><sub>A</sub></em> = id<em><sub>A</sub></em>.</p>
<p>2. If <em>f</em> : <em>A</em> → <em>B</em> is invertible with inverse <em>g</em> : <em>B</em> → <em>A</em>, then <em>g</em> is an isomorphism with inverse <em>f</em>.</p>
<p>3. If <em>f</em> : <em>A</em> → <em>B</em> and <em>f</em>′ : <em>B</em> → <em>C</em> are each invertible with inverses <em>g</em> : <em>B</em> → <em>A</em> and <em>g</em>′: <em>C</em> → <em>B</em>, then the following calculations show that <em>f</em>′ ○ <em>f</em> is invertible with inverse <em>g</em> ○ <em>g</em>′:</p>
<p>(f′○f)○(g○g′)=f′○(f○g)○g′=f′○idB○g′=f′○g′=idC(g○g′)○(f′○f)=g○(g′○f′)○f=g○idB○f=g○f=idA</p>
<p><em>Exercise</em> 2.1.2.19.</p>
<p>Let <em>A</em> and <em>B</em> be these sets:</p>
<p><img src="images/Art_P10.jpg" alt="art" /></p>
<p>Note that the sets <em>A</em> and <em>B</em> are isomorphic. Suppose that <em>f</em> : <em>B</em> → {1, 2, 3, 4, 5} sends “Bob” to 1, sends ♣ to 3, and sends <em>r</em>8 to 4. Is there a canonical function <em>A</em> → {1, 2, 3, 4, 5} corresponding to <em>f</em>?<sup><a href="chapter002.html#endnote_4">4</a></sup></p>
<p><em>Solution</em> 2.1.2.19.</p>
<p>No. There are a lot of choices, and none is any more reasonable than any other, i.e., none are canonical. (In fact, there are six choices; do you see why?)</p>
<p>The point of this exercise is to illustrate that even if one knows that two sets are isomorphic, one cannot necessarily treat them as the same. To treat them as the same, one should have in hand a specified <em>isomorphism g</em> : A→≅B, such as <em>a</em> ↦ <em>r</em>8, 7 ↦ “<em>Bob</em>”, <em>Q</em> ↦ ♣. Now, given <em>f</em> : <em>B</em> → {1, 2, 3, 4, 5}, there is a canonical function <em>A</em> → {1, 2, 3, 4, 5} corresponding to <em>f</em>, namely, <em>f</em> ○ <em>g</em>.</p>
<p><em>Exercise</em> 2.1.2.20.</p>
<p>Find a set <em>A</em> such that for any set <em>X</em>, there is an isomorphism of sets</p>
<p>X≅HomSet(A,X).</p>
<p>Hint: A function <em>A</em> → <em>X</em> points each element of <em>A</em> to an element of <em>X</em>. When would there be the same number of ways to do that as there are elements of of <em>X</em>?</p>
<p><em>Solution</em> 2.1.2.20.</p>
<p>Let <em>A</em> = {☺}. Then to point each element of <em>A</em> to an element of <em>X</em>, one must simply point ☺ to an element of <em>X</em>. The set of ways to do that can be put in one-to-one correspondence with the set of elements of <em>X</em>. For example, if <em>X</em> = {1, 2, 3}, then ☺ ↦ 3 is a function <em>A</em> → <em>X</em> representing the element 3 ∈ <em>X</em>. See Notation <a href="chapter002.html#Not_2-1-2-9">2.1.2.9</a>.</p>
<p><em>Notation</em> 2.1.2.21. For any natural number <em>n</em> ∈ ℕ, define a set</p>
<p>n¯≔{1,2,3,…,n}.   (2.4)</p>
<p>We call <em>n</em> the <em>numeral set</em> of size <em>n</em>. So, in particular, 2 = {1, 2}, 1 = {1}, and 0 = ∅.</p>
<p>Let <em>A</em> be any set. A function <em>f</em> : <em>n</em> → <em>A</em> can be written as a length <em>n</em> sequence</p>
<p>f=(f(1),f(2),…,f(n)).   (2.5)</p>
<p>We call this the <em>sequence notation</em> for <em>f</em>.</p>
<p><em>Exercise</em> 2.1.2.22.</p>
<p>a. Let <em>A</em> = {<em>a</em>, <em>b</em>, <em>c</em>, <em>d</em>}. If <em>f</em> : 10 → <em>A</em> is given in sequence notation by (<em>a</em>, <em>b</em>, <em>c</em>, <em>c</em>, <em>b</em>, <em>a</em>, <em>d</em>, <em>d</em>, <em>a</em>, <em>b</em>), what is <em>f</em>(4)?</p>
<p>b. Let <em>s</em>: 7 → ℕ be given by <em>s</em>(<em>i</em>) = <em>i</em><sup>2</sup>. Write <em>s</em> in sequence notation.</p>
<p><em>Solution</em> 2.1.2.22.</p>
<p>a. <em>c</em></p>
<p>b. (1, 4, 9, 16, 25, 36, 49)</p>
<p><strong>Definition 2.1.2.23</strong> (Cardinality of finite sets). Let <em>A</em> be a set and <em>n</em> ∈ ℕ a natural number. We say that <em>A has cardinality n</em>, denoted</p>
<p>|A|=n,</p>
<p>if there exists an isomorphism of sets <em>A</em> ≅ <em>n</em>. If there exists some <em>n</em> ∈ ℕ such that <em>A</em> has cardinality <em>n</em>, then we say that <em>A</em> is <em>finite</em>. Otherwise, we say that <em>A</em> is <em>infinite</em> and write |<em>A</em>| ⩾ ∞.</p>
<p><em>Exercise</em> 2.1.2.24.</p>
<p>a. Let <em>A</em> = {5, 6, 7}. What is |<em>A</em>|?</p>
<p>b. What is |{1, 1, 2, 3, 5}|?</p>
<p>c. What is |ℕ|?</p>
<p>d. What is |{<em>n</em> ∈ ℕ | <em>n</em> ⩽ 5}|?</p>
<p>We will see in Corollary <a href="chapter003.html#Cor_3-4-5-6">3.4.5.6</a> that for any <em>m</em>, <em>n</em> ∈ ℕ, there is an isomorphism <em>m</em> ≅ <em>n</em> if and only if <em>m</em> = <em>n</em>. So if we find that <em>A</em> has cardinality <em>m</em> and that <em>A</em> has cardinality <em>n</em>, then <em>m</em> = <em>n</em>.</p>
<p><strong>Proposition 2.1.2.25</strong>. <em>Let A and B be finite sets. If there is an isomorphism of sets f</em> : <em>A</em> → <em>B</em>, <em>then the two sets have the same cardinality</em>, |<em>A</em>| = |<em>B</em>|.</p>
<p><em>Proof</em>. If <em>f</em> : <em>A</em> → <em>B</em> is an isomorphism and <em>B</em> ≅ <em>n</em>, then <em>A</em> ≅ <em>n</em> because the composition of two isomorphisms is an isomorphism.</p>
<h1 id="lev_2-2" class="level1"><a href="toc.html#Rlev_2-2"><strong>2.2   Commutative diagrams</strong></a></h1>
<p>At this point it is difficult to precisely define diagrams or commutative diagrams in general, but we can get a heuristic idea.<sup><a href="chapter002.html#endnote_5">5</a></sup> Consider the following picture:</p>
<p><img src="images/Art_P11.jpg" alt="art" /></p>
<p>We say this is a <em>diagram of sets</em> if each of <em>A</em>, <em>B</em>, <em>C</em> is a set and each of <em>f</em>, <em>g</em>, <em>h</em> is a function. We say this diagram <em>commutes</em> if <em>g</em> ○ <em>f</em> = <em>h</em>. In this case we refer to it as a commutative triangle of sets, or, more generally, as a <em>commutative diagram</em> of sets.</p>
<p><em>Application</em> 2.2.1.1. In its most basic form, the central dogma of molecular biology is that DNA codes for RNA codes for protein. That is, there is a function from DNA triplets to RNA triplets and a function from RNA triplets to amino acids. But sometimes we just want to discuss the translation from DNA to amino acids, and this is the composite of the other two. The following commutative diagram is a picture of this fact</p>
<p><img src="images/Art_P12.jpg" alt="art" /></p>
<p>Consider the following picture:</p>
<p><img src="images/Art_P13.jpg" alt="art" /></p>
<p>We say this is a <em>diagram of sets</em> if each of <em>A</em>, <em>B</em>, <em>C</em>, <em>D</em> is a set and each of <em>f</em>, <em>g</em>, <em>h</em>, <em>i</em> is a function. We say this diagram <em>commutes</em> if <em>g</em> ○ <em>f</em> = <em>i</em> ○ <em>h</em>. In this case we refer to it as a commutative square of sets. More generally, it is a commutative diagram of sets.</p>
<p><em>Application</em> 2.2.1.2. Given a physical system <em>S</em>, there may be two mathematical approaches <em>f</em> : <em>S</em> → <em>A</em> and <em>g</em> : <em>S</em> → <em>B</em> that can be applied to it. Either of those results in a prediction of the same sort, <em>f</em>′ : <em>A</em> → <em>P</em> and <em>g</em>′ : <em>B</em> → <em>P</em>. For example, in mechanics we can use either the Lagrangian approach or the Hamiltonian approach to predict future states. To say that the diagram</p>
<p><img src="images/Art_P14.jpg" alt="art" /></p>
<p>commutes would say that these approaches give the same result.</p>
<p>Note that diagram (<a href="chapter002.html#lev_2-6">2.6</a>) is considered to be the same diagram as each of the following:</p>
<p><img src="images/Art_P15.jpg" alt="art" /></p>
<p>In all these we have <em>h</em> = <em>g</em> ○ <em>f</em>, or in diagrammatic order, <em>h</em> = <em>f</em>; <em>g</em>.</p>
<h1 id="lev_2-3" class="level1"><a href="toc.html#Rlev_2-3"><strong>2.3   Ologs</strong></a></h1>
<p>In this book I ground the mathematical ideas in applications whenever possible. To that end I introduce ologs, which serve as a bridge between mathematics and various conceptual landscapes. The following material is taken from Spivak and Kent [43], an introduction to ologs.</p>
<p><img src="images/Art_P16.jpg" alt="art" /></p>
<h2 id="lev_2-3-1" class="level2"><strong>2.3.1   Types</strong></h2>
<p>A type is an abstract concept, a distinction the author has made. Each type is represented as a box containing a <em>singular indefinite noun phrase</em>. Each of the following four boxes is a type:</p>
<p><img src="images/Art_P16a.jpg" alt="art" /></p>
<p>Each of the four boxes in (<a href="chapter002.html#lev_2-8">2.8</a>) represents a type of thing, a whole class of things, and the label on that box is what one should call <em>each example</em> of that class. Thus ⌜a man⌝ does not represent a single man but the set of men, each example of which is called “a man.” Similarly, the bottom right box represents an abstract type of thing, which probably has more than a million examples, but the label on the box indicates the common name for each such example.</p>
<p>Typographical problems emerge when writing a text box in a line of text, e.g., the text box a man seems out of place, and the more in-line text boxes there are, the worse it gets. To remedy this, I denote types that occur in a line of text with corner symbols; e.g., I write ⌜a man⌝ instead of a man.</p>
<h3 id="lev_2-3-1-1" class="level3"><strong>2.3.1.1   Types with compound structures</strong></h3>
<p>Many types have compound structures, i.e., they are composed of smaller units. Examples include</p>
<p><img src="images/Art_P16b.jpg" alt="art" /></p>
<p>It is good practice to declare the variables in a compound type, as in the last two cases of (<a href="chapter002.html#lev_2-9">2.9</a>). In other words, it is preferable to replace the first box in (<a href="chapter002.html#lev_2-9">2.9</a>) with something like</p>
<p><img src="images/Art_P16c.jpg" alt="art" /></p>
<p>so that the variables (<em>m</em>, <em>w</em>) are clear.</p>
<p><em>Rules of good practice</em> 2.3.1.2. A type is presented as a text box. The text in that box should</p>
<p>  (i) begin with the word <em>a</em> or <em>an</em>;</p>
<p>  (ii) refer to a distinction made and recognizable by the olog’s author;</p>
<p>(iii) refer to a distinction for which instances can be documented;</p>
<p>(iv) be the common name that each instance of that distinction can be called; and</p>
<p> (v) declare all variables in a compound structure.</p>
<p>The first, second, third, and fourth rules ensure that the class of things represented by each box appears to the author to be a well defined set, and that the class is appropriately named. The fifth rule encourages good readability of arrows (see Section <a href="chapter002.html#lev_2-3-2">2.3.2</a>).</p>
<p>I do not always follow the rules of good practice throughout this book. I think of these rules being as followed “in the background,” but I have nicknamed various boxes. So ⌜Steve⌝ may stand as a nickname for ⌜a thing classified as Steve⌝ and ⌜arginine⌝ as a nickname for ⌜a molecule of arginine⌝. However, one should always be able to rename each type according to the rules of good practice.</p>
<h2 id="lev_2-3-2" class="level2"><strong>2.3.2   Aspects</strong></h2>
<p>An aspect of a thing <em>x</em> is a way of viewing it, a particular way in which <em>x</em> can be regarded or measured. For example, a woman can be regarded as a person; hence “being a person” is an aspect of a woman. A molecule has a molecular mass (say in daltons), so “having a molecular mass” is an aspect of a molecule. In other words, when it comes to ologs, the word <em>aspect</em> simply means function. The domain <em>A</em> of the function <em>f</em> : <em>A</em> → <em>B</em> is the thing we are measuring, and the codomain is the set of possible answers or results of the measurement.</p>
<p><img src="images/Art_P16d.jpg" alt="art" /></p>
<p><img src="images/Art_P16e.jpg" alt="art" /></p>
<p>So for the arrow in (<a href="chapter002.html#lev_2-10">2.10</a>), the domain is the set of women (a set with perhaps 3 billion elements); the codomain is the set of persons (a set with perhaps 6 billion elements). We can imagine drawing an arrow from each dot in the “woman” set to a unique dot in the “person” set, just as in <a href="chapter002.html#Fig_2-2">Figure 2.2</a>. No woman points to two different people nor to zero people—each woman is exactly one person—so the rules for a function are satisfied. Let us now concentrate briefly on the arrow in (<a href="chapter002.html#lev_2-11">2.11</a>). The domain is the set of molecules, the codomain is the set ℝ<sub>&gt;0</sub> of positive real numbers. We can imagine drawing an arrow from each dot in the “molecule” set to a single dot in the “positive real number” set. No molecule points to two different masses, nor can a molecule have no mass: each molecule has exactly one mass. Note, however, that two different molecules can point to the same mass.</p>
<h3 id="lev_2-3-2-1" class="level3"><strong>2.3.2.1   Invalid aspects</strong></h3>
<p>To be valid an aspect must be a functional relationship. Arrows may on their face appear to be aspects, but on closer inspection they are not functional (and hence not valid as aspects).</p>
<p>Consider the following two arrows:</p>
<p><img src="images/Art_P16f.jpg" alt="art" /></p>
<p><img src="images/Art_P16g.jpg" alt="art" /></p>
<p>A person may have no children or may have more than one child, so the first arrow is invalid: it is not a function. Similarly, if one drew an arrow from each mechanical pencil to each piece of lead it uses, one would not have a function.</p>
<p><em>Warning</em> 2.3.2.2. The author of an olog has a worldview, some fragment of which is captured in the olog. When person A examines the olog of person B, person A may or may not agree with it. For example, person B may have the following olog</p>
<p><img src="images/Art_P17.jpg" alt="art" /></p>
<p>which associates to each marriage a man and a woman. Person A may take the position that some marriages involve two men or two women and thus see B’s olog as wrong. Such disputes are not “problems” with either A’s olog or B’s olog; they are discrepancies between worldviews. Hence, a reader R may see an olog in this book and notice a discrepancy between R’s worldview and my own, but this is not a problem with the olog. Rules are enforced to ensure that an olog is structurally sound, not to ensure that it “correctly reflects reality,” since worldviews can differ.</p>
<p>Consider the aspect ⌜an object⌝→has⌜a weight⌝. At some point in history, this would have been considered a valid function. Now we know that the same object would have a different weight on the moon than it has on earth. Thus, as worldviews change, we often need to add more information to an olog. Even the validity of ⌜an object on earth⌝→has⌜a weight⌝ is questionable, e.g., if I am considered to be the same object on earth before and after I eat Thanksgiving dinner. However, to build a model we need to choose a level of granularity and try to stay within it, or the whole model would evaporate into the nothingness of truth. Any level of granularity is called <em>a stereotype</em>; e.g., we stereotype objects on earth by saying they each have a weight. A stereotype is a lie, more politely a conceptual simplification, that is convenient for the way we want to do business.</p>
<p><em>Remark</em> 2.3.2.3. In keeping with Warning <a href="chapter002.html#War_2-3-2-2">2.3.2.2</a>, the arrows in (<a href="chapter002.html#lev_2-12">2.12*</a>) and (<a href="chapter002.html#lev_2-13">2.13*</a>) may not be wrong but simply reflect that the author has an idiosyncratic worldview or vocabulary. Maybe the author believes that every mechanical pencil uses exactly one piece of lead. If this is so, then ⌜a mechanical pencil⌝→uses⌜a piece of lead⌝ is indeed a valid aspect. Similarly, suppose the author meant to say that each person <em>was once</em> a child, or that a person has an inner child. Since every person has one and only one inner child (according to the author), the map ⌜a person⌝→has as inner child⌜a child⌝ is a valid aspect. We cannot fault the olog for its author’s view, but note that we have changed the name of the label to make the intention more explicit.</p>
<h3 id="lev_2-3-2-4" class="level3"><strong>2.3.2.4   Reading aspects and paths as English phrases</strong></h3>
<p>Each arrow (aspect) X→fY can be read by first reading the label on its source box <em>X</em>, then the label on the arrow <em>f</em>, and finally the label on its target box <em>Y</em>. For example, the arrow</p>
<p><img src="images/Art_P17a.jpg" alt="art" /></p>
<p>is read “a book has as first author a person.”</p>
<p><em>Remark</em> 2.3.2.5. Note that the map in (<a href="chapter002.html#lev_2-14">2.14</a>) is a valid aspect, but a similarly benign-looking map ⌜a book⌝→has as author⌜a person⌝ would not be valid, because it is not functional. When creating an olog, one must be vigilant about this type of mistake because it is easy to miss, and it can corrupt the olog.</p>
<p>Sometimes the label on an arrow can be shortened or dropped altogether if it is obvious from context (see Section <a href="chapter002.html#lev_2-3-3">2.3.3</a>). Here is a common example from the way I write ologs.</p>
<p><img src="images/Art_P18.jpg" alt="art" /></p>
<p>Neither arrow is readable by the preceding protocol (e.g., “a pair (<em>x</em>, <em>y</em>), where <em>x</em> and <em>y</em> are integers <em>x</em> an integer” is not an English sentence), and yet it is clear what each map means. For example, given (8, 11) in <em>A</em>, arrow <em>x</em> would yield 8 and arrow <em>y</em> would yield 11. The label <em>x</em> can be thought of as a nickname for the full name “yields as the value of <em>x</em>,” and similarly for <em>y</em>. I do not generally use the full name, so as not to clutter the olog.</p>
<p>One can also read paths through an olog by inserting the word <em>which</em> (or <em>who</em>) after each intermediate box. For example, olog (<a href="chapter002.html#lev_2-16">2.16</a>) has two paths of length 3 (counting arrows in a chain):</p>
<p><img src="images/Art_P19.jpg" alt="art" /></p>
<p>The top path is read “a child is a person, who has as parents a pair (<em>w</em>, <em>m</em>), where <em>w</em> is a woman and <em>m</em> is a man, which yields, as the value of <em>w</em>, a woman.” The reader should read and understand the content of the bottom path, which associates to every child a year.</p>
<h3 id="lev_2-3-2-6" class="level3"><strong>2.3.2.6   Converting nonfunctional relationships to aspects</strong></h3>
<p>There are many relationships that are not functional, and these cannot be considered aspects. Often the word <em>has</em> indicates a relationship—sometimes it is functional, as in ⌜a person⌝→has⌜a stomach⌝, and sometimes it is not, as in ⌜a father⌝→has⌜a child⌝. Clearly, a father may have more than one child. This one is easily fixed by realizing that the arrow should go the other way: there is a function ⌜a child⌝→has⌜a father⌝.</p>
<p>What about ⌜a person⌝→owns⌜a car⌝. Again, a person may own no cars or more than one car, but this time a car can be owned by more than one person too. A quick fix would be to replace it by ⌜a person⌝→owns⌜a set of cars⌝. This is okay, but the relationship between ⌜a car⌝ and ⌜a set of cars⌝ then becomes an issue to deal with later. There is another way to indicate such nonfunctional relationships. In this case it would look like this:</p>
<p><img src="images/Art_P20.jpg" alt="art" /></p>
<p>This setup will ensure that everything is properly organized. In general, relationships can involve more than two types, and in olog form looks like this:</p>
<p><img src="images/Art_P21.jpg" alt="art" /></p>
<p>For example,</p>
<p><img src="images/Art_P22.jpg" alt="art" /></p>
<p><em>Exercise</em> 2.3.2.7.</p>
<p>On page 25, the arrow in (<a href="chapter002.html#lev_2-12">2.12*</a>) was indicated as an invalid aspect:</p>
<p><img src="images/Art_P22a.jpg" alt="art" /></p>
<p>Create a valid olog that captures the parent-child relationship; your olog should still have boxes ⌜a person⌝ and ⌜a child⌝ but may have an additional box.</p>
<p><em>Rules of good practice</em> 2.3.2.8. An aspect is presented as a labeled arrow pointing from a source box to a target box. The arrow label text should</p>
<p>   (i) begin with a verb;</p>
<p>  (ii) yield an English sentence, when the source box text followed by the arrow text followed by the target box text is read;</p>
<p> (iii) refer to a functional relationship: each instance of the source type should give rise to a specific instance of the target type;</p>
<p>(iv) constitute a useful description of that functional relationship.</p>
<h2 id="lev_2-3-3" class="level2"><strong>2.3.3   Facts</strong></h2>
<p>In this section I discuss facts, by which I mean path equivalences in an olog. It is the notion of path equivalences that makes category theory so powerful.</p>
<p>A <em>path</em> in an olog is a head-to-tail sequence of arrows. That is, any path starts at some box <em>B</em><sub>0</sub>, then follows an arrow emanating from <em>B</em><sub>0</sub> (moving in the appropriate direction), at which point it lands at another box <em>B</em><sub>1</sub>, then follows any arrow emanating from <em>B</em><sub>1</sub>, and so on, eventually landing at a box <em>B<sub>n</sub></em> and stopping there. The number of arrows is the <em>length</em> of the path. So a path of length 1 is just an arrow, and a path of length 0 is just a box. We call <em>B</em><sub>0</sub> the <em>source</em> and <em>B<sub>n</sub></em> the <em>target</em> of the path.</p>
<p>Given an olog, its author may want to declare that two paths are equivalent. For example, consider the two paths from <em>A</em> to <em>C</em> in the olog</p>
<p><img src="images/Art_P23.jpg" alt="art" /></p>
<p>We know as English speakers that a woman parent is called a mother, so these two paths <em>A</em> → <em>C</em> should be equivalent. A mathematical way to say this is that the triangle in olog (<a href="chapter002.html#lev_2-17">2.17</a>) <em>commutes</em>. That is, path equivalences are simply commutative diagrams, as in Section <a href="chapter002.html#lev_2-2">2.2</a>. In the preceding example we concisely say “a woman parent is equivalent to a mother.” We declare this by defining the diagonal map in (<a href="chapter002.html#lev_2-17">2.17</a>) to be <em>the composition</em> of the horizontal map and the vertical map.</p>
<p>I generally prefer to indicate a commutative diagram by drawing a check mark, ✓, in the region bounded by the two paths, as in olog (<a href="chapter002.html#lev_2-17">2.17</a>). Sometimes, however, one cannot do this unambiguously on the two-dimensional page. In such a case I indicate the commutative diagram (fact) by writing an equation. For example, to say that the diagram</p>
<p><img src="images/Art_P24.jpg" alt="art" /></p>
<p>commutes, we could either draw a check mark inside the square or write the equation</p>
<p>A[f,g]≃A[h,i]</p>
<p>above it.<sup><a href="chapter002.html#endnote_6">6</a></sup> Either way, it means that starting from <em>A</em>, “doing <em>f</em>, then <em>g</em>” is equivalent to “doing <em>h</em>, then <em>i</em>.”</p>
<p>Here is another example:</p>
<p><img src="images/Art_P25.jpg" alt="art" /></p>
<p>Note how this diagram gives us the established terminology for the various ways in which DNA, RNA, and protein are related in this context.</p>
<p><em>Exercise</em> 2.3.3.1.</p>
<p>Create an olog for human nuclear biological families that includes the concepts of person, man, woman, parent, father, mother, and child. Make sure to label all the arrows and that each arrow indicates a valid aspect in the sense of Section <a href="chapter002.html#lev_2-3-2-1">2.3.2.1</a>. Indicate with check marks (✓) the diagrams that are intended to commute. If the 2-dimensionality of the page prevents a check mark from being unambiguous, indicate the intended commutativity with an equation.</p>
<p><em>Solution</em> 2.3.3.1.</p>
<p><img src="images/Art_P26.jpg" alt="art" /></p>
<p>Note that neither of the two triangles from child to person commute. To say that they did commute would be to say that “a child and its mother are the same person” and that “a child and its father are the same person.”</p>
<p><em>Example</em> 2.3.3.2 (Noncommuting diagram). In my conception of the world, the following diagram does not commute:</p>
<p><img src="images/Art_P27.jpg" alt="art" /></p>
<p>The noncommutativity of diagram (<a href="chapter002.html#lev_2-18">2.18</a>) does not imply that no person lives in the same city as his or her father. Rather it implies that it is not the case that <em>every</em> person lives in the same city as his or her father.</p>
<p><em>Exercise</em> 2.3.3.3.</p>
<p>Create an olog about a scientific subject, preferably one you think about often. The olog should have at least five boxes, five arrows, and one commutative diagram.</p>
<h3 id="lev_2-3-3-4" class="level3"><strong>2.3.3.4   A formula for writing facts as English</strong></h3>
<p>Every fact consists of two paths, say, <em>P</em> and <em>Q</em>, that are to be declared equivalent. The paths <em>P</em> and <em>Q</em> will necessarily have the same source, say, <em>s</em>, and target, say, <em>t</em>, but their lengths may be different, say, <em>m</em> and <em>n</em> respectively.<sup><a href="chapter002.html#endnote_7">7</a></sup> We draw these paths as</p>
<p>P:•a0=s→f1•a1→f2•a2→f3⋯→fm−1•am−1→fm•am=tQ:•b0=s→g1•b1→g2•b2→g3⋯→gn−1•bn−1→gn•bn=t               (2.19)</p>
<p>Every part <em>ℓ</em> of an olog (i.e., every box and every arrow) has an associated English phrase, which we write as 〈〈<em>ℓ</em>〉〉. Using a dummy variable <em>x</em>, we can convert a fact into English too. The following general formula may be a bit difficult to understand (see Example <a href="chapter002.html#Exa_2-3-3-5">2.3.3.5</a>). The fact <em>P</em> ≃ <em>Q</em> from (<a href="chapter002.html#lev_2-19">2.19</a>) can be Englished as follows:</p>
<p>Given x, 〈〈s〉〉 consider the following.We know that x is 〈〈s〉〉,which 〈〈f1〉〉〈〈a1〉〉, which 〈〈f2〉〉〈〈a2〉〉, which … 〈〈fm−1〉〉〈〈am−1〉〉, which 〈〈fm〉〉〈〈t〉〉,that we call P(x).We also know that x is 〈〈s〉〉,which 〈〈g1〉〉〈〈b1〉〉, which 〈〈g2〉〉〈〈b2〉〉, which … 〈〈gn−1〉〉〈〈bn−1〉〉, which 〈〈gn〉〉〈〈t〉〉,that we call Q(x).Fact: Whenever x is 〈〈s〉〉, we will have P(x)=Q(x).    (2.20)</p>
<p><em>Example</em> 2.3.3.5. Consider the olog</p>
<p><img src="images/Art_P28.jpg" alt="art" /></p>
<p>To put the fact that diagram (<a href="chapter002.html#lev_2-21">2.21</a>) commutes into English, we first English the two paths: <em>F</em> = “a person has an address which is in a city” and <em>G</em> = “a person lives in a city.” The source of both is <em>s</em> = “a person” and the target of both is <em>t</em> = “a city.” Write:</p>
<p>Given <em>x</em>, a person, consider the following.</p>
<p>We know that <em>x</em> is a person,</p>
<p>who has an address, which is in a city,</p>
<p>that we call <em>P</em>(<em>x</em>).</p>
<p>We also know that <em>x</em> is a person,</p>
<p>who lives in a city</p>
<p>that we call <em>Q</em>(<em>x</em>).</p>
<p>Fact: Whenever <em>x</em> is a person, we will have <em>P</em>(<em>x</em>) = <em>Q</em>(<em>x</em>).</p>
<p>More concisely, one reads olog <a href="chapter002.html#lev_2-21">2.21</a> as</p>
<p>A person <em>x</em> has an address, which is in a city, and this is the city <em>x</em> lives in.</p>
<p><em>Exercise</em> 2.3.3.6.</p>
<p>This olog was taken from Spivak [38].</p>
<p><img src="images/Art_P29.jpg" alt="art" /></p>
<p>It says that a landline phone is physically located in the region to which its phone number is assigned. Translate this fact into English using the formula from (<a href="chapter002.html#lev_2-20">2.20</a>).</p>
<p><em>Exercise</em> 2.3.3.7.</p>
<p>In olog (<a href="chapter002.html#lev_2-22">2.22</a>), suppose that the box ⌜an operational landline phone⌝ is replaced with the box ⌜an operational cell phone⌝. Would the diagram still commute?</p>
<h3 id="lev_2-3-3-8" class="level3"><strong>2.3.3.8   Images</strong></h3>
<p>This section discusses a specific kind of fact, generated by any aspect. Recall that every function has an image (<a href="chapter002.html#lev_2-3">2.3</a>), meaning the subset of elements in the codomain that are “hit” by the function. For example, the function <em>f</em> : ℤ → ℤ given by <em>f</em>(<em>x</em>) = 2 * <em>x</em>: ℤ → ℤ has as image the set of all even numbers.</p>
<p>Similarly, the set of mothers arises as the image of the “has as mother” function:</p>
<p><img src="images/Art_P30.jpg" alt="art" /></p>
<p><em>Exercise</em> 2.3.3.9.</p>
<p>For each of the following types, write a function for which it is the image, or write “not clearly useful as an image type.”</p>
<p>a. ⌜a book⌝</p>
<p>b. ⌜a material that has been fabricated by a working process of type <em>T</em> ⌝</p>
<p>c. ⌜a bicycle owner⌝</p>
<p>d. ⌜a child⌝</p>
<p>e. ⌜a used book⌝</p>
<p>f. ⌜a primary residence⌝</p>
<p>__________________</p>
<p><a href="chapter002.html#endnote_ref_1"><sup>1</sup></a>Note that the symbol <em>x</em>′, read “x-prime,” has nothing to do with calculus or derivatives. It is simply notation used to name a symbol that is somehow like <em>x</em>. This suggestion of kinship between <em>x</em> and <em>x</em>′ is meant only as an aid for human cognition, not as part of the mathematics.</p>
<p><a href="chapter002.html#endnote_ref_2"><sup>2</sup></a>This kind of arrow, ↦, is read “maps to.” A function <em>f</em> : <em>X</em> → <em>Y</em> means a rule for assigning to each element <em>x</em> ∈ <em>X</em> an element <em>f</em>(<em>x</em>) ∈ <em>Y</em>. We say that “<em>x</em> maps to <em>f</em>(<em>x</em>)” and write <em>x</em> ↦<em>f</em>(<em>x</em>).</p>
<p><a href="chapter002.html#endnote_ref_3"><sup>3</sup></a>The notation Hom<strong><sub>Set</sub></strong>(−, −) will make more sense later, when it is seen in a larger context. See especially Section <a href="chapter005.html#lev_5-1">5.1</a>.</p>
<p><a href="chapter002.html#endnote_ref_4"><sup>4</sup></a>Canonical, as used here, means something like “best choice,” a choice that stands out as the only reasonable one.</p>
<p><a href="chapter002.html#endnote_ref_5"><sup>5</sup></a>Commutative diagrams are precisely defined in <a href="chapter006.html#lev_6-1-2">Section 6.1.2</a>.</p>
<p><a href="chapter002.html#endnote_ref_6"><sup>6</sup></a>We defined function composition in Section <a href="chapter002.html#lev_2-1-2">2.1.2</a>, but here we are using a different notation. There we used <em>classical order</em>, and our path equivalence would be written <em>g</em> ○ <em>f</em> = <em>i</em> ○ <em>h</em>. As discussed in Remark <a href="chapter002.html#Rem_2-1-2-11">2.1.2.11</a>, category theorists and others often prefer the <em>diagrammatic order</em> for writing compositions, which is <em>f</em>; <em>g</em> = <em>h</em>; <em>i</em>. For ologs, we roughly follow the latter because it makes for better English sentences, and for the same reason, we add the source object to the equation, writing <sub><em>A</em></sub>[<em>f</em>, <em>g</em>] ≃ <sub><em>A</em></sub>[<em>h</em>, <em>i</em>].</p>
<p><a href="chapter002.html#endnote_ref_7"><sup>7</sup></a>If the source equals the target, <em>s</em> = <em>t</em>, then it is possible to have <em>m</em> = 0 or <em>n</em> = 0, and the ideas that follow still make sense.</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter001.html">previous</a>, <a href="chapter003.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter002.html">previous</a>, <a href="chapter004.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<h1 class="chapter-number"><a href="toc.html#chap-3"><strong>Chapter 3</strong></a></h1>
<h1 class="chapter-title"><a href="toc.html#chap-3"><strong>Fundamental Considerations in Set</strong></a></h1>
<p>In this chapter we continue to pursue an understanding of sets. We begin by examining how to combine sets in various ways to get new sets. To that end, products and coproducts are introduced, and then more complex limits and colimits, with the aim of conveying a sense of their <em>universal properties</em>. The chapter ends with some additional interesting constructions in <strong>Set</strong>.</p>
<h1 id="lev_3-1" class="level1"><a href="toc.html#Rlev_3-1"><strong>3.1   Products and coproducts</strong></a></h1>
<p>This section introduces two concepts that are likely to be familiar, although perhaps not by their category-theoretic names: product and coproduct. Each is an example of a large class of ideas that exist far beyond the realm of sets (see Section <a href="chapter006.html#lev_6-1-1">6.1.1</a>).</p>
<h2 id="lev_3-1-1" class="level2"><strong>3.1.1   Products</strong></h2>
<p><strong>Definition 3.1.1.1</strong>. Let <em>X</em> and <em>Y</em> be sets. The <em>product of X and Y</em>, denoted <em>X</em> × <em>Y</em>, is defined as the set of ordered pairs (<em>x</em>, <em>y</em>), where <em>x</em> ∈ <em>X</em> and <em>y</em> ∈ <em>Y</em>. Symbolically,</p>
<p>X×Y={ (x,y)|x∈X, y∈Y }.</p>
<p>There are two natural <em>projection functions</em>, <em>π</em><sub>1</sub> : <em>X</em> × <em>Y</em> → <em>X</em> and <em>π</em><sub>2</sub>: <em>X</em> × <em>Y</em> → <em>Y</em>.</p>
<p><img src="images/Art_P31.jpg" alt="art" /></p>
<p><em>Example</em> 3.1.1.2 (Grid of dots). Let <em>X</em> = {1, 2, 3, 4, 5, 6} and <em>Y</em> = {♣, ♢, ♡, ♠}. Then we can draw <em>X</em> × <em>Y</em> as a 6 by 4 grid of dots, and the projections as projections</p>
<p><img src="images/Art_P32.jpg" alt="art" /></p>
<p><em>Application</em> 3.1.1.3. A traditional (Mendelian) way to predict the genotype of offspring based on the genotype of its parents is by the use of Punnett squares. If <em>F</em> is the set of possible genotypes for the female parent, and <em>M</em> is the set of possible genotypes of the male parent, then <em>F</em> × <em>M</em> is drawn as a square, called a Punnett square, in which every combination is drawn.</p>
<p><em>Exercise</em> 3.1.1.4.</p>
<p>How many elements does the set {<em>a</em>, <em>b</em>, <em>c</em>, <em>d</em>} × {1, 2, 3} have?</p>
<p><em>Application</em> 3.1.1.5. Suppose we are conducting experiments about the mechanical properties of materials, as in Application <a href="chapter002.html#App_2-1-2-2">2.1.2.2</a>. For each material sample we will produce multiple data points in the set ⌜extension⌝ × ⌜force⌝ ≅ ℝ × ℝ.</p>
<p><em>Remark</em> 3.1.1.6. It is possible to take the product of more than two sets as well. For example, if <em>A</em>, <em>B</em>, and <em>C</em> are sets, then <em>A</em> × <em>B</em> × <em>C</em> is the set of triples</p>
<p>A×B×C≔{ (a,b,c)|a∈A,b∈B,c∈C }.</p>
<p>This kind of generality is useful in understanding multiple dimensions, e.g., what physicists mean by ten-dimensional space. It comes under the heading of <em>limits</em> (see Section <a href="chapter006.html#lev_6-1-3">6.1.3</a>).</p>
<p><em>Example</em> 3.1.1.7. Let ℝ be the set of real numbers. By ℝ<sup>2</sup> we mean ℝ × ℝ. Similarly, for any <em>n</em> ∈ ℕ, we define ℝ<sup><em>n</em></sup> to be the product of <em>n</em> copies of ℝ.</p>
<p>According to Penrose [35], Aristotle seems to have conceived of space as something like <em>S</em> ≔ ℝ<sup>3</sup> and of time as something like <em>T</em> ≔ ℝ. Space-time, had he conceived of it, would probably have been <em>S</em> × <em>T</em> ≅ ℝ<sup>4</sup>. He, of course, did not have access to this kind of abstraction, which was probably due to Descartes. (The product <em>X</em> × <em>Y</em> is often called <em>Cartesian product</em>, in his honor.)</p>
<p><em>Exercise</em> 3.1.1.8.</p>
<p>Let ℤ denote the set of integers, and let +: ℤ × ℤ → ℤ denote the addition function and ·: ℤ × ℤ → ℤ denote the multiplication function. Which of the following diagrams commute?</p>
<p>a. <img src="images/Art_P33.jpg" alt="art" /></p>
<p>b. <img src="images/Art_P34.jpg" alt="art" /></p>
<p>c. <img src="images/Art_P35.jpg" alt="art" /></p>
<h3 id="lev_3-1-1-9" class="level3"><strong>3.1.1.9   Universal property for products</strong></h3>
<p>A universal property is an abstract quality that characterizes a given construction. For example, the following proposition says that the product construction is characterized as possessing a certain quality.</p>
<p><strong>Proposition 3.1.1.10</strong> (Universal property for product). <em>Let X and Y be sets. For any set A and functions f</em> : <em>A</em> → <em>X and g</em> : <em>A</em> → <em>Y</em>, <em>there exists a unique function A</em> → <em>X</em> × <em>Y such that the following diagram commutes:</em></p>
<p><img src="images/Art_P36.jpg" alt="art" /></p>
<p><em>We say this function is</em> induced by <em>f and g, and we denote it</em></p>
<p>〈f,g〉:A→X×Y,   where   〈f,g〉(a)=(f(a),g(a)).</p>
<p><em>That is, we have π</em><sub>1</sub> ○ 〈<em>f</em>, <em>g</em>〉 = <em>f and π</em><sub>2</sub> ○ 〈<em>f</em>, <em>g</em>〉 = <em>g</em>, <em>and</em> 〈<em>f</em>, <em>g</em>〉 <em>is the only function for which that is so.</em></p>
<p><em>Proof</em>. Suppose given <em>f</em>, <em>g</em> as in the proposition statement. To provide a function <em>ℓ</em>: <em>A</em> → <em>X</em> × <em>Y</em> is equivalent to providing an element <em>ℓ</em>(<em>a</em>) ∈ <em>X</em> × <em>Y</em> for each <em>a</em> ∈ <em>A</em>. We need such a function <em>ℓ</em> = 〈<em>f</em>, <em>g</em>〉, for which <em>π</em><sub>1</sub> ○ 〈<em>f</em>, <em>g</em>〉 = <em>f</em> and <em>π</em><sub>2</sub> ○ 〈<em>f</em>, <em>g</em>〉 = <em>g</em>. An element of <em>X</em> × <em>Y</em> is an ordered pair (<em>x</em>, <em>y</em>), and we can use 〈<em>f</em>, <em>g</em>〉(<em>a</em>) = (<em>x</em>, <em>y</em>) if and only if <em>x</em> = <em>π</em><sub>1</sub>(<em>x</em>, <em>y</em>) = <em>f</em>(<em>a</em>) and <em>y</em> = <em>π</em><sub>2</sub>(<em>x</em>, <em>y</em>) = <em>g</em>(<em>a</em>). So it is necessary and sufficient to define</p>
<p>〈f,g〉(a)≔(f(a),g(a))</p>
<p>for all <em>a</em> ∈ <em>A</em>.</p>
<p><em>Example</em> 3.1.1.11 (Grid of dots, continued). It is important that the reader sees the universal property for products as completely intuitive.</p>
<p>Recall that if <em>X</em> and <em>Y</em> are sets, say, of cardinalities |<em>X</em>| = <em>m</em> and |<em>Y</em> | = <em>n</em> respectively, then <em>X</em> × <em>Y</em> is an <em>m</em> × <em>n</em> grid of dots, and it comes with two canonical projections X←π1X×Y→π2Y. These allow us to extract from every grid element <em>z</em> ∈ <em>X</em> × <em>Y</em> its column <em>π</em><sub>1</sub>(<em>z</em>) ∈ <em>X</em> and its row <em>π</em><sub>2</sub>(<em>z</em>) ∈ <em>Y</em>.</p>
<p>Suppose that each person in a classroom picks an element of <em>X</em> and an element of <em>Y</em>. Thus we have functions <em>f</em> : <em>C</em> → <em>X</em> and <em>g</em> : <em>C</em> → <em>Y</em>. But is not picking a column and a row the same thing as picking an element in the grid? The two functions <em>f</em> and <em>g</em> induce a unique function <em>C</em> → <em>X</em> × <em>Y</em>. How does this function <em>C</em> → <em>X</em> × <em>Y</em> compare with the original functions <em>f</em> and <em>g</em>? The commutative diagram (<a href="chapter003.html#lev_3-2">3.2</a>) sums up the connection.</p>
<p><em>Example</em> 3.1.1.12. Let ℝ be the set of real numbers, and let 0 ∈ ℝ be the origin. As in Notation <a href="chapter002.html#Not_2-1-2-9">2.1.2.9</a>, it is represented by a function <em>z</em>: {☺} → ℝ, with <em>z</em>(☺) = 0. Thus we can draw functions</p>
<p><img src="images/Art_P37.jpg" alt="art" /></p>
<p>The universal property for products guarantees a function 〈<em>z</em>, <em>z</em>〉: {☺} → ℝ × ℝ, which represents the origin in (0, 0) ∈ ℝ<sup>2</sup>.</p>
<p><em>Exercise</em> 3.1.1.13.</p>
<p>For every set <em>A</em> there is some relationship between the following three sets:</p>
<p>HomSet(A,X),   HomSet(A,Y),   and   HomSet(A,X×Y).</p>
<p>What is it?</p>
<p>Hint: This problem is somewhat recursive in that you will use products in your formula.</p>
<p><em>Exercise</em> 3.1.1.14.</p>
<p>a. Let <em>X</em> and <em>Y</em> be sets. Construct the swap map <em>s</em>: <em>X</em> × <em>Y</em> → <em>Y</em> × <em>X</em> using only the universal property for products. If <em>π</em><sub>1</sub>: <em>X</em> × <em>Y</em> → <em>X</em>, <em>π</em><sub>2</sub>: <em>X</em> × <em>Y</em> → <em>Y</em>, <em>p</em><sub>1</sub>: <em>Y</em> × <em>X</em> → <em>Y</em>, and <em>p</em><sub>2</sub>: <em>Y</em> × <em>X</em> → <em>X</em> are the projection functions, write <em>s</em> in terms of the symbols <em>π</em><sub>1</sub>, <em>π</em><sub>2</sub>, <em>p</em><sub>1</sub>, <em>p</em><sub>2</sub>, ○, and 〈 , 〉.</p>
<p>b. Can you prove that <em>s</em> is an isomorphism using only the universal property for products?</p>
<p><em>Example</em> 3.1.1.15. Suppose given sets <em>X</em>, <em>X</em>′, <em>Y</em>, <em>Y</em>′ and functions <em>m</em>: <em>X</em> → <em>X</em>′ and <em>n</em>: <em>Y</em> → <em>Y</em>′. We can use the universal property for products to construct a function <em>s</em>: <em>X</em> × <em>Y</em> → <em>X</em>′ × <em>Y</em>′.</p>
<p>The universal property (Proposition <a href="chapter003.html#Pro_3-1-1-10">3.1.1.10</a>) says that to get a function from any set <em>A</em> to <em>X</em>′ × <em>Y</em>′, we need two functions, namely, some <em>f</em> : <em>A</em> → <em>X</em>′ and some <em>g</em> : <em>A</em> → <em>Y</em>′. Here we want to use <em>A</em> ≔ <em>X</em> × <em>Y</em>.</p>
<p>What we have readily available are the two projections <em>π</em><sub>1</sub>: <em>X</em> × <em>Y</em> → <em>X</em> and <em>π</em><sub>2</sub>: <em>X</em> × <em>Y</em> → <em>Y</em>. But we also have <em>m</em>: <em>X</em> → <em>X</em>′ and <em>n</em>: <em>Y</em> → <em>Y</em>′. Composing, we set <em>f</em> ≔ <em>m</em> ○ <em>π</em><sub>1</sub> and <em>g</em> ≔ <em>n</em> ○ <em>π</em><sub>2</sub>.</p>
<p><img src="images/Art_P38.jpg" alt="art" /></p>
<p>The dotted arrow is often called the <em>product</em> of <em>m</em>: <em>X</em> → <em>X</em>′ and <em>n</em>: <em>Y</em> → <em>Y</em>′. Here it is denoted 〈<em>f</em>, <em>g</em>〉, but <em>f</em> and <em>g</em> were not given variables. Since writing 〈<em>m</em> ○ <em>π</em><sub>1</sub>, <em>n</em> ○ <em>π</em><sub>2</sub>〉 is clunky notation, we instead denote this function</p>
<p>m×n: X×Y→X′×Y′.</p>
<h3 id="lev_3-1-1-16" class="level3"><strong>3.1.1.16   Ologging products</strong></h3>
<p>Given two objects <em>c</em>, <em>d</em> in an olog, there is a canonical label 〈〈<em>c</em> × <em>d</em>〉〉 for their product <em>c</em> × <em>d</em>, written in terms of the labels 〈〈<em>c</em>〉〉 and 〈〈<em>d</em>〉〉. Namely,</p>
<p>〈〈c×d〉〉≔“a pair (x,y), where x is 〈〈c〉〉 and y is 〈〈d〉〉.”</p>
<p>The projections <em>c</em> ← <em>c</em> × <em>d</em> → <em>d</em> can be labeled “yields, as <em>x</em>,” and “yields, as <em>y</em>,” respectively.</p>
<p>Suppose that <em>e</em> is another object, and <em>p</em>: <em>e</em> → <em>c</em> and <em>q</em>: <em>e</em> → <em>d</em> are two arrows. By the universal property for products (Proposition <a href="chapter003.html#Pro_3-1-1-10">3.1.1.10</a>), <em>p</em> and <em>q</em> induce a unique arrow <em>e</em> → <em>c</em> × <em>d</em>, making the evident diagrams commute. This arrow can be labeled</p>
<p>“yields, insofar as it 〈〈p〉〉〈〈c〉〉 and 〈〈q〉〉〈〈d〉〉,”.</p>
<p><em>Example</em> 3.1.1.17. Every car owner owns at least one car, but there is no obvious function ⌜a car owner⌝ → ⌜a car⌝ because he or she may own more than one. One good choice would be the car that the person drives most often, which can be called his or her primary car. Also, given a person and a car, an economist could ask how much utility the person would get out of the car. From all this we can put together the following olog involving products:</p>
<p><img src="images/Art_P39.jpg" alt="art" /></p>
<p>The composite map <em>O</em> → <em>V</em> tells us the utility a car owner gets out of their primary car.</p>
<h2 id="lev_3-1-2" class="level2"><strong>3.1.2   Coproducts</strong></h2>
<p>We can characterize the coproduct of two sets with its own universal property.</p>
<p><strong>Definition 3.1.2.1</strong>. Let <em>X</em> and <em>Y</em> be sets. The <em>coproduct of X and Y</em>, denoted <em>X</em> ⊔ <em>Y</em>, is defined as the disjoint union of <em>X</em> and <em>Y</em>, i.e., the set for which an element is either an element of <em>X</em> or an element of <em>Y</em>. If something is an element of both <em>X</em> and <em>Y</em>, then we include both copies, and distinguish between them, in <em>X</em> ⊔ <em>Y</em>. See Example <a href="chapter003.html#Exa_3-1-2-2">3.1.2.2</a>.</p>
<p>There are two natural inclusion functions, <em>i</em><sub>1</sub>: <em>X</em> → <em>X</em> ⊔ <em>Y</em> and <em>i</em><sub>2</sub>: <em>Y</em> → <em>X</em> ⊔ <em>Y</em>.</p>
<p><img src="images/Art_P40.jpg" alt="art" /></p>
<p><em>Example</em> 3.1.2.2. The coproduct of <em>X</em> ≔ {<em>a</em>, <em>b</em>, <em>c</em>, <em>d</em>} and <em>Y</em> ≔ {1, 2, 3} is</p>
<p>X⊔Y≅{ a,b,c,d,1,2,3 }.</p>
<p>The coproduct of <em>X</em> and itself is</p>
<p>X⊔X≅{ a1,b1,c1,d1,a2,b2,c2,d2 }.</p>
<p>The names of the elements in <em>X</em> ⊔ <em>Y</em> are not so important. What is important are the inclusion maps <em>i</em><sub>1</sub>, <em>i</em><sub>2</sub> from (<a href="chapter003.html#lev_3-3">3.3</a>), which ensure that we know where each element of <em>X</em> ⊔ <em>Y</em> came from.</p>
<p><em>Example</em> 3.1.2.3 (Airplane seats).</p>
<p><img src="images/Art_P41.jpg" alt="art" /></p>
<p><em>Exercise</em> 3.1.2.4.</p>
<p>Would you say that ⌜a phone⌝ is the coproduct of ⌜a cell phone⌝ and ⌜a landline phone⌝?</p>
<p><em>Example</em> 3.1.2.5 (Disjoint union of dots). Below, <em>X</em> and <em>Y</em> are sets, having six and four elements respectively, and <em>X</em> ⊔ <em>Y</em> is their coproduct, which has ten elements.</p>
<p><img src="images/Art_P42.jpg" alt="art" /></p>
<h3 id="lev_3-1-2-6" class="level3"><strong>3.1.2.6   Universal property for coproducts</strong></h3>
<p><strong>Proposition 3.1.2.7</strong> (Universal property for coproduct). <em>Let X and Y be sets. For any set A and functions f</em> : <em>X</em> → <em>A and g</em> : <em>Y</em> → <em>A</em>, <em>there exists a unique function X</em> ⊔<em>Y</em> → <em>A such that the following diagram commutes:</em></p>
<p><img src="images/Art_P43.jpg" alt="art" /></p>
<p><em>We say this function is</em> induced by <em>f and g, and we denote it</em><sup><a href="chapter003.html#endnote_1">1</a></sup></p>
<p>{fg:X⊔Y→A.</p>
<p><em>That is, we have</em> {fg○i1=f <em>and</em> {fg○i2=g , <em>and</em> {fg <em>is the only function for which that is so</em>.</p>
<p><em>Proof</em>. Suppose given <em>f</em>, <em>g</em> as in the proposition statement. To provide a function <em>ℓ</em>: <em>X</em> ⊔ <em>Y</em> → <em>A</em> is equivalent to providing an element <em>f</em>(<em>m</em>) ∈ <em>A</em> for each <em>m</em> ∈ <em>X</em> ⊔ <em>Y</em>. We need such a function ℓ={fg such that {fg○i1=f and {fg○i2=g . But each element <em>m</em> ∈ <em>X</em> ⊔ <em>Y</em> is either of the form <em>i</em><sub>1</sub><em>x</em> or <em>i</em><sub>2</sub><em>y</em> and cannot be of both forms. So we assign</p>
<p>{fg (m)={f(x)  if m=i1x,g(y) if m=i2y,    (3.6)</p>
<p>This assignment is necessary and sufficient to make all relevant diagrams commute.</p>
<p><em>Slogan</em> 3.1.2.8.</p>
<p><em>Any time behavior is determined by cases, there is a coproduct involved</em>.</p>
<p><em>Exercise</em> 3.1.2.9.</p>
<p>Let <em>f</em> : ℤ → ℕ be the function defined by</p>
<p>f(n)={nif n⩾0,−nif n&lt;0.</p>
<p>a. What is the standard name for <em>f</em>?</p>
<p>b. In the terminology of Proposition <a href="chapter003.html#Pro_3-1-2-7">3.1.2.7</a>, what are <em>A</em>, <em>X</em>, <em>Y</em>, and <em>X</em> ⊔ <em>Y</em> ?</p>
<p><em>Application</em> 3.1.2.10 (Piecewise defined curves). In science, curves are often defined or considered piecewise. For example, in testing the mechanical properties of a material, we might be interested in various regions of deformation, such as elastic, plastic, or post-fracture. These are three intervals on which the material displays different kinds of properties.</p>
<p>For real numbers <em>a</em> ⩽ <em>b</em> ∈ ℝ, let [<em>a</em>, <em>b</em>] ≔ {<em>x</em> ∈ ℝ | <em>a</em> ⩽ <em>x</em> ⩽ <em>b</em>} denote the closed interval. Given a function [a, b]→fℝ and a function [c, d]→gℝ, the universal property for coproducts implies that they extend uniquely to a function [<em>a</em>, <em>b</em>] ⊔ [<em>c</em>, <em>d</em>] → ℝ, which will appear as a piecewise defined curve,</p>
<p>{fg(x)={f(x)if x∈[a, b],g(x)if x∈[c, d].</p>
<p>Often we are given a curve on [<em>a</em>, <em>b</em>] and another on [<em>b</em>, <em>c</em>], where the two curves agree at the point <em>b</em>. This situation is described by pushouts, which are mild generalizations of coproducts (see Section <a href="chapter003.html#lev_3-3-2">3.3.2</a>).</p>
<p><em>Example</em> 3.1.2.11 (Airplane seats, continued). The universal property for coproducts says the following. Any time we have a function <em>X</em> → <em>A</em> and a function <em>Y</em> → <em>A</em>, we get a unique function <em>X</em> ⊔ <em>Y</em> → <em>A</em>. For example, every economy-class seat in an airplane and every first-class seat in an airplane is actually <em>in a particular airplane</em>. Every economy-class seat has a price, as does every first-class seat.</p>
<p><img src="images/Art_P44.jpg" alt="art" /></p>
<p>The universal property for coproducts formalizes the following intuitively obvious fact:</p>
<p>If we know how economy-class seats are priced and we know how first-class seats are priced, and if we know that every seat is either economy class or first class, then we automatically know how all seats are priced.</p>
<p>To say it another way (and using the other induced map),</p>
<p>If we keep track of which airplane every economy-class seat is in and we keep track of which airplane every first-class seat is in, and if we know that every seat is either economy class or first class, then we require no additional tracking for any airplane seat whatsoever.</p>
<p><em>Exercise</em> 3.1.2.12.</p>
<p>Write the universal property for coproduct, in terms of a relationship between the following three sets:</p>
<p>HomSet(X,A),   HomSet(Y,A),   and   HomSet(X⊔Y,A).</p>
<p><em>Solution</em> 3.1.2.12.</p>
<p>HomSet(X⊔Y,A)→≅HomSet(X,A)×HomSet(Y,A).</p>
<p>To assign an <em>A</em> value to each element of <em>X</em> ⊔ <em>Y</em>, you can delegate responsibility: have one person assign an <em>A</em> value to each element of <em>X</em>, and have another person assign an <em>A</em> value to each element of <em>Y</em>. One function is equivalent to two.</p>
<p><em>Example</em> 3.1.2.13. In the following olog the types <em>A</em> and <em>B</em> are disjoint, so the coproduct <em>C</em> = <em>A</em> ⊔ <em>B</em> is just the union.</p>
<p><img src="images/Art_P45.jpg" alt="art" /></p>
<p><em>Example</em> 3.1.2.14. In the following olog <em>A</em> and <em>B</em> are not disjoint, so care must be taken to differentiate common elements.</p>
<p><img src="images/Art_P46.jpg" alt="art" /></p>
<p>Since ducks can both swim and fly, each duck is found twice in <em>C</em>, once labeled “<em>A</em>”, a flyer, and once labeled “<em>B</em>”, a swimmer. The types <em>A</em> and <em>B</em> are kept disjoint in <em>C</em>, which justifies the name disjoint union.</p>
<p><em>Exercise</em> 3.1.2.15.</p>
<p>Following Section <a href="chapter003.html#lev_3-1-1-16">3.1.1.16</a>, devise a naming system for coproducts, the inclusions, and the universal maps. Try it out by making an olog (involving coproducts) that discusses the idea that both a .wav file and an .mp3 file can be played on a modern computer. Be careful that your arrows are valid (see Section <a href="chapter002.html#lev_2-3-2-1">2.3.2.1</a>).</p>
<h1 id="lev_3-2" class="level1"><a href="toc.html#Rlev_3-2"><strong>3.2   Finite limits in Set</strong></a></h1>
<p>This section discusses <em>limits</em> of variously shaped diagrams of sets. This is made more precise in Section <a href="chapter006.html#lev_6-1-3">6.1.3</a>, which discusses arbitrary limits in arbitrary categories.</p>
<h2 id="lev_3-2-1" class="level2"><strong>3.2.1   Pullbacks</strong></h2>
<p><strong>Definition 3.2.1.1</strong> (Pullback). Suppose given the following diagram of sets and functions:</p>
<p><img src="images/Art_P47.jpg" alt="art" /></p>
<p>Its <em>fiber product</em> is the set</p>
<p>X×ZY≔{ (x,z,y)|f(x)=z=g(y) }.</p>
<p>There are obvious projections <em>π</em><sub>1</sub>: <em>X</em> ×<em><sub>Z</sub> Y</em> → <em>X</em> and <em>π</em><sub>2</sub> : <em>X</em> ×<em><sub>Z</sub> Y</em> → <em>Y</em> (e.g., <em>π</em><sub>2</sub>(<em>x</em>, <em>z</em>, <em>y</em>) = <em>y</em>). The following diagram commutes:</p>
<p><img src="images/Art_P48.jpg" alt="art" /></p>
<p>Given the setup of diagram (<a href="chapter003.html#lev_3-8">3.8</a>), we define a <em>pullback of X and Y over Z</em> to be any set <em>W</em> for which we have an isomorphism W→≅X×ZY. The corner symbol ⌟ in diagram (<a href="chapter003.html#lev_3-9">3.9</a>) indicates that <em>X</em> ×<em><sub>Z</sub> Y</em> is a pullback.</p>
<p><em>Exercise</em> 3.2.1.2.</p>
<p>Let <em>X</em>, <em>Y</em>, <em>Z</em> be as drawn and <em>f</em> : <em>X</em> → <em>Z</em> and <em>g</em> : <em>Y</em> → <em>Z</em> the indicated functions.</p>
<p><img src="images/Art_P49.jpg" alt="art" /></p>
<p>What is the fiber product of the diagram X→fZ←gY?</p>
<p><em>Exercise</em> 3.2.1.3.</p>
<p>a. Draw a set <em>X</em> with five elements and a set <em>Y</em> with three elements. Color each element of <em>X</em> and each element of <em>Y</em> red, blue, or green,<sup><a href="chapter003.html#endnote_2">2</a></sup> and do so in a random-looking way. Considering your coloring of <em>X</em> as a function <em>X</em> → <em>C</em>, where <em>C</em> = {red, blue, green}, and similarly obtaining a function <em>Y</em> → <em>C</em>, draw the fiber product <em>X</em> ×<em><sub>C</sub> Y</em>.</p>
<p>b. The universal property for products guarantees a function <em>X</em> ×<em><sub>C</sub> Y</em> → <em>X</em> × <em>Y</em>, which will be an injection. This means that the drawing you made of the fiber product can be embedded into the 5 × 3 grid. Draw the grid and indicate this subset.</p>
<p><em>Solution</em> 3.2.1.3.</p>
<p>a. Let <em>X</em> = {1, 2, 3, 4, 5} and <em>Y</em> = {<em>a</em>, <em>b</em>, <em>c</em>}. The fiber product is shown in part (b).</p>
<p>b.</p>
<p><img src="images/Art_P50.jpg" alt="art" /></p>
<p>Note that inside the set of <em>X</em> × <em>Y</em> = 15 possible (<em>x</em>, <em>y</em>) pairs is the set of pairs that agree on color—this is <em>X</em> ×<em><sub>C</sub> Y</em>. The grid <em>X</em> × <em>Y</em> is not drawn, but it includes the drawn dots, <em>X</em> ×<em><sub>C</sub> Y</em> ⊆ <em>X</em> × <em>Y</em>, as well as eight nondrawn dots such as (3, <em>a</em>), which “couldn’t agree on a color.”</p>
<p><em>Remark</em> 3.2.1.4. Some may prefer to denote the fiber product in (<a href="chapter003.html#lev_3-8">3.8</a>) by <em>f</em> × <em><sub>Z</sub> g</em> rather than <em>X</em> ×<em><sub>Z</sub> Y</em>. The former is mathematically better notation, but human-readability is often enhanced by the latter, which is also more common in the literature. We use whichever is more convenient.</p>
<p><em>Exercise</em> 3.2.1.5.</p>
<p>Let <em>f</em> : <em>X</em> → <em>Z</em> and <em>g</em> : <em>Y</em> → <em>Z</em> be functions.</p>
<p>a. Suppose that <em>Y</em> = ∅; what can you say about <em>X</em> ×<em><sub>Z</sub> Y</em>?</p>
<p>b. Suppose now that <em>Y</em> is any set but that <em>Z</em> has exactly one element; what can you say about <em>X</em> ×<em><sub>Z</sub> Y</em>?</p>
<p><em>Exercise</em> 3.2.1.6.</p>
<p>Let <em>S</em> = ℝ<sup>3</sup>, <em>T</em> = ℝ, and think of them as (Aristotelian) space and time, with the origin in <em>S</em> × <em>T</em> given by the center of mass of MIT at the time of its founding. Let <em>Y</em> = <em>S</em> × <em>T</em>, and let <em>g</em><sub>1</sub> : <em>Y</em> → <em>S</em> be one projection and <em>g</em><sub>2</sub> : <em>Y</em> → <em>T</em> the other projection. Let <em>X</em> = {☺} be a set with one element, and let <em>f</em><sub>1</sub> : <em>X</em> → <em>S</em> and <em>f</em><sub>2</sub> : <em>X</em> → <em>T</em> be given by the origin in both cases.</p>
<p>a. What are the fiber products <em>W</em><sub>1</sub> and <em>W</em><sub>2</sub>:</p>
<p><img src="images/Art_P51.jpg" alt="art" /></p>
<p>b. Interpret these sets in terms of the center of mass of MIT at the time of its founding.</p>
<h3 id="lev_3-2-1-7" class="level3"><strong>3.2.1.7   Using pullbacks to define new ideas from old</strong></h3>
<p>The fiber product of a diagram can serve to define a new concept. For example, olog (<a href="chapter003.html#lev_3-13">3.13</a>) defines what it means for a cell phone to have a bad battery, in terms of the length of time for which it remains charged. Being explicit reduces the chance of misunderstandings between different groups of people. This can be useful in situations like audits and those in which one is trying to reuse or understand data gathered by others.</p>
<p><em>Example</em> 3.2.1.8. Consider the following two ologs. The one on the right is the pullback of the one on the left.</p>
<p><img src="images/Art_P52.jpg" alt="art" /></p>
<p>Check from Definition <a href="chapter003.html#Def_3-2-1-1">3.2.1.1</a> that the label “a customer that is wealthy and loyal” is fair and straightforward as a label for the fiber product <em>A</em> = <em>B</em> ×<em><sub>D</sub> C</em>, given the labels on <em>B</em>, <em>C</em>, and <em>D</em>.</p>
<p><em>Remark</em> 3.2.1.9. Note that in diagram (<a href="chapter003.html#lev_3-11">3.11</a>) the upper left box in the pullback could have been (noncanonically named) ⌜a good customer⌝. If it were taken to be the fiber product, then the author would be effectively <em>defining</em> a good customer to be one that is wealthy and loyal.</p>
<p><em>Exercise</em> 3.2.1.10.</p>
<p>For each of the following, an author has proposed that the right-hand diagram is a pullback. Do you think their labels are appropriate or misleading; that is, is the label in the upper left box of the pullback reasonable given the rest of the olog, or is it suspect in some way?</p>
<p>a.</p>
<p><img src="images/Art_P53.jpg" alt="art" /></p>
<p>b.</p>
<p><img src="images/Art_P54.jpg" alt="art" /></p>
<p>c.</p>
<p><img src="images/Art_P55.jpg" alt="art" /></p>
<p><em>Exercise</em> 3.2.1.11.</p>
<p>Consider your olog from Exercise <a href="chapter002.html#Exe_2-3-3-1">2.3.3.1</a>. Are any of the commutative squares in it actually pullback squares?</p>
<p><strong>Definition 3.2.1.12</strong> (Preimage). Let <em>f</em> : <em>X</em> → <em>Y</em> be a function and <em>y</em> ∈ <em>Y</em> an element. The <em>preimage of y under f</em>, denoted <em>f</em><sup>−1</sup>(<em>y</em>), is the subset <em>f</em><sup>−1</sup>(<em>y</em>) ≔ {<em>x</em> ∈ <em>X</em> | <em>f</em>(<em>x</em>) = <em>y</em>}. If <em>Y</em>′ ⊆ <em>Y</em> is any subset, the <em>preimage of Y</em>′ <em>under f</em>, denoted <em>f</em><sup>−1</sup>(<em>Y</em>′), is the subset <em>f</em><sup>−1</sup>(<em>Y</em>′) = {<em>x</em> ∈ <em>X</em> | <em>f</em>(<em>x</em>) ∈ <em>Y</em>′}.</p>
<p><em>Exercise</em> 3.2.1.13.</p>
<p>Let <em>f</em> : <em>X</em> → <em>Y</em> be a function and <em>y</em> ∈ <em>Y</em> an element. Draw a pullback diagram in which the fiber product is isomorphic to the preimage <em>f</em><sup>−1</sup>(<em>y</em>).</p>
<p><em>Exercise</em> 3.2.1.14.</p>
<p>Consider the function <em>f</em> : ℕ → ℕ, where <em>f</em>(<em>n</em>) = <em>n</em> + 3. Let <em>A</em> = {<em>i</em> ∈ ℕ | <em>i</em> ⩾ 7}, and let <em>g</em> : <em>A</em> → ℕ be the inclusion, e.g., <em>g</em>(17) = 17. What is the pullback of the following diagram?</p>
<p><img src="images/Art_P56.jpg" alt="art" /></p>
<p><strong>Proposition 3.2.1.15</strong> (Universal property for pullback). <em>Suppose given the diagram of sets and functions as below:</em></p>
<p><img src="images/Art_P57.jpg" alt="art" /></p>
<p><em>For any set A and the following commutative solid-arrow diagram (i.e., functions f</em> : <em>A</em> → <em>X and g</em> : <em>A</em> → <em>Y such that t</em> ○ <em>f</em> = <em>u</em> ○ <em>g), there is a unique function A</em> → <em>X</em> ×<em><sub>Z</sub> Y such that the diagram commutes:</em></p>
<p><img src="images/Art_P58.jpg" alt="art" /></p>
<p><em>Exercise</em> 3.2.1.16.</p>
<p>a. Create an olog whose underlying shape is a commutative square. Now add the fiber product so that the shape is the same as that of diagram (<a href="chapter003.html#lev_3-12">3.12</a>).</p>
<p>b. Use your result to devise English labels to the object <em>X</em> ×<em><sub>Z</sub></em> <em>Y</em>, to the projections <em>π</em><sub>1</sub>, <em>π</em><sub>2</sub>, and to the dotted map A→〈f,g〉ZX×ZY, such that these labels are as canonical as possible.</p>
<h3 id="lev_3-2-1-17" class="level3"><strong>3.2.1.17   Pasting diagrams for pullback</strong></h3>
<p>Consider the following diagram, which includes a left-hand square, a right-hand square, and a big rectangle:</p>
<p><img src="images/Art_P59.jpg" alt="art" /></p>
<p>The right-hand square has a corner symbol indicating that <em>B</em>′ ≅ <em>B</em> ×<em><sub>C</sub> C</em>′ is a pullback. But the corner symbol in the leftmost corner is ambiguous; it might be indicating that the left-hand square is a pullback, or it might be indicating that the big rectangle is a pullback. It turns out not to be ambiguous because the left-hand square is a pullback if and only if the big rectangle is. This is the content of the following proposition.</p>
<p><strong>Proposition 3.2.1.18</strong>. <em>Consider the diagram:</em></p>
<p><img src="images/Art_P60.jpg" alt="art" /></p>
<p><em>where B</em>′ ≅ <em>B</em> ×<em><sub>C</sub> C</em>′ <em>is a pullback. Then there is an isomorphism A</em> ×<em><sub>B</sub> B</em>′ ≅ <em>A</em> ×<em><sub>C</sub> C</em>′. <em>In other words, there is an isomorphism</em></p>
<p>A×B(B×CC′)≅A×CC′.</p>
<p><em>Proof.</em> We first provide a map <em>ϕ</em>: <em>A</em>×<em><sub>B</sub></em>(<em>B</em>×<em><sub>C</sub>C</em>′) → <em>A</em>×<em><sub>C</sub>C</em>′. An element of <em>A</em>×<em><sub>B</sub></em>(<em>B</em>×<em><sub>C</sub>C</em>′) is of the form (<em>a</em>, <em>b</em>, (<em>b</em>, <em>c</em>, <em>c</em>′)) such that <em>f</em>(<em>a</em>) = <em>b</em>, <em>g</em>(<em>b</em>) = <em>c</em> and <em>k</em>(<em>c</em>′) = <em>c</em>. But this implies that <em>g</em> ○ <em>f</em>(<em>a</em>) = <em>c</em> = <em>k</em>(<em>c</em>′) so we put <em>ϕ</em>(<em>a</em>, <em>b</em>, (<em>b</em>, <em>c</em>, <em>c</em>′)) ≔ (<em>a</em>, <em>c</em>, <em>c</em>′) ∈ <em>A</em> ×<em><sub>C</sub> C</em>′. Now we provide a proposed inverse, <em>ψ</em> : <em>A</em> ×<em><sub>C</sub> C</em>′ → <em>A</em> ×<em><sub>B</sub></em> (<em>B</em> ×<em><sub>C</sub> C</em>′). Given (<em>a</em>, <em>c</em>, <em>c</em>′) with <em>g</em> ○ <em>f</em>(<em>a</em>) = <em>c</em> = <em>k</em>(<em>c</em>′), let <em>b</em> = <em>f</em>(<em>a</em>) and note that (<em>b</em>, <em>c</em>, <em>c</em>′) is an element of <em>B</em> ×<em><sub>C</sub> C</em>′. So we can define <em>ψ</em>(<em>a</em>, <em>c</em>, <em>c</em>′) = (<em>a</em>, <em>b</em>, (<em>b</em>, <em>c</em>, <em>c</em>′)). It is easy to see that <em>ϕ</em> and <em>ψ</em> are inverse.</p>
<p>Proposition <a href="chapter003.html#Pro_3-2-1-18">3.2.1.18</a> can be useful in authoring ologs. For example, the type ⌜a cell phone that has a bad battery⌝ is vague, but we can lay out precisely what it means using pullbacks:</p>
<p><img src="images/Art_P61.jpg" alt="art" /></p>
<p>The category-theoretic fact described here says that since <em>A</em> ≅ <em>B</em> ×<em><sub>D</sub> C</em> and <em>C</em> ≅ <em>D</em> ×<em><sub>F</sub> E</em>, it follows that <em>A</em> ≅ <em>B</em> ×<em><sub>F</sub> E</em>. That is, we can deduce the definition “a cell phone that has a bad battery is defined as a cell phone that has a battery which remains charged for less than one hour.”</p>
<p><em>Exercise</em> 3.2.1.19.</p>
<p>a. Create an olog that defines two people to be “of approximately the same height” if and only if their height difference is less than half an inch, using a pullback. Your olog can include the box ⌜a real number <em>x</em> such that −.5 &lt; <em>x</em> &lt; .5⌝.</p>
<p>b. In the same olog, use pullbacks to make a box for those people whose height is approximately the same as a person named “Mary Quite Contrary.”</p>
<p><em>Exercise</em> 3.2.1.20.</p>
<p>Consider the following diagrams. In the left-hand one, both squares commute.</p>
<p><img src="images/Art_P62.jpg" alt="art" /></p>
<p>Let <em>W</em> = <em>X</em> ×<em><sub>Z</sub></em> <em>Y</em> and <em>W</em>′ = <em>X</em>′ ×<sub><em>Z</em>′</sub> <em>Y</em>′ be fiber products, and form the right-hand diagram. Use the universal property for fiber products to construct a map <em>W</em> → <em>W</em>′ such that all squares commute.</p>
<p><em>Solution</em> 3.2.1.20.</p>
<p>We redraw the right-hand diagram, with arrows labeled and a new dotted arrow:</p>
<p><img src="images/Art_P63.jpg" alt="art" /></p>
<p>The commutativity of the right, back, and bottom squares can be written equationally as</p>
<p>c′∘g∘a=f∘c∘a=f∘d∘b=d′∘e∘b.</p>
<p>Therefore, the universal property for pullbacks (<a href="chapter003.html#Pro_3-2-1-15">3.2.1.15</a>) allows us to form the desired map <em>W</em> → <em>W</em>′ as 〈<em>g</em> ○ <em>a</em>, <em>e</em> ○ <em>b</em>〉<sub><em>Z</em>′</sub></p>
<h2 id="lev_3-2-2" class="level2"><strong>3.2.2   Spans, experiments, and matrices</strong></h2>
<p><strong>Definition 3.2.2.1</strong>. Given sets <em>A</em> and <em>B</em>, a <em>span on A and B</em> is a set <em>R</em> together with functions <em>f</em> : <em>R</em> → <em>A</em> and <em>g</em> : <em>R</em> → <em>B</em>.</p>
<p><img src="images/Art_P64.jpg" alt="art" /></p>
<p><em>Application</em> 3.2.2.2. Think of <em>A</em> and <em>B</em> as observables and <em>R</em> as a set of experiments performed on these two variables.</p>
<p>For example, let’s rename variables and say that <em>T</em> is the set of possible temperatures of a gas in a fixed container and that <em>P</em> is the set of possible pressures of the gas, so we have the span T←fE→gP. We perform 1,000 experiments in which we change and record the temperature, and we simultaneously record the pressure. The results might look like this:</p>
<p>Experiment E</p>
<p><strong>ID</strong></p>
<p><strong>Temperature</strong></p>
<p><strong>Pressure</strong></p>
<p>1</p>
<p>100</p>
<p>72</p>
<p>2</p>
<p>100</p>
<p>73</p>
<p>3</p>
<p>100</p>
<p>72</p>
<p>4</p>
<p>200</p>
<p>140</p>
<p>5</p>
<p>200</p>
<p>138</p>
<p>6</p>
<p>200</p>
<p>141</p>
<p>⋮</p>
<p>⋮</p>
<p>⋮</p>
<p><strong>Definition 3.2.2.3</strong>. Let <em>A</em>, <em>B</em>, and <em>C</em> be sets, and let A←fR→gB and B←f′R′→g′C be spans. Their <em>composite span</em> is given by the fiber product <em>R</em> ×<em><sub>B</sub> R</em>′ as in this diagram:</p>
<p><img src="images/Art_P65.jpg" alt="art" /></p>
<p><em>Application</em> 3.2.2.4. Let’s look back at the lab’s experiment in Application <a href="chapter003.html#App_3-2-2-2">3.2.2.2</a>, which resulted in a span T←fE→gP. Suppose we notice that something looks a little wrong. The pressure should be linear with the temperature but it does not appear to be. We hypothesize that the volume of the container is increasing under pressure. We look up this container online and see that experiments have been done to measure the volume as the interior pressure changes. That data gives us a span P←f′E′→g′V.</p>
<p>The composite of our lab’s span with the online data span yields a span <em>T</em> ← <em>E</em>″ → <em>V</em>, where <em>E</em>″ ≔ <em>E</em> ×<em><sub>P</sub> E</em>′. What information does this span give us? In explaining it, one might say, “whenever an experiment <em>e</em> in our lab yielded the same pressure as the online experiment <em>e</em>′ recorded, we called that a data point <em>e</em>″. Every data point has an associated temperature (from our lab) and an associated volume (from the online experiment). This is the best we can do.”</p>
<p>The information we get this way might be seen by some as unscientific, but it certainly is the kind of information people use in business and in everyday life calculation—we get data from multiple sources and put it together. Moreover, it is scientific in the sense that it is reproducible. The way we obtained our <em>T</em>-<em>V</em> data is completely transparent.</p>
<p>We can relate spans to matrices of natural numbers, and see a natural categorification of matrix addition and matrix multiplication. If the spans come from experiments, as in Applications <a href="chapter003.html#App_3-2-2-2">3.2.2.2</a> and <a href="chapter003.html#App_3-2-2-4">3.2.2.4</a>, the matrices will look like huge but sparse matrices. Let’s go through that.</p>
<p>Let <em>A</em> and <em>B</em> be sets, and let <em>A</em> ← <em>R</em> → <em>B</em> be a span. By the universal property for products, we have a unique map R→pA×B.</p>
<p>We make a matrix of natural numbers out of this data as follows. The set of rows is <em>A</em>, the set of columns is <em>B</em>. For elements <em>a</em> ∈ <em>A</em> and <em>b</em> ∈ <em>B</em>, the (<em>a</em>, <em>b</em>) entry is the cardinality of its preimage, |<em>p</em><sup>−1</sup>(<em>a</em>, <em>b</em>)|, i.e., the number of elements in <em>R</em> that are sent by <em>p</em> to (<em>a</em>, <em>b</em>).</p>
<p>Suppose we are given two (<em>A</em>, <em>B</em>) spans, i.e., <em>A</em> ← <em>R</em> → <em>B</em> and <em>A</em> ← <em>R</em>′ → <em>B</em>; we might think of these has having the same <em>dimensions</em>, i.e., they are both |<em>A</em>| × |<em>B</em>| matrices. We can take the disjoint union <em>R</em> ⊔ <em>R</em>′, and by the universal property for coproducts we have a unique span <em>A</em> ← <em>R</em> ⊔ <em>R</em>′ → <em>B</em> making the requisite diagram commute.<a href="chapter003.html#endnote_3"><sup>3</sup></a> The matrix corresponding to this new span will be the sum of the matrices corresponding to the two previous spans out of which it was made.</p>
<p>Given a span <em>A</em> ← <em>R</em> → <em>B</em> and a span <em>B</em> ← <em>S</em> → <em>C</em>, the composite span can be formed as in Definition <a href="chapter003.html#Def_3-2-2-3">3.2.2.3</a>. It will correspond to the usual multiplication of an |<em>A</em>| × |<em>B</em>| matrix by a |<em>B</em>| × |<em>C</em>| matrix, resulting in a |<em>A</em>| × |<em>C</em>| matrix.</p>
<p><em>Exercise</em> 3.2.2.5.</p>
<p>Let <em>A</em> = {1, 2} and <em>B</em> = {1, 2, 3}, and consider the span A←fR→gB given by the table</p>
<p><em>R</em></p>
<p><strong>ID</strong></p>
<p><strong>f</strong> : <strong>A</strong></p>
<p><strong>g</strong> : <strong>B</strong></p>
<p>1</p>
<p>1</p>
<p>2</p>
<p>2</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>1</p>
<p>3</p>
<p>4</p>
<p>2</p>
<p>1</p>
<p>5</p>
<p>2</p>
<p>2</p>
<p>6</p>
<p>2</p>
<p>3</p>
<p>7</p>
<p>2</p>
<p>3</p>
<p>8</p>
<p>2</p>
<p>3</p>
<p>So <em>R</em> = 8.</p>
<p>a. What is the matrix corresponding to this span?</p>
<p>b. If <em>R</em>′ ⊆ <em>A</em>×<em>B</em> is a subset, with corresponding span A←f′R′→g′B given by projections, what can you say about the numbers in the corresponding matrix?</p>
<p><em>Construction</em> 3.2.2.6. Given a span A←fR→gB, one can draw a <em>bipartite graph</em> with each element of <em>A</em> drawn as a dot on the left, each element of <em>B</em> drawn as a dot on the right, and each element <em>r</em> ∈ <em>R</em> drawn as an arrow connecting vertex <em>f</em>(<em>r</em>) on the left to vertex <em>g</em>(<em>r</em>) on the right.</p>
<p><em>Exercise</em> 3.2.2.7.</p>
<p>a. Draw the bipartite graph (as in Construction <a href="chapter003.html#Con_3-2-2-6">3.2.2.6</a>) corresponding to the span T←fE→gP in Application <a href="chapter003.html#App_3-2-2-2">3.2.2.2</a> (assuming the ellipses are vacuous, i.e., assuming that |<em>E</em>| = 6).</p>
<p>b. Now make up your own span P←f′E′→g′V (with |<em>E</em>′| ⩾ 2), and write it out in database form as in Application <a href="chapter003.html#App_3-2-2-2">3.2.2.2</a> and in bipartite graph form.</p>
<p>c. Draw the composite span <em>T</em> ← <em>E</em> ×<em><sub>P</sub> E</em>′ → <em>V</em> as a bipartite graph.</p>
<p>d. Describe in words how the composite span graph (for <em>T</em> ← <em>E</em> ×<em><sub>P</sub> E</em>′ → <em>V</em> ) relates to the graphs of its factors (<em>T</em> ← <em>E</em> → <em>P</em> and <em>P</em> ← <em>E</em>′ → <em>V</em> ).</p>
<h2 id="lev_3-2-3" class="level2"><strong>3.2.3   Equalizers and terminal objects</strong></h2>
<p><strong>Definition 3.2.3.1</strong>. Suppose given two parallel arrows</p>
<p>X⇉gfY.(3.14)</p>
<p>The <em>equalizer of f and g</em> is the set</p>
<p>Eq(f,g)≔{ x∈X|f(x)=g(x)}</p>
<p>which is a subset of <em>X</em>. Writing <em>p</em>: <em>Eq</em>(<em>f</em>, <em>g</em>) → <em>X</em> for the inclusion, we have a commutative diagram</p>
<p>Eq(f,g)→pX⇉gfY</p>
<p>with <em>f</em> ○ <em>p</em> = <em>g</em> ○ <em>p</em>.</p>
<p><em>Example</em> 3.2.3.2. Suppose one has designed an experiment to test a theoretical prediction. The question is, When does the theory match the experiment? The answer is given by the equalizer of the following diagram:</p>
<p><img src="images/Art_P67.jpg" alt="art" /></p>
<p>The equalizer is the set of all inputs for which the theory and the experiment yield the same output.</p>
<p><em>Exercise</em> 3.2.3.3.</p>
<p>Create an olog that uses equalizers in a reasonably interesting way. Alternatively, use an equalizer to specify those published authors who have published exactly one paper. Hint: Find a function from authors to papers; then find another.</p>
<p><em>Exercise</em> 3.2.3.4.</p>
<p>Find a universal property enjoyed by the equalizer of two arrows <em>f</em> : <em>X</em> → <em>Y</em> and <em>g</em> : <em>X</em> → <em>Y</em>, and present it in the style of Propositions <a href="chapter003.html#Pro_3-1-1-10">3.1.1.10</a>, <a href="chapter003.html#Pro_3-1-2-7">3.1.2.7</a>, and <a href="chapter003.html#Pro_3-2-1-15">3.2.1.15</a>.</p>
<p><em>Exercise</em> 3.2.3.5.</p>
<p>a. A terminal set is a set <em>S</em> such that for every set <em>X</em>, there exists a unique function <em>X</em> → <em>S</em>. Find a terminal set.</p>
<p>b. Do you think that the notion <em>terminal set</em> belongs here in Section <a href="chapter003.html#lev_3-2">3.2</a>, i.e., in the same world as products, pullbacks, and equalizers? Why? Another way to ask this is, If products, pullbacks, and equalizers are all <em>limits</em>, then what do limits have in common?</p>
<p><em>Solution</em> 3.2.3.5.</p>
<p>a. Let <em>S</em> = {☺}. Then <em>S</em> is a terminal set. So is <em>S</em> = {43}. This was the content of Exercise <a href="chapter002.html#Exe_2-1-2-13">2.1.2.13</a>, part (a).</p>
<p>b. The notion of a terminal set does fit well into Section <a href="chapter003.html#lev_3-2">3.2</a> because it has a similar kind of universal property. Namely, for any other set <em>S</em>′ that might fill the position of <em>S</em>, there is a unique map <em>S</em>′ → <em>S</em>. See Section <a href="chapter006.html#lev_6-1-3">6.1.3</a>.</p>
<h1 id="lev_3-3" class="level1"><a href="toc.html#Rlev_3-3"><strong>3.3   Finite colimits in Set</strong></a></h1>
<p>This section parallels Section <a href="chapter003.html#lev_3-2">3.2</a>. I introduce several types of finite colimits to give the reader some intuition about them without formally defining colimits yet.</p>
<h2 id="lev_3-3-1" class="level2"><strong>3.3.1   Background: equivalence relations</strong></h2>
<p><strong>Definition 3.3.1.1</strong> (Equivalence relations and equivalence classes). Let <em>X</em> be a set, and consider the product <em>X</em> × <em>X</em>, as in Definition <a href="chapter003.html#Def_3-1-1-1">3.1.1.1</a>. An <em>equivalence relation on X</em> is a subset <em>R</em> ⊆ <em>X</em> × <em>X</em> satisfying the following properties for all <em>x</em>, <em>y</em>, <em>z</em> ∈ <em>X</em>:</p>
<p><strong>Reflexivity:</strong> (<em>x</em>, <em>x</em>) ∈ <em>R</em>;</p>
<p><strong>Symmetry:</strong> (<em>x</em>, <em>y</em>) ∈ <em>R</em> if and only if (<em>y</em>, <em>x</em>) ∈ <em>R</em>;</p>
<p><strong>Transitivity:</strong> If (<em>x</em>, <em>y</em>) ∈ <em>R</em> and (<em>y</em>, <em>z</em>) ∈ <em>R</em>, then (<em>x</em>, <em>z</em>) ∈ <em>R</em>.</p>
<p>If <em>R</em> is an equivalence relation, we often write <em>x</em> ∼<em><sub>R</sub> y</em>, or simply <em>x</em> ∼ <em>y</em>, to mean (<em>x</em>, <em>y</em>) ∈ <em>R</em>. For convenience we may refer to the equivalence relation by the symbol ∼, saying that ∼ is an equivalence relation on <em>X</em>.</p>
<p>An <em>equivalence class of</em> ∼ is a subset <em>A</em> ⊆ <em>X</em> such that</p>
<ul>
<li><em>A</em> is nonempty, <em>A</em> ≠ ∅;</li>
<li>if <em>x</em> ∈ <em>A</em>, then <em>y</em> ∈ <em>A</em> if and only if <em>x</em> ∼ <em>y</em>.</li>
</ul>
<p>Suppose that ∼ is an equivalence relation on <em>X</em>. The <em>quotient of X by</em> ∼, denoted <em>X</em>/ ∼, is the set of equivalence classes of ∼. By definition, for any element <em>x</em> ∈ <em>X</em>, there is exactly one equivalence class <em>A</em> such that <em>x</em> ∈ <em>A</em>. Thus we can define a function <em>Q</em>: <em>X</em> → <em>X</em>/∼, called the <em>quotient function</em>, sending each element <em>x</em> ∈ <em>X</em> to the equivalence class containing it. Note that for any <em>y</em> ∈ <em>X</em>/∼, there is some <em>x</em> ∈ <em>X</em> with <em>Q</em>(<em>x</em>) = <em>y</em>; we call <em>x</em> a <em>representative</em> of the equivalence class <em>y</em>.</p>
<p><em>Example</em> 3.3.1.2. Let ℤ denote the set of integers. Define a relation <em>R</em> ⊆ ℤ × ℤ by</p>
<p>R={(x,y)|∃n∈ℤ such that x+7n=y}.</p>
<p>Then <em>R</em> is an equivalence relation because <em>x</em> + 7 * 0 = <em>x</em> (reflexivity); <em>x</em> + 7 * <em>n</em> = <em>y</em> if and only if <em>y</em> + 7 * (−<em>n</em>) = <em>x</em> (symmetry); and <em>x</em> + 7<em>n</em> = <em>y</em> and <em>y</em> + 7<em>m</em> = <em>z</em> together imply that <em>x</em> + 7(<em>m</em> + <em>n</em>) = <em>z</em> (transitivity).</p>
<p>An example equivalence class <em>A</em> ⊆ ℤ for this relation is <em>A</em> = {…, −12, −5, 2, 9, …}.</p>
<p><em>Exercise</em> 3.3.1.3.</p>
<p>Let <em>X</em> be the set of people on earth. Define a binary relation <em>R</em> ⊆ <em>X</em> × <em>X</em> on <em>X</em> as follows. For a pair (<em>x</em>, <em>y</em>) of people, put (<em>x</em>, <em>y</em>) ∈ <em>R</em> if <em>x</em> cares what happens to <em>y</em>. Justify your answers to the following questions:</p>
<p>a. Is this relation reflexive?</p>
<p>b. Is it symmetric?</p>
<p>c. Is it transitive?</p>
<p>d. What if “cares what happens to” is replaced with “has shaken hands with”. Is this relation reflexive, symmetric, transitive?</p>
<p><em>Example</em> 3.3.1.4 (Partitions). An equivalence relation on a set <em>X</em> can be thought of as a way of partitioning <em>X</em>. A <em>partition of X</em> consists of a set <em>I</em>, called <em>the set of parts</em>, and for every element <em>i</em> ∈ <em>I</em>, the selection of a subset <em>X<sub>i</sub></em> ⊆ <em>X</em> such that two properties hold:</p>
<ul>
<li>Every element <em>x</em> ∈ <em>X</em> is in some part (i.e., for all <em>x</em> ∈ <em>X</em>, there exists <em>i</em> ∈ <em>I</em> such that <em>x</em> ∈ <em>X<sub>i</sub></em>).</li>
<li>No element can be found in two different parts (i.e., if <em>x</em> ∈ <em>X<sub>i</sub></em> and <em>x</em> ∈ <em>X<sub>j</sub></em>, then <em>i</em> = <em>j</em>).</li>
</ul>
<p>Given a partition of <em>X</em>, we define an equivalence relation ∼ on <em>X</em> by putting <em>x</em> ∼ <em>x</em>′ if <em>x</em> and <em>x</em>′ are in the same part (i.e., if there exists <em>i</em> ∈ <em>I</em> such that <em>x</em>, <em>x</em>′ ∈ <em>X<sub>i</sub></em>). The parts become the equivalence classes of this relation. Conversely, given an equivalence relation, one makes a partition on <em>X</em> by taking <em>I</em> to be the set of equivalence classes and, for each <em>i</em> ∈ <em>I</em>, letting <em>X<sub>i</sub></em> be the elements in that equivalence class.</p>
<p><em>Exercise</em> 3.3.1.5.</p>
<p>Let <em>X</em> and <em>B</em> be sets, and let <em>f</em> : <em>X</em> → <em>B</em> be a function. Define a subset <em>R<sub>f</sub></em> ⊆ <em>X</em> × <em>X</em> by</p>
<p>Rf={(x,y)|f(x)=f(y)}.</p>
<p>a. Let <em>f</em> : ℝ → ℝ be given by the cosine function, <em>f</em>(<em>x</em>) = <em>cos</em>(<em>x</em>), and let <em>R<sub>f</sub></em> ⊆ ℝ × ℝ be the relation as defined. Find <em>x</em>, <em>y</em> ∈ ℝ such that <em>x</em> ≠ <em>y</em>, but (<em>x</em>, <em>y</em>) ∈ <em>R<sub>f</sub></em>.</p>
<p>b. Is <em>R<sub>f</sub></em> an equivalence relation, for any <em>f</em>?</p>
<p>c. Are all equivalence relations on <em>X</em> obtainable in this way (as <em>R<sub>f</sub></em> for some function having domain <em>X</em>)?</p>
<p>d. Does this viewpoint on equivalence classes relate to that of Example <a href="chapter003.html#Exa_3-3-1-4">3.3.1.4</a>?</p>
<p><em>Exercise</em> 3.3.1.6.</p>
<p>Take a set <em>I</em> of sets. That is, suppose <em>I</em> is a set and that for each element <em>i</em> ∈ <em>I</em>, you are given a set <em>X<sub>i</sub></em>. For every two elements <em>i</em>, <em>j</em> ∈ <em>I</em>, say that <em>i</em> ∼ <em>j</em> if <em>X<sub>i</sub></em> and <em>X<sub>j</sub></em> are isomorphic. Is this relation an equivalence relation on <em>I</em>?</p>
<p>Any relation can be enlarged to an equivalence relation with minimal alteration.</p>
<p><strong>Proposition 3.3.1.7</strong> (Generating equivalence relations). <em>Let X be a set and R</em> ⊆ <em>X</em> × <em>X any subset. There exists a relation S</em> ⊆ <em>X</em> × <em>X such that</em></p>
<ul>
<li><em>S is an equivalence relation;</em></li>
<li><em>R</em> ⊆ <em>S;</em></li>
<li><em>for any equivalence relation S</em>′ <em>such that R</em> ⊆ <em>S</em>′, <em>we have S</em> ⊆ <em>S</em>′.</li>
</ul>
<p><em>The relation S</em>′ <em>is called</em> the equivalence relation generated by <em>R.</em></p>
<p><em>Proof.</em> Let <em>L<sub>R</sub></em> be the set of all equivalence relations on <em>X</em> that contain <em>R</em>. In other words, each element <em>ℓ</em> ∈ <em>L<sub>R</sub></em> is an equivalence relation, so we have <em>R</em> ⊆ <em>ℓ</em> ⊆ <em>X</em> × <em>X</em>. The set <em>L<sub>R</sub></em> is nonempty because <em>X</em> × <em>X</em> ⊆ <em>X</em> × <em>X</em> is an equivalence relation containing <em>R</em>. Let <em>S</em> denote the set of pairs (<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>) ∈ <em>X</em> × <em>X</em> that appear in every element of <em>L<sub>R</sub></em>, that is, S=∩ℓ∈LRℓ. Note that <em>R</em> ⊆ <em>S</em> by definition. We need only show that <em>S</em> is an equivalence relation.</p>
<p>Clearly, <em>S</em> is reflexive, because each <em>ℓ</em> ∈ <em>L<sub>R</sub></em> is. If (<em>x</em>, <em>y</em>) ∈ <em>S</em>, then (<em>x</em>, <em>y</em>) ∈ <em>ℓ</em> for all <em>ℓ</em> ∈ <em>L<sub>R</sub></em>. But since each <em>ℓ</em> is an equivalence relation, (<em>y</em>, <em>x</em>) ∈ <em>ℓ</em> too, so (<em>y</em>, <em>x</em>) ∈ <em>S</em>. This shows that <em>S</em> is symmetric. The proof that it is transitive is similar: if (<em>x</em>, <em>y</em>) ∈ <em>S</em> and (<em>y</em>, <em>z</em>) ∈ <em>S</em>, then they are both in each <em>ℓ</em>, which puts (<em>x</em>, <em>z</em>) in each <em>ℓ</em>, which puts it in <em>S</em>.</p>
<p><em>Exercise</em> 3.3.1.8.</p>
<p>Consider the set ℝ of real numbers. Draw the coordinate plane ℝ × ℝ, and give it coordinates <em>x</em> and <em>y</em>. A binary relation on ℝ is a subset <em>S</em> ⊆ ℝ × ℝ, which can be graphed as a set of points in the (<em>x</em>, <em>y</em>) plane.</p>
<p>a. Draw the relation {(<em>x</em>, <em>y</em>) | <em>y</em> = <em>x</em><sup>2</sup>}.</p>
<p>b. Draw the relation {(<em>x</em>, <em>y</em>) | <em>y</em> ⩾ <em>x</em><sup>2</sup>}.</p>
<p>c. Let <em>S</em><sub>0</sub> be the equivalence relation on ℝ generated (in the sense of Proposition <a href="chapter003.html#Pro_3-3-1-7">3.3.1.7</a>) by the empty set. Draw <em>S</em><sub>0</sub> as a subset of the plane.</p>
<p>d. Consider the equivalence relation <em>S</em><sub>1</sub> generated by {(1, 2), (1, 3)}. Draw <em>S</em><sub>1</sub> in the plane. Highlight the equivalence class containing (1, 2).</p>
<p>e. The reflexivity property and the symmetry property (from Definition <a href="chapter003.html#Def_3-3-1-1">3.3.1.1</a>) have pleasing visualizations in ℝ × ℝ; what are they?</p>
<p>f. Can you think of a heuristic for visualizing the transitivity property?</p>
<p><em>Exercise</em> 3.3.1.9.</p>
<p>Let <em>X</em> be a set, and consider the empty relation <em>R</em> = ∅ ⊆ <em>X</em> × <em>X</em>.</p>
<p>a. What is the equivalence relation ∼ generated by <em>R</em> (called the <em>trivial equivalence relation</em> on <em>X</em>)?</p>
<p>b. Is the quotient function <em>X</em> → <em>X</em>/∼ always an isomorphism?</p>
<p><em>Solution</em> 3.3.1.9.</p>
<p>a. It is the smallest reflexive relation <em>R</em> ≔ {(<em>x</em>, <em>x</em>) | <em>x</em> ∈ <em>X</em>}.</p>
<p>b. Yes. We have <em>x</em> ∼ <em>y</em> if and only if <em>x</em> = <em>y</em>, so each equivalence class contains precisely one element.</p>
<p><em>Exercise</em> 3.3.1.10.</p>
<p>Consider the binary relation <em>R</em> = {(<em>n</em>, <em>n</em> + 1) | <em>n</em> ∈ ℤ} ⊆ ℤ × ℤ.</p>
<p>a. What is the equivalence relation ∼ generated by <em>R</em>?</p>
<p>b. How many equivalence classes are there?</p>
<p><em>Exercise</em> 3.3.1.11.</p>
<p>Suppose <em>N</em> is a network (system of nodes and edges). Let <em>X</em> be the nodes of the network, and let <em>R</em> ⊆ <em>X</em> × <em>X</em> denote the relation such that (<em>x</em>, <em>y</em>) ∈ <em>R</em> iff there exists an edge connecting <em>x</em> to <em>y</em>.<sup><a href="chapter003.html#endnote_4">4</a></sup></p>
<p>a. What is the equivalence relation ∼ generated by <em>R</em>?</p>
<p>b. What is the quotient <em>X</em>/∼?</p>
<p><em>Solution</em> 3.3.1.11.</p>
<p>a. Node <em>x</em> is equivalent to node <em>y</em> if and only if one can get from <em>x</em> to <em>y</em> by moving along some finite number of edges (including no edges if <em>x</em> = <em>y</em>). In other words, if nodes are street addresses in a city, and each edge is like a street, then two addresses are equivalent if a pedestrian can get from one to the other.</p>
<p>b. It is called the set of “connected components” of the network. Think of a connected component as an island within the network. A pedestrian can get from everywhere on the island to everywhere else on the island but cannot get off the island.</p>
<p><em>Remark</em> 3.3.1.12. Let <em>X</em> be a set and <em>R</em> ⊆ <em>X</em> × <em>X</em> a relation. The proof of Proposition <a href="chapter003.html#Pro_3-3-1-7">3.3.1.7</a> has the benefit of working even if |<em>X</em>| ⩾ ∞, but it has the cost that it is not very intuitive nor useful in practice when <em>X</em> is finite. The intuitive way to think about the idea of equivalence relation generated by <em>R</em> is as follows:</p>
<ol>
<li>First add to <em>R</em> what is demanded by reflexivity, <em>R</em><sub>1</sub> ≔ <em>R</em> ∪ {(<em>x</em>, <em>x</em>) | <em>x</em> ∈ <em>X</em>}.</li>
<li>To the result, add what is demanded by symmetry, <em>R</em><sub>2</sub> ≔ <em>R</em><sub>1</sub> ∪{(<em>x</em>, <em>y</em>) | (<em>y</em>, <em>x</em>) ∈ <em>R</em><sub>1</sub>}.</li>
<li><p>Finally, to the result, add what is demanded by transitivity,</p>
<p>S=R2∪{(x,z)|(x,y)∈R2,and (y,z)∈R2}.</p></li>
</ol>
<p>Then <em>S</em> is an equivalence relation, the smallest one containing <em>R</em>.</p>
<h2 id="lev_3-3-2" class="level2"><strong>3.3.2   Pushouts</strong></h2>
<p>Equivalence relations are used to define pushouts.</p>
<p><strong>Definition 3.3.2.1</strong> (Pushout). Suppose given the following diagram of sets and functions:</p>
<p><img src="images/Art_P68.jpg" alt="art" /></p>
<p>Its <em>fiber sum</em>, denoted <em>X</em> ⊔<em><sub>W</sub> Y</em>, is defined as the quotient of <em>X</em> ⊔ <em>W</em> ⊔ <em>Y</em> by the equivalence relation ∼ generated by <em>w</em> ∼ <em>f</em>(<em>w</em>) and <em>w</em> ∼ <em>g</em>(<em>w</em>) for all <em>w</em> ∈ <em>W</em>.</p>
<p>X⊔WY≔(X⊔W⊔Y)/∼,  where ∀w∈W, w∼f(w),and w∼g(w).</p>
<p>There are obvious functions <em>i</em><sub>1</sub> : <em>X</em> → <em>X</em> ⊔<em><sub>W</sub> Y</em> and <em>i</em><sub>2</sub> : <em>Y</em> → <em>X</em> ⊔<em><sub>W</sub> Y</em>, called <em>inclusions</em>.<sup><a href="chapter003.html#endnote_5">5</a></sup> The following diagram commutes:</p>
<p><img src="images/Art_P69.jpg" alt="art" /></p>
<p>Given the setup of diagram (<a href="chapter003.html#lev_3-15">3.15</a>), we define a <em>pushout of X and Y over W</em> to be any set <em>Z</em> for which we have an isomorphism <em>X</em> ⊔<em><sub>W</sub></em> Y→≅Z. The corner symbol ⌜ in diagram (<a href="chapter003.html#lev_3-16">3.16</a>) indicates that <em>X</em> ⊔<em><sub>W</sub> Y</em> is a pushout.</p>
<p><em>Example</em> 3.3.2.2. Let <em>X</em> = {<em>x</em> ∈ ℝ | 0 ⩽ <em>x</em> ⩽ 1} be the set of numbers between 0 and 1, inclusive, and let <em>Y</em> = {<em>y</em> ∈ ℝ | 1 ⩽ <em>y</em> ⩽ 2} be the set of numbers between 1 and 2, inclusive. We can form <em>X</em> ⊔ <em>Y</em>, but it has two copies of 1. This is weird, so we use pushouts; let <em>W</em> = {1}. Then the pushout X←fW→gY, where <em>f</em> and <em>g</em> are the inclusions (1 ↦ 1), is <em>X</em> ⊔<em><sub>W</sub> Y</em> ≅ {<em>z</em> ∈ ℝ | 0 ⩽ <em>z</em> ⩽ 2}, as desired.</p>
<p><img src="images/Art_P70.jpg" alt="art" /></p>
<p><em>Example</em> 3.3.2.3 (Pushout). In ologs (<a href="chapter003.html#lev_3-17">3.17</a>) and (<a href="chapter003.html#lev_3-18">3.18</a>) right-hand diagram is a pushout of the left-hand diagram. The new object, <em>D</em>, is the union of <em>B</em> and <em>C</em>, but instances of <em>A</em> are equated to their <em>B</em> and <em>C</em> aspects.</p>
<p><img src="images/Art_P71.jpg" alt="art" /></p>
<p>In diagram (<a href="chapter003.html#lev_3-17">3.17</a>), the two arrows in the left-hand olog are inclusions: its author considers every cell in the shoulder to be both part of the arm and part of the torso. The pushout is then the union. In olog (<a href="chapter003.html#lev_3-17">3.17</a>), the shoulder is seen as part of the arm and part of the torso. When taking the union of these two parts, we do not want to double-count cells in the shoulder (as would be done in the coproduct <em>B</em> ⊔ <em>C</em>; see Example <a href="chapter003.html#Exa_3-1-2-14">3.1.2.14</a>). Thus we create a new type <em>A</em> for cells in the shoulder, which are considered the same whether viewed as cells in the arm or cells in the torso. In general, if one wishes to take two things and glue them together, with <em>A</em> as the glue and <em>B</em> and <em>C</em> as the two things to be glued, the result is the pushout <em>B</em> ⊔<em><sub>A</sub> C</em>. (A nice image of this can be seen in the setting of topological spaces; see Example <a href="chapter006.html#Exa_6-1-3-39">6.1.3.39</a>.)</p>
<p><img src="images/Art_P72.jpg" alt="art" /></p>
<p>In olog (<a href="chapter003.html#lev_3-18">3.18</a>), if every mathematics course is simply “too hard,” then when reading off a list of courses, each math course may either be read aloud or simply be read as “too hard.” To form <em>D</em> we begin by taking the union of <em>B</em> and <em>C</em>, and then we consider everything in <em>A</em> to be the same whether one looks at it as a course or as the phrase “too hard.” The math courses are all blurred together as one thing. Thus we see that the power to equate different things can be exercised with pushouts.</p>
<p><em>Exercise</em> 3.3.2.4.</p>
<p>Let <em>W</em>, <em>X</em>, <em>Y</em> be as drawn and <em>f</em> : <em>W</em> → <em>X</em> and <em>g</em> : <em>W</em> → <em>Y</em> the indicated functions.</p>
<p><img src="images/Art_P73.jpg" alt="art" /></p>
<p>The pushout of the diagram X←fW→gY is a set <em>P</em>. Write the cardinality |<em>P</em> | of <em>P</em> (see Definition <a href="chapter002.html#Def_2-1-2-23">2.1.2.23</a>).</p>
<p><em>Exercise</em> 3.3.2.5.</p>
<p>Suppose that <em>W</em> = ∅; what can you say about <em>X</em> ⊔<em><sub>W</sub> Z</em>?</p>
<p><em>Exercise</em> 3.3.2.6.</p>
<p>Let <em>W</em> ≔ ℕ = {0, 1, 2, …} denote the set of natural numbers, let <em>X</em> = ℤ denote the set of integers, and let <em>Y</em> = {☺} denote a one-element set. Define <em>f</em> : <em>W</em> → <em>X</em> by <em>f</em>(<em>w</em>) = −(<em>w</em> + 1), and define <em>g</em> : <em>W</em> → <em>Y</em> to be the unique map. Describe the set <em>X</em> ⊔<em><sub>W</sub> Y</em>.</p>
<p><em>Exercise</em> 3.3.2.7.</p>
<p>Let <em>i</em>: <em>R</em> ⊆ <em>X</em> × <em>X</em> be an equivalence relation (see Example <a href="chapter002.html#Exa_2-1-2-4">2.1.2.4</a> for notation). Composing with the projections <em>π</em><sub>1</sub>, <em>π</em><sub>2</sub> : <em>X</em> × <em>X</em> → <em>X</em>, we have two maps, <em>π</em><sub>1</sub> ○ <em>i,</em> : <em>R</em> → <em>X</em> and <em>π</em><sub>2</sub> ○ <em>i</em>: <em>R</em> → <em>X</em>.</p>
<p>a. Consider the pushout <em>X</em> ⊔<em><sub>R</sub> X</em> of the diagram</p>
<p>X←π1○iR→π2○iX.</p>
<p>How should one think about <em>X</em> ⊔<em><sub>R</sub> X</em>? That is, before we defined pushouts, we went through some work to define something we can now call <em>X</em> ⊔<em><sub>R</sub> X</em>—what was it?</p>
<p>b. If <em>i</em>: <em>R</em> ⊆ <em>X</em> × <em>X</em> is not assumed to be an equivalence relation, we can still define this pushout. Is there a relationship between the pushout X←π1○iR→π2○iX and the equivalence relation generated by <em>R</em> ⊆ <em>X</em> × <em>X</em>?</p>
<p><strong>Proposition 3.3.2.8</strong> (Universal property for pushout). <em>Suppose given the following diagram of sets and functions:</em></p>
<p><img src="images/Art_P74.jpg" alt="art" /></p>
<p><em>The pushout, X</em> ⊔<em><sub>W</sub> Y together with the inclusions i</em><sub>1</sub> <em>and i</em><sub>2</sub>, <em>satisfies the following property. For any set A and commutative solid arrow diagram (i.e., functions f</em> : <em>X</em> → <em>A and g</em> : <em>Y</em> → <em>A such that f</em> ○ <em>t</em> = <em>g</em> ○ <em>u)</em>,</p>
<p><img src="images/Art_P75.jpg" alt="art" /></p>
<p><em>there exists a unique arrow</em> w{ fg : <em>X</em> ⊔ <em><sub>W</sub> Y</em> → <em>A making everything commute,</em></p>
<p>f=w{ fg○i1  and  g=w{ fg○i2.</p>
<h2 id="lev_3-3-3" class="level2"><strong>3.3.3   Other finite colimits</strong></h2>
<p><strong>Definition 3.3.3.1</strong> (Coequalizer). Suppose given two parallel arrows</p>
<p>X⇉gfY.(3.20)</p>
<p>The <em>coequalizer of f and g</em> is the commutative diagram</p>
<p>X⇉gfY→qCoeq(f,g),</p>
<p>where we define</p>
<p>Coeq(f,g)≔Y/∼, where f(x)∼g(x) for all x∈X,</p>
<p>and <em>q</em> is the quotient function <em>q</em> : <em>Y</em> → <em>Y</em> /∼.</p>
<p><em>Exercise</em> 3.3.3.2.</p>
<p>Let <em>X</em> = ℝ be the set of real numbers. What is the coequalizer of the two maps <em>X</em> → <em>X</em> given by <em>x</em> ↦ <em>x</em> and <em>x</em> ↦ (<em>x</em> + 1) respectively?</p>
<p><em>Exercise</em> 3.3.3.3.</p>
<p>Find a universal property enjoyed by the coequalizer of two arrows.</p>
<p><em>Exercise</em> 3.3.3.4.</p>
<p>An initial set is a set <em>S</em> such that for every set <em>A</em>, there exists a unique function <em>S</em> → <em>A</em>.</p>
<p>a. Find an initial set.</p>
<p>b. Do you think that the notion <em>initial set</em> belongs here in Section <a href="chapter003.html#lev_3-3">3.3</a>, i.e., in the same world as coproducts, pushouts, and coequalizers? Why? Another way to ask this is, If coproducts, pushouts, and coequalizers are all colimits, what do colimits have in common?</p>
<p><em>Solution</em> 3.3.3.4.</p>
<p>a. Let <em>S</em> = ∅. Then <em>S</em> is the initial set. This was the content of Exercise <a href="chapter002.html#Exe_2-1-2-13">2.1.2.13</a> part (b).</p>
<p>b. The notion of an initial set does fit well into Section <a href="chapter003.html#lev_3-3">3.3</a> because it has a similar kind of universal property. Namely, for any other set <em>S</em>′ that might fill the position of <em>S</em>, there is a unique map <em>S</em> → <em>S</em>′. See Section <a href="chapter006.html#lev_6-1-3">6.1.3</a>.</p>
<h1 id="lev_3-4" class="level1"><a href="toc.html#Rlev_3-4"><strong>3.4   Other notions in Set</strong></a></h1>
<p>This section discusses some additional notions in the category <strong>Set</strong>.</p>
<h2 id="lev_3-4-1" class="level2"><strong>3.4.1   Retractions</strong></h2>
<p><strong>Definition 3.4.1.1</strong>. Suppose given a function <em>f</em> : <em>X</em> → <em>Y</em> and a function <em>g</em> : <em>Y</em> → <em>X</em> such that <em>g</em> ○ <em>f</em> = id<em><sub>X</sub></em>. In this case we call <em>f</em> a <em>retract section</em> and we call <em>g</em> a <em>retract projection</em>.</p>
<p><em>Exercise</em> 3.4.1.2.</p>
<p>Create an olog that includes sets <em>X</em> and <em>Y</em> and functions <em>f</em> : <em>X</em> → <em>Y</em> and <em>g</em> : <em>Y</em> → <em>X</em> such that <em>g</em> ○ <em>f</em> = id<em><sub>X</sub></em>, but such that <em>f</em> ○ <em>g</em> ≠ id<em><sub>Y</sub></em> ; that is, such that <em>f</em> is a retract section but not an isomorphism.</p>
<h2 id="lev_3-4-2" class="level2"><strong>3.4.2   Currying</strong></h2>
<p>Currying is the idea that when a function takes many inputs, we can input them one at a time or all at once. For example, consider the function that takes a material <em>M</em> and an extension <em>E</em> and returns the force transmitted through material <em>M</em> when it is pulled to extension <em>E</em>. This is a function <em>e</em>: ⌜a material⌝ × ⌜an extension⌝ → ⌜a force⌝. This function takes two inputs at once, but it is convenient to curry the second input. Recall that Hom<strong><sub>Set</sub></strong>(⌜an extension⌝, ⌜a force⌝) is the set of theoretical force-extension curves. Currying transforms <em>e</em> into a function</p>
<p>e′:⌜a material⌝→HomSet(⌜an extension⌝,⌜a force⌝).</p>
<p>This is a more convenient way to package the same information: each material <em>M</em> has a force-extension curve <em>e</em>′(<em>M</em>). This will be made precise in Proposition <a href="chapter003.html#Pro_3-4-2-3">3.4.2.3</a>.</p>
<p><em>Notation</em> 3.4.2.1. Let <em>A</em> and <em>B</em> be sets. We sometimes denote by <em>B<sup>A</sup></em> the set of functions from <em>A</em> to <em>B</em>,</p>
<p>BA≔HomSet(A,B).(3.21)</p>
<p><em>Exercise</em> 3.4.2.2.</p>
<p>For a finite set <em>A</em>, let |<em>A</em>| ∈ ℕ denote the cardinality of (number of elements in) <em>A</em>. If <em>A</em> and <em>B</em> are both finite (including the possibility that one or both are empty), is it always true that |<em>B<sup>A</sup></em>| = |<em>B</em>|<sup>|<em>A</em>|</sup>?</p>
<p><strong>Proposition 3.4.2.3</strong> (Currying). <em>Let A denote a set. For any sets X</em>, <em>Y there is a bijection</em></p>
<p>ϕ:HomSet(X×A,Y)→≅HomSet(X,YA).(3.22)</p>
<p><em>Proof.</em> Suppose given <em>f</em> : <em>X</em> × <em>A</em> → <em>Y</em>. Define <em>ϕ</em>(<em>f</em>): <em>X</em> → <em>Y <sup>A</sup></em> as follows: for any <em>x</em> ∈ <em>X</em>, let <em>ϕ</em>(<em>f</em>)(<em>x</em>): <em>A</em> → <em>Y</em> be defined as follows: for any <em>a</em> ∈ <em>A</em>, let <em>ϕ</em>(<em>f</em>)(<em>x</em>)(<em>a</em>) ≔ <em>f</em>(<em>x</em>, <em>a</em>).</p>
<p>We now construct the inverse, <em>ψ</em> : Hom<strong><sub>Set</sub></strong>(<em>X</em>, <em>Y<sup>A</sup></em>) → Hom<strong><sub>Set</sub></strong>(<em>X</em> × <em>A</em>, <em>Y</em>). Suppose given <em>g</em> : <em>X</em> → <em>Y <sup>A</sup></em>. Define <em>ψ</em>(<em>g</em>): <em>X</em> × <em>A</em> → <em>Y</em> as follows: for any pair (<em>x</em>, <em>a</em>) ∈ <em>X</em> × <em>A</em> let <em>ψ</em>(<em>g</em>)(<em>x</em>, <em>a</em>) ≔ <em>g</em>(<em>x</em>)(<em>a</em>).</p>
<p>Then for any <em>f</em> ∈ Hom<strong><sub>Set</sub></strong>(<em>X</em> × <em>A</em>, <em>Y</em>), we have <em>ψ</em> ○ <em>ϕ</em>(<em>f</em>)(<em>x</em>, <em>a</em>) = <em>ϕ</em>(<em>f</em>)(<em>x</em>)(<em>a</em>) = <em>f</em>(<em>x</em>, <em>a</em>), and for any <em>g</em> ∈ Hom<strong><sub>Set</sub></strong>(<em>X</em>, <em>Y<sup>A</sup></em>), we have <em>ϕ</em> ○ <em>ψ</em>(<em>g</em>)(<em>x</em>)(<em>a</em>) = <em>ψ</em>(<em>g</em>)(<em>x</em>, <em>a</em>) = <em>g</em>(<em>x</em>)(<em>a</em>). Thus we see that <em>ϕ</em> is an isomorphism as desired.</p>
<p><em>Exercise</em> 3.4.2.4.</p>
<p>Let <em>X</em> = {1, 2}, <em>A</em> = {<em>a</em>, <em>b</em>}, and <em>Y</em> = {<em>x</em>, <em>y</em>}.</p>
<p>a. Write three distinct elements of <em>L</em> ≔ Hom<strong><sub>Set</sub></strong>(<em>X</em> × <em>A</em>, <em>Y</em>).</p>
<p>b. Write all the elements of <em>M</em> ≔ Hom<strong><sub>Set</sub></strong>(<em>A</em>, <em>Y</em>).</p>
<p>c. For each of the three elements <em>ℓ</em> ∈ <em>L</em> you chose in part (a), write the corresponding function <em>ϕ</em>(<em>ℓ</em>): <em>X</em> → <em>M</em> guaranteed by Proposition <a href="chapter003.html#Pro_3-4-2-3">3.4.2.3</a>.</p>
<p><em>Exercise</em> 3.4.2.5.</p>
<p>Let <em>A</em> and <em>B</em> be sets. We defined <em>B<sup>A</sup></em> ≔ Hom<strong><sub>Set</sub></strong>(<em>A</em>, <em>B</em>), so we can write the identity function as id<em><sub>B<sup>A</sup></sub></em> : Hom<strong><sub>Set</sub></strong>(<em>A</em>, <em>B</em>) → <em>B<sup>A</sup></em>. Proposition <a href="chapter003.html#Pro_3-4-2-3">3.4.2.3</a>, make the substitutions <em>X</em> = Hom<strong><sub>Set</sub></strong>(<em>A</em>, <em>B</em>), <em>Y</em> = <em>B</em>, and <em>A</em> = <em>A</em>. Consider the function</p>
<p>ϕ−1:HomSet(HomSet(A,B),BA)→HomSet(HomSet(A,B)×A,B)</p>
<p>obtained as the inverse of (<a href="chapter003.html#lev_3-22">3.22</a>). We have a canonical element id<em><sub>B<sup>A</sup></sub></em> in the domain of <em>ϕ</em><sup>−1</sup>. We can apply the function <em>ϕ</em><sup>−1</sup> and obtain an element <em>ev</em> = <em>ϕ</em><sup>−1</sup>(id<em><sub>B<sup>A</sup></sub></em>) ∈ Hom<strong><sub>Set</sub></strong>(Hom<strong><sub>Set</sub></strong>(<em>A</em>, <em>B</em>) × <em>A</em>, <em>B</em>), which is itself a function,</p>
<p>ev:HomSet(A,B)×A→B.(3.23)</p>
<p>a. Describe the function <em>ev</em> in terms of how it operates on elements in its domain.</p>
<p>b. Why might one be tempted to denote this function <em>ev</em>?</p>
<p><em>Solution</em> 3.4.2.5.</p>
<p>a. An element in Hom<strong><sub>Set</sub></strong>(<em>A</em>, <em>B</em>) × <em>A</em> is a pair (<em>f</em>, <em>a</em>), where <em>f</em> : <em>A</em> → <em>B</em> is a function and <em>a</em> ∈ <em>A</em> is an element. Applying <em>ev</em> to (<em>f</em>, <em>a</em>) returns <em>f</em>(<em>a</em>), an element of <em>B</em> as desired.</p>
<p>b. One might be tempted because they are the first two letters of the word <em>evaluate</em>—we evaluate the function <em>f</em> on the input <em>a</em>.</p>
<p>If <em>n</em> ∈ ℕ is a natural number, recall from (<a href="chapter002.html#lev_2-4">2.4</a>) that there is a set <em>n</em> = {1, 2, …, <em>n</em>}. If <em>A</em> is a set, we often make the abbreviation</p>
<p>An≔An¯.(3.24)</p>
<p><em>Exercise</em> 3.4.2.6.</p>
<p>Example <a href="chapter003.html#Exa_3-1-1-7">3.1.1.7</a> said that ℝ<sup>2</sup> is an abbreviation for ℝ × ℝ, but (<a href="chapter003.html#lev_3-24">3.24</a>) says that ℝ<sup>2</sup> is an abbreviation for ℝ<sup>2</sup> = Hom<strong><sub>Set</sub></strong>(2, ℝ). Use Exercise <a href="chapter002.html#Exe_2-1-2-20">2.1.2.20</a>, Exercise <a href="chapter003.html#Exe_3-1-2-12">3.1.2.12</a>, and the fact that 1+1=2, to prove that these are isomorphic, ℝ<sup>2</sup> ≅ ℝ × ℝ.</p>
<p>(The answer to Exercise <a href="chapter002.html#Exe_2-1-2-20">2.1.2.20</a> was <em>A</em> = {☺}; i.e., Hom<strong><sub>Set</sub></strong>({☺}, <em>X</em>) ≅ <em>X</em> for all <em>X</em>. The answer to Exercise <a href="chapter003.html#Exe_3-1-2-12">3.1.2.12</a> was Hom<strong><sub>Set</sub></strong>(<em>X</em> ⊔ <em>Y</em>, <em>A</em>) →≅ Hom<strong><sub>Set</sub></strong>(<em>X</em>, <em>A</em>) × Hom<strong><sub>Set</sub></strong>(<em>Y</em>, <em>A</em>).)</p>
<h2 id="lev_3-4-3" class="level2"><strong>3.4.3   Arithmetic of sets</strong></h2>
<p>Proposition <a href="chapter003.html#Pro_3-4-3-1">3.4.3.1</a> summarizes some properties of products, coproducts, and exponentials, and shows them all in a familiar light, namely, that of elementary school arithmetic. In fact, one can think of the natural numbers as literally being the isomorphism classes of finite sets—that is what they are used for in counting.</p>
<p>Consider the standard procedure for counting the elements of a set <em>S</em>, say, cows in a field. One points to an element in <em>S</em> and simultaneously says “one”, points to another element in <em>S</em> and simultaneously says “two”, and so on until finished. By pointing at a cow as you speak a number, you are drawing an imaginary line between the number and the cow. In other words, this procedure amounts to nothing more than creating an isomorphism (one-to-one mapping) between <em>S</em> and some set {1, 2, 3, …, <em>n</em>}.</p>
<p>Again, the natural numbers are the isomorphism classes of finite sets. Their behavior, i.e., the arithmetic of natural numbers, reflects the behavior of sets. For example, the fact that multiplication distributes over addition is a fact about grids of dots, as in Example <a href="chapter003.html#Exa_3-1-1-2">3.1.1.2</a>. The following proposition lays out such arithmetic properties of sets.</p>
<p>This proposition denotes the coproduct of two sets <em>A</em> and <em>B</em> by the notation <em>A</em> + <em>B</em> rather than <em>A</em> ⊔ <em>B</em>. It is a reasonable notation in general, and one that is often used.</p>
<p><strong>Proposition 3.4.3.1</strong>. <em>The following isomorphisms exist for any sets A, B, and C (except for one caveat; see Exercise <a href="chapter003.html#Exe_3-4-3-2">3.4.3.2</a>).</em></p>
<ul>
<li><em>A</em> + 0 ≅ <em>A</em></li>
<li><em>A</em> + <em>B</em> ≅ <em>B</em> + <em>A</em></li>
<li>(<em>A</em> + <em>B</em>) + <em>C</em> ≅ <em>A</em> + (<em>B</em> + <em>C</em>)</li>
<li><em>A</em> × 0 ≅ 0</li>
<li><em>A</em> × 1 ≅ <em>A</em></li>
<li><em>A</em> × <em>B</em> ≅ <em>B</em> × <em>A</em></li>
<li>(<em>A</em> × <em>B</em>) × <em>C</em> ≅ <em>A</em> × (<em>B</em> × <em>C</em>)</li>
<li><em>A</em> × (<em>B</em> + <em>C</em>) ≅ (<em>A</em> × <em>B</em>) + (<em>A</em> × <em>C</em>)</li>
<li><em>A</em><sup>0</sup> ≅ 1</li>
<li><em>A</em><sup>1</sup> ≅ <em>A</em></li>
<li>0<em><sup>A</sup></em> ≅ 0</li>
<li>1<em><sup>A</sup></em> ≅ 1</li>
<li><em>A</em><sup><em>B</em> + <em>C</em></sup> ≅ <em>A<sup>B</sup></em> × <em>A<sup>C</sup></em></li>
<li>(<em>A<sup>B</sup></em>)<em><sup>C</sup></em> ≅ <em>A</em><sup><em>B</em>×<em>C</em></sup></li>
<li>(<em>A</em> × <em>B</em>)<em><sup>C</sup></em> ≅ <em>A<sup>C</sup></em> × <em>B<sup>C</sup></em></li>
</ul>
<p><em>Exercise</em> 3.4.3.2.</p>
<p>Everything in Proposition <a href="chapter003.html#Pro_3-4-3-1">3.4.3.1</a> is true except in one case, namely, that of</p>
<p>0¯0¯.</p>
<p>In this case we get conflicting answers, because for any set <em>A</em>, including <em>A</em> = ∅ = 0, we have claimed both that <em>A</em><sup>0</sup> ≅ 1 and that 0<em><sup>A</sup></em> ≅ 0.</p>
<p>What is the correct answer for 0<sup>0</sup>, based on the definitions of 0 and 1, given in (<a href="chapter002.html#lev_2-4">2.4</a>), and of <em>A<sup>B</sup></em>, given in (<a href="chapter003.html#lev_3-21">3.21</a>)?</p>
<p><em>Solution</em> 3.4.3.2.</p>
<p>Hom<strong><sub>Set</sub></strong>(∅, ∅) has one element, so 0<sup>0</sup> ≅ 1.</p>
<p><em>Exercise</em> 3.4.3.3.</p>
<p>It is also true of natural numbers that if <em>a</em>, <em>b</em> ∈ ℕ and <em>ab</em> = 0, then either <em>a</em> = 0 or <em>b</em> = 0. Is the analogous statement true of all sets?</p>
<p>Proposition <a href="chapter003.html#Pro_3-4-3-1">3.4.3.1</a> is in some sense about isomorphisms. It says that understanding isomorphisms of finite sets reduces to understanding natural numbers. But note that there is much more going on in <strong>Set</strong> than isomorphisms; in particular, there are functions that are not invertible.</p>
<p>In grade school you probably never saw anything that looked like this:</p>
<p>53×3→5</p>
<p>And yet in Exercise <a href="chapter003.html#Exe_3-4-2-5">3.4.2.5</a> we found a function <em>ev</em> : <em>B<sup>A</sup></em> × <em>A</em> → <em>B</em> that exists for any sets <em>A</em>, <em>B</em>. This function <em>ev</em> is not an isomorphism, so it somehow does not show up as an equation of natural numbers. But it still has important meaning.<sup><a href="chapter003.html#endnote_6">6</a></sup> In terms of mere number, it looks like we are being told of an important function 575 → 5, which is bizarre. The issue here is precisely the one confronted in Exercise <a href="chapter002.html#Exe_2-1-2-19">2.1.2.19</a>.</p>
<p><em>Exercise</em> 3.4.3.4.</p>
<p>Explain why there is a canonical function 5<sup>3</sup> × 3 → 5, but not a canonical function 575 → 5.</p>
<p><em>Slogan</em> 3.4.3.5.</p>
<p><em>It is true that a set is isomorphic to any other set with the same number of elements, but do not be fooled into thinking that the study of sets reduces to the study of numbers. Functions that are not isomorphisms cannot be captured within the framework of numbers.</em></p>
<h2 id="lev_3-4-4" class="level2"><strong>3.4.4   Subobjects and characteristic functions</strong></h2>
<p><strong>Definition 3.4.4.1</strong>. For any set <em>B</em>, define the <em>power-set of B</em>, denoted ℙ(<em>B</em>), to be the set of subsets of <em>B</em>.</p>
<p><em>Exercise</em> 3.4.4.2.</p>
<p>a. How many elements does ℙ(∅) have?</p>
<p>b. How many elements does ℙ({☺}) have?</p>
<p>c. How many elements does ℙ({1, 2, 3, 4, 5, 6}) have?</p>
<p>d. Why it be named “power-set”?</p>
<p><em>Solution</em> 3.4.4.2.</p>
<p>a. |ℙ(∅)| = 1.</p>
<p>b. |ℙ({☺})| = 2.</p>
<p>c. |ℙ({1, 2, 3, 4, 5, 6})| = 64.</p>
<p>d. For any finite set <em>X</em>, we find that |ℙ(<em>X</em>)| = 2<sup>|<em>X</em>|</sup>, i.e., 2 to the <em>power</em> |<em>X</em>|.</p>
<h3 id="lev_3-4-4-3" class="level3"><strong>3.4.4.3   Simplicial complexes</strong></h3>
<p><strong>Definition 3.4.4.4</strong>. Let <em>V</em> be a set, let ℙ(<em>V</em>) be its power-set. Since each element <em>x</em> ∈ ℙ(<em>V</em>) is a subset <em>x</em> ⊆ <em>U</em>, we can make sense of the expression <em>x</em> ⊆ <em>x</em>′ for <em>x</em>, <em>x</em>′ ∈ ℙ(<em>V</em>). A subset <em>X</em> ⊆ ℙ(<em>V</em>) is called <em>downward-closed</em> if for every <em>u</em> ∈ <em>X</em> and every <em>u</em>′ ⊆ <em>u</em>, we have <em>u</em>′ ∈ <em>X</em>. We say that <em>X contains all atoms</em> if for every <em>v</em> ∈ <em>V</em>, the singleton set {<em>v</em>} is an element of <em>X</em>.</p>
<p>A <em>simplicial complex</em> is a pair (<em>V</em>, <em>X</em>), where <em>V</em> is a set and <em>X</em> ⊆ ℙ(<em>V</em>) is a downward-closed subset that contains all atoms. The elements of <em>X</em> are called <em>simplices</em> (singular: <em>simplex</em>). Any subset <em>u</em> ⊆ <em>V</em> has a cardinality |<em>u</em>|, so we have a function <em>X</em> → ℕ sending each simplex to its cardinality. The set of simplices with cardinality <em>n</em> + 1 is denoted <em>X<sub>n</sub></em>, and each element <em>x</em> ∈ <em>X<sub>n</sub></em> is called an <em>n-simplex</em>.<sup><a href="chapter003.html#endnote_7">7</a></sup> Since <em>X</em> contains all atoms (subsets of cardinality 1), we have an isomorphism <em>X</em><sub>0</sub> ≅ <em>V</em>, and we may also call the 0-simplices <em>vertices</em>. We sometimes call the 1-simplices <em>edges</em>.<sup><a href="chapter003.html#endnote_8">8</a></sup></p>
<p>Since <em>X</em><sub>0</sub> ≅ <em>V</em>, a simplicial complex (<em>V</em>, <em>X</em>) may simply be denoted <em>X</em>.</p>
<p><em>Example</em> 3.4.4.5. Let <em>n</em> ∈ ℕ be a natural number, and let <em>V</em> = <em>n</em> + 1. Define <em>the n-simplex</em>, denoted ∆<em><sup>n</sup></em>, to be the simplicial complex ℙ(<em>V</em>) ⊆ ℙ(<em>V</em>), i.e., the whole power-set, which indeed is downward-closed and contains all atoms.</p>
<p>We can draw a simplicial complex <em>X</em> by first putting all the vertices on the page as dots. Then for every <em>x</em> ∈ <em>X</em><sub>1</sub>, we see that <em>x</em> = {<em>v</em>, <em>v</em>′} consists of two vertices, and we draw an edge connecting <em>v</em> and <em>v</em>′. For every <em>y</em> ∈ <em>X</em><sub>2</sub> we see that <em>y</em> = {<em>w</em>, <em>w</em>′, <em>w</em>″} consists of three vertices, and we draw a (filed-in) triangle connecting them. All three edges will be drawn too, because <em>X</em> is assumed to be downward-closed.</p>
<p>The 0-simplex ∆<sup>0</sup>, the 1-simplex ∆<sup>1</sup>, the 2-simplex ∆<sup>2</sup>, and the 3-simplex ∆<sup>3</sup> are drawn here:</p>
<p><img src="images/Art_P76.jpg" alt="art" /></p>
<p>The <em>n</em>-simplices for various <em>n</em> ∈ ℕ are not the only simplicial complexes. In general, a simplicial complex is a union, or gluing together of simplices in a prescribed manner. For example, consider the simplicial complex <em>X</em> with vertices <em>X</em><sub>0</sub> = {1, 2, 3, 4}, edges <em>X</em><sub>1</sub> = {{1, 2}, {2, 3}, {2, 4}}, and no higher simplices <em>X</em><sub>2</sub> = <em>X</em><sub>3</sub> = ⋯ = ∅. We might draw <em>X</em> as follows:</p>
<p><img src="images/Art_P77.jpg" alt="art" /></p>
<p><em>Exercise</em> 3.4.4.6.</p>
<p>Let <em>X</em> be the following simplicial complex, so that <em>X</em><sub>0</sub> = {<em>A</em>, <em>B</em>, …, <em>M</em>}.</p>
<p><img src="images/Art_P78.jpg" alt="art" /></p>
<p>In this case <em>X</em><sub>1</sub> consists of elements like {<em>A</em>, <em>B</em>} and {<em>D</em>, <em>K</em>}, but not {<em>D</em>, <em>J</em>}.</p>
<p>Write <em>X</em><sub>2</sub>, <em>X</em><sub>3</sub>, and <em>X</em><sub>4</sub>. Hint: The drawing of <em>X</em> is supposed to indicate that <em>X</em><sub>3</sub> should have one element.</p>
<p><em>Exercise</em> 3.4.4.7.</p>
<p>The 2-simplex ∆<sup>2</sup> is drawn as a filled-in triangle with vertices <em>V</em> = {1, 2, 3}. There is a simplicial complex, often denoted <em>∂</em>∆<sup>2</sup>, that would be drawn as an empty triangle with the same set of vertices.</p>
<p>a. Draw ∆<sup>2</sup> and <em>∂</em>∆<sup>2</sup> side by side and make clear the difference.</p>
<p>b. Write <em>X</em> = <em>∂</em>∆<sup>2</sup> as a simplicial complex. In other words, what are the elements of the sets <em>X</em><sub>0</sub>, <em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, <em>X</em><sub>3</sub>, …?</p>
<h3 id="lev_3-4-4-8" class="level3"><strong>3.4.4.8   Subobject classifier</strong></h3>
<p>Given a subset <em>A</em> ⊆ <em>X</em>, we can decide for every element of <em>X</em> whether it is in <em>A</em> or not. This is a true/false question for <em>X</em>.</p>
<p><strong>Definition 3.4.4.9</strong>. We define the <em>subobject classifier</em> for <strong>Set</strong>, denoted Ω, to be the set Ω ≔ {<em>True</em>, <em>False</em>}, together with the function {☺} → Ω sending the unique element to <em>True</em>.</p>
<p><strong>Proposition 3.4.4.10</strong>. <em>Let X be a set. There is an isomorphism</em></p>
<p>ϕ:HomSet(X,Ω)→≅ℙ(X).</p>
<p><em>Proof.</em> Given a function <em>f</em> : <em>X</em> → Ω, let <em>ϕ</em>(<em>f</em>) = {<em>x</em> ∈ <em>X</em> | <em>f</em>(<em>x</em>) = <em>True</em>} ⊆ <em>X</em>. We now construct a function <em>ψ</em> : ℙ(<em>X</em>) → Hom<strong><sub>Set</sub></strong>(<em>X,</em> Ω) to serve as the inverse of <em>ϕ</em>. Given a subset <em>A</em> ⊆ <em>X</em>, we define</p>
<p>ψ(A):X→Ω  by ψ(i)(x)={ Trueif x∈A,Falseif x∉A.(3.25)</p>
<p>One checks easily that <em>ϕ</em> and <em>ψ</em> are mutually inverse.</p>
<p><em>Slogan</em> 3.4.4.11.</p>
<p><em>A function X to</em> Ω = {<em>True</em>, <em>False</em>} <em>is like a roll call. We are interested in the subset that calls out True.</em></p>
<p><strong>Definition 3.4.4.12</strong> (Characteristic function). Given a subset <em>A</em> ⊆ <em>X</em>, we define its <em>characteristic function of A in X</em> to be the function <em>ψ</em>(<em>A</em>): <em>X</em> → Ω, from (<a href="chapter003.html#lev_3-25">3.25</a>).</p>
<p>Let <em>X</em> be any set, and let ℙ(<em>X</em>) be its power-set. By Proposition <a href="chapter003.html#Pro_3-4-4-10">3.4.4.10</a> there is a bijection between ℙ(<em>X</em>) and Ω<em><sup>X</sup></em>. Since Ω has cardinality 2, the cardinality of ℙ(<em>X</em>) is 2<sup>|<em>X</em>|</sup>, which explains the correct answer to Exercise <a href="chapter003.html#Exe_3-4-4-2">3.4.4.2</a>.</p>
<p><em>Exercise</em> 3.4.4.13.</p>
<p>Let <em>f</em> : <em>X</em> → Ω denote the characteristic function of some subset <em>A</em> ⊆ <em>X</em>, and define <em>A</em>′ = <em>X</em> − <em>A</em> to be its complement, i.e., <em>A</em>′ = {<em>x</em> ∈ <em>X</em> | <em>x</em> ∉ <em>A</em>}.</p>
<p>a. What is the characteristic function of <em>A</em>′ ⊆ <em>X</em>?</p>
<p>b. Can you phrase it in terms of <em>f</em> and some function Ω → Ω?</p>
<h2 id="lev_3-4-5" class="level2"><strong>3.4.5   Surjections, injections</strong></h2>
<p>The classical definition of injections and surjections, given in Definition <a href="chapter003.html#Def_3-4-5-1">3.4.5.1</a> involves elements. But a more robust notion involves functions; it is given in Proposition <a href="chapter003.html#Pro_3-4-5-8">3.4.5.8</a>.</p>
<p><strong>Definition 3.4.5.1</strong>. Let <em>f</em> : <em>X</em> → <em>Y</em> be a function.</p>
<ul>
<li>We say that <em>f</em> is <em>injective</em> if for all <em>x</em>, <em>x</em>′ ∈ <em>X</em> with <em>f</em>(<em>x</em>) = <em>f</em>(<em>x</em>′), we have <em>x</em> = <em>x</em>′.</li>
<li>We say that <em>f</em> is <em>surjective</em> if for all <em>y</em> ∈ <em>Y</em>, there exists some <em>x</em> ∈ <em>X</em> such that <em>f</em>(<em>x</em>) = <em>y</em>.</li>
<li>We say that <em>f</em> is <em>bijective</em> if it is both injective and surjective.</li>
</ul>
<p>We sometimes denote an injective function <em>X</em> ↪ <em>Y</em>, a surjective function <em>X</em> ↠ <em>Y</em>, and a bijective function <em>X</em> →≅ <em>Y</em> (see Proposition <a href="chapter003.html#Pro_3-4-5-4">3.4.5.4</a>).</p>
<p><em>Exercise</em> 3.4.5.2.</p>
<p>a. Is the function <em>f</em> : ℤ → ℕ, given by <em>f</em>(<em>n</em>) = <em>n</em><sup>2</sup>, injective, surjective, or neither?</p>
<p>b. Is the function <em>g</em> : ℕ → ℕ, given by <em>g</em>(<em>n</em>) = <em>n</em><sup>2</sup>, injective, surjective, or neither?</p>
<p>c. Is the function <em>h</em>: ℤ → ℕ, given by <em>h</em>(<em>n</em>) = |<em>n</em>| (the absolute value), injective, surjective, or neither?</p>
<p>d. Is the function <em>i</em>: ℤ → ℤ, given by <em>i</em>(<em>n</em>) = −<em>n</em>, injective, surjective, or neither?</p>
<p><em>Exercise</em> 3.4.5.3.</p>
<p>Let <em>f</em> : <em>X</em> → <em>Y</em> and <em>g</em> : <em>Y</em> → <em>Z</em> be functions.</p>
<p>a. Show that if <em>f</em> and <em>g</em> are injections, then so is <em>g</em> ○ <em>f</em>.</p>
<p>b. Show that if <em>f</em> and <em>g</em> are both surjections, then so is <em>g</em> ○ <em>f</em>.</p>
<p>c. Show that if <em>g</em> ○ <em>f</em> is an injection, then so is <em>f</em>.</p>
<p>d. Show that if <em>g</em> ○ <em>f</em> is a surjection, then so is <em>g</em>.</p>
<p><em>Solution</em> 3.4.5.3.</p>
<p>a. Let <em>x</em>, <em>x</em>′ ∈ <em>X</em> and suppose that <em>g</em> ○ <em>f</em>(<em>x</em>) = <em>g</em> ○ <em>f</em>(<em>x</em>′). Then <em>g</em>(<em>f</em>(<em>x</em>)) = <em>g</em>(<em>f</em>(<em>x</em>′)), so the injectivity of <em>g</em> implies that <em>f</em>(<em>x</em>) = <em>f</em>(<em>x</em>′); the injectivity of <em>f</em> implies that <em>x</em> = <em>x</em>′.</p>
<p>b. Let <em>z</em> ∈ <em>Z</em> be an element. The surjectivity of <em>g</em> implies that there is some <em>y</em> ∈ <em>Y</em> with <em>g</em>(<em>y</em>) = <em>z</em>; the surjectivity of <em>f</em> implies that there is some <em>x</em> ∈ <em>X</em> with <em>f</em>(<em>x</em>) = <em>y</em>.</p>
<p>c. Let <em>x</em>, <em>x</em>′ ∈ <em>X</em> and suppose that <em>f</em>(<em>x</em>) = <em>f</em>(<em>x</em>′). Because <em>g</em> is a function, <em>g</em> ○ <em>f</em>(<em>x</em>) = <em>g</em> ○ <em>f</em>(<em>x</em>′), and now the injectivity of <em>g</em> ○ <em>f</em> implies that <em>x</em> = <em>x</em>′.</p>
<p>d. Let <em>z</em> ∈ <em>Z</em> be an element. The surjectivity of <em>g</em> ○ <em>f</em> implies that there is some <em>x</em> ∈ <em>X</em> with <em>g</em> ○ <em>f</em>(<em>x</em>) = <em>z</em>. But then we have found <em>y</em> ≔ <em>f</em>(<em>x</em>) ∈ <em>Y</em> with <em>g</em>(<em>y</em>) = <em>z</em>.</p>
<p><strong>Proposition 3.4.5.4</strong>. <em>A function f</em> : <em>X</em> → <em>Y is bijective if and only if it is an isomorphism.</em></p>
<p><em>Proof.</em> Suppose that <em>f</em> is bijective; we define an inverse <em>g</em> : <em>Y</em> → <em>X</em>. For each <em>y</em> ∈ <em>Y</em>, the preimage <em>f</em><sup>−1</sup>(<em>y</em>) ⊆ <em>X</em> is a set with exactly one element. Indeed, it has at least one element because <em>f</em> is surjective, and it has at most one element because <em>f</em> is injective. Define <em>g</em>(<em>y</em>) to be the unique element of <em>f</em><sup>−1</sup>(<em>y</em>). It is easy to see that <em>f</em> and <em>g</em> are mutually inverse.</p>
<p>Note that for every set <em>X</em>, the identity function id<em><sub>X</sub></em> : <em>X</em> → <em>X</em> is bijective. Suppose now that <em>f</em> is an isomorphism, and let <em>g</em> be its inverse. The composition <em>g</em> ○ <em>f</em> = id<em><sub>X</sub></em> is injective, and the composition <em>f</em> ○ <em>g</em> = id<em><sub>Y</sub></em> is surjective, so <em>f</em> is injective and surjective by Exercise <a href="chapter003.html#Exe_3-4-5-3">3.4.5.3</a>.</p>
<p><strong>Proposition 3.4.5.5</strong>. <em>Let m, n</em> ∈ ℕ <em>be natural numbers. Then m</em> ⩽ <em>n if and only if there exists an injection m</em> ↪ <em>n.</em></p>
<p><em>Sketch of proof.</em> If <em>m</em> ⩽ <em>n</em>, then there is an inclusion {1, 2, …, <em>m</em>} → {1, 2, …, <em>n</em>}. Suppose now that we are given an injection <em>f</em> : <em>m</em> → <em>n</em>; we assume that <em>m</em> &gt; <em>n</em> and derive a contradiction. If <em>m</em> &gt; <em>n</em>, then <em>n</em> + 1 ⩽ <em>m</em>, and we have already shown that there exists an injection <em>g</em> : <em>n</em> + 1 ↪ <em>m</em>. Composing, we have an injection <em>h</em> ≔ <em>g</em> ○ <em>f</em> : <em>n</em> + 1 ↪ <em>n</em> by Exercise <a href="chapter003.html#Exe_3-4-5-3">3.4.5.3</a>. One can show by induction on <em>n</em> that this is impossible.</p>
<p><strong>Corollary 3.4.5.6</strong>. <em>Let m, n</em> ∈ ℕ <em>be natural numbers. Then m</em> = <em>n if and only if there exists an isomorphism f</em> : <em>m</em> →≅ <em>n.</em></p>
<p><em>Proof.</em> If <em>m</em> = <em>n</em>, then the identity id<em><sub>m</sub></em> : <em>m</em> → <em>n</em> is an isomorphism.</p>
<p>On the other hand, if we have an isomorphism <em>f</em> : <em>m</em> →≅ <em>n</em>, then both it and its inverse are injective by Proposition <a href="chapter003.html#Pro_3-4-5-4">3.4.5.4</a>. Thus <em>m</em> ⩽ <em>n</em> and <em>n</em> ⩽ <em>m</em> by Proposition <a href="chapter003.html#Pro_3-4-5-5">3.4.5.5</a>, which implies <em>m</em> = <em>n</em>.</p>
<p><strong>Definition 3.4.5.7</strong> (Monomorphisms, epimorphisms). Let <em>f</em> : <em>X</em> → <em>Y</em> be a function.</p>
<p>We say that <em>f</em> is a <em>monomorphism</em> if for all sets <em>A</em> and pairs of functions <em>g</em>, <em>g</em>′ : <em>A</em> → <em>X</em>,</p>
<p><img src="images/Art_P79.jpg" alt="art" /></p>
<p>if <em>f</em> ○ <em>g</em> = <em>f</em> ○ <em>g</em>′, then <em>g</em> = <em>g</em>′.</p>
<p>We say that <em>f</em> is an <em>epimorphism</em> if for all sets <em>B</em> and pairs of functions <em>h</em>, <em>h</em>′ : <em>Y</em> → <em>B</em>,</p>
<p><img src="images/Art_P80.jpg" alt="art" /></p>
<p>if <em>h</em> ○ <em>f</em> = <em>h</em>′ ○ <em>f</em>, then <em>h</em> = <em>h</em>′.</p>
<p><strong>Proposition 3.4.5.8</strong>. <em>Let f</em> : <em>X</em> → <em>Y be a function. Then f is injective if and only if it is a monomorphism; f is surjective if and only if it is an epimorphism.</em></p>
<p><em>Proof.</em> We use notation as in Definition <a href="chapter003.html#Def_3-4-5-7">3.4.5.7</a>.</p>
<p>If <em>f</em> is a monomorphism, it is clearly injective by putting <em>A</em> = {☺}. Suppose that <em>f</em> injective, and let <em>g</em>, <em>g</em>′ : <em>A</em> → <em>X</em> be functions such that <em>f</em> ○ <em>g</em> = <em>f</em> ○ <em>g</em>′, but suppose for contradiction that <em>g</em> ≠ <em>g</em>′. Then there is some element <em>a</em> ∈ <em>A</em> such <em>g</em>(<em>a</em>) ≠ <em>g</em>′(<em>a</em>) ∈ <em>X</em>. But by injectivity <em>f</em>(<em>g</em>(<em>a</em>)) ≠ <em>f</em>(<em>g</em>′(<em>a</em>)), contradicting the fact that <em>f</em> ○ <em>g</em> = <em>f</em> ○ <em>g</em>′.</p>
<p>Suppose that <em>f</em> : <em>X</em> → <em>Y</em> is an epimorphism, and choose some <em>y</em><sub>0</sub> ∈ <em>Y</em> (noting that if <em>Y</em> is empty, then the claim is vacuously true). Let <em>B</em> = Ω, and let <em>h</em>: <em>Y</em> → Ω denote the characteristic function of the subset {<em>y</em><sub>0</sub>} ⊆ <em>Y</em>, and let <em>h</em>′ : <em>Y</em> → Ω denote the characteristic function of ∅ ⊆ <em>Y</em>. Note that <em>h</em>(<em>y</em>) = <em>h</em>′(<em>y</em>) for all <em>y</em> ≠ <em>y</em><sub>0</sub>. Then since <em>f</em> is an epimorphism and <em>h</em> ≠ <em>h</em>′, we must have <em>h</em> ○ <em>f</em> ≠ <em>h</em>′ ○ <em>f</em>, so there exists <em>x</em> ∈ <em>X</em> with <em>h</em>(<em>f</em>(<em>x</em>)) ≠ <em>h</em>′(<em>f</em>(<em>x</em>)), which implies that <em>f</em>(<em>x</em>) = <em>y</em><sub>0</sub>. This proves that <em>f</em> is surjective.</p>
<p>Finally, suppose that <em>f</em> is surjective, and let <em>h</em>, <em>h</em>′ : <em>Y</em> → <em>B</em> be functions with <em>h</em> ○ <em>f</em> = <em>h</em>′ ○ <em>f</em>. For any <em>y</em> ∈ <em>Y</em>, there exists some <em>x</em> ∈ <em>X</em> with <em>f</em>(<em>x</em>) = <em>y</em>, so <em>h</em>(<em>y</em>) = <em>h</em>(<em>f</em>(<em>x</em>)) = <em>h</em>′(<em>f</em>(<em>x</em>)) = <em>h</em>′(<em>y</em>). This proves that <em>f</em> is an epimorphism.</p>
<p><strong>Proposition 3.4.5.9</strong>. <em>Let g</em> : <em>A</em> → <em>Y be a monomorphism. Then for any function f</em> : <em>X</em> → <em>Y</em>, <em>the left-hand map g</em>′ : <em>X</em> ×<em><sub>Y</sub> A</em> → <em>X in the diagram</em></p>
<p><img src="images/Art_P81.jpg" alt="art" /></p>
<p><em>is a monomorphism.</em></p>
<p><em>Proof.</em> To show that <em>g</em>′ is a monomorphism, we take an arbitrary set <em>B</em> and two maps <em>m</em>, <em>n</em>: <em>B</em> → <em>X</em> ×<em><sub>Y</sub> A</em> such that <em>g</em>′ ○ <em>m</em> = <em>g</em>′ ○ <em>n</em>, denoting that function <em>p</em> ≔ <em>g</em>′ ○ <em>m</em>: <em>B</em> → <em>X</em>. Now let <em>q</em> = <em>f</em>′ ○ <em>m</em> and <em>r</em> = <em>f</em>′ ○ <em>n</em>. The diagram looks like this:</p>
<p><img src="images/Art_P82.jpg" alt="art" /></p>
<p>We have that</p>
<p>g∘q=g∘f′∘m=f∘g′∘m=f∘p=f∘g′∘n=g∘f′∘n=g∘r</p>
<p>But we assumed that <em>g</em> is a monomorphism, so this implies that <em>q</em> = <em>r</em>. By the universal property for pullbacks, Proposition <a href="chapter003.html#Pro_3-2-1-15">3.2.1.15</a>, we have <em>m</em> = <em>n</em> = 〈<em>q</em>, <em>p</em>〉<em><sub>Y</sub></em> : <em>B</em> → <em>X</em> ×<em><sub>Y</sub> A</em>.</p>
<p><em>Example</em> 3.4.5.10. Suppose an olog has a fiber product square</p>
<p><img src="images/Art_P83.jpg" alt="art" /></p>
<p>such that <em>g</em> is intended to be a monomorphism and <em>f</em> is any map.<sup><a href="chapter003.html#endnote_9">9</a></sup> In this case, there are labeling systems for <em>f</em>′, <em>g</em>′, and <em>X</em> ×<em><sub>Y</sub> A</em>. Namely,</p>
<ul>
<li>“is” is an appropriate label for <em>g</em> and <em>g</em>′;</li>
<li>the label for <em>f</em> is an appropriate label for <em>f</em>′;</li>
<li>〈〈<em>X</em> ×<em><sub>Y</sub> A</em>〉〉 ≔ “〈〈<em>X</em>〉〉, which 〈〈<em>f</em>〉〉 〈〈<em>A</em>〉〉” is an appropriate label for <em>X</em> ×<em><sub>Y</sub> A</em>.</li>
</ul>
<p>To give an explicit example,</p>
<p><img src="images/Art_P84.jpg" alt="art" /></p>
<p><strong>Corollary 3.4.5.11</strong>. <em>Let i</em>: <em>A</em> → <em>X be a monomorphism, and let True</em>: {☺} → Ω <em>be the subobject classifier (see Definition <a href="chapter003.html#Def_3-4-4-9">3.4.4.9</a>). Then there is a fiber product square of the form</em></p>
<p><img src="images/Art_P85.jpg" alt="art" /></p>
<p><em>Proof.</em> Let <em>X</em>′ ⊆ <em>X</em> denote the image of <em>i</em>, and let <em>f</em> : <em>X</em> → Ω denote the characteristic function of <em>X</em>′ ⊆ <em>X</em>, given by Proposition <a href="chapter003.html#Pro_3-4-4-10">3.4.4.10</a>. Then it is easy to check that diagram (<a href="chapter003.html#lev_3-26">3.26</a>) is a pullback.</p>
<p><em>Exercise</em> 3.4.5.12.</p>
<p>Consider the subobject classifier Ω = {<em>True</em>, <em>False</em>}, the singleton {☺}, and the map {☺} →True Ω from Definition <a href="chapter003.html#Def_3-4-4-9">3.4.4.9</a>. In diagram (<a href="chapter003.html#lev_3-26">3.26</a>), in the spirit of Example <a href="chapter003.html#Exa_3-4-5-10">3.4.5.10</a>, devise a label for Ω, a label for {☺}, and a label for <em>True</em>. Given a subobject <em>A</em> ⊆ <em>X</em>, both labeled, devise a label for <em>f</em>, a label for <em>i</em>, and a label for <em>f</em>′ such that the English smoothly fits the mathematics.</p>
<p><em>Exercise</em> 3.4.5.13.</p>
<p>Show, in analogy to Proposition <a href="chapter003.html#Pro_3-4-5-9">3.4.5.9</a>, that pushouts preserve epimorphisms.</p>
<h2 id="lev_3-4-6" class="level2"><strong>3.4.6   Multisets, relative sets, and set-indexed sets</strong></h2>
<p>In this section we prepare to consider categories other than <strong>Set</strong> by looking at some categories related to <strong>Set</strong>.</p>
<h3 id="lev_3-4-6-1" class="level3"><strong>3.4.6.1   Multisets</strong></h3>
<p>Consider the set <em>X</em> of words in a given document. If <em>WC</em>(<em>X</em>) is the word count of the document, we do not generally have <em>WC</em>(<em>X</em>) = |<em>X</em>|. The reason is that a set cannot contain the same element more than once, so words like <em>the</em> might be undercounted in |<em>X</em>|. A <em>multiset X</em> consists of a set of names, <em>N<sub>X</sub></em>, and each name is assigned a multiplicity, i.e., a positive finite number of times it is to be counted. For example, the multiset <em>X</em> =(The, man, just, ate, and, ate, and, ate) has names <em>N<sub>X</sub></em> = {The, man, just, ate, and}, and these names have multiplicity 1, 1, 1, 3, 2 respectively.</p>
<p>But if <em>X</em> and <em>Y</em> are multisets, what is the appropriate type of mapping from <em>X</em> to <em>Y</em>? Since every set can be cast as a multiset (in which each element has multiplicity 1), let’s restrict ourselves to notions of mapping that agree with the usual one on sets. That is, if multisets <em>X</em> and <em>Y</em> happen to be ordinary sets, then our mappings <em>X</em> → <em>Y</em> should just be functions.</p>
<p>In order to define what I believe is the appropriate notion of mapping of multisets, it is useful to take a step back from this definition. The role of the natural numbers in multisets is to count the number of occurrences of each element. The point perhaps is not the number, but the set of occurrences it counts. Each occurrence has a name, so we have a function from occurrences to names. The fact that every name has multiplicity at least 1 means that this function is surjective. So I suggest the following definition of multisets and mappings.</p>
<p><strong>Definition 3.4.6.2</strong>. A <em>multiset</em> is a sequence <em>X</em> ≔ (<em>Oc</em>, <em>N</em>, <em>π</em>), where <em>Oc</em> and <em>N</em> are sets and <em>π</em> : <em>Oc</em> → <em>N</em> is a surjective function. We refer to <em>Oc</em> as the set of <em>occurrences in X</em>, to <em>N</em> as the set of <em>names in X</em>, and to <em>π</em> as the <em>naming function for X</em>. Given a name <em>x</em> ∈ <em>N</em>, let <em>π</em><sup>−1</sup>(<em>x</em>) ⊆ <em>Oc</em> be the preimage; the number of elements in <em>π</em><sup>−1</sup>(<em>x</em>) is called the <em>multiplicity of x</em>.</p>
<p>Suppose that <em>X</em> = (<em>Oc</em>, <em>N</em>, <em>π</em>) and <em>X</em>′ = (<em>Oc</em>′, <em>N</em>′, <em>π</em>′) are multisets. A <em>mapping from X to Y</em>, denoted <em>f</em> : <em>X</em> → <em>Y</em>, consists of a pair (<em>f</em><sub>1</sub>, <em>f</em><sub>0</sub>) such that <em>f</em><sub>1</sub> : <em>Oc</em> → <em>Oc</em>′ and <em>f</em><sub>0</sub> : <em>N</em> → <em>N</em>′ are functions and such that the following diagram commutes:</p>
<p><img src="images/Art_P86.jpg" alt="art" /></p>
<p><em>Exercise</em> 3.4.6.3.</p>
<p>Suppose that a pseudo-multiset is defined to be almost the same as a multiset, except that <em>π</em> is not required to be surjective.</p>
<p>a. Write a pseudo-multiset that is not a multiset.</p>
<p>b. Describe the difference between the two notions (multiset vs. pseudo-multiset) in terms of multiplicities.</p>
<p><em>Exercise</em> 3.4.6.4.</p>
<p>Consider the multisets <em>X</em> = (<em>a</em>, <em>a</em>, <em>b</em>, <em>c</em>) and <em>Y</em> = (<em>d</em>, <em>d</em>, <em>e</em>, <em>e</em>, <em>e</em>).</p>
<p>a. Write each of them in the form (<em>Oc</em>, <em>N</em>, <em>π</em>), as in Definition <a href="chapter003.html#Def_3-4-6-2">3.4.6.2</a>.</p>
<p>b. In terms of the same definition, how many mappings <em>X</em> → <em>Y</em> are there?</p>
<p>c. If we were to remove the restriction that diagram (<a href="chapter003.html#lev_3-27">3.27</a>) must commute, how many mappings <em>X</em> → <em>Y</em> would there be?</p>
<h3 id="lev_3-4-6-5" class="level3"><strong>3.4.6.5   Relative sets</strong></h3>
<p>Continuing with ideas from multisets, let’s suppose that we have a fixed set <em>N</em> of names that we want to keep once and for all. Whenever someone discusses a set, each of its elements must have a name in <em>N</em>. And whenever someone discusses a mapping, it must preserve the naming. For example, if <em>N</em> is the set of English words, then every document consists of a set {1, 2, 3, …, <em>n</em>} mapping to <em>N</em> (e.g., 1 ↦ Continuing, 2 ↦ with, 3 ↦ ideas, …). A mapping from document <em>A</em> to document <em>B</em> would send each word found somewhere in <em>A</em> to the same word found somewhere in <em>B</em>. This notion is defined in the following definition.</p>
<p><strong>Definition 3.4.6.6</strong> (Relative set). Let <em>N</em> be a set. A <em>relative set over N</em>, or simply a <em>set over N</em>, is a pair (<em>E</em>, <em>π</em>) such that <em>E</em> is a set and <em>π</em> : <em>E</em> → <em>N</em> is a function. A <em>mapping of relative sets over N</em>, denoted <em>f</em> : (<em>E</em>, <em>π</em>) → (<em>E</em>′, <em>π</em>′), is a function <em>f</em> : <em>E</em> → <em>E</em>′ such that the following triangle commutes, i.e., <em>π</em> = <em>π</em>′ ○ <em>f</em>:</p>
<p><img src="images/Art_P87.jpg" alt="art" /></p>
<p><em>Exercise</em> 3.4.6.7.</p>
<p>Given sets <em>X</em>, <em>Y</em>, <em>Z</em> and functions <em>f</em> : <em>X</em> → <em>Y</em> and <em>g</em> : <em>Y</em> → <em>Z</em>, we can compose them to get a function <em>X</em> → <em>Z</em>. If <em>N</em> is a set, if (<em>X</em>, <em>p</em>), (<em>Y</em>, <em>q</em>), and (<em>Z</em>, <em>r</em>) are relative sets over <em>N</em>, and if <em>f</em> : (<em>X</em>, <em>p</em>) → (<em>Y</em>, <em>q</em>) and <em>g</em> : (<em>Y</em>, <em>q</em>) → (<em>Z</em>, <em>r</em>) are mappings of relative sets, is there a reasonable notion of composition such that we get a mapping of relative sets(<em>X</em>, <em>p</em>) → (<em>Z</em>, <em>r</em>)? Hint: Draw diagrams.</p>
<p><em>Exercise</em> 3.4.6.8.</p>
<p>a. Let {☺} denote a set with one element. What is the difference between sets relative to <em>N</em> ≔ {☺} and simply sets?</p>
<p>b. Describe the sets relative to ∅. How many are there?</p>
<h3 id="lev_3-4-6-9" class="level3"><strong>3.4.6.9   Indexed sets</strong></h3>
<p>Let <em>A</em> be a set. Suppose we want to assign to each element <em>a</em> ∈ <em>A</em> a set <em>S<sub>a</sub></em>. This is called an <em>A</em>-indexed set. In category theory we are always interested in the legal mappings between two different objects of the same sort of structure, so we need a notion of <em>A</em>-indexed mappings.</p>
<p><em>Example</em> 3.4.6.10. Let <em>C</em> be a set of classrooms. For each <em>c</em> ∈ <em>C</em>, let <em>P<sub>c</sub></em> denote the set of people in classroom <em>c</em>, and let <em>S<sub>c</sub></em> denote the set of seats (chairs) in classroom <em>c</em>. Then <em>P</em> and <em>S</em> are <em>C</em>-indexed sets. The appropriate kind of mapping between them respects the indices. That is, a mapping of <em>C</em>-indexed sets <em>P</em> → <em>S</em> should, for each classroom <em>c</em> ∈ <em>C</em>, be a function <em>P<sub>c</sub></em> → <em>S<sub>c</sub></em>.<sup><a href="chapter003.html#endnote_10">10</a></sup></p>
<p><strong>Definition 3.4.6.11</strong>. Let <em>A</em> be a set. An <em>A-indexed set</em> is a collection of sets <em>S<sub>a</sub></em>, one for each element <em>a</em> ∈ <em>A</em>; for now we denote this (<em>S<sub>a</sub></em>)<sub><em>a</em>∈<em>A</em></sub>. Each element <em>a</em> ∈ <em>A</em> is called an <em>index</em>. If (Sa’)a∈A is another <em>A</em>-indexed set, an <em>A-indexed function from</em> (<em>S<sub>a</sub></em>)<sub><em>a</em>∈<em>A</em></sub> to (Sa’)a∈A, denoted</p>
<p>(fa)a∈A:(Sa)a∈A→(Sa′)a∈A,</p>
<p>is a collection of functions <em>f<sub>a</sub></em> : <em>S<sub>a</sub></em> → Sa’, one for each element <em>a</em> ∈ <em>A</em>.</p>
<p><em>Exercise</em> 3.4.6.12.</p>
<p>Let {☺} denote a one-element set. What are {☺}-indexed sets and {☺}-indexed functions?</p>
<p><em>Exercise</em> 3.4.6.13.</p>
<p>There is a strong relationship between <em>A</em>-indexed sets and relative sets over <em>A</em>. What is it?</p>
<p>__________________</p>
<p><a href="chapter003.html#endnote_ref_1"><sup>1</sup></a>We are using a two-line symbol, which is a bit unusual. A certain function <em>X</em> ⊔ <em>Y</em> → <em>A</em> is being denoted by the symbol {fg, called <em>case notation</em>. The reasoning for this will be clear from the proof, especially (<a href="chapter003.html#lev_3-6">3.6</a>).</p>
<p><a href="chapter003.html#endnote_ref_2"><sup>2</sup></a>You may use shadings rather than coloring, if you prefer.</p>
<p><a href="chapter003.html#endnote_ref_3"><sup>3</sup></a>The following diagram commutes:</p>
<p><img src="images/Art_P65a.jpg" alt="art" /></p>
<p><a href="chapter003.html#endnote_ref_4"><sup>4</sup></a>The meaning of <em>iff</em> is “if and only if.” In this case we are saying that the pair (<em>x</em>, <em>y</em>) is in <em>R</em> if and only if there exists an arrow connecting <em>x</em> and <em>y</em>.</p>
<p><a href="chapter003.html#endnote_ref_5"><sup>5</sup></a>Note that the term <em>inclusion</em> is not too good because it seems to suggest that <em>i</em><sub>1</sub> and <em>i</em><sub>2</sub> are injective (see Definition <a href="chapter003.html#Def_3-4-5-1">3.4.5.1</a>) and this is not always the case. The reason we use <em>inclusion</em> terminology is to be consistent with the terminology of coproducts. The functions <em>i</em><sub>1</sub> and <em>i</em><sub>2</sub> are sometimes called <em>coprojections</em>.</p>
<p><a href="chapter003.html#endnote_ref_6"><sup>6</sup></a>Roughly, the existence of <em>ev</em> : 5<sup>3</sup> × 3 → 5 says that given a dot in a 5 × 5 × 5 grid of dots, and given one of the three axes, one can tell the coordinate of that dot along that axis.</p>
<p><a href="chapter003.html#endnote_ref_7"><sup>7</sup></a>It seems anomalous that the set of subsets with cardinality 2 is denoted <em>X</em><sub>1</sub>, and so on. But this is standard convention because it fits with the standard notion of dimension: each element of <em>X</em><sub>1</sub> corresponds to a two-dimensional shape, and more generally, each element of <em>X<sub>n</sub></em> is <em>n</em>-dimensional.</p>
<p><a href="chapter003.html#endnote_ref_8"><sup>8</sup></a>The reason I write <em>X</em><sub>0</sub> ≅ <em>V</em> rather than <em>X</em><sub>0</sub> = <em>V</em> is that <em>X</em><sub>0</sub> is the set of one-element subsets of <em>V</em>. So if <em>V</em> = {<em>a</em>, <em>b</em>, <em>c</em>}, then <em>X</em><sub>0</sub> = {{<em>a</em>}, {<em>b</em>}, {<em>c</em>}}. This is really just pedantry.</p>
<p><a href="chapter003.html#endnote_ref_9"><sup>9</sup></a>Of course, this diagram is symmetrical, so the same ideas hold if <em>f</em> is a monomorphism and <em>g</em> is any map.</p>
<p><a href="chapter003.html#endnote_ref_10"><sup>10</sup></a>If we wanted to allow people from any classroom to choose a chair from just any classroom, category theory would tell us to reconsider <em>P</em> and <em>S</em> as sets, forgetting their <em>C</em>-indices. See Section <a href="chapter007.html#lev_7-1-4-6">7.1.4.6</a>.</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter002.html">previous</a>, <a href="chapter004.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter003.html">previous</a>, <a href="chapter005.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<h1 class="chapter-number"><a href="toc.html#chap-4"><strong>Chapter 4</strong></a></h1>
<h1 class="chapter-title"><a href="toc.html#chap-4"><strong>Categories and Functors, Without Admitting It</strong></a></h1>
<p>In this chapter we begin to use our understanding of sets to examine more interesting mathematical worlds, each of which organizes understanding of a certain kind of domain. For example, monoids organize thoughts about agents acting on objects. Groups are monoids except restricted to only allow agents to act in reversible ways. We then study graphs, which are systems of nodes and arrows that can capture ideas like information flow through a network or model connections between building blocks in a material. We discuss orders, which can be used to study taxonomies or hierarchies. Finally we take a mathematical look at databases, which actually subsume everything else in the chapter. Databases are connection patterns for structuring information.</p>
<p>Everything studied in this chapter is an example of a category (see Chapter 5). So is <strong>Set</strong>, the category of sets studied in Chapters 2 and 3. One way to think of a category is as a bunch of objects and a connection pattern between them. The category <strong>Set</strong> has individual sets as objects, with functions serving as the connections between them. But there is a certain self-similarity here—each set, thought of as a bag of dots, can itself be viewed as a category: the objects inside it are just disconnected. Each set <em>is</em> a category, but there is also a category <em>of</em> sets. In this way, sets have an interior view and an exterior view, as do all the categories in this chapter. Each monoid <em>is</em> a category, but there is also a category <em>of</em> monoids.</p>
<p>However, the word <em>category</em> is not used much in this chapter. It seems preferable to let the ideas arise as interesting structures in their own right before explaining how everything fits into a single framework.</p>
<h1 id="lev_4-1" class="level1"><a href="toc.html#Rlev_4-1"><strong>4.1   Monoids</strong></a></h1>
<p>A common way to interpret phenomena around us is to say that agents are acting on objects. For example, the user of a computer drawing program <em>acts on</em> the canvas in certain prescribed ways. Choices of actions from an available list can be performed in sequence to transform one image into another. As another example, one might investigate the notion that time <em>acts on</em> the position of hands on a clock in a prescribed way. A first rule for actions is captured in the following slogan.</p>
<p><em>Slogan</em> 4.1.0.14.</p>
<p><em>The performance of a sequence of several actions is itself the performance of an action—a more complex action, but an action nonetheless.</em></p>
<p>Mathematical objects called <em>monoids</em> and <em>groups</em> are tasked with encoding the agent’s perspective, i.e., what the agent can do, and what happens when she does a sequence of actions in succession. A monoid can be construed as a set of actions together with a formula that encodes how a sequence of actions is itself considered an action. A group is the same as a monoid except that every action is required to be reversible.</p>
<h2 id="lev_4-1-1" class="level2"><strong>4.1.1   Definition and examples</strong></h2>
<p><strong>Definition 4.1.1.1</strong> (Monoid). A <em>monoid</em> is a sequence (<em>M</em>, <em>e</em>, ⋆), where <em>M</em> is a set, <em>e</em> ∈ <em>M</em> is an element, and ⋆: <em>M</em> × <em>M</em> → <em>M</em> is a function, such that the following <em>monoid laws</em> hold for all <em>m</em>, <em>n</em>, <em>p</em> ∈ <em>M</em>:</p>
<ul>
<li><em>m</em> ⋆ <em>e</em> = <em>m</em>.</li>
<li><em>e</em> ⋆ <em>m</em> = <em>m</em>.</li>
<li>(<em>m</em> ⋆ <em>n</em>) ⋆ <em>p</em> = <em>m</em> ⋆ (<em>n</em> ⋆ <em>p</em>).</li>
</ul>
<p>We refer to <em>e</em> as the <em>unit element</em> and to ⋆ as the <em>multiplication formula</em> for the monoid.<sup><a href="chapter004.html#endnote_1">1</a></sup> We call the first two rules <em>unit laws</em> and the third rule the <em>associativity law</em> for monoids.</p>
<p><em>Remark</em> 4.1.1.2. To be pedantic, the conditions from Definition <a href="chapter004.html#Def_4-1-1-1">4.1.1.1</a> should be stated</p>
<ul>
<li>⋆(<em>m</em>, <em>e</em>) = <em>m</em>.</li>
<li>⋆(<em>e</em>, <em>m</em>) = <em>m</em>.</li>
<li>⋆(⋆(<em>m</em>, <em>n</em>), <em>p</em>) = ⋆(<em>m</em>, (⋆(<em>n</em>, <em>p</em>)).</li>
</ul>
<p>The way they are written in Definition <a href="chapter004.html#Def_4-1-1-1">4.1.1.1</a> is called <em>infix notation</em>,. Given a function ⋆: <em>A</em> × <em>B</em> → <em>C</em>, we may write <em>a</em> ⋆ <em>b</em> rather than ⋆(<em>a</em>, <em>b</em>).</p>
<p><em>Example</em> 4.1.1.3 (Additive monoid of natural numbers). Let <em>M</em> = ℕ be the set of natural numbers. Let <em>e</em> = 0, and let ⋆: <em>M</em> × <em>M</em> → <em>M</em> denote addition, so that ⋆(4<em></em>, 18) = 4 ⋆ 18 = 22. Then the equations <em>m</em> ⋆ 0 = <em>m</em> and 0 ⋆ <em>m</em> = <em>m</em> hold, and (<em>m</em> ⋆ <em>n</em>) ⋆ <em>p</em> = <em>m</em> ⋆ (<em>n</em> ⋆ <em>p</em>) because, as we learned in grade school, addition is associative. By assigning <em>e</em> and ⋆ in this way, we have given ℕ the structure of a monoid. We usually denote it (ℕ, 0, +).</p>
<p><em>Remark</em> 4.1.1.4. Sometimes we are working with a monoid (<em>M</em>, <em>e</em>, ⋆), and the unit <em>e</em> and multiplication ⋆ are somehow clear from context. In this case we might refer to the set <em>M</em> as though it were the whole monoid. For example, if we were discussing the monoid from Example <a href="chapter004.html#Exa_4-1-1-3">4.1.1.3</a>, we might refer to it as ℕ. The danger comes because sets may have multiple monoid structures (see Exercise <a href="chapter004.html#Exe_4-1-1-6">4.1.1.6</a>).</p>
<p><em>Example</em> 4.1.1.5 (Nonmonoid). If <em>M</em> is a set, we might call a function <em>f</em> : <em>M</em> × <em>M</em> → <em>M</em> an <em>operation on M</em>. For example, if <em>M</em> = ℕ is the set of natural numbers, we can consider the operation <em>f</em> : ℕ × ℕ → ℕ called exponentiation e.g., <em>f</em>(2, 5) = 2 × 2 × 2 × 2 × 2 = 32 and <em>f</em>(7, 2) = 49. This is indeed an operation, but it is not the multiplication formula for any monoid. First, there is no possible unit. Trying the obvious choice of <em>e</em> = 1, we see that <em>a</em><sup>1</sup> = <em>a</em> (good), but that 1<em><sup>a</sup></em> = 1 (bad: we need it to be <em>a</em>). Second, this operation is not associative because in general <em>a</em><sup>(<em>b<sup>c</sup></em>)</sup> ≠ (<em>a<sup>b</sup></em>)<em><sup>c</sup></em>. For example, 2<sup>(1<sup>2</sup>)</sup> = 2, but (2<sup>1</sup>)<sup>2</sup> = 4.</p>
<p>One might also attempt to consider an operation <em>f</em> : <em>M</em> × <em>M</em> → <em>M</em> that upon closer inspection is not even an operation. For example, if <em>M</em> = ℤ, then exponentiation is not even an operation. Indeed, f(2,−1)=2−1=12, and this is not an integer. To have a function <em>f</em> : <em>M</em> × <em>M</em> → <em>M</em>, it is required that every element of the domain—in this case every pair of integers—have an output under <em>f</em>. So there is no exponentiation function on ℤ.</p>
<p><em>Exercise</em> 4.1.1.6.</p>
<p>Let <em>M</em> = ℕ be the set of natural numbers. Taking <em>e</em> = 1 as the unit, devise a formula for ⋆ that gives ℕ the structure of a monoid.</p>
<p><em>Solution</em> 4.1.1.6.</p>
<p>Let ⋆ denote the usual multiplication of natural numbers, e.g., 5 ⋆ 7 = 35. Then for any <em>m</em>, <em>n</em>, <em>p</em> ∈ ℕ, we have 1 ⋆ <em>m</em> = <em>m</em> ⋆ 1 = <em>m</em> and (<em>m</em> ⋆ <em>n</em>) ⋆ <em>p</em> = <em>m</em> ⋆ (<em>n</em> ⋆ <em>p</em>), as required.</p>
<p><em>Exercise</em> 4.1.1.7.</p>
<p>Find an operation on the set <em>M</em> = {1, 2, 3, 4}, i.e., a legitimate function <em>f</em> : <em>M</em> × <em>M</em> → <em>M</em>, such that <em>f</em> cannot be the multiplication formula for a monoid on <em>M</em>. That is, either it is not associative or no element of <em>M</em> can serve as a unit.</p>
<p><em>Exercise</em> 4.1.1.8.</p>
<p>In both Example <a href="chapter004.html#Exa_4-1-1-3">4.1.1.3</a> and Exercise <a href="chapter004.html#Exe_4-1-1-6">4.1.1.6</a>, the monoids (<em>M</em>, <em>e</em>, ⋆) satisfied an additional rule called <em>commutativity</em>, namely, <em>m</em> ⋆ <em>n</em> = <em>n</em> ⋆ <em>m</em> for every <em>m</em>, <em>n</em> ∈ <em>M</em>. There is a monoid (<em>M</em>, <em>e</em>, ⋆) in linear algebra that is not commutative; if you have background in linear algebra, what monoid (<em>M</em>, <em>e</em>, ⋆) might I be referring to?</p>
<p><em>Exercise</em> 4.1.1.9.</p>
<p>Recall the notion of commutativity for monoids from Exercise <a href="chapter004.html#Exe_4-1-1-8">4.1.1.8</a>.</p>
<p>a. What is the smallest set <em>M</em> that you can give the structure of a noncommutative monoid?</p>
<p>b. What is the smallest set <em>M</em> that you can give the structure of a monoid?</p>
<p><em>Example</em> 4.1.1.10 (Trivial monoid). There is a monoid with only one element, <em>M</em> = ({<em>e</em>}, <em>e</em>, ⋆), where ⋆: {<em>e</em>} × {<em>e</em>} → {<em>e</em>} is the unique function. We call this monoid <em>the trivial monoid</em> and sometimes denote it 1.</p>
<p><em>Example</em> 4.1.1.11. Suppose that (<em>M</em>, <em>e</em>, ⋆) is a monoid. Given elements <em>m</em><sub>1</sub>, <em>m</em><sub>2</sub>, <em>m</em><sub>3</sub>, <em>m</em><sub>4</sub>, there are five different ways to parenthesize the product <em>m</em><sub>1</sub> ⋆ <em>m</em><sub>2</sub> ⋆ <em>m</em><sub>3</sub> ⋆ <em>m</em><sub>4</sub>, and the associativity law for monoids will show them all to be the same. We have</p>
<p>((<em>m</em><sub>1</sub> ⋆ <em>m</em><sub>2</sub>) ⋆ <em>m</em><sub>3</sub>) ⋆ <em>m</em><sub>4</sub></p>
<p>= (<em>m</em><sub>1</sub> ⋆ <em>m</em><sub>2</sub>) ⋆ (<em>m</em><sub>3</sub> ⋆ <em>m</em><sub>4</sub>)</p>
<p>= (<em>m</em><sub>1</sub> ⋆ (<em>m</em><sub>2</sub> ⋆ <em>m</em><sub>3</sub>)) ⋆ <em>m</em><sub>4</sub></p>
<p>= <em>m</em><sub>1</sub> ⋆ (<em>m</em><sub>2</sub> ⋆ (<em>m</em><sub>3</sub> ⋆ <em>m</em><sub>4</sub>))</p>
<p>= <em>m</em><sub>1</sub> ⋆ ((<em>m</em><sub>2</sub> ⋆ <em>m</em><sub>3</sub>) ⋆ <em>m</em><sub>4</sub>).</p>
<p>In fact, the product of any list of monoid elements is the same, regardless of parenthesization. Therefore, we can unambiguously write <em>m</em><sub>1</sub> ⋆ <em>m</em><sub>2</sub> ⋆ <em>m</em><sub>3</sub> ⋆ <em>m</em><sub>4</sub> ⋆ <em>m</em><sub>5</sub> rather than any given parenthesization of it. A substantial generalization of this is known as the <em>coherence theorem</em> and can be found in Mac Lane [29].</p>
<h3 id="lev_4-1-1-12" class="level3"><strong>4.1.1.12   Free monoids and finitely presented monoids</strong></h3>
<p><strong>Definition 4.1.1.13</strong>. Let <em>X</em> be a set. A <em>list in X</em> is a pair (<em>n</em>, <em>f</em>), where <em>n</em> ∈ ℕ is a natural number (called the <em>length of the list</em>) and <em>f</em> : <em>n</em> → <em>X</em> is a function, where <em>n</em> = {1, 2, …, <em>n</em>}.</p>
<p>We may denote such a list</p>
<p>(n,f)=[f(1),f(2),…,f(n)].</p>
<p>The set of lists in <em>X</em> is denoted List(<em>X</em>).</p>
<p>The <em>empty list</em> is the unique list in which <em>n</em> = 0; we may denote it [ ]. Given an element <em>x</em> ∈ <em>X</em>, the <em>singleton list on x</em> is the list [<em>x</em>]. Given a list <em>L</em> = (<em>n</em>, <em>f</em>) and a number <em>i</em> ∈ ℕ with <em>i</em> ⩽ <em>n</em>, the <em>ith entry of L</em> is the element <em>f</em>(<em>i</em>) ∈ <em>X</em>.</p>
<p>Given two lists <em>L</em> = (<em>n</em>, <em>f</em>) and <em>L</em>′ = (<em>n</em>′, <em>f</em>′), define the <em>concatenation of L and L</em>′, denoted <em>L</em> ++ <em>L</em>′, to be the list (<em>n</em> + <em>n</em>′, <em>f</em> ++ <em>f</em>′), where <em>f</em> ++ <em>f</em>′ : <em>n</em> + <em>n</em>′ → <em>X</em> is given on 1 ⩽ <em>i</em> ⩽ <em>n</em> + <em>n</em>′ by</p>
<p>(f++f′)(i)≔{f(i)if 1⩽i⩽n,f′(i−n)if n+1⩽i⩽n+n′.</p>
<p><em>Example</em> 4.1.1.14. Let <em>X</em> = {<em>a</em>, <em>b</em>, <em>c</em>, …, <em>z</em>}. The following are elements of List(<em>X</em>):</p>
<p>[a,b,c],[p], [p,a,a,a,p],[],….</p>
<p>The concatenation of [<em>a</em>, <em>b</em>, <em>c</em>] and [<em>p</em>, <em>a</em>, <em>a</em>, <em>a</em>, <em>p</em>] is [<em>a</em>, <em>b</em>, <em>c</em>, <em>p</em>, <em>a</em>, <em>a</em>, <em>a</em>, <em>p</em>]. The concatenation of any list <em>ℓ</em> with [ ] is just <em>ℓ</em>.</p>
<p><strong>Definition 4.1.1.15</strong>. Let <em>X</em> be a set. The <em>free monoid generated by X</em> is the sequence <em>F<sub>X</sub></em> ≔ (List(<em>X</em>), [ ], ++), where List(<em>X</em>) is the set of lists of elements in <em>X</em>, [ ] ∈ List(<em>X</em>) is the empty list, and ++ is the operation of list concatenation. We refer to <em>X</em> as the set of <em>generators</em> for the monoid <em>F<sub>X</sub></em>.</p>
<p><em>Exercise</em> 4.1.1.16.</p>
<p>Let {☺} denote a one-element set.</p>
<p>a. What is the free monoid generated by the set {☺}?</p>
<p>b. What is the free monoid generated by ∅?</p>
<p>An equivalence relation that interacts well with the multiplication formula of a monoid is called a congruence on that monoid.</p>
<p><strong>Definition 4.1.1.17</strong>. Let M≔(M,e,⋆) be a monoid. A <em>congruence</em> on M is an equivalence relation ∼ on <em>M</em>, such that for any <em>m</em>, <em>m</em>′ ∈ <em>M</em> and any <em>n</em>, <em>n</em>′ ∈ <em>M</em>, if <em>m</em> ∼ <em>m</em>′ and <em>n</em> ∼ <em>n</em>′, then <em>m</em> ⋆ <em>n</em> ∼ <em>m</em>′ ∼ <em>n</em>′.</p>
<p><strong>Proposition 4.1.1.18</strong>. <em>Suppose that</em> M≔(M,e,⋆) <em>is a monoid. Then the following facts hold:</em></p>
<ol>
<li><em>Given any relation R</em> ⊆ <em>M</em> × <em>M</em>, <em>there is a smallest congruence S containing R. We call S the</em> congruence generated by <em>R.</em></li>
<li><em>If R</em> = ∅ <em>and</em> ∼ <em>is the congruence it generates, then there is an isomorphism</em> M→≅(M/∼).</li>
<li><em>Suppose that</em> ∼ <em>is a congruence on</em> M. Then there is a monoid structure M/∼ <em>on the quotient set M</em>/∼, <em>compatible with</em> M.</li>
</ol>
<p><em>Proof</em>.     1. Let <em>L<sub>R</sub></em> be the set of all congruences on M that contain <em>R</em>. Using reasoning similar to that used in the proof of Proposition <a href="chapter003.html#Pro_3-3-1-7">3.3.1.7</a>, one sees that <em>L<sub>R</sub></em> is nonempty and that its intersection, S=∩ℓ∈LRℓ, serves.</p>
<p>2. If <em>R</em> = ∅, then the minimal reflexive relation {(<em>m</em>, <em>m</em>) | <em>m</em> ∈ <em>M</em>} ⊆ <em>M</em> × <em>M</em> is the congruence generated by <em>M</em>. We have an isomorphism M→≅M/∼. by Exercise <a href="chapter003.html#Exe_3-3-1-9">3.3.1.9</a>.</p>
<p>3. Let <em>Q</em>: <em>M</em> → <em>M</em>/∼ be the quotient function (as in Definition <a href="chapter003.html#Def_3-3-1-1">3.3.1.1</a>); note that it is surjective. We first want to give a monoid structure on <em>M</em>/∼, i.e., we need a unit element <em>e</em>′ and a multiplication formula ⋆′. Let <em>e</em>′ = <em>Q</em>(<em>e</em>). Suppose given <em>p</em>, <em>q</em> ∈ <em>M</em>/∼ and respectively let <em>m</em>, <em>n</em> ∈ <em>M</em> be a pair of representatives, so <em>Q</em>(<em>m</em>) = <em>p</em> and <em>Q</em>(<em>n</em>) = <em>q</em>. Define <em>p</em>⋆′<em>q</em> ≔ <em>Q</em>(<em>m</em>⋆<em>n</em>). If we chose a different pair of representatives <em>Q</em>(<em>m</em>′) = <em>p</em> and <em>Q</em>(<em>n</em>′) = <em>q</em>, then we would have <em>m</em> ∼ <em>m</em>′ and <em>n</em> ∼ <em>n</em>′ so (<em>m</em> ⋆ <em>n</em>) ∼ (<em>m</em>′ ⋆ <em>n</em>′), which implies <em>Q</em>(<em>m</em> ⋆ <em>n</em>) = <em>Q</em>(<em>m</em>′ ⋆ <em>n</em>′); hence the composition formula is well defined. It is easy to check that M/∼≔ (<em>M</em>/∼, <em>e</em>′, ⋆′) is a monoid. It follows that <em>Q</em>: <em>M</em> → <em>M</em>/∼ extends to a monoid homomorphism <em>Q</em>: M → M/∼, as in Definition (<a href="chapter004.html#Def_4-1-4-1">4.1.4.1</a>), which makes precise the <em>compatibility</em> claim.</p>
<p><strong>Definition 4.1.1.19</strong> (Presented monoid). Let <em>G</em> be a finite set, and let <em>R</em> ⊆ List(<em>G</em>) × List(<em>G</em>) be a relation. The <em>monoid presented by generators G and relations R</em> is the monoid M = (<em>M</em>, <em>e</em>, ⋆), defined as follows. Begin with the free monoid <em>F<sub>G</sub></em> = (List(<em>G</em>), [ ], ++) generated by <em>G</em>. Let ∼ denote the congruence on <em>F<sub>G</sub></em> generated by <em>R</em>, as in <a href="chapter004.html#Pro_4-1-1-18">Proposition 4.1.1.18</a>, and define M ≔ <em>F<sub>G</sub></em>/∼.</p>
<p>Each element <em>r</em> ∈ <em>R</em> is of the form <em>r</em> = (<em>ℓ</em>, <em>ℓ</em>′) for lists <em>ℓ</em>, <em>ℓ</em>′ ∈ List(<em>G</em>). For historical reasons we call the each of the resulting expressions <em>ℓ</em> ∼ <em>ℓ</em>′ a <em>relation</em> in <em>R</em>.</p>
<p><em>Slogan</em> 4.1.1.20.</p>
<p><em>A presented monoid is a set of buttons you can press and some facts about when different button sequences have the same results.</em></p>
<p><em>Remark</em> 4.1.1.21. Every free monoid is a presented monoid, because we can just take the set of relations to be empty.</p>
<p><em>Example</em> 4.1.1.22. Let <em>G</em> = {<em>a</em>, <em>b</em>, <em>c</em>, <em>d</em>}. Think of these as buttons that can be pressed. The free monoid <em>F<sub>G</sub></em> = (List(<em>G</em>), [ ], ++) is the set of all ways of pressing buttons, e.g., pressing <em>a</em>, then <em>a</em>, then <em>c</em>, then <em>c</em>, then <em>d</em> corresponds to the list [<em>a</em>, <em>a</em>, <em>c</em>, <em>c</em>, <em>d</em>]. The idea of presented monoids is that we can assert that pressing [<em>a</em>, <em>a</em>, <em>c</em>] always gives the same result as pressing [<em>d</em>, <em>d</em>] and that pressing [<em>c</em>, <em>a</em>, <em>c</em>, <em>a</em>] is the same thing as doing nothing.</p>
<p>In this case, the relation <em>R</em> ⊆ List(<em>G</em>) × List(<em>G</em>) would be</p>
<p><em>R</em></p>
<p>[<em>a</em>, <em>a</em>, <em>c</em>]</p>
<p>[<em>d</em>, <em>d</em>]</p>
<p>[<em>a</em>, <em>c</em>, <em>a</em>, <em>c</em>]</p>
<p>[]</p>
<p>As in <a href="chapter004.html#Pro_4-1-1-18">Proposition 4.1.1.18</a>, the relation <em>R</em> generates a congruence ∼ on List(<em>G</em>), and this can be complex. For example, would you guess that [<em>b</em>, <em>c</em>, <em>b</em>, <em>d</em>, <em>d</em>, <em>a</em>, <em>c</em>, <em>a</em>, <em>a</em>, <em>c</em>, <em>d</em>] ∼ [<em>b</em>, <em>c</em>, <em>b</em>, <em>a</em>, <em>d</em>, <em>d</em>, <em>d</em>]? Here is the calculation in <em>M</em> = List(<em>G</em>)/∼ :</p>
<p>[<em>b</em>, <em>c</em>, <em>b</em>, <em>d</em>, <em>d</em>, <em>a</em>, <em>c</em>, <em>a</em>, <em>a</em>, <em>c</em>, <em>d</em>]</p>
<p>= [<em>b</em>, <em>c</em>, <em>b</em>] ⋆ [<em>d</em>, <em>d</em>] ⋆ [<em>a</em>, <em>c</em>, <em>a</em>, <em>a</em>, <em>c</em>, <em>d</em>]</p>
<p>= [<em>b</em>, <em>c</em>, <em>b</em>, <em>a</em>] ⋆ [<em>a</em>, <em>c</em>, <em>a</em>, <em>c</em>] ⋆ [<em>a</em>, <em>a</em>, <em>c</em>, <em>d</em>]</p>
<p>= [<em>b</em>, <em>c</em>, <em>b</em>, <em>a</em>, <em>a</em>, <em>a</em>, <em>c</em>, <em>d</em>]</p>
<p>= [<em>b</em>, <em>c</em>, <em>b</em>, <em>a</em>] ⋆ [<em>a</em>, <em>a</em>, <em>c</em>] ⋆ [<em>d</em>]</p>
<p>= [<em>b</em>, <em>c</em>, <em>b</em>, <em>a</em>, <em>d</em>, <em>d</em>, <em>d</em>].</p>
<p><em>Exercise</em> 4.1.1.23.</p>
<p>Let <em>K</em> ≔ {<em>BS</em>, <em>a</em>, <em>b</em>, <em>c</em>, …, <em>z</em>}, <em>a set having 27 elements. Suppose one thinks of BS</em> ∈ <em>K as the backspace key and the elements a</em>, <em>b</em>, … <em>z</em> ∈ <em>K as the letter keys on a keyboard. Then the free monoid List</em>(<em>K</em>) <em>is not quite appropriate for modeling the keyboard because we want</em>, <em>e.g.</em>, [<em>a</em>, <em>b</em>, <em>d</em>, <em>BS</em>] = [<em>a</em>, <em>b</em>].</p>
<p>a. Choose a set of relations for which the monoid presented by generators <em>K</em> and the chosen relations is appropriate to this application.</p>
<p>b. Under your relations, how does the singleton list [<em>BS</em>] compare with the empty list [ ]? Is that suitable?</p>
<h3 id="lev_4-1-1-24" class="level3"><strong>4.1.1.24   Cyclic monoids</strong></h3>
<p><strong>Definition 4.1.1.25</strong>. A monoid is called <em>cyclic</em> if it has a presentation involving only one generator.</p>
<p><em>Example</em> 4.1.1.26. Let <em>Q</em> be a symbol; we look at some cyclic monoids generated by {<em>Q</em>}. With no relations the monoid would be the free monoid on one generator and would have underlying set {[ ], [<em>Q</em>], [<em>Q</em>, <em>Q</em>], [<em>Q</em>, <em>Q</em>, <em>Q</em>], …}, with unit element [ ] and multiplication given by concatenation (e.g., [<em>Q</em>, <em>Q</em>, <em>Q</em>] ++ [<em>Q</em>, <em>Q</em>] = [<em>Q</em>, <em>Q</em>, <em>Q</em>, <em>Q</em>, <em>Q</em>]). This is just ℕ, the additive monoid of natural numbers.</p>
<p>With the really strong relation [<em>Q</em>] ~ [ ] we would get the trivial monoid, as in Example <a href="chapter004.html#Exa_4-1-1-10">4.1.1.10</a>.</p>
<p>Another possibility is given in the first part of Example <a href="chapter004.html#Exa_4-1-2-3">4.1.2.3</a>, where the relation <em>Q</em><sup>12</sup> ~ [ ] is used, where <em>Q</em><sup>12</sup> is shorthand for [<em>Q</em>, <em>Q</em>, <em>Q</em>, <em>Q</em>, <em>Q</em>, <em>Q</em>, <em>Q</em>, <em>Q</em>, <em>Q</em>, <em>Q</em>, <em>Q</em>, <em>Q</em>]. This monoid has 12 elements.</p>
<p><em>Example</em> 4.1.1.27. Consider the cyclic monoid with generator <em>Q</em> and relation <em>Q</em><sup>7</sup> = <em>Q</em><sup>4</sup>. This monoid has seven elements,</p>
<p>{ Q0,Q1,Q2,Q3,Q4,Q5,Q6 },</p>
<p>where <em>Q</em><sup>0</sup> = <em>e</em> and <em>Q</em><sup>1</sup> = <em>Q</em>. As an example of the multiplication formula, we have:</p>
<p>Q6⋆Q5=Q7*Q4=Q4*Q4=Q7*Q=Q5.</p>
<p>One might depict the cyclic monoid with relation <em>Q</em><sup>7</sup> = <em>Q</em><sup>4</sup> as follows:</p>
<p><img src="images/Art_P89.jpg" alt="art" /></p>
<p>To see the mathematical source of this intuitive depiction, see Example <a href="chapter007.html#Exa_7-2-1-19">7.2.1.19</a>.</p>
<p><em>Exercise</em> 4.1.1.28.</p>
<p>Classify all the cyclic monoids up to isomorphism. That is, construct a naming system such that every cyclic monoid can be given a name in your system, no two nonisomorphic cyclic monoids have the same name, and no name exists in the system unless it refers to a cyclic monoid.</p>
<p>Hint: One might see a pattern in which the three monoids in Example <a href="chapter004.html#Exa_4-1-1-26">4.1.1.26</a> correspond respectively to ∞, 1, and 12, and think that Cyclic monoids can be classified by (i.e., systematically named by elements of) the set ℕ ⊔ {∞}. That idea is on the right track, but it is not complete.</p>
<p><em>Solution</em> 4.1.1.28.</p>
<p>Cyclic monoids are either finite or infinite. The free monoid on one generator, (ℕ, 0, +) is the only infinite cyclic monoid, because once one makes a relation <em>Q</em><sup><em>m</em></sup> ~ <em>Q</em><sup><em>n</em></sup> on List(<em>Q</em>) for some <em>n</em> &gt; <em>m</em>, it is ensured that there are only finitely many elements (in fact, <em>n</em>-many). Finite cyclic monoids can be drawn as backward <em>σ</em>’s (i.e., as <img src="images/Art_P89a.jpg" alt="art" />), with varying loop lengths and total lengths. The finite cyclic monoids can be classified by the set</p>
<p>FCM≔{(n,k)∈ℕ×ℕ|1⩽k⩽n }.</p>
<p>For each (<em>n</em>, <em>k</em>) ∈ <em>FCM</em>, there is a cyclic monoid with <em>n</em> elements and a loop of length <em>k</em>. For example, we can draw (8, 6) and (5, 1) respectively as</p>
<p><img src="images/Art_P90.jpg" alt="art" /></p>
<p>How do these pictures correspond to monoids? The nodes represent elements, so (8, 6) has eight elements. The unit element is the leftmost node (the only one with no arrow pointing to it). Each node is labeled by the length of the shortest path from the unit (so 0 is the unit). To multiply <em>m</em> ⋆ <em>n</em>, we see where the path of length <em>m</em> + <em>n</em>, starting at 0, ends up. So in the cyclic monoid of type (8, 6), we have 4 + 4 = 2, whereas in (5, 1), we have 4 + 4 = 4.</p>
<h2 id="lev_4-1-2" class="level2"><strong>4.1.2   Monoid actions</strong></h2>
<p><strong>Definition 4.1.2.1</strong> (Monoid action). Let (<em>M</em>, <em>e</em>, ⋆) be a monoid, and let <em>S</em> be a set. An <em>action of</em> (<em>M</em>, <em>e</em>, ⋆) <em>on S</em>, or simply an <em>action of M on S</em>, or an <em>M action on S</em>, is a function</p>
<p><img src="images/Art_P91.jpg" alt="art" /></p>
<p>such that the following <em>monoid action laws</em> hold for all <em>m</em>, <em>n</em> ∈ <em>M</em> and all <em>s</em> ∈ <em>S</em>:</p>
<ul>
<li><em>e</em> <img src="images/rotate.jpg" alt="art" /> <em>s</em> = <em>s</em></li>
<li><em>m</em> <img src="images/rotate.jpg" alt="art" /> (<em>n</em> <img src="images/rotate.jpg" alt="art" /> <em>s</em>) = (<em>m</em> ⋆ <em>n</em>) <img src="images/rotate.jpg" alt="art" /> <em>s</em>.<sup><a href="chapter004.html#endnote_2">2</a></sup></li>
</ul>
<p><em>Remark</em> 4.1.2.2. To be pedantic (and because it is sometimes useful), we may decide not to use infix notation. That is, we may rewrite <img src="images/rotate.jpg" alt="art" /> as <em>α</em>: <em>M</em> × <em>S</em> → <em>S</em> and restate the conditions from Definition <a href="chapter004.html#Def_4-1-2-1">4.1.2.1</a> as</p>
<ul>
<li><em>α</em>(<em>e</em>, <em>s</em>) = <em>s</em>;</li>
<li><em>α</em>(<em>m</em>, <em>α</em>(<em>n</em>, <em>s</em>)) = <em>α</em>(<em>m</em> ⋆ <em>n</em>, <em>s</em>).</li>
</ul>
<p><em>Example</em> 4.1.2.3. Let <em>S</em> = {0, 1, 2, … , 11}, and let <em>N</em> = (ℕ, 0, +) be the additive monoid of natural numbers (see Example <a href="chapter004.html#Exa_4-1-1-3">4.1.1.3</a>). We define a function <img src="images/rotate.jpg" alt="art" />: ℕ × <em>S</em> → <em>S</em> by taking a pair (<em>n</em>, <em>s</em>) to the remainder that appears when <em>n</em> + <em>s</em> is divided by 12. For example, 4 <img src="images/rotate.jpg" alt="art" /> 2 = 6 and 8 <img src="images/rotate.jpg" alt="art" /> 9 = 5. This function has the structure of a monoid action because the monoid laws from Definition <a href="chapter004.html#Def_4-1-2-1">4.1.2.1</a> hold.</p>
<p>Similarly, let <em>T</em> denote the set of points on a circle, elements of which are denoted by a real number in the interval [0, 12), i.e.,</p>
<p>T={ x∈ℝ|0⩽x&lt;12 },</p>
<p>and let <em>R</em> = (ℝ, 0, +) denote the additive monoid of real numbers. Then there is an action <em>R</em> × <em>T</em> → <em>T</em>, similar to the preceding one (see Exercise <a href="chapter004.html#Exe_4-1-2-4">4.1.2.4</a>).</p>
<p>One can think of this as an action of the monoid of time on the clock. Here <em>T</em> is the set of positions at which the hour hand may be pointing. Given any number <em>r</em> ∈ <em>R</em>, we can go around the clock by <em>r</em> many hours and get a new hour-hand position. For example, 7.25 <img src="images/rotate.jpg" alt="art" /> 8.5 = 3.75, meaning that 7.25 hours after 8:30 is 3:45.</p>
<p><em>Exercise</em> 4.1.2.4.</p>
<p>Warning: This exercise is abstract.</p>
<p>a. Realize the set <em>T</em> ≔ [0, 12) ⊆ ℝ as a coequalizer of some pair of arrows ℝ ⇉ ℝ.</p>
<p>b. For any <em>x</em> ∈ ℝ, realize the mapping <em>x</em>+: <em>T</em> → <em>T</em>, implied by Example <a href="chapter004.html#Exa_4-1-2-3">4.1.2.3</a>, using the universal property for coequalizers.</p>
<p>c. Prove that it is an action.</p>
<p><em>Solution</em> 4.1.2.4.</p>
<p>a. Let <em>f</em> : ℝ → ℝ be given by <em>f</em>(<em>x</em>) = <em>x</em> + 12. Then id<sub>ℝ</sub> and <em>f</em> are a pair of arrows ℝ → ℝ, and their coequalizer is <em>T</em>.</p>
<p>b. Let <em>x</em> ∈ ℝ be a real number. We want a function <em>x</em>+: <em>T</em> → <em>T</em>, but we begin with a function (by the same name) <em>x</em>+: ℝ → ℝ, given by adding <em>x</em> to any real number. The following solid-arrow diagram commutes because 12 + <em>x</em> = <em>x</em> + 12 for any <em>x</em> ∈ ℝ:</p>
<p><img src="images/Art_P92.jpg" alt="art" /></p>
<p>By the universal property for coequalizers, there is a unique dotted arrow <em>T</em> → <em>T</em> making the diagram commute, and this is <em>x</em>+: <em>T</em> → <em>T</em>. It represents the action “add <em>x</em> ∈ ℝ hours to clock position <em>t</em> ∈ <em>T</em>.”</p>
<p>c. Clearly, if <em>x</em> = 0, then the <em>x</em>+ function is id<sub>ℝ</sub>, and it follows from the universal property that 0+ = id<sub><em>T</em></sub>. We see that <em>x</em> + (<em>y</em> + <em>t</em>) = (<em>x</em> + <em>y</em>) + <em>t</em> using the commutative diagram</p>
<p><img src="images/Art_P93.jpg" alt="art" /></p>
<p>The universal property for coequalizers implies the result.</p>
<p><em>Exercise</em> 4.1.2.5.</p>
<p>Let <em>B</em> denote the set of buttons (or positions) of a video game controller (other than, say, “start” and “select”), and consider the free monoid List(<em>B</em>) on <em>B</em>.</p>
<p>a. What would it mean for List(<em>B</em>) to act on the set of states of some (single-player) video game? Imagine a video game <em>G</em>′ that uses the controller, but for which List(<em>B</em>) would not be said to act on the states of <em>G</em>′. Now imagine a simple game <em>G</em> for which List(<em>B</em>) would be said to act. Describe the games <em>G</em> and <em>G</em>′.</p>
<p>b. Can you think of a state <em>s</em> of <em>G</em>, and two distinct elements <em>ℓ</em>, <em>ℓ</em>′ ∈ List(<em>B</em>) such that <em>ℓ</em> <img src="images/rotate.jpg" alt="art" /> <em>s</em> = <em>ℓ</em>′ <img src="images/rotate.jpg" alt="art" /> <em>s</em>?</p>
<p>c. In video game parlance, what would you call a monoid element <em>b</em> ∈ <em>B</em> such that for every state <em>s</em> ∈ <em>G</em>, one has <em>b</em> <img src="images/rotate.jpg" alt="art" /> <em>s</em> = <em>s</em>?</p>
<p>d. In video game parlance, what would you call a state <em>s</em> ∈ <em>S</em> such that for every sequence of buttons <em>ℓ</em> ∈ List(<em>B</em>), one has <em>ℓ</em> <img src="images/rotate.jpg" alt="art" /> <em>s</em> = <em>s</em>?</p>
<p>e. Define ℝ<sub>&gt;0</sub> to be the set of positive real numbers, and consider the free monoid <em>M</em> ≔ List(ℝ<sub>&gt;0</sub> × <em>B</em>). An element of this monoid can be interpreted as a list in which each entry is a button <em>b</em> ∈ <em>B</em> being pressed after a wait time <em>t</em> ∈ ℝ<sub>&gt;0</sub>. Can you find a game that uses the controller but for which <em>M</em> does not act?</p>
<p><em>Application</em> 4.1.2.6. Let <em>f</em> : ℝ → ℝ be a differentiable function of which we want to find roots (points <em>x</em> ∈ ℝ such that <em>f</em>(<em>x</em>) = 0). Let <em>x</em><sub>0</sub> ∈ ℝ be a starting point. For any <em>n</em> ∈ ℕ, we can apply Newton’s method to <em>x</em><sub><em>n</em></sub> to get</p>
<p>xn+1=xn−f(xn)f′(xn).</p>
<p>This is a monoid (namely, ℕ, the free monoid on one generator) acting on a set (namely, ℝ).</p>
<p>However, Newton’s method can get into trouble. For example, at a critical point it causes division by zero, and sometimes it can oscillate or overshoot. In these cases we want to perturb a bit to the left or right. To have these actions available to us, we would add “perturb” elements to our monoid. Now we have more available actions at any point, but at the cost of using a more complicated monoid.</p>
<p>When publishing an experimental finding, there may be some deep methodological questions that are not considered suitably important to mention. For example, one may not publish the kind of solution-finding method (e.g., Newton’s method or Runge-Kutta) that was used, or the set of available actions, e.g., what kinds of perturbation were used by the researcher. However, these may actually influence the reproducibility of results. By using a language such as that of monoid actions, we can align our data model with our unspoken assumptions about how functions are analyzed.</p>
<p><em>Remark</em> 4.1.2.7. A monoid is useful for understanding how an agent acts on the set of states of an object, but there is only one <em>context</em> for action—at any point, all actions are available. In reality, it is often the case that contexts can change and different actions are available at different times. For example, on a computer the commands available in one application have no meaning in another. This points us to categories, which are generalizations of monoids (see Chapter 5).</p>
<h3 id="lev_4-1-2-8" class="level3"><strong>4.1.2.8   Monoid actions as ologs</strong></h3>
<p>If monoids are understood in terms of how they act on sets, then it is reasonable to think of them in terms of ologs. In fact, the ologs associated to monoids are precisely those ologs that have exactly one type (and possibly many arrows and commutative diagrams).</p>
<p><em>Example</em> 4.1.2.9. This example shows how to associate an olog to a monoid action. Consider the monoid <em>M</em> generated by the set {<em>u</em>, <em>d</em>, <em>r</em>}, standing for “up, down, right,” and subject to the relations</p>
<p>[ u,d ]∼[ ],[ d,u ]∼[ ],[u,r ]=[ r,u ],and[ d,r ]=[ r,d ].</p>
<p>We might imagine that <em>M</em> acts on the set of positions for a character in an old video game. In that case the olog corresponding to this action should look something like <a href="chapter004.html#Fig_4-1">Figure 4.1</a>.</p>
<p><img src="images/Art_P94.jpg" alt="art" /></p>
<p><strong>Figure 4.1</strong></p>
<h3 id="lev_4-1-2-10" class="level3"><strong>4.1.2.10   Finite state machines</strong></h3>
<p>According to Wikipedia, a <em>deterministic finite state machine</em> is a quintuple (Σ, <em>S</em>, <em>s</em><sub>0</sub>, <em>δ</em>, <em>F</em>), where</p>
<ol>
<li>Σ is a finite nonempty set of symbols, called the <em>input alphabet</em>;</li>
<li><em>S</em> is a finite, nonempty set, called <em>the state set</em>;</li>
<li><em>δ</em> : Σ × <em>S</em> → <em>S</em> is a function, called the <em>state-transition function</em>;</li>
<li><em>s</em><sub>0</sub> ∈ <em>S</em> is an element, called <em>the initial state</em>;</li>
<li><em>F</em> ⊆ <em>S</em> is a subset, called the <em>set of final states</em>.</li>
</ol>
<p>Here we focus on the state transition function <em>δ</em>, by which the alphabet Σ acts on the set <em>S</em> of states (see <a href="chapter004.html#Fig_4-2">Figure 4.2</a>).</p>
<p><img src="images/Art_P95.jpg" alt="art" /></p>
<p><strong>Figure 4.2</strong> A finite state machine with alphabet Σ = {<em>a</em>, <em>b</em>} and state set <em>S</em> = {State 0, State 1, State 2}.</p>
<p>The following proposition expresses the notion of finite state automata in terms of free monoids and their actions on finite sets.</p>
<p><strong>Proposition 4.1.2.11</strong>. <em>Let</em> Σ, <em>S be finite nonempty sets. Giving a function δ</em> : Σ×<em>S</em> → <em>S is equivalent to giving an action of the free monoid</em> List(Σ) <em>on S</em>.</p>
<p><em>Proof</em>. The proof is sketched here, leaving two details for Exercise <a href="chapter004.html#Exe_4-1-2-13">4.1.2.13</a>. By Definition <a href="chapter004.html#Def_4-1-2-1">4.1.2.1</a>, we know that function <em>ϵ</em>: List(Σ) × <em>S</em> → <em>S</em> constitutes an action of the monoid List(Σ) on the set <em>S</em> if and only if, for all <em>s</em> ∈ <em>S</em>, we have <em>ϵ</em>([ ], <em>s</em>) = <em>s</em>, and for any two elements <em>m</em>, <em>m</em>′ ∈ List(Σ), we have <em>ϵ</em>(<em>m</em>, <em>ϵ</em>(<em>m</em>′, <em>s</em>)) = <em>ϵ</em>(<em>m</em> ++ <em>m</em>′, <em>s</em>), where <em>m</em> ++ <em>m</em>′ is the concatenation of lists. Let</p>
<p>A≔{ ϵ:List(Σ)×S→S|ϵ constitutes an action }.</p>
<p>We need to prove that there is an isomorphism of sets</p>
<p>ϕ:A→≅Homset(Σ×S,S).</p>
<p>Given an element <em>ϵ</em>: List(Σ) × <em>S</em> → <em>S</em> in <em>A</em>, define <em>ϕ</em>(<em>ϵ</em>) on an element (<em>σ</em>, <em>s</em>) ∈ Σ × <em>S</em> by <em>ϕ</em>(<em>ϵ</em>)(<em>σ</em>, <em>s</em>) ≔ <em>ϵ</em>([<em>σ</em>], <em>s</em>), where [<em>σ</em>] is the one-element list. We now define</p>
<p>ψ:Homset(Σ×S,S)→A.</p>
<p>Given an element <em>f</em> ∈ Hom<sub><strong>Set</strong></sub>(Σ × <em>S</em>, <em>S</em>), define <em>ψ</em>(<em>f</em>): List(Σ) × <em>S</em> → <em>S</em> on a pair (<em>L</em>, <em>s</em>) ∈ List(Σ) × <em>S</em>, where <em>L</em> = [<em>ℓ</em><sub>1</sub>, … , <em>ℓ</em><sub><em>n</em></sub>] as follows. By induction, if <em>n</em> = 0, put <em>ψ</em>(<em>f</em>)(<em>L</em>, <em>s</em>) = <em>s</em>; if <em>n</em> ⩾ 1, let <em>∂L</em> = [<em>ℓ</em><sub>1</sub>, … , <em>ℓ</em><sub><em>n</em>−1</sub>] and put <em>ψ</em>(<em>f</em>)(<em>L</em>, <em>s</em>) = <em>ψ</em>(<em>f</em>)(<em>∂L</em>, <em>f</em>(<em>ℓ</em><sub><em>n</em></sub>, <em>s</em>)).</p>
<p>One checks easily that <em>ψ</em>(<em>f</em>) satisfies these two rules, making it an action of List(Σ) on <em>S</em>. It is also easy to check that <em>ϕ</em> and <em>ψ</em> are mutually inverse, completing the proof. (See Exercise <a href="chapter004.html#Exe_4-1-2-13">4.1.2.13</a>).</p>
<p>The idea of this section is summed up as follows:</p>
<p><em>Slogan</em> 4.1.2.12.</p>
<p><em>A finite state machine is an action of a free monoid on a finite set</em>.</p>
<p><em>Exercise</em> 4.1.2.13.</p>
<p>Consider the functions <em>ϕ</em> and <em>ψ</em> as defined in the proof of Proposition <a href="chapter004.html#Pro_4-1-2-11">4.1.2.11</a>.</p>
<p>a. Show that for any <em>f</em> : Σ × <em>S</em> → <em>S</em>, the map <em>ψ</em>(<em>f</em>): List(Σ) × <em>S</em> → <em>S</em> constitutes an action.</p>
<p>b. Show that <em>ϕ</em> and <em>ψ</em> are mutually inverse functions (i.e., <em>ϕ</em> ○ <em>ψ</em> = id<sub>Hom(Σ×<em>S</em>,<em>S</em>)</sub> and <em>ψ</em> ○ <em>ϕ</em> = id<sub><em>A</em></sub>).</p>
<p><em>Solution</em> 4.1.2.13.</p>
<p>a. Let <em>s</em> ∈ <em>S</em> be an arbitrary element. By the base of the induction, <em>ψ</em>(<em>f</em>)([ ], <em>s</em>) = <em>s</em>, so <em>ψ</em>(<em>f</em>) satisfies the unit law. Now let <em>L</em><sub>1</sub>, <em>L</em><sub>2</sub> ∈ List(Σ) be two lists with <em>L</em> = <em>L</em><sub>1</sub> ++ <em>L</em><sub>2</sub> their concatenation. We need to show that <em>ψ</em>(<em>f</em>)(<em>L</em><sub>1</sub>, <em>ψ</em>(<em>f</em>)(<em>L</em><sub>2</sub>, <em>s</em>)) = <em>ψ</em>(<em>f</em>)(<em>L</em>, <em>s</em>). We do this by induction on the length of <em>L</em><sub>2</sub>. If |<em>L</em><sub>2</sub>| = 0, then <em>L</em> = <em>L</em><sub>1</sub> and we have that <em>ψ</em>(<em>f</em>)(<em>L</em><sub>1</sub>, <em>ψ</em>(<em>f</em>)(<em>L</em><sub>2</sub>, <em>s</em>)) = <em>ψ</em>(<em>f</em>)(<em>L</em><sub>1</sub>, <em>s</em>) = <em>ψ</em>(<em>f</em>)(<em>L</em>, <em>s</em>).</p>
<p>Now suppose the result is true for all lists of length |<em>L</em><sub>2</sub>| − 1 ⩾ 0. We have <em>∂L</em> = <em>L</em><sub>1</sub> ++ <em>∂L</em><sub>2</sub>, where <em>∂</em> removes the last entry of a nonempty list. If <em>ℓ</em> is the last entry of <em>L</em> and <em>L</em><sub>2</sub>, then we have</p>
<p>ψ(f)(L1,ψ(f)(L2,s))=ψ(f)(L1,ψ(f)(∂L2,f(ℓ,s)))=ψ(f)(∂L,f(ℓ,s))=ψ(f)(L,s).</p>
<p>b. We first show that for <em>f</em> ∈ Hom(Σ × <em>S</em>, <em>S</em>), we have <em>ϕ</em> ○ <em>ψ</em>(<em>f</em>) = <em>f</em>. To do so, we choose (<em>σ</em>, <em>s</em>) ∈ Σ × <em>S</em>, and the formulas for <em>ϕ</em> and <em>ψ</em> from the proof of Proposition <a href="chapter004.html#Pro_4-1-2-11">4.1.2.11</a> give</p>
<p>ϕ(ψ(f))(σ,s)=ψ(f)([ σ ],s)=f(σ,s).</p>
<p>We next show that for <em>ϵ</em> ∈ <em>A</em>, we have <em>ψ</em> ○ <em>ϕ</em>(<em>ϵ</em>) = <em>ϵ</em>. To do so, we choose (<em>L</em>, <em>s</em>) ∈ List(Σ) × <em>S</em> and show that <em>ψ</em>(<em>ϕ</em>(<em>ϵ</em>))(<em>L</em>, <em>s</em>) = <em>ϵ</em>(<em>L</em>, <em>s</em>). We do this by induction on the length <em>n</em> = |<em>L</em>| of <em>L</em>. If <em>n</em> = 0, then <em>ψ</em>(<em>ϕ</em>(<em>ϵ</em>))([ ], <em>s</em>) = <em>s</em> = <em>ϵ</em>([ ], <em>s</em>). We may now assume that <em>n</em> ⩾ 1 and that the result holds for <em>∂L</em>. Let <em>ℓ</em> be the last entry of <em>L</em>. We use the formulas for <em>ϕ</em> and <em>ψ</em>, and the fact that <em>ϵ</em> is an action, to get the following derivation:</p>
<p>ψ(ϕ(ϵ))(L,s)=ψ(ϕ(ϵ))(∂L,ϕ(ϵ)(ℓ,s))=ψ(ϕ(ϵ))(∂L,ϵ([ ℓ ],s))=ϵ(∂L,ϵ([ ℓ ],s))=ϵ(∂L++[ℓ],s)=ϵ(L,s).</p>
<h2 id="lev_4-1-3" class="level2"><strong>4.1.3   Monoid action tables</strong></h2>
<p>Let <em>M</em> be a monoid generated by the set <em>G</em> = {<em>g</em><sub>1</sub>, … , <em>g</em><sub><em>m</em></sub>}, and with some relations, and suppose that <em>α</em>: <em>M</em> × <em>S</em> → <em>S</em> is an action of <em>M</em> on a set <em>S</em> = {<em>s</em><sub>1</sub>, … , <em>s</em><sub><em>n</em></sub>}. We can represent the action <em>α</em> using an <em>action table</em> whose columns are the generators <em>g</em> ∈ <em>G</em> and whose rows are the elements of <em>S</em>. In each cell (<em>row</em>, <em>col</em>), where <em>row</em> ∈ <em>S</em> and <em>col</em> ∈ <em>G</em>, we put the element <em>α</em>(<em>col</em>, <em>row</em>) ∈ <em>S</em>.</p>
<p><em>Example</em> 4.1.3.1 (Action table). If Σ and <em>S</em> are the sets from <a href="chapter004.html#Fig_4-2">Figure 4.2</a>, the displayed action of List(Σ) on <em>S</em> would be given by action table (<a href="chapter004.html#eq_4-1">4.1</a>)</p>
<p><img src="images/Art_P96.jpg" alt="art" /></p>
<p><em>Example</em> 4.1.3.2 (Multiplication action table). Every monoid (<em>M</em>, <em>e</em>, ⋆) acts on itself by its multiplication formula, ⋆: <em>M</em> × <em>M</em> → <em>M</em>. If <em>G</em> is a generating set for <em>M</em>, we can write the elements of <em>G</em> as the columns and the elements of <em>M</em> as rows, and call this a multiplication table. For example, let (ℕ, 1, *) denote the multiplicative monoid of natural numbers. The multiplication table is the usual multiplication table from grade school:</p>
<p><img src="images/Art_P97.jpg" alt="art" /></p>
<p>Try to understand what is meant by this: “Applying column 2 and then column 2 returns the same thing as applying column 4.”</p>
<p>Table (<a href="chapter004.html#eq_4-2">4.2</a>) implicitly takes every element of ℕ as a generator (since there is a column for every natural number). In fact, there is a smallest generating set for the monoid (ℕ, 1, *), so that every element of the monoid is a product of some combination of these generators, namely, the primes and 0.</p>
<p><img src="images/Art_P98.jpg" alt="art" /></p>
<p><em>Exercise</em> 4.1.3.3.</p>
<p>Let ℕ be the additive monoid of natural numbers, let <em>S</em> = {0, 1, 2, … , 11}, and let Clock: ℕ × <em>S</em> → <em>S</em> be the clock action given in Example <a href="chapter004.html#Exa_4-1-2-3">4.1.2.3</a>. Using a small generating set for the monoid, write the corresponding action table.</p>
<h2 id="lev_4-1-4" class="level2"><strong>4.1.4   Monoid homomorphisms</strong></h2>
<p>A monoid (<em>M</em>, <em>e</em>, ⋆) involves a set, a unit element, and a multiplication formula. For two monoids to be comparable, their sets, unit elements, and multiplication formulas should be appropriately comparable. For example, the additive monoids ℕ and ℤ should be comparable because ℕ ⊆ ℤ is a subset, the unit elements in both cases are the same <em>e</em> = 0, and the multiplication formulas are both integer addition.</p>
<p><strong>Definition 4.1.4.1</strong>. Let M≔(M,e,⋆) and M′≔(M′,e′,⋆′) be monoids. A <em>monoid homomorphism f from</em> M <em>to</em> M′, denoted f:M→M′, is a function f:M→M′ satisfying two conditions:</p>
<ul>
<li><em>f</em>(<em>e</em>) = <em>e</em>′.</li>
<li><em>f</em>(<em>m</em><sub>1</sub> ⋆ <em>m</em><sub>2</sub>) = <em>f</em>(<em>m</em><sub>1</sub>) ⋆′ <em>f</em>(<em>m</em><sub>2</sub>), for all <em>m</em><sub>1</sub>, <em>m</em><sub>2</sub> ∈ <em>M</em>.</li>
</ul>
<p>The set of monoid homomorphisms from M to M′ is denoted HomMon(M,M′).</p>
<p><em>Example</em> 4.1.4.2 (From ℕ to ℤ). As stated, the inclusion map <em>i</em>: ℕ → ℤ induces a monoid homomorphism (ℕ, 0, +) → (ℤ, 0, +) because <em>i</em>(0) = 0 and <em>i</em>(<em>n</em><sub>1</sub> + <em>n</em><sub>2</sub>) = <em>i</em>(<em>n</em><sub>1</sub>) + <em>i</em>(<em>n</em><sub>2</sub>).</p>
<p>Let <em>i</em><sub>5</sub> : ℕ → ℤ denote the function <em>i</em><sub>5</sub>(<em>n</em>) = 5 * <em>n</em>, so <em>i</em><sub>5</sub>(4) = 20. This is also a monoid homomorphism because <em>i</em><sub>5</sub>(0) = 5*0 = 0 and <em>i</em><sub>5</sub>(<em>n</em><sub>1</sub> + <em>n</em><sub>2</sub>) = 5*(<em>n</em><sub>1</sub> + <em>n</em><sub>2</sub>) = 5*<em>n</em><sub>1</sub> + 5*<em>n</em><sub>2</sub> = <em>i</em><sub>5</sub>(<em>n</em><sub>1</sub>) + <em>i</em><sub>5</sub>(<em>n</em><sub>2</sub>).</p>
<p><em>Application</em> 4.1.4.3. Let <em>R</em> = {<em>a</em>, <em>c</em>, <em>g</em>, <em>u</em>}, and let <em>T</em> = <em>R</em><sup>3</sup>, the set of triplets in <em>R</em>. Let R=List(R) be the free monoid on <em>R</em>, and let T=List(T) denote the free monoid on <em>T</em>. There is a monoid homomorphism F:T→R given by sending <em>t</em> = (<em>r</em><sub>1</sub>, <em>r</em><sub>2</sub>, <em>r</em><sub>3</sub>) to the list [<em>r</em><sub>1</sub>, <em>r</em><sub>2</sub>, <em>r</em><sub>3</sub>].<sup><a href="chapter004.html#endnote_3">3</a></sup></p>
<p>If <em>A</em> is the set of amino acids and A=List(A) is the free monoid on <em>A</em>, the process of translation gives a monoid homomorphism G:T→A , turning a list of RNA triplets into a polypeptide. But how do we go from a list of RNA nucleotides to a polypeptide, i.e., from R to A ? It seems that there is no good way to do this mathematically. So what is going wrong?</p>
<p>The answer is that there should not be a monoid homomorphism R→A because not all sequences of nucleotides produce a polypeptide; for example, if the sequence has only two elements, it does not code for a polypeptide. There are several possible remedies to this problem. One is to take the image of F:T→R , which is a submonoid R′⊆R . It is not hard to see that there is a monoid homomorphism F′:R′→T , and we can compose it with <em>G</em> to get the desired monoid homomorphism G○F′:R′→A.<sup><a href="chapter004.html#endnote_4">4</a></sup></p>
<p><em>Example</em> 4.1.4.4. Given any monoid M=(M,e,⋆) , there is a unique monoid homomorphism from M to the trivial monoid 1 (see Example <a href="chapter004.html#Exa_4-1-1-10">4.1.1.10</a>). There is also a unique homomorphism 1¯→M because a monoid homomorphism must send the unit to the unit. These facts together means that between any two monoids M and M′ we can always construct a homomorphism</p>
<p>M→!1¯→!M′,</p>
<p>called the <em>trivial homomorphism</em> M→M′ . It sends everything in <em>M</em> to <em>e</em> ∈ <em>M</em>′. A homomorphism M→M′ that is not trivial is called a <em>nontrivial homomorphism</em>.</p>
<p><strong>Proposition 4.1.4.5</strong>. <em>Let</em> M=(ℤ,0,+) <em>and</em> M′=(ℕ,0,+) . <em>The only monoid homomorphism</em> f:M→M′ <em>is trivial, i.e., it sends every element m</em> ∈ ℤ <em>to</em> 0 ∈ ℕ.</p>
<p><em>Proof</em>. Let f:M→M′ be a monoid homomorphism, and let <em>n</em> = <em>f</em>(1) and <em>n</em>′ = <em>f</em>(−1) in ℕ. Then we know that since 0 = 1+(−1) in ℤ, we must have 0 = <em>f</em>(0) = <em>f</em>(1+(−1)) = <em>f</em>(1)+<em>f</em>(−1) = <em>n</em>+<em>n</em>′ ∈ ℕ. But if <em>n</em> ⩾ 1, then this is impossible, so <em>n</em> = 0. Similarly, <em>n</em>′ = 0. Any element <em>m</em> ∈ ℤ can be written as <em>m</em> = 1 + 1 + ⋯ + 1 or as <em>m</em> = −1 + −1 + ⋯ + −1, and it is easy to see that <em>f</em>(1) + <em>f</em>(1) + ⋯ + <em>f</em>(1) = 0 = <em>f</em>(−1) + <em>f</em>(−1) + ⋯ + <em>f</em>(−1). Therefore, <em>f</em>(<em>m</em>) = 0 for all <em>m</em> ∈ ℤ.</p>
<p><em>Exercise</em> 4.1.4.6.</p>
<p>For any <em>m</em> ∈ ℤ, let <em>i</em><sub><em>m</em></sub>: ℕ → ℤ be the function <em>i</em><sub><em>m</em></sub>(<em>n</em>) = <em>m</em> * <em>n</em>, so <em>i</em><sub>6</sub>(7) = −42. All such functions are monoid homomorphisms (ℕ, 0, +) → (ℤ, 0, +). Do any monoid homomorphisms (ℕ, 0, +) → (ℤ, 0, +) not come in this way? For example, what about using <em>n</em> ↦ (5<em>n</em> − 1) or <em>n</em> ↦ <em>n</em><sup>2</sup> or some other function?</p>
<p><em>Exercise</em> 4.1.4.7.</p>
<p>Let M≔(ℕ,0,+) be the additive monoid of natural numbers, let N=(ℝ⩾0,0,+) be the additive monoid of nonnegative real numbers, and let P≔(ℝ&gt;0,1,*) be the multiplicitive monoid of positive real numbers. Can you think of any nontrivial monoid homomorphisms (Example <a href="chapter004.html#Exa_4-1-4-4">4.1.4.4</a>) of the following sorts:</p>
<p>a. f:M→N?</p>
<p>b. g:M→P?</p>
<p>c. h:N→P?</p>
<p>d. i:N→M?</p>
<p>e. j:P→N?</p>
<h3 id="lev_4-1-4-8" class="level3"><strong>4.1.4.8   Homomorphisms from free monoids</strong></h3>
<p>Recall that (ℕ, 0, +) is the free monoid on one generator. It turns out that for any other monoid M=(M,e,⋆) , the set of monoid homomorphisms ℕ→M is in bijection with the set <em>M</em>. This is a special case (in which <em>G</em> is a set with one element) of the following proposition.</p>
<p><strong>Proposition 4.1.4.9</strong>. <em>Let G be a set, let F</em> (<em>G</em>) ≔ (List(<em>G</em>), [ ], ++) <em>be the free monoid on G, and let</em> M≔(M,e,⋆) <em>be any monoid. There is a natural bijection</em></p>
<p>HomMon(F(G),M)→≅Homset(G,M).</p>
<p><em>Proof</em>. We provide a function ϕ:HomMon(F(G),M)→Homset(G,M) and a function ψ:Homset(G,M)→HomMon(F(G),M) and show that they are mutually inverse. Let us first construct <em>ϕ</em>. Given a monoid homomorphism f:F(G)→M , we need to provide <em>ϕ</em>(<em>f</em>): <em>G</em> → <em>M</em>. Given any <em>g</em> ∈ <em>G</em>, we define <em>ϕ</em>(<em>f</em>)(<em>g</em>) ≔ <em>f</em>([<em>g</em>]).</p>
<p>Now let us construct <em>ψ</em>. Given <em>p</em>: <em>G</em> → <em>M</em>, we need to provide ψ(p):List(G)→M such that <em>ψ</em>(<em>p</em>) is a monoid homomorphism. For a list <em>L</em> = [<em>g</em><sub>1</sub>, … , <em>g</em><sub><em>n</em></sub>] ∈ List(<em>G</em>), define <em>ψ</em>(<em>p</em>)(<em>L</em>) ≔ <em>p</em>(<em>g</em><sub>1</sub>) ⋆ ⋯ ⋆ <em>p</em>(<em>g</em><sub><em>n</em></sub>) ∈ <em>M</em>. In particular, <em>ψ</em>(<em>p</em>)([ ]) = <em>e</em>. It is not hard to see that this is a monoid homomorphism. Also, <em>ϕ</em> ○ <em>ψ</em>(<em>p</em>) = <em>p</em> for all <em>p</em> ∈ Hom<sub><strong>Set</strong></sub>(<em>G</em>, <em>M</em>). We show that <em>ψ</em> ○ <em>ϕ</em>(<em>f</em>) = <em>f</em> for all f∈HomMon(F(G),M) . Choose <em>L</em> = [<em>g</em><sub>1</sub>, … , <em>g</em><sub><em>n</em></sub>] ∈ List(<em>G</em>). Then</p>
<p>ψ(ϕf)(L)=(ϕf)(g1)⋆⋯⋆(ϕf)(gn)=f[ g1 ]⋆⋯⋆f[ gn ]=f([ g1,…,gn ])=f(L).</p>
<p><em>Exercise</em> 4.1.4.10.</p>
<p>Let <em>G</em> = {<em>a</em>, <em>b</em>}, let M≔(M,e,⋆) be any monoid, and let <em>f</em> : <em>G</em> → <em>M</em> be given by <em>f</em>(<em>a</em>) = <em>m</em> and <em>f</em>(<em>b</em>) = <em>n</em>, where <em>m</em>, <em>n</em> ∈ <em>M</em>. If ψ:Homset(G,M)→HomMon(F(G),M) is the function constructed in the proof of Proposition <a href="chapter004.html#Pro_4-1-4-9">4.1.4.9</a> and <em>L</em> = [<em>a</em>, <em>a</em>, <em>b</em>, <em>a</em>, <em>b</em>], what is <em>ψ</em>(<em>f</em>)(<em>L</em>) ?</p>
<h3 id="lev_4-1-4-11" class="level3"><strong>4.1.4.11   Restriction of scalars</strong></h3>
<p>A monoid homomorphism <em>f</em> : <em>M</em> → <em>M</em>′ (see Definition <a href="chapter004.html#Def_4-1-4-1">4.1.4.1</a>) ensures that the elements of <em>M</em> have a reasonable interpretation in <em>M</em>′; they act the same way over in <em>M</em>′ as they did in <em>M</em>. If we have such a homomorphism <em>f</em> and we have an action <em>α</em>: <em>M</em>′ × <em>S</em> → <em>S</em> of <em>M</em>′ on a set <em>S</em>, then we have a method for allowing <em>M</em> to act on <em>S</em> as well. Namely, we take an element of <em>M</em>, send it to <em>M</em>′, and use that to act on <em>S</em>. In terms of functions, we define ∆<sub><em>f</em></sub>(<em>α</em>) to be the composite:</p>
<p><img src="images/Art_P99.jpg" alt="art" /></p>
<p>After Proposition <a href="chapter004.html#Pro_4-1-4-12">4.1.4.12</a> we will know that ∆<sub><em>f</em></sub>(<em>α</em>): <em>M</em> × <em>S</em> → <em>S</em> is indeed a monoid action, and we say that it is given by <em>restriction of scalars along f</em>.</p>
<p><strong>Proposition 4.1.4.12</strong>. <em>Let</em> M≔(M,e,⋆) <em>and</em> M′≔(M′,e′,⋆′) <em>be monoids</em>, f:M→M′ <em>a monoid homomorphism, S a set, and suppose that α</em>: <em>M</em>′ × <em>S</em> → <em>S is an action of</em> M′ <em>on S. Then</em> ∆<sub><em>f</em></sub>(<em>α</em>): <em>M</em> × <em>S</em> → <em>S</em>, <em>as defined, is a monoid action as well</em>.</p>
<p><em>Proof</em>. Refer to Remark <a href="chapter004.html#Rem_4-1-2-2">4.1.2.2</a>, We assume <em>α</em> is a monoid action and want to show that ∆<sub><em>f</em></sub>(<em>α</em>) is too. We have ∆<sub><em>f</em></sub>(<em>α</em>)(<em>e</em>, <em>s</em>) = <em>α</em>(<em>f</em>(<em>e</em>), <em>s</em>) = <em>α</em>(<em>e</em>′, <em>s</em>) = <em>s</em>. We also have</p>
<p>Δf(α)(m,Δf(α)(n,s))=α(f(m),α(f(n),s))=α(f(m)⋆′f(n),s)=α(f(m⋆n),s)=Δf(α)(m⋆n,s).</p>
<p>Then the unit law and the multiplication law hold.</p>
<p><em>Example</em> 4.1.4.13. Let ℕ and ℤ denote the additive monoids of natural numbers and integers respectively, and let <em>i</em>: ℕ → ℤ be the inclusion, which Example <a href="chapter004.html#Exa_4-1-4-2">4.1.4.2</a> showed is a monoid homomorphism. There is an action <em>α</em>: ℤ × ℝ → ℝ of the monoid ℤ on the set ℝ of real numbers, given by <em>α</em>(<em>n</em>, <em>x</em>) = <em>n</em> + <em>x</em>. Clearly, this action works just as well if we restrict the scalars to ℕ ⊆ ℤ, and allow only adding natural numbers to real numbers. This is the action ∆<sub><em>i</em></sub><em>α</em>: ℕ × ℝ → ℝ, because for (<em>n</em>, <em>x</em>) ∈ ℕ × ℝ, we have ∆<sub><em>i</em></sub><em>α</em>(<em>n</em>, <em>x</em>) = <em>α</em>(<em>i</em>(<em>n</em>), <em>x</em>) = <em>α</em>(<em>n</em>, <em>x</em>) = <em>n</em> + <em>x</em>, just as expected.</p>
<p><em>Example</em> 4.1.4.14. Suppose that <em>V</em> is a complex vector space. In particular, this means that the monoid ℂ of complex numbers (under multiplication) acts on the elements of <em>V</em>. The elements of ℂ are called <em>scalars</em> in this context. If <em>i</em>: ℝ → ℂ is the inclusion of the real line inside ℂ, then <em>i</em> is a monoid homomorphism. Restriction of scalars in the preceding sense turns <em>V</em> into a real vector space, so the name “restriction of scalars” is apt.</p>
<p><em>Exercise</em> 4.1.4.15.</p>
<p>Let ℕ be the free monoid on one generator, and let Σ = {<em>a</em>, <em>b</em>}. Consider the map of monoids <em>f</em> : ℕ → List(Σ) given by sending 1 ↦ [<em>a</em>, <em>b</em>, <em>b</em>, <em>b</em>]. Consider the state set <em>S</em> = {State 0, State 1, State 2}. The monoid action <em>α</em>: List(Σ)×<em>S</em> → <em>S</em> given in Example <a href="chapter004.html#Exa_4-1-3-1">4.1.3.1</a> can be transformed by restriction of scalars along <em>f</em> to an action ∆<sub><em>f</em></sub>(<em>α</em>) of ℕ on <em>S</em>. Write its action table.</p>
<h1 id="lev_4-2" class="level1"><a href="toc.html#Rlev_4-2"><strong>4.2   Groups</strong></a></h1>
<p>Groups are monoids with the property that every element has an inverse. If we think of these structures in terms of how they act on sets, the difference between groups and monoids is that the action of every group element can be undone. One way of thinking about groups is in terms of symmetries. For example, the rotations and reflections of a square form a group because they can be undone.</p>
<p>Another way to think of the difference between monoids and groups is in terms of time. Monoids are likely useful in thinking about diffusion, in which time plays a role and things cannot be undone. Groups are more likely useful in thinking about mechanics, where actions are time-reversible.</p>
<h2 id="lev_4-2-1" class="level2"><strong>4.2.1   Definition and examples</strong></h2>
<p><strong>Definition 4.2.1.1</strong>. Let (<em>M</em>, <em>e</em>, ⋆) be a monoid. An element <em>m</em> ∈ <em>M</em> is said to <em>have an inverse</em> if there exists an <em>m</em>′ ∈ <em>M</em> such that <em>mm</em>′ = <em>e</em> and <em>m</em>′<em>m</em> = <em>e</em>. A <em>group</em> is a monoid (<em>M</em>, <em>e</em>, ⋆) in which every element <em>m</em> ∈ <em>M</em> has an inverse.</p>
<p><strong>Proposition 4.2.1.2</strong>. <em>Suppose that</em> M≔(M,e,⋆) <em>is a monoid, and let m</em> ∈ <em>M be an element. Then m has at most one inverse</em>.<sup><a href="chapter004.html#endnote_5">5</a></sup></p>
<p><em>Proof</em>. Suppose that both <em>m</em>′ and <em>m</em>″ are inverses of <em>m</em>; we want to show that <em>m</em>′ = <em>m</em>″. This follows by the associative law for monoids:</p>
<p>m′=m′(mm″)=(m′m)m″=m″.</p>
<p><em>Example</em> 4.2.1.3. The additive monoid (ℕ, 0, +) is not a group because none of its elements are invertible, except for 0. However, the monoid of integers (ℤ, 0, +) is a group. The monoid of clock positions from Example <a href="chapter004.html#Exa_4-1-1-26">4.1.1.26</a> is also a group. For example, the inverse of <em>Q</em><sup>5</sup> is <em>Q</em><sup>7</sup> because <em>Q</em><sup>5</sup> ⋆ <em>Q</em><sup>7</sup> = <em>e</em> = <em>Q</em><sup>7</sup> ⋆ <em>Q</em><sup>5</sup>.</p>
<p><em>Example</em> 4.2.1.4. Consider a square centered at the origin in ℝ<sup>2</sup>. It has rotational and mirror symmetries. There are eight of these, denoted</p>
<p>{ e,ρ,ρ2,ρ3,ϕ,ϕρ,ϕρ2,ϕρ3 },</p>
<p>where <em>ρ</em> stands for 90° counterclockwise rotation and <em>ϕ</em> stands for horizontal flip (across the vertical axis). So relations include <em>ρ</em><sup>4</sup> = <em>e</em>, <em>ϕ</em><sup>2</sup> = <em>e</em>, and <em>ρ</em><sup>3</sup><em>ϕ</em> = <em>ϕρ</em>. This group is called the <em>dihedral group of order eight</em>.</p>
<p><em>Example</em> 4.2.1.5. The set of 3 × 3 matrices can be given the structure of a monoid, where the unit element is the 3 × 3 identity matrix, the multiplication formula is given by matrix multiplication. It is a monoid but not a group because not all matrices are invertible.</p>
<p>The subset of invertible matrices does form a group, called <em>the general linear group of degree 3</em> and denoted <em>GL</em><sub>3</sub>. Inside of <em>GL</em><sub>3</sub> is the <em>orthogonal group</em>, denoted <em>O</em><sub>3</sub>, of matrices <em>M</em> such that <em>M</em><sup>−1</sup> = <em>M</em><sup>⊤</sup>. These matrices correspond to symmetries of the two-dimensional sphere centered at the origin in ℝ<sup>2</sup>.</p>
<p>Another interesting group is the Euclidean group <em>E</em>(3), which consists of all <em>isometries</em> of ℝ<sup>3</sup>, i.e., all functions ℝ<sup>3</sup> → ℝ<sup>3</sup> that preserve distances.</p>
<p><em>Application</em> 4.2.1.6. In crystallography one is often concerned with the symmetries that arise in the arrangement <em>A</em> of atoms in a molecule. To think about symmetries in terms of groups, we first define an <em>atom arrangement</em> to be a finite subset <em>i</em>: <em>A</em> ⊆ ℝ<sup>3</sup>. A symmetry in this case is an isometry of ℝ<sup>3</sup> (see Example <a href="chapter004.html#Exa_4-2-1-5">4.2.1.5</a>), say, <em>f</em> : ℝ<sup>3</sup> → ℝ<sup>3</sup>, such that there exists a dotted arrow making the following diagram commute:</p>
<p><img src="images/Art_P100.jpg" alt="art" /></p>
<p>That is, it is an isometry of ℝ<sup>3</sup> such that each atom of <em>A</em> is sent to a position currently occupied by an atom of <em>A</em>. It is not hard to show that the set of such isometries forms a group, called the <em>space group</em> of the crystal.</p>
<p><em>Exercise</em> 4.2.1.7.</p>
<p>Let <em>X</em> be a finite set. A <em>permutation of X</em> is an isomorphism f:X→≅X. Let Iso(<em>X</em>) ≔ {<em>f</em> : <em>X</em> → <em>X</em> | <em>f</em> is an isomorphism} be the set of permutations of <em>X</em>. Here is a picture of an element in Iso(<em>S</em>), where <em>S</em> = {<em>s</em><sub>1</sub>, <em>s</em><sub>2</sub>, <em>s</em><sub>3</sub>, <em>s</em><sub>4</sub>}:</p>
<p><img src="images/Art_P101.jpg" alt="art" /></p>
<p>a. Devise a unit and a multiplication formula, such that the set Iso(<em>X</em>) of permutations of <em>X</em> forms a monoid.</p>
<p>b. Is the monoid Iso(<em>X</em>) always in fact a group?</p>
<p><em>Solution</em> 4.2.1.7.</p>
<p>a. We can take the unit to be the identity function idS:S→≅S and the multiplication formula to be a composition of isomorphisms <em>f</em> ⋆ <em>g</em> = <em>f</em> ○ <em>g</em>. Clearly, id<sub><em>S</em></sub> ○ <em>f</em> = <em>f</em> ○ id<sub><em>S</em></sub> = <em>f</em> and (<em>f</em> ○ <em>g</em>) ○ <em>h</em> = <em>f</em> ○ (<em>g</em> ○ <em>h</em>), so this formula satisfies the unit and multiplication laws. In other words, we have put a monoid structure on the set <em>Iso</em>(<em>S</em>).</p>
<p>b. Yes, Iso(<em>X</em>) is a group because every element of <em>f</em> ∈ <em>Iso</em>(<em>S</em>) is invertible. Namely, the fact that <em>f</em> is an isomorphism means that there is some <em>f</em><sup>−1</sup> ∈ <em>Iso</em>(<em>S</em>) with <em>f</em> ○ <em>f</em><sup>−1</sup> = <em>f</em><sup>−1</sup> ○ <em>f</em> = id<sub><em>S</em></sub>.</p>
<p><em>Exercise</em> 4.2.1.8.</p>
<p>In Exercise <a href="chapter004.html#Exe_4-1-1-28">4.1.1.28</a> you classified the cyclic monoids. Which of them are groups?</p>
<p><strong>Definition 4.2.1.9</strong> (Group action). Let (<em>G</em>, <em>e</em>, ⋆) be a group and <em>S</em> a set. An <em>action</em> of <em>G</em> on <em>S</em> is a function <img src="images/rotate.jpg" alt="art" />: <em>G</em> × <em>S</em> → <em>S</em> such that for all <em>s</em> ∈ <em>S</em> and <em>g</em>, <em>g</em>′ ∈ <em>G</em>, we have</p>
<ul>
<li><em>e</em> <img src="images/rotate.jpg" alt="art" /> <em>s</em> = <em>s</em>;</li>
<li><em>g</em> <img src="images/rotate.jpg" alt="art" /> (<em>g</em>′ <img src="images/rotate.jpg" alt="art" /> <em>s</em>) = (<em>g</em> ⋆ <em>g</em>′) <img src="images/rotate.jpg" alt="art" /> <em>s</em>.</li>
</ul>
<p>In other words, considering <em>G</em> as a monoid, it is an action in the sense of Definition <a href="chapter004.html#Def_4-1-2-1">4.1.2.1</a>.</p>
<p><em>Example</em> 4.2.1.10. When a group acts on a set, it has the character of symmetry. For example, consider the group whose elements are angles <em>θ</em>. This group may be denoted <em>U</em>(1) and is often formalized as the unit circle in ℂ, i.e., the set of complex numbers <em>z</em> = <em>a</em> + <em>bi</em> such that |<em>z</em>| = <em>a</em><sup>2</sup> + <em>b</em><sup>2</sup> = 1. The set of such points is given the structure of a group (<em>U</em>(1), 1 + 0<em>i</em>, ⋆) by defining the unit element to be 1 + 0<em>i</em> and the group law to be complex multiplication. But for those unfamiliar with complex numbers, this is simply angle addition, where we understand that 360° = 0°. If <em>θ</em><sub>1</sub> = 190° and <em>θ</em><sub>2</sub> = 278°, then <em>θ</em><sub>1</sub> ⋆ <em>θ</em><sub>2</sub> = 468° = 108°. In the language of complex numbers, <em>z</em> = <em>e</em><sup><em>iθ</em></sup>.</p>
<p>The group <em>U</em>(1) acts on any set that we can picture as having rotational symmetry about a fixed axis, such as the earth around the north-south axis. We will define <em>S</em> = {(<em>x</em>, <em>y</em>, <em>z</em>) ∈ ℝ<sup>3</sup> | <em>x</em><sup>2</sup> + <em>y</em><sup>2</sup> + <em>z</em><sup>2</sup> = 1} to be the unit sphere in ℝ<sup>3</sup>, and seek to understand the rotational action of <em>U</em>(1) on <em>S</em>.</p>
<p>We first show that <em>U</em>(1) acts on ℝ<sup>3</sup> by <em>θ</em> <img src="images/rotate.jpg" alt="art" /> (<em>x</em>, <em>y</em>, <em>z</em>) = (<em>x</em> cos <em>θ</em> + <em>y</em> sin <em>θ</em>, −<em>x</em> sin <em>θ</em> + <em>y</em> cos <em>θ</em>, <em>z</em>), or with matrix notation as</p>
<p><img src="images/Art_P102.jpg" alt="art" /></p>
<p>Trigonometric identities ensure that this is indeed an action.</p>
<p>In terms of action tables, we would need infinitely many rows and columns to express this action. Here is a sample:</p>
<p>Action of <em>U</em>(1) on ℝ<sup>3</sup></p>
<p>ℝ<sup>3</sup></p>
<p><em>θ</em> = 45°</p>
<p><em>θ</em> = 90°</p>
<p><em>θ</em> = 100°</p>
<p>⋯</p>
<p>(0, 0, 0)</p>
<p>(0, 0, 0)</p>
<p>(0, 0, 0)</p>
<p>(0, 0, 0)</p>
<p>⋯</p>
<p>(1, 0, 0)</p>
<p>(0.71, 0.71, 0)</p>
<p>(0, 1, 0)</p>
<p>(−0.17, 0.98, 0)</p>
<p>⋯</p>
<p>(0, 1, −4.2)</p>
<p>(−0.71, 0.71, −4.2)</p>
<p>(−1, 0, −4.2)</p>
<p>(−0.98, −0.17, −4.2)</p>
<p>⋯</p>
<p>(3, 4, 2)</p>
<p>(4.95, 0.71, 2)</p>
<p>(−4, 3, 2)</p>
<p>(3.42, −3.65, 2)</p>
<p>⋯</p>
<p>⋮</p>
<p>⋮</p>
<p>⋮</p>
<p>⋮</p>
<p>⋱</p>
<p>Since <em>S</em> ⊆ ℝ<sup>3</sup> consists of all vectors of length 1, we need to check that the action preserves length, i.e., that if (<em>x</em>, <em>y</em>, <em>z</em>) ∈ <em>S</em>, then <em>θ</em> <img src="images/rotate.jpg" alt="art" /> (<em>x</em>, <em>y</em>, <em>z</em>) ∈ <em>S</em>. In this way we will have confirmed that <em>U</em>(1) indeed acts on <em>S</em>. The calculation begins by assuming <em>x</em><sup>2</sup> + <em>y</em><sup>2</sup> + <em>z</em><sup>2</sup> = 1, and one uses trigonometric identities to see that</p>
<p>(x cos⁡θ+y sin⁡θ)2+(−x sin⁡θ+y cos⁡θ)2+z2=x2+y2+z2=1.</p>
<p><em>Exercise</em> 4.2.1.11.</p>
<p>Let <em>X</em> be a set and consider the group Iso(<em>X</em>) of permutations of <em>X</em> (see Exercise <a href="chapter004.html#Exe_4-2-1-7">4.2.1.7</a>). Find a canonical action of Iso<sub><em>X</em></sub> on <em>X</em>.</p>
<p><em>Solution</em> 4.2.1.11.</p>
<p>The elements of Iso(<em>X</em>) are isomorphisms f:X→≅X . To get an action <img src="images/rotate.jpg" alt="art" />: Iso(<em>X</em>) × <em>X</em> → <em>X</em>, we need, for every pair (<em>f</em>, <em>x</em>), an element of <em>X</em>. The obvious choice is <em>f</em>(<em>x</em>) ∈ <em>X</em>.<sup><a href="chapter004.html#endnote_6">6</a></sup> Let’s check that this really gives an action. For any <em>f</em>, <em>g</em> ∈ Iso(<em>X</em>) and any <em>x</em> ∈ <em>X</em> we indeed have id<sub><em>X</em></sub>(<em>x</em>) = <em>x</em> and we indeed have <em>f</em>(<em>g</em>(<em>x</em>)) = (<em>f</em> ○ <em>g</em>)(<em>x</em>), so our choice works.</p>
<p><strong>Definition 4.2.1.12</strong>. Let <em>G</em> be a group acting on a set <em>X</em>. For any point <em>x</em> ∈ <em>X</em>, the <em>orbit of x</em>, denoted <em>Gx</em>, is the set</p>
<p>Gx≔{ x′∈X|∃g∈G such that gx=x′ }.</p>
<p><em>Application</em> 4.2.1.13. Let <em>S</em> be the surface of the earth, understood as a sphere, and let <em>G</em> = <em>U</em>(1) be the group of angles acting on <em>S</em> by rotation as in Example <a href="chapter004.html#Exa_4-2-1-10">4.2.1.10</a>. The orbit of any point <em>p</em> = (<em>x</em>, <em>y</em>, <em>z</em>) ∈ <em>S</em> is the set of points on the same latitude line as <em>p</em>.</p>
<p>One may also consider a small band around the earth, i.e., the set <em>A</em> = {(<em>x</em>, <em>y</em>, <em>z</em>) | 1.0 ⩽ <em>x</em><sup>2</sup> + <em>y</em><sup>2</sup> + <em>z</em><sup>2</sup> ⩽ 1.05}. The action of <em>U</em>(1) <img src="images/rotate.jpg" alt="art" /> <em>S</em> extends to an action <em>U</em>(1) <img src="images/rotate.jpg" alt="art" /> <em>A</em>. The orbits are latitude-lines-at-altitude. A simplifying assumption in climatology may be given by assuming that <em>U</em>(1) acts on all currents in the atmosphere in an appropriate sense. Thus, instead of considering movement within the whole space <em>A</em>, we only allow movement that behaves the same way throughout each orbit of the group action.</p>
<p><em>Exercise</em> 4.2.1.14.</p>
<p>a. Consider the <em>U</em>(1) action on the sphere <em>S</em> given in Example <a href="chapter004.html#Exa_4-2-1-10">4.2.1.10</a>. Describe the set of orbits of this action.</p>
<p>b. What are the orbits of the canonical action of the permutation group Iso<sub>{1,2,3}</sub> on the set {1, 2, 3}? (See Exercise <a href="chapter004.html#Exe_4-2-1-11">4.2.1.11</a>.)</p>
<p><em>Exercise</em> 4.2.1.15.</p>
<p>Let (<em>G</em>, <em>e</em>, ⋆) be a group and <em>X</em> a set on which <em>G</em> acts. Is “being in the same orbit” an equivalence relation on <em>X</em>?</p>
<p><strong>Definition 4.2.1.16</strong>. Let <em>G</em> and <em>G</em>′ be groups. A <em>group homomorphism f</em> : <em>G</em> → <em>G</em>′ is defined to be a monoid homomorphism <em>G</em> → <em>G</em>′, where <em>G</em> and <em>G</em>′ are being regarded as monoids in accordance with Definition <a href="chapter004.html#Def_4-2-1-1">4.2.1.1</a>.</p>
<h1 id="lev_4-3" class="level1"><a href="toc.html#Rlev_4-3"><strong>4.3   Graphs</strong></a></h1>
<p>Unless otherwise specified, whenever I speak of graphs in this book, I do not mean curves in the plane, such as parabolas, or pictures of functions generally, but rather systems of vertices and arrows.</p>
<p><em>Graphs</em> are taken to be <em>directed</em>, meaning that every arrow points <em>from</em> a vertex <em>to</em> a vertex; rather than merely connecting vertices, arrows have direction. If <em>a</em> and <em>b</em> are vertices, there can be many arrows from <em>a</em> to <em>b</em>, or none at all. There can be arrows from <em>a</em> to itself. Here is the formal definition in terms of sets and functions.</p>
<h2 id="lev_4-3-1" class="level2"><strong>4.3.1   Definition and examples</strong></h2>
<p><strong>Definition 4.3.1.1</strong>. A <em>graph G</em> consists of a sequence <em>G</em> ≔ (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>), where</p>
<ul>
<li><em>V</em> is a set, called <em>the set of vertices of G</em> (singular: <em>vertex</em>);</li>
<li><em>A</em> is a set, called <em>the set of arrows of G</em>;</li>
<li><em>src</em>: <em>A</em> → <em>V</em> is a function, called <em>the source function for G</em>;</li>
<li><em>tgt</em>: <em>A</em> → <em>V</em> is a function, called <em>the target function for G</em>.</li>
</ul>
<p>Given an arrow <em>a</em> ∈ <em>A</em> we refer to <em>src</em>(<em>a</em>) as the <em>source vertex</em> of <em>a</em> and to <em>tgt</em>(<em>a</em>) as the <em>target vertex</em> of <em>a</em>.</p>
<p>To draw a graph, first draw a dot for every element of <em>V</em>. Then for every element <em>a</em> ∈ <em>A</em>, draw an arrow connecting dot <em>src</em>(<em>a</em>) to dot <em>tgt</em>(<em>a</em>).</p>
<p><em>Example</em> 4.3.1.2 (Graph). Here is a picture of a graph <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>):</p>
<p><img src="images/Art_P103.jpg" alt="art" /></p>
<p>We have <em>V</em> = {<em>v</em>, <em>w</em>, <em>x</em>, <em>y</em>, <em>z</em>} and <em>A</em> = {<em>f</em>, <em>g</em>, <em>h</em>, <em>i</em>, <em>j</em>, <em>k</em>}. The source and target functions <em>src</em>, <em>tgt</em>: <em>A</em> → <em>V</em> are expressed in the following table (left-hand side):</p>
<p><img src="images/Art_P104.jpg" alt="art" /></p>
<p>In fact, all the data of the graph <em>G</em> is captured in these two tables—together they tell us the sets <em>A</em> and <em>V</em> and the functions <em>src</em> and <em>tgt</em>.</p>
<p><em>Example</em> 4.3.1.3. Every olog has an underlying graph, in the sense of Definition <a href="chapter004.html#Def_4-3-1-1">4.3.1.1</a>. An olog has additional information, namely, information about which pairs of paths are declared equivalent as well as text that has certain English-readability rules.</p>
<p><em>Exercise</em> 4.3.1.4.</p>
<p>a. Draw the graph corresponding to the following tables:</p>
<p><img src="images/Art_P105.jpg" alt="art" /></p>
<p>b. Write two tables like the ones in part (a) corresponding to the following graph:</p>
<p><img src="images/Art_P106.jpg" alt="art" /></p>
<p><em>Exercise</em> 4.3.1.5.</p>
<p>a. Let <em>A</em> = {1, 2, 3, 4, 5} and <em>B</em> = {<em>a</em>, <em>b</em>, <em>c</em>}. Draw them, and choose an arbitrary function <em>f</em> : <em>A</em> → <em>B</em> and draw it.</p>
<p>b. Let <em>A</em> ⊔ <em>B</em> be the coproduct of <em>A</em> and <em>B</em> (Definition <a href="chapter003.html#Def_3-1-2-1">3.1.2.1</a>), and let A→i1A⊔B←i2B be the two inclusions. Consider the two functions <em>src</em>, <em>tgt</em>: <em>A</em> → <em>A</em> ⊔ <em>B</em>, where <em>src</em> = <em>i</em><sub>1</sub> and <em>tgt</em> is the composition A→fB→i2A⊔B. Draw the associated graph <em>G</em> ≔ (<em>A</em> ⊔ <em>B</em>, <em>A</em>, <em>src</em>, <em>tgt</em>).</p>
<p><em>Exercise</em> 4.3.1.6.</p>
<p>a. Let <em>V</em> be a set. Suppose we just draw the elements of <em>V</em> as vertices and have no arrows between them. Is this a graph?</p>
<p>b. Given <em>V</em>, is there any other canonical or somehow automatic nonrandom procedure for generating a graph with those vertices?</p>
<p><em>Solution</em> 4.3.1.6.</p>
<p>a. Yes. With arrows <em>A</em> = ∅, there is a unique function !: <em>A</em> → <em>V</em>, so we have (<em>V</em>, ∅, !, !). This is called the <em>discrete graph</em> on vertices <em>V</em>.</p>
<p>b. Yes. Choose as arrows <em>A</em> = <em>V</em> × <em>V</em>, and let <em>src</em>: <em>A</em> → <em>V</em> and <em>tgt</em>: <em>A</em> → <em>V</em> be the projections. This gives the <em>indiscrete graph Ind</em>(<em>V</em>) ≔ (<em>V</em>, <em>V</em> × <em>V</em>, <em>π</em><sub>1</sub>, <em>π</em><sub>2</sub>) on vertices <em>V</em>. An indiscrete graph is one in which each vertex is connected (backward and forward) to every other vertex and also points to itself.</p>
<p>Another would be (<em>V</em>, <em>V</em>, id<sub><em>V</em></sub>, id<sub><em>V</em></sub>), which puts a loop at every vertex and has no other arrows.</p>
<p><em>Example</em> 4.3.1.7. Recall from Construction <a href="chapter003.html#Con_3-2-2-6">3.2.2.6</a> the notion of a bipartite graph, defined to be a span (i.e., pair of functions; see Definition <a href="chapter003.html#Def_3-2-2-1">3.2.2.1</a>) A←fR→gB. Now that we have a formal definition of a graph, we might hope that the notion of bipartite graphs fits in as a particular sort of graph, and it does. Let <em>V</em> = <em>A</em> ⊔ <em>B</em>, and let <em>i</em>: <em>A</em> → <em>V</em> and <em>j</em> : <em>B</em> → <em>V</em> be the inclusions. Let <em>src</em> = <em>i</em> ○ <em>f</em> : <em>R</em> → <em>V</em>, and let <em>tgt</em> = <em>j</em> ○ <em>g</em> : <em>R</em> → <em>V</em> be the composites:</p>
<p><img src="images/Art_P107.jpg" alt="art" /></p>
<p>Then (<em>V</em>, <em>R</em>, <em>src</em>, <em>tgt</em>) is a graph that would be drawn exactly as specified the drawing of spans in Construction <a href="chapter003.html#Con_3-2-2-6">3.2.2.6</a>.</p>
<p><em>Example</em> 4.3.1.8. Let <em>n</em> ∈ ℕ be a natural number. The <em>chain graph of length n</em>, denoted [<em>n</em>], is the following graph:</p>
<p>•0→•1→⋯→•n</p>
<p>In general, [<em>n</em>] has <em>n</em> arrows and <em>n</em> + 1 vertices. In particular, when <em>n</em> = 0, we have that [0] is the graph consisting of a single vertex and no arrows.</p>
<p><em>Example</em> 4.3.1.9. Let <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) be a graph, Suppose that we want to spread it out over discrete time, so that each arrow does not occur within a given time slice but instead over a quantum unit of time.</p>
<p>Let [ℕ] = (ℕ, ℕ, <em>n</em> ↦<em>n</em>, <em>n</em> ↦ <em>n</em> + 1) be the graph depicted:</p>
<p>•0→0•1→1•2→2⋯</p>
<p>The discussion of limits in a category (see Chapter 6) clarifies that products can be taken in the category of graphs (see Example <a href="chapter006.html#Exa_6-1-1-5">6.1.1.5</a>), so [ℕ] × <em>G</em> will make sense. For now, we construct it by hand.</p>
<p>Let <em>T</em>(<em>G</em>) = (<em>V</em> × ℕ, <em>A</em> × ℕ, <em>src</em>′, <em>tgt</em>′) be a new graph, where for <em>a</em> ∈ <em>A</em> and <em>n</em> ∈ ℕ, we have <em>src</em>′(<em>a</em>, <em>n</em>) ≔ (<em>src</em>(<em>a</em>), <em>n</em>) and <em>tgt</em>′(<em>a</em>, <em>n</em>) = (<em>tgt</em>(<em>a</em>), <em>n</em> + 1).</p>
<p>Let <em>G</em> be the following graph:</p>
<p><img src="images/Art_P108.jpg" alt="art" /></p>
<p>Then <em>T</em>(<em>G</em>) will be the graph</p>
<p><img src="images/Art_P109.jpg" alt="art" /></p>
<p>The <em>f</em> arrows still take <em>a</em>’s to <em>a</em>’s, and the <em>g</em> arrows still take <em>a</em>’s to <em>b</em>’s, but they always march forward in time.</p>
<p><em>Exercise</em> 4.3.1.10.</p>
<p>Let <em>G</em> be the following graph:</p>
<p><img src="images/Art_P110.jpg" alt="art" /></p>
<p>Draw the graph <em>T</em>(<em>G</em>) defined in Example <a href="chapter004.html#Exa_4-3-1-9">4.3.1.9</a>, using ellipses (⋯) if necessary.</p>
<p><em>Solution</em> 4.3.1.10.</p>
<p><img src="images/Art_P111.jpg" alt="art" /></p>
<p><em>Exercise</em> 4.3.1.11.</p>
<p>Consider the following infinite graph <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>):</p>
<p><img src="images/Art_P112.jpg" alt="art" /></p>
<p>a. Write the sets <em>A</em> and <em>V</em>.</p>
<p>b. What are the source and target functions <em>A</em> → <em>V</em>?</p>
<p><em>Exercise</em> 4.3.1.12.</p>
<p>A graph is a pair of functions <em>A</em> ⇉ <em>V</em>. This sets up the notion of equalizer and coequalizer (see Definitions <a href="chapter003.html#Def_3-2-3-1">3.2.3.1</a> and <a href="chapter003.html#Def_3-3-3-1">3.3.3.1</a>).</p>
<p>a. What feature of a graph <em>G</em> is captured by the equalizer of its source and target functions?</p>
<p>b. What feature of a graph <em>G</em> is captured by the coequalizer of its source and target functions?</p>
<p><em>Solution</em> 4.3.1.12.</p>
<p>a. The equalizer of <em>src</em>, <em>tgt</em> is the set of loops in <em>G</em>, i.e., arrows pointing from a vertex to itself.</p>
<p>b. The coequalizer of <em>srs</em>, <em>tgt</em> is the set of connected components in <em>G</em>. See Exercise <a href="chapter003.html#Exe_3-3-1-11">3.3.1.11</a>.</p>
<h2 id="lev_4-3-2" class="level2"><strong>4.3.2   Paths in a graph</strong></h2>
<p>One usually has some idea of what a path in a graph is, especially if one is is told that a path must always follow the direction of arrows. The following definition makes this idea precise. In particular, one can have paths of any finite length <em>n</em> ∈ ℕ, even length 0 or 1. Also, we want to be able to talk about the source vertex and target vertex of a path as well as about concatenation of paths.</p>
<p><strong>Definition 4.3.2.1</strong>. Let <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) be a graph. A <em>path of length n</em> in <em>G</em>, denoted p∈PathG(n) , is a head-to-tail sequence</p>
<p>p=(v0→a1v1→a2v2→a3⋯→anvn)(4.4)</p>
<p>of arrows in <em>G</em>, denoted [ a1,a2,…,an ]v0 . A path is a list of arrows, so we use a variant of list notation, but the extra subscript at the beginning, which indicates the source vertex, reminds us that this list is actually a path. We have canonical isomorphisms PathG(1)≅A and PathG(0)≅V : a path of length 1 is an arrow, and a path of length 0 is a vertex. We refer to the length 0 path [ ]v on vertex <em>v</em> as the <em>trivial path on v</em>.</p>
<p>We denote by Path<sub><em>G</em></sub> the set of paths (of any length) in <em>G</em>, i.e.,</p>
<p>PathG≔∐n∈ℕPathG(n).</p>
<p>Every path <em>p</em> ∈ Path<sub><em>G</em></sub> has a source vertex and a target vertex, and we may denote these src¯,tgt¯:PathG→V. If <em>p</em> is a path with src¯(p)=v and tgt¯(p)=w , we may denote it <em>p</em>: <em>v</em> → <em>w</em>. Given two vertices <em>v</em>, <em>w</em> ∈ <em>V</em>, we write Path<sub><em>G</em></sub>(<em>v</em>, <em>w</em>) to denote the set of all paths <em>p</em>: <em>v</em> → <em>w</em>.</p>
<p>There is a concatenation operation on paths. Given a path <em>p</em>: <em>v</em> → <em>w</em> and <em>q</em> : <em>w</em> → <em>x</em>, we define the concatenation, denoted <em>p</em> ++ <em>q</em> : <em>v</em> → <em>x</em>, using concatenation of lists (see Definition <a href="chapter004.html#Def_4-1-1-13">4.1.1.13</a>). That is, if p=[ a1,a2,…,am ]v and q=[ b1,b2,…,bn ]w , then p++q=[ a1,…,am,b1,…,bn ]v . In particular, if p=[ ]v is the trivial path on vertex <em>v</em> (resp. if r=[ ]w is the trivial path on vertex <em>w</em>), then for any path <em>q</em> : <em>v</em> → <em>w</em>, we have <em>p</em> ++ <em>q</em> = <em>q</em> (resp. <em>q</em> ++ <em>r</em> = <em>q</em>).</p>
<p><em>Example</em> 4.3.2.2. Let <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) be a graph, and suppose <em>v</em> ∈ <em>V</em> is a vertex. If <em>p</em>: <em>v</em> → <em>v</em> is a path of length |<em>p</em>| ∈ ℕ with src¯(p)=tgt¯(p)=v , we call it a <em>loop of length</em> |<em>p</em>|. For <em>n</em> ∈ ℕ, we write <em>p</em><sup><em>n</em></sup> : <em>v</em> → <em>v</em> to denote the <em>n</em>-fold concatenation <em>p</em><sup><em>n</em></sup> ≔ <em>p</em>++<em>p</em>++ ⋯ ++<em>p</em> (where <em>p</em> is written <em>n</em> times).</p>
<p><em>Example</em> 4.3.2.3. In diagram (<a href="chapter004.html#eq_4-3">4.3</a>), page 120, we see a graph <em>G</em>. In it, there are no paths from <em>v</em> to <em>y</em>, one path (namely, [ f ]v ) from <em>v</em> to <em>w</em>, two paths (namely, <em>v</em>[<em>f</em>, <em>g</em>] and [ f,h ]v ) from <em>v</em> to <em>x</em>, and infinitely many paths</p>
<p>{[i]y q1++[j,k]y r1++⋯++[i]y qn ++[j,k]yrn|n,q1,r1,…,qn,rn∈ℕ}</p>
<p>from <em>y</em> to <em>y</em>. There are other paths as well in <em>G</em>, including the five trivial paths.</p>
<p><em>Exercise</em> 4.3.2.4.</p>
<p>How many paths are there in the following graph?</p>
<p>•1→f•2→g•3</p>
<p><em>Exercise</em> 4.3.2.5.</p>
<p>Let <em>G</em> be a graph, and consider the set Path<sub><em>G</em></sub> of paths in <em>G</em>. Suppose someone claimed that there is a monoid structure on the set Path<sub><em>G</em></sub>, where the multiplication formula is given by concatenation of paths. Are they correct? Why, or why not?</p>
<h2 id="lev_4-3-3" class="level2"><strong>4.3.3   Graph homomorphisms</strong></h2>
<p>A graph (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) involves two sets and two functions. For two graphs to be comparable, their two sets and their two functions should be appropriately comparable.</p>
<p><strong>Definition 4.3.3.1</strong>. Let <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) and <em>G</em>′ = (<em>V</em>′, <em>A</em>′, <em>src</em>′, <em>tgt</em>′) be graphs. A <em>graph homomorphism f from G to G</em>′, denoted <em>f</em> : <em>G</em> → <em>G</em>′, consists of two functions <em>f</em><sub>0</sub>: <em>V</em> → <em>V</em>′ and <em>f</em><sub>1</sub>: <em>A</em> → <em>A</em>′ such that the diagrams in (<a href="chapter004.html#eq_4-5">4.5</a>) commute:</p>
<p><img src="images/Art_P114.jpg" alt="art" /></p>
<p><em>Remark</em> 4.3.3.2. The conditions (<a href="chapter004.html#eq_4-5">4.5</a>) may look abstruse at first, but they encode a very important idea, roughly stated “arrows are bound to their endpoints.” Under a map of graphs <em>G</em> → <em>G</em>′, one cannot flippantly send an arrow of <em>G</em> any old arrow of <em>G</em>′: it must still connect the vertices it connected before. Following is an example of a mapping that does not respect this condition: <em>a</em> connects 1 and 2 before but not after:</p>
<p><img src="images/Art_P115.jpg" alt="art" /></p>
<p>The commutativity of the diagrams in (<a href="chapter004.html#eq_4-5">4.5</a>) is exactly what is needed to ensure that arrows are handled in the expected way by a proposed graph homomorphism.</p>
<p><em>Example</em> 4.3.3.3 (Graph homomorphism). Let <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) and <em>G</em>′ = (<em>V</em>′, <em>A</em>′, <em>src</em>′, <em>tgt</em>′) be the graphs drawn in (<a href="chapter004.html#eq_4-6">4.6</a>):</p>
<p><img src="images/Art_P116.jpg" alt="art" /></p>
<p>The colors indicate the choice of function <em>f</em><sub>0</sub>: <em>V</em> → <em>V</em>′. Given that choice, condition (<a href="chapter004.html#eq_4-5">4.5</a>) imposes in this case that there is a unique choice of graph homomorphism <em>f</em> : <em>G</em> → <em>G</em>′. In other words, where arrows are sent is completely determined by where vertices are sent, in this particular case.</p>
<p><em>Exercise</em> 4.3.3.4.</p>
<p>a. Where are <em>a</em>, <em>b</em>, <em>c</em>, <em>d</em>, <em>e</em> sent under <em>f</em><sub>1</sub> : <em>A</em> → <em>A</em>′ in diagram (<a href="chapter004.html#eq_4-6">4.6</a>)?</p>
<p>b. Choose an element <em>x</em> ∈ <em>A</em>, and check that it behaves as specified by diagram (<a href="chapter004.html#eq_4-5">4.5</a>).</p>
<p><em>Exercise</em> 4.3.3.5.</p>
<p>Let <em>G</em> be a graph, let <em>n</em> ∈ ℕ be a natural number, and let [<em>n</em>] be the chain graph of length <em>n</em>, as in Example <a href="chapter004.html#Exa_4-3-1-8">4.3.1.8</a>. Is a path of length <em>n</em> in <em>G</em> the same thing as a graph homomorphism [<em>n</em>] → <em>G</em>, or are there subtle differences? More precisely, is there always an isomorphism between the set of graph homomorphisms [<em>n</em>] → <em>G</em> and the set PathG(n) of length <em>n</em> paths in <em>G</em>?</p>
<p><em>Solution</em> 4.3.3.5.</p>
<p>Yes, a path of length <em>n</em> in <em>G</em> is the same thing as a graph homomorphism [<em>n</em>] → <em>G</em>. The discussion of categories in Chapter 5 makes clear how to write this fact formally as an isomorphism:</p>
<p>HomGrap([n],G)≅PathG(n).</p>
<p><em>Exercise</em> 4.3.3.6.</p>
<p>Given a homomorphism of graphs <em>f</em> : <em>G</em> → <em>G</em>′, there is an induced function between their sets of paths, Path(<em>f</em>): Path(<em>G</em>) → Path(<em>G</em>′).</p>
<p>a. Explain how this works.</p>
<p>b. Is it the case that for every <em>n</em> ∈ ℕ, the function Path(<em>f</em>) carries Path<sup>(<em>n</em>)</sup>(<em>G</em>) to Path<sup>(<em>n</em>)</sup>(<em>G</em>′), or can path lengths change in this process?</p>
<p>c. Suppose that <em>f</em><sub>0</sub> and <em>f</em><sub>1</sub> are injective (meaning no two distinct vertices in <em>G</em> are sent to the same vertex (resp. for arrows) under <em>f</em>). Does this imply that Path(<em>f</em>) is also injective (meaning no two distinct paths are sent to the same path under <em>f</em>)?</p>
<p>d. Suppose that <em>f</em><sub>0</sub> and <em>f</em><sub>1</sub> are surjective (meaning every vertex in <em>G</em>′ and every arrow in <em>G</em>′ is in the image of <em>f</em>). Does this imply that Path(<em>f</em>) is also surjective? Hint: At least one of the answers to parts (b)–(d) is no.</p>
<p><em>Exercise</em> 4.3.3.7.</p>
<p>Given a graph (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>), let 〈<em>src</em>, <em>tgt</em>〉: <em>A</em> → <em>V</em> × <em>V</em> be the function guaranteed by the universal property for products. One might hope to summarize condition (<a href="chapter004.html#eq_4-5">4.5</a>) for graph homomorphisms by the commutativity of the single square</p>
<p><img src="images/Art_P117.jpg" alt="art" /></p>
<p>Is the commutativity of the diagram in (<a href="chapter004.html#eq_4-7">4.7</a>) indeed equivalent to the commutativity of the diagrams in (<a href="chapter004.html#eq_4-5">4.5</a>)?</p>
<p><em>Solution</em> 4.3.3.7.</p>
<p>Yes. This follows from the universal property for products, Proposition <a href="chapter003.html#Pro_3-1-1-10">3.1.1.10</a>.</p>
<h3 id="lev_4-3-3-8" class="level3"><strong>4.3.3.8   Binary relations and graphs</strong></h3>
<p><strong>Definition 4.3.3.9</strong>. Let <em>X</em> be a set. A <em>binary relation on X</em> is a subset <em>R</em> ⊆ <em>X</em> × <em>X</em>.</p>
<p>If <em>X</em> = ℕ is the set of integers, then the usual ⩽ defines a binary relation on <em>X</em>: given (<em>m</em>, <em>n</em>) ∈ ℕ × ℕ, we put (<em>m</em>, <em>n</em>) ∈ <em>R</em> iff <em>m</em> ⩽ <em>n</em>. As a table it might be written as in the left-hand table in (<a href="chapter004.html#eq_4-8">4.8</a>):</p>
<p><img src="images/Art_P118.jpg" alt="art" /></p>
<p>The middle table is the relation {(<em>m</em>, <em>n</em>) ∈ ℕ × ℕ | <em>n</em> = 5<em>m</em>} ⊆ ℕ × ℕ, and the right-hand table is the relation {(<em>m</em>, <em>n</em>) ∈ ℕ × ℕ | |<em>n</em> − <em>m</em>| ⩽ 1} ⊆ ℕ × ℕ.</p>
<p><em>Exercise</em> 4.3.3.10.</p>
<p>A relation on ℝ is a subset of ℝ × ℝ, and one can indicate such a subset of the plane by shading. Choose an error bound <em>ϵ</em> &gt; 0, and draw the relation one might refer to as <em>ϵ</em>-approximation. To say it another way, draw the relation “<em>x</em> is within <em>ϵ</em> of <em>y</em>.”</p>
<p><em>Exercise</em> 4.3.3.11.</p>
<p>Recall that (<a href="chapter004.html#eq_4-8">4.8</a>) uses tables to express relations; it may help to use the terminology of tables in answering some of the following questions.</p>
<p>a. If <em>R</em> ⊆ <em>S</em> × <em>S</em> is a binary relation, find a natural way to make a graph <em>G</em><sub><em>R</em></sub> from it, having vertices <em>S</em>.</p>
<p>b. What is the set <em>A</em> of arrows in <em>G</em><sub><em>R</em></sub>?</p>
<p>c. What are the source and target functions <em>src</em>, <em>tgt</em>: <em>A</em> → <em>S</em> in <em>G</em><sub><em>R</em></sub>?</p>
<p>d. Consider the seven number rows in the left-hand table in (<a href="chapter004.html#eq_4-8">4.8</a>), ignoring the elipses. Draw the corresponding graph.</p>
<p>e. Do the same for the right-hand table in (<a href="chapter004.html#eq_4-8">4.8</a>).</p>
<p><em>Solution</em> 4.3.3.11.</p>
<p>a. We have two projections <em>π</em><sub>1</sub>, <em>π</em><sub>2</sub> : <em>S</em> × <em>S</em> → <em>S</em>, and we have an inclusion <em>i</em>: <em>R</em> ⊆ <em>S</em> × <em>S</em>. Thus we have a graph</p>
<p>R⇉π2○iπ1○iS</p>
<p>The idea is that for each row in the table, we draw an arrow from the first column’s value to the second column’s value.</p>
<p>b. It is <em>R</em>, which one could call “the number of rows in the table.”</p>
<p>c. These are <em>π</em><sub>1</sub> ○ <em>i</em> and <em>π</em><sub>2</sub> ○ <em>i</em>, which one could call “the first and second columns in the table.” In other words, <em>G</em><sub><em>R</em></sub> ≔ (<em>S</em>, <em>R</em>, <em>π</em><sub>1</sub> ○ <em>i</em>, <em>π</em><sub>2</sub> ○ <em>i</em>).</p>
<p>d. The seven solid arrows in the following graph correspond to the seven displayed rows in the left-hand table, and we include 3 more dashed arrows to complete the picture (they still satisfy the ⩽ relation).</p>
<p><img src="images/Art_P119.jpg" alt="art" /></p>
<p>e. Seven rows, seven arrows:</p>
<p><img src="images/Art_P120.jpg" alt="art" /></p>
<p><em>Exercise</em> 4.3.3.12.</p>
<p>a. If (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) is a graph, find a natural way to make a binary relation <em>R</em> ⊆ <em>V</em> × <em>V</em> from it.</p>
<p>b. For the left-hand graph <em>G</em> in (<a href="chapter004.html#eq_4-6">4.6</a>), and write out the corresponding binary relation in table form.</p>
<p><em>Exercise</em> 4.3.3.13.</p>
<p>a. Given a binary relation <em>R</em> ⊆ <em>S</em> × <em>S</em>, you know from Exercise <a href="chapter004.html#Exe_4-3-3-11">4.3.3.11</a> how to construct a graph out of it, and from Exercise <a href="chapter004.html#Exe_4-3-3-12">4.3.3.12</a> how to make a new binary relation out of that, making a roundtrip. How does the resulting relation compare with the original?</p>
<p>b. Given a graph <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>), you know from Exercise <a href="chapter004.html#Exe_4-3-3-12">4.3.3.12</a> how to make a new binary relation out of it, and from Exercise <a href="chapter004.html#Exe_4-3-3-11">4.3.3.11</a> how to construct a new graph out of that, making the other roundtrip. How does the resulting graph compare with the original?</p>
<h1 id="lev_4-4" class="level1"><a href="toc.html#Rlev_4-4"><strong>4.4   Orders</strong></a></h1>
<p>People usually think of certain sets as though they come with a canonical order. For example, one might think the natural numbers come with the ordering by which 3 &lt; 5, or that the letters in the alphabet come with the order by which <em>b</em> &lt; <em>e</em>. But in fact we <em>put</em> orders on sets, and some orders are simply more commonly used. For instance, one could order the letters in the alphabet by frequency of use, in which case <em>e</em> would come before <em>b</em>. Given different purposes, we can put different orders on the same set. For example, in Example <a href="chapter004.html#Exa_4-4-3-2">4.4.3.2</a> we give a different ordering on the natural numbers that is useful in elementary number theory.</p>
<p>In science, we might order the set of materials in two different ways. In the first, we could consider material <em>A</em> to be less than material <em>B</em> if <em>A</em> is an ingredient or part of <em>B</em>, so water would be less than concrete. But we could also order materials based on how electrically conductive they are, whereby concrete would be less than water. This section is about different kinds of orders.</p>
<h2 id="lev_4-4-1" class="level2"><strong>4.4.1   Definitions of preorder, partial order, linear order</strong></h2>
<p><strong>Definition 4.4.1.1</strong>. Let <em>S</em> be a set and <em>R</em> ⊆ <em>S</em> × <em>S</em> a binary relation on <em>S</em>; if (<em>s</em>, <em>s</em>′) ∈ <em>R</em>, we write <em>s</em> ⩽ <em>s</em>′. Then we say that <em>R</em> is a <em>preorder</em> if, for all <em>s</em>, <em>s</em>′, <em>s</em>″ ∈ <em>S</em>, we have</p>
<p><strong>Reflexivity:</strong> <em>s</em> ⩽ <em>s</em>, and</p>
<p><strong>Transitivity:</strong> if <em>s</em> ⩽ <em>s</em>′ and <em>s</em>′ ⩽ <em>s</em>″, then <em>s</em> ⩽ <em>s</em>″.</p>
<p>We say that <em>R</em> is a <em>partial order</em> if it is a preorder and, in addition, for all <em>s</em>, <em>s</em>′ ∈ <em>S</em>, we have</p>
<p><strong>Antisymmetry:</strong> If <em>s</em> ⩽ <em>s</em>′ and <em>s</em>′ ⩽ <em>s</em>, then <em>s</em> = <em>s</em>′.</p>
<p>We say that <em>R</em> is a <em>linear order</em> if it is a partial order and, in addition, for all <em>s</em>, <em>s</em>′ ∈ <em>S</em>, we have</p>
<p><strong>Comparability:</strong> Either <em>s</em> ⩽ <em>s</em>′ or <em>s</em>′ ⩽ <em>s</em>.</p>
<p>We denote such a preorder (or partial order or linear order) by (<em>S</em>, ⩽).</p>
<p><em>Exercise</em> 4.4.1.2.</p>
<p>a. The relation in the left-hand table in (<a href="chapter004.html#eq_4-8">4.8</a>) is a preorder. Is it a linear order?</p>
<p>b. Show that neither the middle table nor the right-hand table in (<a href="chapter004.html#eq_4-8">4.8</a>) is even a preorder.</p>
<p><em>Example</em> 4.4.1.3 (Partial order not linear order). The following is an olog for playing cards:</p>
<p><img src="images/Art_P121.jpg" alt="art" /></p>
<p>We can put a binary relation on the set of boxes here by saying <em>A</em> ⩽ <em>B</em> if there is a path <em>A</em> → <em>B</em>. One can see immediately that this is a preorder because length 0 paths give reflexivity, and concatenation of paths gives transitivity. To see that it is a partial order we only note that there are no loops of any length. But this partial order is not a linear order because there is no path (in either direction) between, e.g., ⌜a 4 of diamonds⌝ and ⌜a black queen⌝, so it violates the comparability condition.</p>
<p><em>Remark</em> 4.4.1.4. Note that olog (<a href="chapter004.html#eq_4-9">4.9</a>) in Example <a href="chapter004.html#Exa_4-4-1-3">4.4.1.3</a> is a good olog in the sense that given any collection of cards (e.g., choose 45 cards at random from each of seven decks and throw them in a pile), they can be classified according to it. In other words, each box in the olog will refer to some subset of the pile, and every arrow will refer to a function between these sets. For example, the arrow a⌜ heart⌝→isa⌜ red card⌝ is a function from the set of hearts in the pile to the set of red cards in the pile.</p>
<p><em>Example</em> 4.4.1.5 (Preorder, not partial order). Every equivalence relation is a preorder, but rarely are they partial orders. For example, if <em>S</em> = {1, 2} and we put <em>R</em> = <em>S</em> × <em>S</em>, then this is an equivalence relation. It is a preorder but not a partial order (because 1 ⩽ 2 and 2 ⩽ 1, but 1 ≠ 2, so antisymmetry fails).</p>
<p><em>Application</em> 4.4.1.6. Classically, we think of time as linearly ordered. A model is (ℝ, ⩽), the usual linear order on the set of real numbers. But according to the theory of relativity, there is not actually a single order to the events in the universe. Different observers correctly observe different orders on the set of events.</p>
<p><em>Example</em> 4.4.1.7 (Finite linear orders). Let <em>n</em> ∈ ℕ be a natural number. Define a linear order [<em>n</em>] = ({0, 1, 2, … , <em>n</em>}, ⩽) in the standard way. Pictorially,</p>
<p>[ n ]≔•0→⩽•1→⩽•2→⩽⋯→⩽•n</p>
<p>Every finite linear order, i.e., linear order on a finite set, is of the preceding form. That is, though the labels might change, the picture would be the same. This can be made precise when morphisms of orders are defined (see Definition <a href="chapter004.html#Def_4-4-4-1">4.4.4.1</a>)</p>
<p><em>Exercise</em> 4.4.1.8.</p>
<p>Let <em>S</em> = {1, 2, 3}.</p>
<p>a. Find a preorder <em>R</em> ⊆ <em>S</em> × <em>S</em> such that the set <em>R</em> is as small as possible. Is it a partial order? Is it a linear order?</p>
<p>b. Find a preorder <em>R</em>′ ⊆ <em>S</em> × <em>S</em> such that the set <em>R</em>′ is as large as possible. Is it a partial order? Is it a linear order?</p>
<p><em>Exercise</em> 4.4.1.9.</p>
<p>a. List all the preorder relations possible on the set {1, 2}.</p>
<p>b. For any <em>n</em> ∈ ℕ, how many linear orders exist on the set {1, 2, 3, … , <em>n</em>}?</p>
<p>c. Does your formula work when <em>n</em> = 0?</p>
<p><em>Remark</em> 4.4.1.10. We can draw any preorder (<em>S</em>, ⩽) as a graph with vertices <em>S</em> and with an arrow <em>a</em> → <em>b</em> if <em>a</em> ⩽ <em>b</em>. These are precisely the graphs with the following two properties for any vertices <em>a</em>, <em>b</em> ∈ <em>S</em>:</p>
<p>1. There is at most one arrow <em>a</em> → <em>b</em>.</p>
<p>2. If there is a path from <em>a</em> to <em>b</em>, then there is an arrow <em>a</em> → <em>b</em>.</p>
<p>If (<em>S</em>, ⩽) is a partial order, then the associated graph has an additional no-loops property:</p>
<p>3. If <em>n</em> ∈ ℕ is an integer with <em>n</em> ⩾ 2, then there are no paths of length <em>n</em> that start at <em>a</em> and end at <em>a</em>.</p>
<p>If (<em>S</em>, ⩽) is a linear order then there is an additional comparability property:</p>
<p>4. For any two vertices <em>a</em>, <em>b</em>, there is an arrow <em>a</em> → <em>b</em> or an arrow <em>b</em> → <em>a</em>.</p>
<p>Given a graph <em>G</em>, we can create a binary relation ⩽ on its set <em>S</em> of vertices as follows. Put <em>a</em> ⩽ <em>b</em> if there is a path in <em>G</em> from <em>a</em> to <em>b</em>. This relation will be reflexive and transitive, so it is a preorder. If the graph satisfies property 3, then the preorder will be a partial order, and if the graph also satisfies property 4, then the partial order will be a linear order. Thus graphs give us a nice way to visualize orders.</p>
<p><em>Slogan</em> 4.4.1.11.</p>
<p><em>A graph generates a preorder: v</em> ⩽ <em>w if there is a path v</em> → <em>w</em>.</p>
<p><em>Exercise</em> 4.4.1.12.</p>
<p>Let <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) be the following graph:</p>
<p><img src="images/Art_P122.jpg" alt="art" /></p>
<p>In the corresponding preorder, which of the following are true?</p>
<p>a. <em>a</em> ⩽ <em>b</em>.</p>
<p>b. <em>a</em> ⩽ <em>d</em>.</p>
<p>c. <em>c</em> ⩽ <em>b</em>.</p>
<p>d. <em>b</em> = <em>c</em>.</p>
<p>e. <em>e</em> ⩽ <em>f</em>.</p>
<p>f. <em>f</em> ⩽ <em>d</em>.</p>
<p><em>Exercise</em> 4.4.1.13.</p>
<p>a. Let <em>S</em> = {1, 2}. The set ℙ(<em>S</em>) of subsets of <em>S</em> form a partial order. Draw the associated graph.</p>
<p>b. Repeat this for <em>Q</em> = ∅, <em>R</em> = {1}, and <em>T</em> = {1, 2, 3}. That is, draw the partial orders on ℙ(<em>Q</em>), ℙ(<em>R</em>), and ℙ(<em>T</em>).</p>
<p>c. Do you see <em>n</em>-dimensional cubes?</p>
<p><em>Solution</em> 4.4.1.13.</p>
<p>a.</p>
<p><img src="images/Art_P123.jpg" alt="art" /></p>
<p>b.</p>
<p><img src="images/Art_P124.jpg" alt="art" /></p>
<p>c. Yes. The graph associated to ℙ(<em>n</em>) looks like an <em>n</em>-dimensional cube.</p>
<p><strong>Definition 4.4.1.14</strong>. Let (<em>S</em>, ⩽) be a preorder. A <em>clique</em> is a subset <em>S</em>′ ⊆ <em>S</em> such that for each <em>a</em>, <em>b</em> ∈ <em>S</em>′, one has <em>a</em> ⩽ <em>b</em>.</p>
<p><em>Exercise</em> 4.4.1.15.</p>
<p>True or false: A partial order is a preorder that has no cliques? (If false, is there a nearby true statement?)</p>
<p><em>Solution</em> 4.4.1.15.</p>
<p>False. Every element is always in its own clique, so if <em>X</em> is a partial order with at least one element, then it has a clique. But a nearby statement is true. Let’s define a <em>nontrivial clique</em> to be a clique consisting of two or more elements.</p>
<p><em>Slogan</em>.</p>
<p><em>A partial order is a preorder that has no nontrivial cliques</em>.</p>
<p>Just as every relation generates an equivalence relation (see Proposition <a href="chapter003.html#Pro_3-3-1-7">3.3.1.7</a>), every relation also generates a preorder.</p>
<p><em>Example</em> 4.4.1.16. Let <em>X</em> be a set and <em>R</em> ⊆ <em>X</em> × <em>X</em> a relation. For elements <em>x</em>, <em>y</em> ∈ <em>X</em>, we say there is an <em>R-path</em> from <em>x</em> to <em>y</em> if there exists a natural number <em>n</em> ∈ ℕ and elements <em>x</em><sub>0</sub>, <em>x</em><sub>1</sub>, … , <em>x</em><sub><em>n</em></sub> ∈ <em>X</em> such that</p>
<ol>
<li><em>x</em> = <em>x</em><sub>0</sub>;</li>
<li><em>x</em><sub><em>n</em></sub> = <em>y</em>;</li>
<li>for all <em>i</em> ∈ ℕ, if 0 ⩽ <em>i</em> ⩽ <em>n</em> − 1, then (<em>x</em><sub><em>i</em></sub>, <em>x</em><sub><em>i</em>+1</sub>) ∈ <em>R</em>.</li>
</ol>
<p>Let R¯ denote the relation where (x,y)∈R¯ if there exists an <em>R</em>-path from <em>x</em> to <em>y</em>. We call R¯ the <em>preorder generated by R</em>. and note some facts about R¯:</p>
<p><strong>Containment.</strong> If (<em>x</em>, <em>y</em>) ∈ <em>R</em>, then (x,y)∈R¯. That is, R⊆R¯.</p>
<p><strong>Reflexivity.</strong> For all <em>x</em> ∈ <em>X</em>, we have (x,x)∈R¯.</p>
<p><strong>Transitivity.</strong> For all <em>x</em>, <em>y</em>, <em>z</em> ∈ <em>X</em>, if (x,y)∈R¯ and (y,z)∈R¯ , then (x,z)∈R¯.</p>
<p>Let’s write <em>x</em> ⩽ <em>y</em> if (x,y)∈R¯ . To check the containment claim, use <em>n</em> = 1 so <em>x</em><sub>0</sub> = <em>x</em> and <em>x</em><sub><em>n</em></sub> = <em>y</em>. To check the reflexivity claim, use <em>n</em> = 0 so <em>x</em> = <em>x</em><sub>0</sub> = <em>y</em> and condition 3 is vacuously satisfied. To check transitivitiy, suppose given <em>R</em>-paths <em>x</em> = <em>x</em><sub>0</sub> ⩽ <em>x</em><sub>1</sub> ⩽ … ⩽ <em>x</em><sub><em>n</em></sub> = <em>y</em> and <em>y</em> = <em>y</em><sub>0</sub> ⩽ <em>y</em><sub>1</sub> ⩽ … ⩽ <em>y</em><sub><em>p</em></sub> = <em>z</em>; then <em>x</em> = <em>x</em><sub>0</sub> ⩽ <em>x</em><sub>1</sub> ⩽ … ⩽ <em>x</em><sub><em>n</em></sub> ⩽ <em>y</em><sub>1</sub> ⩽ … ⩽ <em>y</em><sub><em>p</em></sub> = <em>z</em> will be an <em>R</em>-path from <em>x</em> to <em>z</em>.</p>
<p>We can turn any relation into a preorder in a canonical way. Here is a concrete case of this idea.</p>
<p>Let <em>X</em> = {<em>a</em>, <em>b</em>, <em>c</em>, <em>d</em>} and suppose given the relation {(<em>a</em>, <em>b</em>), (<em>b</em>, <em>c</em>), (<em>b</em>, <em>d</em>), (<em>d</em>, <em>c</em>), (<em>c</em>, <em>c</em>)}. This is neither reflexive nor transitive, so it is not a preorder. To make it a preorder we follow the preceding prescription. Starting with <em>R</em>-paths of length <em>n</em> = 0, we put {(<em>a</em>, <em>a</em>), (<em>b</em>, <em>b</em>), (<em>c</em>, <em>c</em>), (<em>d</em>, <em>d</em>)} into R¯ . The <em>R</em>-paths of length 1 add the original elements, {(<em>a</em>, <em>b</em>), (<em>b</em>, <em>c</em>), (<em>b</em>, <em>d</em>), (<em>d</em>, <em>c</em>), (<em>c</em>, <em>c</em>)}. Redundancy (e.g., (<em>c</em>, <em>c</em>)) is permissible, but from now on in this example we write only the new elements. The <em>R</em>-paths of length 2 add {(<em>a</em>, <em>c</em>), (<em>a</em>, <em>d</em>)} to R¯ . One can check that <em>R</em>-paths of length 3 and above do not add anything new to R¯ , so we are done. The relation</p>
<p>R¯={ (a,a),(b,b),(c,c),(d,d),(a,b),(b,c),(b,d),(d,c)(a,c),(a,d) }</p>
<p>is reflexive and transitive, hence a preorder.</p>
<p><em>Exercise</em> 4.4.1.17.</p>
<p>Let <em>X</em> = {<em>a</em>, <em>b</em>, <em>c</em>, <em>d</em>, <em>e</em>, <em>f</em>}, and let <em>R</em> = {(<em>a</em>, <em>b</em>), (<em>b</em>, <em>c</em>), (<em>b</em>, <em>d</em>), (<em>d</em>, <em>e</em>), (<em>f</em>, <em>a</em>)}.</p>
<p>a. What is the preorder R¯ generated by <em>R</em>?</p>
<p>b. Is it a partial order?</p>
<p><em>Exercise</em> 4.4.1.18.</p>
<p>Let <em>X</em> be the set of people, and let <em>R</em> ⊆ <em>X</em> × <em>X</em> be the relation with (<em>x</em>, <em>y</em>) ∈ <em>R</em> if <em>x</em> is the child of <em>y</em>. Describe the preorder generated by <em>R</em> in layperson’s terms.</p>
<h2 id="lev_4-4-2" class="level2"><strong>4.4.2   Meets and joins</strong></h2>
<p>Let <em>X</em> be any set. Recall from Definition <a href="chapter003.html#Def_3-4-4-9">3.4.4.9</a> that the power-set of <em>X</em>, denoted ℙ(<em>X</em>), is the set of subsets of <em>X</em>. There is a natural order on ℙ(<em>X</em>) given by the subset relationship, as exemplified in Exercise <a href="chapter004.html#Exe_4-4-1-13">4.4.1.13</a>. Given two elements <em>a</em>, <em>b</em> ∈ ℙ(<em>X</em>), we can consider them as subsets of <em>X</em> and take their intersection as an element of ℙ(<em>X</em>), denoted <em>a</em> ∩ <em>b</em>. We can also consider them as subsets of <em>X</em> and take their union as an element of ℙ(<em>X</em>), denoted <em>a</em> ∪ <em>b</em>. The intersection and union operations are generalized in the following definition.</p>
<p><strong>Definition 4.4.2.1</strong>. Let (<em>S</em>, ⩽) be a preorder, and let <em>s</em>, <em>t</em> ∈ <em>S</em> be elements. A <em>meet of s and t</em> is an element <em>w</em> ∈ <em>S</em> satisfying the following universal property:</p>
<ul>
<li><em>w</em> ⩽ <em>s</em> and <em>w</em> ⩽ <em>t</em>,</li>
<li>for any <em>x</em> ∈ <em>S</em>, if <em>x</em> ⩽ <em>s</em> and <em>x</em> ⩽ <em>t</em>, then <em>x</em> ⩽ <em>w</em>.</li>
</ul>
<p>If <em>w</em> is a meet of <em>s</em> and <em>t</em>, we write <em>w</em> ≅ <em>s</em> ∧ <em>t</em>.</p>
<p>A <em>join of s and t</em> is an element <em>w</em> ∈ <em>S</em> satisfying the following universal property:</p>
<ul>
<li><em>s</em> ⩽ <em>w</em> and <em>t</em> ⩽ <em>w</em>,</li>
<li>for any <em>x</em> ∈ <em>S</em>, if <em>s</em> ⩽ <em>x</em> and <em>t</em> ⩽ <em>x</em>, then <em>w</em> ⩽ <em>x</em>.</li>
</ul>
<p>If <em>w</em> is a join of <em>s</em> and <em>t</em>, we write <em>w</em> ≅ <em>s</em> ∨ <em>t</em>.</p>
<p>That is, the meet of <em>s</em> and <em>t</em> is the biggest thing that is smaller than both, i.e., a <em>greatest lower bound</em>, and the join of <em>s</em> and <em>t</em> is the smallest thing that is bigger than both, i.e., a <em>least upper bound</em>. Note that the meet of <em>s</em> and <em>t</em> might be <em>s</em> or <em>t</em> itself.</p>
<p>It may happen that <em>s</em> and <em>t</em> have more than one meet (or more than one join). However, any two meets of <em>s</em> and <em>t</em> must be in the same clique, by the universal property (and the same for joins).</p>
<p><em>Exercise</em> 4.4.2.2.</p>
<p>Consider the partial order from Example <a href="chapter004.html#Exa_4-4-1-3">4.4.1.3</a>.</p>
<p>a. What is the join of ⌜a diamond⌝ and ⌜a heart⌝?</p>
<p>b. What is the meet of ⌜a black card⌝ and ⌜a queen⌝?</p>
<p>c. What is the meet of ⌜a diamond⌝ and ⌜a card⌝?</p>
<p>Not every two elements in a preorder need have a meet, nor need they have a join.</p>
<p><em>Exercise</em> 4.4.2.3.</p>
<p>a. If possible, find two elements in the partial order from Example <a href="chapter004.html#Exa_4-4-1-3">4.4.1.3</a> that do not have a meet.<sup><a href="chapter004.html#endnote_7">7</a></sup></p>
<p>b. If possible, find two elements that do not have a join (in that preorder).</p>
<p><em>Solution</em> 4.4.2.3.</p>
<p>a. There is no meet for ⌜a heart⌝ and ⌜a club⌝; no card is both.</p>
<p>b. Every two elements have a join here. But note that some of these joins are “wrong” because the olog is not complete. For example, we have ⌜a 4⌝ ∨ ⌜a queen⌝ = ⌜a card⌝, whereas the correct answer would be ⌜a card that is either a 4 or a queen⌝.</p>
<p><em>Exercise</em> 4.4.2.4.</p>
<p>As mentioned, the power-set <em>S</em> ≔ ℙ(<em>X</em>) of any set <em>X</em> naturally has the structure of a partial order. Its elements <em>s</em> ∈ <em>S</em> correspond to subsets <em>s</em> ⊆ <em>X</em>, and we put <em>s</em> ⩽ <em>t</em> if and only if <em>s</em> ⊆ <em>t</em> as subsets of <em>X</em>. The meet of two elements is their intersection as subsets of <em>X</em>, <em>s</em> ∧ <em>t</em> = <em>s</em> ∩ <em>t</em>, and the join of two elements is their union as subsets of <em>X</em>, <em>s</em> ∨ <em>t</em> = <em>s</em> ∪ <em>t</em>.</p>
<p>a. Is it possible to put a monoid structure on the set <em>S</em> in which the multiplication formula is given by meets? If so, what would the unit element be?</p>
<p>b. Is it possible to put a monoid structure on the set <em>S</em> in which the multiplication formula is given by joins? If so, what would the unit element be?</p>
<p><em>Example</em> 4.4.2.5 (Trees). A <em>tree</em>, i.e., a system of nodes and branches, all of which emanate from a single node called the <em>root</em>, is a partial order but generally not a linear order. A tree (<em>T</em>, ⩽) can either be oriented toward the root (so the root is the largest element of the partial order) or away from the root (so the root is the smallest element); let’s only consider the former.</p>
<p>A tree is pictured as a graph in (<a href="chapter004.html#eq_4-10">4.10</a>). The root is labeled <em>e</em>.</p>
<p><img src="images/Art_P125.jpg" alt="art" /></p>
<p>In a tree every pair of elements <em>s</em>, <em>t</em> ∈ <em>T</em> has a join <em>s</em> ∧ <em>t</em> (their closest mutual ancestor). On the other hand, if <em>s</em> and <em>t</em> have a join <em>c</em> = <em>s</em> ∨ <em>t</em>, then either <em>c</em> = <em>s</em> or <em>c</em> = <em>t</em>.</p>
<p><em>Exercise</em> 4.4.2.6.</p>
<p>Consider the tree drawn in (<a href="chapter004.html#eq_4-10">4.10</a>).</p>
<p>a. What is the join <em>i</em> ∨ <em>h</em>?</p>
<p>b. What is the join <em>h</em> ∨ <em>b</em>?</p>
<p>c. What is the meet <em>b</em> ∧ <em>a</em>?</p>
<p>d. What is the meet <em>b</em> ∧ <em>g</em>?</p>
<h2 id="lev_4-4-3" class="level2"><strong>4.4.3   Opposite order</strong></h2>
<p><strong>Definition 4.4.3.1</strong>. Let S≔(S,⩽) be a preorder. The <em>opposite preorder</em>, denoted Sop, is the preorder (<em>S</em>, ⩽<sup>op</sup>) having the same set of elements but where <em>s</em> ⩽<sup>op</sup> <em>s</em>′ iff <em>s</em>′ ⩽ <em>s</em>.</p>
<p><em>Example</em> 4.4.3.2. Consider the preorder N≔(ℕ,divides), where <em>a</em> divides <em>b</em> if “<em>a</em> goes into <em>b</em> evenly,” i.e., if there exists <em>n</em> ∈ ℕ such that <em>a</em> * <em>n</em> = <em>b</em>. So 5 divides 35, and so on. Then Nop is the set of natural numbers but where <em>m</em> ⩽ <em>n</em> iff <em>m</em> is a multiple of <em>n</em>. So 6 ⩽ 2 and 6 ⩽ 3, but 6 ≰ 4.</p>
<p><em>Exercise</em> 4.4.3.3.</p>
<p>Suppose that S≔(S,⩽) is a preorder.</p>
<p>a. If S is a partial order, is Sop also a partial order?</p>
<p>b. If S is a linear order, is Sop a linear order?</p>
<p><em>Exercise</em> 4.4.3.4.</p>
<p>Suppose that S≔(S,⩽) is a preorder and that <em>s</em><sub>1</sub>, <em>s</em><sub>2</sub> ∈ <em>S</em> have join <em>s</em><sub>1</sub> ∨ <em>s</em><sub>2</sub> = <em>t</em> in S. The preorder Sop has the same elements as S. Is <em>t</em> the join of <em>s</em><sub>1</sub> and <em>s</em><sub>2</sub> in Sop, or is it their meet, or is it not necessarily their meet or their join?</p>
<h2 id="lev_4-4-4" class="level2"><strong>4.4.4   Morphism of orders</strong></h2>
<p>An order (<em>S</em>, ⩽), be it a preorder, a partial order, or a linear order, involves a set and a binary relation. For two orders to be comparable, their sets and their relations should be appropriately comparable.</p>
<p><strong>Definition 4.4.4.1</strong>. Let S≔(S,⩽) and S′≔(S′,⩽′) be preorders (resp. partial orders or linear orders). A <em>morphism of preorders</em> (resp. <em>partial orders</em> or <em>linear orders</em>) <em>f from</em> S to S′, denoted f:S→S′, is a function f:S→S′ such that, for every pair of elements <em>s</em><sub>1</sub>, <em>s</em><sub>2</sub> ∈ <em>S</em>, if <em>s</em><sub>1</sub> ⩽ <em>s</em><sub>2</sub>, then <em>f</em>(<em>s</em><sub>1</sub>) ⩽′ <em>f</em>(<em>s</em><sub>2</sub>).</p>
<p><em>Example</em> 4.4.4.2. Let <em>X</em> and <em>Y</em> be sets, and let <em>f</em> : <em>X</em> → <em>Y</em> be a function. Then for every subset <em>X</em>′ ⊆ <em>X</em>, its image <em>f</em>(<em>X</em>′) ⊆ <em>Y</em> is a subset (see Exercise <a href="chapter002.html#Exe_2-1-2-8">2.1.2.8</a>). Thus we have a function <em>F</em> : ℙ(<em>X</em>) → ℙ(<em>Y</em>), given by taking images. This is a morphism of partial orders (ℙ(<em>X</em>), ⊆) → (ℙ(<em>Y</em>), ⊆). Indeed, if <em>a</em> ⊆ <em>b</em> in ℙ(<em>X</em>), then <em>f</em>(<em>a</em>) ⊆ <em>f</em>(<em>b</em>) in ℙ(<em>Y</em>).</p>
<p><em>Application</em> 4.4.4.3. It is often said that a team is only as strong as its weakest member. Is this true for materials? The hypothesis that a material is only as strong as its weakest constituent can be understood as follows.</p>
<p>Recall from the beginning of Section <a href="chapter004.html#lev_4-4">4.4</a> (page 132) that we can put several different orders on the set <em>M</em> of materials. One example is the order given by constituency (<em>m</em> ⩽<sub><em>C</em></sub> <em>m</em>′ if <em>m</em> is an ingredient or constituent of <em>m</em>′). Another order is given by strength: <em>m</em> ⩽<sub><em>S</em></sub> <em>m</em>′ if <em>m</em>′ is stronger than <em>m</em> (in some fixed setting).</p>
<p>Is it true that if material <em>m</em> is a constituent of material <em>m</em>′, then the strength of <em>m</em>′ is less than or equal to the strength of <em>m</em>? Mathematically the question would be, Is there a morphism of preorders (<em>M</em>, ⩽<sub><em>C</em></sub>) → (<em>M</em>, ⩽<sub><em>S</em></sub>)<sup>op</sup>?</p>
<p><em>Exercise</em> 4.4.4.4.</p>
<p>Let <em>X</em> and <em>Y</em> be sets, and let <em>f</em> : <em>X</em> → <em>Y</em> be a function. Then for every subset <em>Y</em>′ ⊆ <em>Y</em>, its preimage <em>f</em><sup>−1</sup>(<em>Y</em>′) ⊆ <em>X</em> is a subset (see Definition <a href="chapter003.html#Def_3-2-1-12">3.2.1.12</a>). Thus we have a function <em>F</em> : ℙ(<em>Y</em>) → ℙ(<em>X</em>), given by taking preimages. Is it a morphism of partial orders?</p>
<p><em>Example</em> 4.4.4.5. Let <em>S</em> be a set. The smallest preorder structure that can be put on <em>S</em> is to say <em>a</em> ⩽ <em>b</em> iff <em>a</em> = <em>b</em>. This is indeed reflexive and transitive, and it is called the <em>discrete preorder on S</em>.</p>
<p>The largest preorder structure that can be put on <em>S</em> is to say <em>a</em> ⩽ <em>b</em> for all <em>a</em>, <em>b</em> ∈ <em>S</em>. This again is reflexive and transitive, and it is called the <em>indiscrete preorder on S</em>.</p>
<p><em>Exercise</em> 4.4.4.6.</p>
<p>Let <em>S</em> be a set, and let (<em>T</em>, ⩽<sub><em>T</em></sub>) be a preorder. Let ⩽<sub><em>D</em></sub> be the discrete preorder on <em>S</em>.</p>
<p>a. A morphism of preorders (<em>S</em>, ⩽<sub><em>D</em></sub>) → (<em>T</em>, ⩽<sub><em>T</em></sub>) is a function <em>S</em> → <em>T</em> satisfying certain properties (see Definition <a href="chapter004.html#Def_4-4-4-1">4.4.4.1</a>). Which functions <em>S</em> → <em>T</em> arise in this way?</p>
<p>b. Given a morphism of preorders (<em>T</em>, ⩽<sub><em>T</em></sub>) → (<em>S</em>, ⩽<sub><em>D</em></sub>), we get a function <em>T</em> → <em>S</em>. In terms of ⩽<sub><em>T</em></sub>, which functions <em>T</em> → <em>S</em> arise in this way?</p>
<p><em>Exercise</em> 4.4.4.7.</p>
<p>Let <em>S</em> be a set, and let (<em>T</em>, ⩽<sub><em>T</em></sub>) be a preorder. Let ⩽<sub><em>I</em></sub> be the indiscrete preorder on <em>S</em>, as in Example <a href="chapter004.html#Exa_4-4-4-5">4.4.4.5</a>.</p>
<p>a. Given a morphism of preorders (<em>S</em>, ⩽<sub><em>I</em></sub>) → (<em>T</em>, ⩽<sub><em>T</em></sub>), we get a function <em>S</em> → <em>T</em>. In terms of ⩽<sub><em>T</em></sub>, which functions <em>S</em> → <em>T</em> arise in this way?</p>
<p>b. Given a morphism of preorders (<em>T</em>, ⩽<sub><em>T</em></sub>) → (<em>S</em>, ⩽<sub><em>I</em></sub>), we get a function <em>T</em> → <em>S</em>. In terms of ⩽<sub><em>T</em></sub>, which functions <em>T</em> → <em>S</em> arise in this way?</p>
<h2 id="lev_4-4-5" class="level2"><strong>4.4.5   Other applications</strong></h2>
<h3 id="lev_4-4-5-1" class="level3"><strong>4.4.5.1   Biological classification</strong></h3>
<p>Biological classification is a method for dividing the set of organisms into distinct classes, called taxa. In fact, it turns out that such a classification, say, a phylogenetic tree, can be understood as a partial order <em>C</em> on the set of taxa. The typical <em>ranking</em> of these taxa, including kingdom, phylum, and so on, can be understood as morphism of orders <em>f</em> : <em>C</em> → [<em>n</em>], for some <em>n</em> ∈ ℕ.</p>
<p>For example, we may have a tree (see Example <a href="chapter004.html#Exa_4-4-2-5">4.4.2.5</a>) that looks like this:</p>
<p><img src="images/Art_P126.jpg" alt="art" /></p>
<p>We also have a linear order that looks like this:</p>
<p><img src="images/Art_P127.jpg" alt="art" /></p>
<p>and the ranking system that puts Eukaryota at Domain and Homo Sapien at Species is an order-preserving function from the dots upstairs to the dots downstairs; that is, it is a morphism of preorders.</p>
<p><em>Exercise</em> 4.4.5.2.</p>
<p>Since the phylogenetic tree is a tree, it has all joins.</p>
<p>a. Determine the join of dogs and humans.</p>
<p>b. If we did not require the phylogenetic partial order to be a tree, what would it mean if two taxa (nodes in the phylogenetic partial order), say, <em>a</em> and <em>b</em>, had meet <em>c</em> with <em>c</em> ≠ <em>a</em> and <em>c</em> ≠ <em>b</em>?</p>
<p><em>Exercise</em> 4.4.5.3.</p>
<p>a. In your favorite scientific subject, are there any interesting classification systems that are actually orders?</p>
<p>b. Choose one such system; what would meets mean in that setting?</p>
<h3 id="lev_4-4-5-4" class="level3"><strong>4.4.5.4   Security</strong></h3>
<p>Security, say of sensitive information, is based on two things: a security clearance and need to know. Security clearance might consist of levels like confidential, secret, top secret. But maybe we can throw in “President’s eyes only” and some others too, like “anyone.”</p>
<p><em>Exercise</em> 4.4.5.5.</p>
<p>Does it appear that security clearance is a preorder, a partial order, or a linear order?</p>
<p>“Need to know” is another classification of people. For each bit of information, we do not necessarily want everyone to know about it, even everyone with the specified clearance. It is only disseminated to those who need to know.</p>
<p><em>Exercise</em> 4.4.5.6.</p>
<p>Let <em>P</em> be the set of all people, and let I¯ be the set of all pieces of information known by the government. For each subset I⊆I¯, let <em>K</em>(<em>I</em>) ⊆ <em>P</em> be the set of people who need to know every piece of information in <em>I</em>. Let S={ K(I)|I⊆I¯ } be the set of all “need to know” groups, with the subset relation denoted ⩽.</p>
<p>a. Is (<em>S</em>, ⩽) a preorder? If not, find a nearby preorder.</p>
<p>b. If <em>I</em><sub>1</sub> ⊆ <em>I</em><sub>2</sub>, do we always have <em>K</em>(<em>I</em><sub>1</sub>) ⩽ <em>K</em>(<em>I</em><sub>2</sub>) or <em>K</em>(<em>I</em><sub>2</sub>) ⩽ <em>K</em>(<em>I</em><sub>1</sub>) or possibly neither?</p>
<p>c. Should the preorder (<em>S</em>, ⩽) have all meets?</p>
<p>d. Should (<em>S</em>, ⩽) have all joins?</p>
<h3 id="lev_4-4-5-7" class="level3"><strong>4.4.5.7   Spaces and geography</strong></h3>
<p>Consider closed curves that can be drawn in the plane ℝ<sup>2</sup>, e.g., circles, ellipses, and kidney-bean shaped curves. The interiors of these closed curves (not including the boundary itself) are called <em>basic open sets in</em> ℝ<sup>2</sup>. The good thing about such an interior <em>U</em> is that any point <em>p</em> ∈ <em>U</em> is not on the boundary, so no matter how close <em>p</em> is to the boundary of <em>U</em>, there will always be a tiny basic open set surrounding <em>p</em> and completely contained in <em>U</em>. In fact, the union of any collection of basic open sets still has this property. That is, an <em>open set in</em> ℝ<sup>2</sup> is any subset <em>U</em> ⊆ ℝ<sup>2</sup> that can be formed as the union of a collection of basic open sets.</p>
<p><em>Example</em> 4.4.5.8. Let <em>U</em> = {(<em>x</em>, <em>y</em>) ∈ ℝ<sup>2</sup> | <em>x</em> &gt; 0}. To see that <em>U</em> is open, define the following sets: for any <em>a</em>, <em>b</em> ∈ ℝ, let <em>S</em>(<em>a</em>, <em>b</em>) be the square parallel to the axes, with side length 1, where the upper left corner is (<em>a</em>, <em>b</em>). Note that <em>S</em>(<em>a</em>, <em>b</em>) is a closed curve, so if we let <em>S</em>′(<em>a</em>, <em>b</em>) be the interior of <em>S</em>(<em>a</em>, <em>b</em>), then each <em>S</em>′(<em>a</em>, <em>b</em>) is a basic open set. Now <em>U</em> is the union of <em>S</em>′(<em>a</em>, <em>b</em>) over the collection of all <em>a</em> &gt; 0 and all <em>b</em>,</p>
<p>U=∪a,b∈ℝ,a&gt;0 S′(a,b),</p>
<p>so <em>U</em> is open.</p>
<p><em>Example</em> 4.4.5.9. The idea of open sets extends to spaces beyond ℝ<sup>2</sup>. For example, on the earth one could define a basic open set to be the interior of any region one can draw a closed curve around (with a metaphorical pen), and define open sets to be unions of these basic open sets.</p>
<p><em>Exercise</em> 4.4.5.10.</p>
<p>Let (<em>S</em>, ⊆) be the partial order of open subsets on earth as defined in Example <a href="chapter004.html#Exa_4-4-5-9">4.4.5.9</a>.</p>
<p>a. If ⩽ is the subset relation, is (<em>S</em>, ⩽) a partial order or just a preorder, or neither?</p>
<p>b. Does it have meets?</p>
<p>c. Does it have joins?</p>
<p><em>Exercise</em> 4.4.5.11.</p>
<p>Let <em>S</em> be the set of open subsets of earth as defined in Example <a href="chapter004.html#Exa_4-4-5-9">4.4.5.9</a>. For each open subset of earth, suppose we know the range of recorded temperature throughout <em>s</em> (i.e., the low and high throughout the region). Thus to each element <em>s</em> ∈ <em>S</em> we assign an interval <em>T</em>(<em>s</em>) ≔ {<em>x</em> ∈ ℝ | <em>a</em> ⩽ <em>x</em> ⩽ <em>b</em>}. The set <em>V</em> of intervals of ℝ can be partially ordered by the subset relation.</p>
<p>a. Does the assignment <em>T</em> : <em>S</em> → <em>V</em> amount to a morphism of orders?</p>
<p>b. If so, does it preserve meets or joins? Hint: It does not preserve both.</p>
<p><em>Solution</em> 4.4.5.11.</p>
<p>a. Suppose <em>s</em> is a subregion of <em>s</em>′, e.g., New Mexico as a subregion of North America. This question is asking whether the range of temperatures recorded throughout New Mexico is a subset of the range of temperatures recorded throughout North America, which, of course, it is.</p>
<p>b. The question on meets is, If we take two regions <em>s</em> and <em>s</em>′ and intersect them, is the temperature range on <em>s</em> ∩ <em>s</em>′ equal to the intersection <em>T</em>(<em>s</em>) ∩ <em>T</em>(<em>s</em>′)? Clearly, if a temperature <em>t</em> is recorded somewhere in <em>s</em> ∩ <em>s</em>′, then it is recorded somewhere in <em>s</em> and somewhere in <em>s</em>′, so <em>T</em>(<em>s</em> ∩ <em>s</em>′) ⊆ <em>T</em>(<em>s</em>) ∩ <em>T</em>(<em>s</em>′). But is it true that if a temperature is recorded somewhere in <em>s</em> and somewhere in <em>s</em>′, then it must be recorded somewhere in <em>s</em> ∩ <em>s</em>′? No, that is false. So <em>T</em> does not preserve meets.</p>
<p>The question on joins is, If we take the union of two regions <em>s</em> and <em>s</em>′, is the temperature range on <em>s</em>∪<em>s</em>′ equal to the union <em>T</em>(<em>s</em>)∪<em>T</em>(<em>s</em>′)? If a temperature is recorded somewhere in <em>s</em> ∪ <em>s</em>′, then it is either recorded somewhere in <em>s</em> or somewhere in <em>s</em>′ (or both), so <em>T</em>(<em>s</em> ∪ <em>s</em>′) ⊆ <em>T</em>(<em>s</em>) ∪ <em>T</em>(<em>s</em>′). And if a temperature is recorded somewhere in <em>s</em>, then it is recorded somewhere in <em>s</em> ∪ <em>s</em>′, so <em>T</em>(<em>s</em>) ⊆ <em>T</em>(<em>s</em> ∪ <em>s</em>′). Similarly, <em>T</em>(<em>s</em>′) ⊆ <em>T</em>(<em>s</em> ∪ <em>s</em>′), so in fact <em>T</em> does preserve joins: <em>T</em>(<em>s</em> ∪ <em>s</em>′) = <em>T</em>(<em>s</em>) ∪ <em>T</em>(<em>s</em>′).</p>
<p><em>Exercise</em> 4.4.5.12.</p>
<p>a. Can you think of a space relevant to an area of science for which it makes sense to assign an interval of real numbers to each open set, analogously to Exercise <a href="chapter004.html#Exe_4-4-5-11">4.4.5.11</a>? For example, for a sample of some material under stress, perhaps the strain on each open set is somehow an interval?</p>
<p>b. Check that your assignment, which you might denote as in Exercise <a href="chapter004.html#Exe_4-4-5-11">4.4.5.11</a> by <em>T</em> : <em>S</em> → <em>V</em>, is a morphism of orders.</p>
<p>c. How does it act with respect to meets and/or joins?</p>
<h1 id="lev_4-5" class="level1"><a href="toc.html#Rlev_4-5"><strong>4.5   Databases: schemas and instances</strong></a></h1>
<p>So far this chapter has discussed classical objects from mathematics. The present section is about databases, which are classical objects from computer science. These are truly “categories and functors, without admitting it” (see Theorem <a href="chapter005.html#The_5-4-2-3">5.4.2.3</a>).</p>
<h2 id="lev_4-5-1" class="level2"><strong>4.5.1   What are databases?</strong></h2>
<p>Data, in particular, the set of observations made during experiment, plays a primary role in science of any kind. To be useful, data must be organized, often in a row-and-column display called a table. Columns existing in different tables can refer to the same data.</p>
<p>A database is a collection of tables, each table <em>T</em> of which consists of a set of columns and a set of rows. We roughly explain the role of tables, columns, and rows as follows. The existence of table <em>T</em> suggests the existence of a fixed methodology for observing objects or events of a certain type. Each column <em>c</em> in <em>T</em> prescribes a single kind or method of observation, so that the datum inhabiting any cell in column <em>c</em> refers to an observation of that kind. Each row <em>r</em> in <em>T</em> has a fixed sourcing event or object, which can be observed using the methods prescribed by the columns. The cell (<em>r</em>, <em>c</em>) refers to the observation of kind <em>c</em> made on event <em>r</em>. All of the rows in <em>T</em> should refer to uniquely identifiable objects or events of a single type, and the name of the table <em>T</em> should refer to that type.</p>
<p><em>Example</em> 4.5.1.1. When graphene is strained (lengthened by a factor of <em>x</em> ⩾ 1), it becomes stressed (carries a force in the direction of the lengthening). The following is a madeup set of data:</p>
<p><img src="images/Art_P128.jpg" alt="art" /></p>
<p>In the table in (<a href="chapter004.html#eq_4-11">4.11</a>) titled “Graphene Sample,” the rows refer to graphene samples, and the table is so named. Each graphene sample can be observed according to the source supplier from which it came, the strain that it was subjected to, and the stress that it carried. These observations are the columns. In the right-hand table the rows refer to suppliers of various things, and the table is so named. Each supplier can be observed according to its full name and its phone number; these are the columns.</p>
<p>In the left-hand table it appears either that each graphene sample was used only once, or that the person recording the data did not keep track of which samples were reused. If such details become important later, the lab may want to change the layout of the left-hand table by adding an appropriate column. This can be accomplished using morphisms of schemas (see Section <a href="chapter005.html#lev_5-4-1">5.4.1</a>).</p>
<h3 id="lev_4-5-1-2" class="level3"><strong>4.5.1.2   Primary keys, foreign keys, and data columns</strong></h3>
<p>There is a bit more structure in the tables in (<a href="chapter004.html#eq_4-11">4.11</a>) than first meets the eye. Each table has a <em>primary ID column</em>, on the left, as well as some <em>data columns</em> and some <em>foreign key columns</em>. The primary key column is tasked with uniquely identifying different rows. Each data column houses elementary data of a certain sort. Perhaps most interesting from a structural point of view are the foreign key columns, because they link one table to another, creating a connection pattern between tables. Each foreign key column houses data that needs to be further unpacked. It thus refers us to another <em>foreign</em> table, in particular, to the primary ID column of that table. In (<a href="chapter004.html#eq_4-11">4.11</a>) the Source column is a foreign key to the Supplier table.</p>
<p>Here is another example, taken from Spivak [39].</p>
<p><em>Example</em> 4.5.1.3. Consider the bookkeeping necessary to run a department store. We keep track of a set of employees and a set of departments. For each employee <em>e</em>, we keep track of</p>
<p>E.1 the <strong>first</strong> name of <em>e</em>, which is a FirstNameString,</p>
<p>E.2 the <strong>last</strong> name of <em>e</em>, which is a LastNameString,</p>
<p>E.3 the <strong>manager</strong> of <em>e</em>, which is an Employee,</p>
<p>E.4 the department that <em>e</em> <strong>works in</strong>, which is a Department.</p>
<p>For each department <em>d</em>, we keep track of</p>
<p>D.1 the <strong>name</strong> of <em>d</em>, which is a DepartmentNameString,</p>
<p>D.2 the <strong>secretary</strong> of <em>d</em>, which is an Employee.</p>
<p>We can suppose that E.1, E.2, and D.1 are data columns (referring to names of various sorts), and E.3, E.4, and D.2 are foreign key columns (referring to managers, secretaries, etc.).</p>
<p>The tables in (<a href="chapter004.html#eq_4-12">4.12</a>) show how such a database might look at a particular moment in time.</p>
<p><img src="images/Art_P129.jpg" alt="art" /></p>
<h3 id="lev_4-5-1-4" class="level3"><strong>4.5.1.4   Business rules</strong></h3>
<p>Looking at the tables in (<a href="chapter004.html#eq_4-12">4.12</a>), one may notice a few patterns. First, every employee works in the same department as his or her manager. Second, every department’s secretary works in that department. Perhaps the business counts on these rules for the way it structures itself. In that case the database should enforce those rules, i.e., it should check that whenever the data is updated, it conforms to the rules:</p>
<p>Rule 1For every employee e, the manager of e works in the same department that e works in.Rule 2For every department d, the secretary of d works in department d.(4.13)</p>
<p>Together, the statements E.1, E.2, E.3, E.4, D.1, and D.2 from Example <a href="chapter004.html#Exa_4-5-1-3">4.5.1.3</a> and Rule 1 and Rule 2 constitute the <em>schema</em> of the database. This is formalized in Section <a href="chapter004.html#lev_4-5-2">4.5.2</a>.</p>
<h3 id="lev_4-5-1-5" class="level3"><strong>4.5.1.5   Data columns as foreign keys</strong></h3>
<p>To make everything consistent, we could even say that data columns are specific kinds of foreign keys. That is, each data column constitutes a foreign key to some non-branching <em>leaf table</em>, which has no additional data.</p>
<p><em>Example</em> 4.5.1.6. Consider again Example <a href="chapter004.html#Exa_4-5-1-3">4.5.1.3</a>. Note that first names and last names have a particular type, which we all but ignored. We could cease to ignore them by adding three tables, as follows:</p>
<p><img src="images/Art_P130.jpg" alt="art" /></p>
<p>In combination, (<a href="chapter004.html#eq_4-12">4.12</a>) and (<a href="chapter004.html#eq_4-14">4.14</a>) form a collection of five tables, each with the property that every column is either a primary key or a foreign key. The notion of data column is now subsumed under the notion of foreign key column. Each column is either a primary key (one per table, labeled ID) or a foreign key column (everything else).</p>
<h2 id="lev_4-5-2" class="level2"><strong>4.5.2   Schemas</strong></h2>
<p>Pictures here, roughly graphs, should capture the <em>conceptual layout</em> to which the data conforms, without being concerned (yet) with the individual pieces of data that may populate the tables in this instant. We proceed at first by example; the precise definition of schema is given in Definition <a href="chapter004.html#Def_4-5-2-7">4.5.2.7</a>.</p>
<p><em>Example</em> 4.5.2.1. In Examples <a href="chapter004.html#Exa_4-5-1-3">4.5.1.3</a> and <a href="chapter004.html#Exa_4-5-1-6">4.5.1.6</a>, the conceptual layout for a department store was given, and some example tables were shown. We were instructed to keep track of employees, departments, and six types of data (E.1, E.2, E.3, E.4, D.1, and D.2), and to follow two rules (Rule 1, Rule 2). All of this is summarized in the following picture:</p>
<p><img src="images/Art_P131.jpg" alt="art" /></p>
<p>The five tables from (<a href="chapter004.html#eq_4-12">4.12</a>) and (<a href="chapter004.html#eq_4-14">4.14</a>) are seen as five vertices; this is also the number of primary ID columns. The six foreign key columns from (<a href="chapter004.html#eq_4-12">4.12</a>) and (<a href="chapter004.html#eq_4-14">4.14</a>) are seen as six arrows; each points from a table to a foreign table. The two rules from (<a href="chapter004.html#eq_4-13">4.13</a>) are seen as declarations at the top of (<a href="chapter004.html#eq_4-15">4.15</a>). These path equivalence declarations are explained in Definition <a href="chapter004.html#Def_4-5-2-3">4.5.2.3</a>.</p>
<p><em>Exercise</em> 4.5.2.2.</p>
<p>Create a schema (consisting of dots and arrows) describing the conceptual layout of information presented in Example <a href="chapter004.html#Exa_4-5-1-1">4.5.1.1</a>.</p>
<p>In order to define schemas, we must first define the notion of <em>congruence</em> for an arbitrary graph <em>G</em>. Roughly a congruence is an equivalence relation that indicates how different paths in <em>G</em> are related (see Section <a href="chapter004.html#lev_4-3-2">4.3.2</a>). A notion of congruence for monoids was given in Definition <a href="chapter004.html#Def_4-1-1-17">4.1.1.17</a>, and the current notion is a generalization of that. A congruence (in addition to being reflexive, symmetric, and transitive) has two sorts of additional properties: congruent paths must have the same source and target, and the composition of congruent paths with other congruent paths must yield congruent paths. Formally we have Definition <a href="chapter004.html#Def_4-5-2-3">4.5.2.3</a>.</p>
<p><strong>Definition 4.5.2.3</strong>. Let <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) be a graph, and let Path<em><sub>G</sub></em> denote the set of paths in <em>G</em> (see Definition <a href="chapter004.html#Def_4-3-2-1">4.3.2.1</a>). A <em>path equivalence declaration</em> (or PED) is an expression of the form <em>p</em> ≃ <em>q</em>, where <em>p</em>, <em>q</em> ϵ Path<em><sub>G</sub></em> have the same source and target, <em>src</em>(<em>p</em>) = <em>src</em>(<em>q</em>) and <em>tgt</em>(<em>p</em>) = <em>tgt</em>(<em>q</em>).</p>
<p>A <em>congruence</em> on <em>G</em> is a relation ≃ on Path<em><sub>G</sub></em> that has the following properties:</p>
<ol>
<li>The relation ≃ is an equivalence relation.</li>
<li>If <em>p</em> ≃ <em>q</em>, then <em>src</em>(<em>p</em>) = <em>src</em>(<em>q</em>).</li>
<li>If <em>p</em> ≃ <em>q</em>, then <em>tgt</em>(<em>p</em>) = <em>tgt</em>(<em>q</em>).</li>
<li>Suppose given paths <em>p</em>, <em>p</em>′: <em>a</em> → <em>b</em> and <em>q</em>, <em>q</em>′: <em>b</em> → <em>c</em>. If <em>p</em> ≃ <em>p</em>′ and <em>q</em> ≃ <em>q</em>′, then (<em>p</em> ++ <em>q</em>) ≃ (<em>p</em>′ ++ <em>q</em>′).</li>
</ol>
<p><em>Remark</em> 4.5.2.4. Any set of path equivalence declarations (PEDs) generates a congruence. The proof of this is analogous to that of Proposition <a href="chapter004.html#Pro_4-1-1-18">4.1.1.18</a>. We tend to elide the difference between a congruence and a set of PEDs that generates it.</p>
<p>The basic idea for generating a congruence from a set <em>R</em> of PEDs is to proceed as follows. First find the equivalence relation generated by <em>R</em>. Then every time there are paths <em>p</em>, <em>p</em>′: <em>a</em> → <em>b</em> and <em>q</em>, <em>q</em>′: <em>b</em> → <em>c</em> with <em>p</em> ≃ <em>p</em>′ and <em>q</em> ≃ <em>q</em>′,</p>
<p><img src="images/Art_P132.jpg" alt="art" /></p>
<p>add to <em>R</em> the relation (<em>p</em> ++ <em>q</em>) ≃ (<em>p</em>′ ++ <em>q</em>′).</p>
<p><em>Exercise</em> 4.5.2.5.</p>
<p>Suppose given the following graph <em>G</em>, with the PED <sub><em>b</em></sub>[<em>w</em>, <em>x</em>] ≃ <em><sub>b</sub></em>[<em>y</em>, <em>z</em>]:</p>
<p><img src="images/Art_P133.jpg" alt="art" /></p>
<p>In the congruence generated by that PED, is it the case that <sub><em>a</em></sub>[<em>v</em>, <em>w</em>, <em>x</em>] ≃ <em><sub>a</sub></em>[<em>v</em>, <em>y</em>, <em>z</em>]?</p>
<p><em>Exercise</em> 4.5.2.6.</p>
<p>Consider the graph shown in (<a href="chapter004.html#eq_4-15">4.15</a>) and the two declarations shown at the top. They generate a congruence.</p>
<p>a. Is it true that the following PED is an element of this congruence?</p>
<p>Employee manager manager worksIn ≃? Employee worksIn</p>
<p>b. What about this one?</p>
<p>Employee worksIn secretary ≃? Employee</p>
<p>c. What about this one?</p>
<p>Department secretary manager worksIn name ≃? Department name</p>
<p><strong>Definition 4.5.2.7</strong>. A <em>database schema</em> (or simply <em>schema</em>) C consists of a pair C≔(G,≃), where <em>G</em> is a graph and ≃ is a congruence on <em>G</em>.</p>
<p><em>Example</em> 4.5.2.8. Pictured in (<a href="chapter004.html#eq_4-15">4.15</a>) is a graph with two PEDs; these generate a congruence, as discussed in Remark <a href="chapter004.html#Rem_4-5-2-4">4.5.2.4</a>. Thus this constitutes a database schema.</p>
<p>A schema can be converted into a system of tables, each with a primary key and some number of foreign keys referring to other tables, as discussed in Section <a href="chapter004.html#lev_4-5-1">4.5.1</a>. Definition <a href="chapter004.html#Def_4-5-2-7">4.5.2.7</a> gives a precise conceptual understanding of what a schema is, and the following rules describe how to convert it into a table layout.</p>
<p><em>Rules of good practice</em> 4.5.2.9. Converting a schema C=(G,≃) into a table layout should be done as follows:</p>
<p>   (i) There should be a table for every vertex in <em>G</em>, and if the vertex is named, the table should have that name.</p>
<p>  (ii) Each table should have a leftmost column called ID, set apart from the other columns by a double vertical line.</p>
<p> (iii) To each arrow <em>a</em> in <em>G</em> having source vertex <em>s</em> ≔ <em>src</em>(<em>a</em>) and target vertex <em>t</em> ≔ <em>tgt</em>(<em>a</em>), there should be a foreign key column <em>a</em> in table <em>s</em>, referring to table <em>t</em>; if the arrow <em>a</em> is named, column <em>a</em> should have that name.</p>
<p><em>Example</em> 4.5.2.10 (Discrete dynamical system). Consider the schema</p>
<p><img src="images/Art_P134.jpg" alt="art" /></p>
<p>in which the congruence is trivial (i.e., generated by the empty set of PEDs.) This schema is quite interesting. It encodes a set <em>s</em> and a function <em>f</em>: <em>s</em> → <em>s</em>. Such a thing is called a <em>discrete dynamical system</em>. One imagines <em>s</em> as the set of states, and for any state <em>x</em> ∈ <em>s</em>, the function <em>f</em> encodes a notion of next state <em>f</em>(<em>x</em>) ∈ <em>s</em>. For example,</p>
<p><img src="images/Art_P135.jpg" alt="art" /></p>
<p><em>Application</em> 4.5.2.11. Imagine a deterministic quantum-time universe in which there are discrete time steps. We model it as a discrete dynamical system, i.e., a table of the form (<a href="chapter004.html#eq_4-17">4.17</a>). For every possible state of the universe we include a row in the table. The state in the next instant is recorded in the second column.<sup><a href="chapter004.html#endnote_8">8</a></sup></p>
<p><em>Example</em> 4.5.2.12 (Finite hierarchy). The schema Loop can also be used to encode hierarchies, such as the manager relation from <a href="chapter004.html#Exa_4-5-1-3">Examples 4.5.1.3</a> and <a href="chapter004.html#Exa_4-5-2-1">4.5.2.1</a>,</p>
<p><img src="images/Art_P136.jpg" alt="art" /></p>
<p>One problem with this, however, is if a schema has even one loop, then it can have infinitely many paths (corresponding, e.g., to an employee’s manager’s manager’s manager’s … manager).</p>
<p>Sometimes we know that in a given company that process eventually terminates, a famous example being that at Ben and Jerry’s ice cream company, there were only seven levels. In that case we know that an employee’s eighth-level manager is equal to his or her seventh-level manager. This can be encoded by the PED</p>
<p><sub>E</sub>[mgr, mgr, mgr, mgr, mgr, mgr, mgr, mgr] ≃ <sub>E</sub>[mgr, mgr, mgr, mgr, mgr, mgr, mgr]</p>
<p>or more concisely, <sub>E</sub>[mgr]<sup>8</sup> = <sub>E</sub>[mgr]<sup>7</sup>.</p>
<p><em>Exercise</em> 4.5.2.13.</p>
<p>There is a nontrivial PED on Loop that holds for the data in Example <a href="chapter004.html#Exa_4-5-2-10">4.5.2.10</a>.</p>
<p>a. What is it?</p>
<p>b. How many equivalence classes of paths in Loop are there after you impose that relation?</p>
<p><em>Exercise</em> 4.5.2.14.</p>
<p>Let <em>P</em> be a chess-playing program, playing against itself. Given any position (where a position includes the history of the game so far), <em>P</em> will make a move.</p>
<p>a. Is this an example of a discrete dynamical system?</p>
<p>b. How do the rules for ending the game in a win or draw play out in this model? (Look up online how chess games end if you do not know.)</p>
<h3 id="lev_4-5-2-15" class="level3"><strong>4.5.2.15   Ologging schemas</strong></h3>
<p>It should be clear that a database schema is nothing but an olog in disguise. The difference is basically the readability requirements for ologs. There is an important new addition in this section, namely, that schemas and ologs can be filled in with data. Conversely, we have seen that databases are not any harder to understand than ologs are.</p>
<p><em>Example</em> 4.5.2.16. Consider the olog</p>
<p><img src="images/Art_P137.jpg" alt="art" /></p>
<p>We can document some instances of this relationship using the following table:</p>
<p><img src="images/Art_P138.jpg" alt="art" /></p>
<p>Clearly, this table of instances can be updated as more moons are discovered by the olog’s owner (be it by telescope, conversation, or research).</p>
<p><em>Exercise</em> 4.5.2.17.</p>
<p>In fact, Example <a href="chapter004.html#Exa_4-5-2-16">4.5.2.16</a> did not follow rules <a href="chapter004.html#rul_4-5-2-9">4.5.2.9</a>. Strictly following those rules, copy over the data from (<a href="chapter004.html#eq_4-19">4.19</a>) into tables that are in accordance with schema (<a href="chapter004.html#eq_4-18">4.18</a>).</p>
<p><em>Exercise</em> 4.5.2.18.</p>
<p>a. Write a schema (olog) in terms of the boxes ⌜a thing I own⌝ and ⌜a place⌝ and one arrow that might help a person remember where she decided to put random things.</p>
<p>b. What is a good label for the arrow?</p>
<p>c. Fill in some rows of the corresponding set of tables for your own case.</p>
<p><em>Exercise</em> 4.5.2.19.</p>
<p>Consider the olog</p>
<p><img src="images/Art_P139.jpg" alt="art" /></p>
<p>a. What path equivalence declarations would be appropriate for this olog? You can use <em>y</em>: <em>F</em> → <em>C</em>, <em>t</em>: <em>F</em> → <em>C</em>, and <em>f</em>: <em>C</em> → <em>F</em> for “youngest,” “tallest,” and “father,” if you prefer.</p>
<p>b. How many PEDs are in the congruence?</p>
<p><em>Solution</em> 4.5.2.19.</p>
<p>a. There are two: <em>F.t.f</em> ≃ <em>F</em> and <em>F.y.f</em> ≃ <em>F</em>, meaning “a father <em>F</em> ’s tallest child has as father <em>F</em> ” and “a father <em>F</em> ’s youngest child has as father <em>F</em>.”</p>
<p>b. There are infinitely many PEDs in this congruence, including <sub><em>F</em></sub>[<em>t</em>, <em>f</em>, <em>t</em>] ≃ <sub><em>F</em></sub>[<em>t</em>] and <sub><em>F</em></sub>[<em>t</em>, <em>f</em>, <em>y</em>] ≃ <sub><em>F</em></sub>[<em>y</em>]. But the congruence is <em>generated</em> by only two PEDs, those in part (a).</p>
<h2 id="lev_4-5-3" class="level2"><strong>4.5.3   Instances</strong></h2>
<p>Given a database schema (<em>G</em>, ≃), an instance of it is just a bunch of tables whose data conform to the specified layout. These can be seen throughout the previous section, most explicitly in the relationship between schema (<a href="chapter004.html#eq_4-15">4.15</a>) and tables (<a href="chapter004.html#eq_4-12">4.12</a>) and (<a href="chapter004.html#eq_4-14">4.14</a>), and between schema (<a href="chapter004.html#eq_4-16">4.16</a>) and table (<a href="chapter004.html#eq_4-17">4.17</a>). Following is the mathematical definition.</p>
<p><strong>Definition 4.5.3.1</strong>. Let C=(G,≃), where <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>). An <em>instance on</em> C, denoted (PK,FK):C→Set, is defined as follows: One announces some constituents (A. primary ID part, B. foreign key part) and shows that they conform to a law (1. preservation of congruence). Specifically, one announces</p>
<p>A. a function PK: <em>V</em> → <strong>Set</strong>, i.e., to each vertex <em>v</em> ∈ <em>V</em> one provides a set PK(<em>v</em>);<sup><a href="chapter004.html#endnote_9">9</a></sup></p>
<p>B. for every arrow <em>a</em> ∈ <em>A</em> with <em>v</em> = <em>src</em>(<em>a</em>) and <em>w</em> = <em>tgt</em>(<em>a</em>), a function FK(<em>a</em>): PK(<em>v</em>) → PK(<em>w</em>).<sup><a href="chapter004.html#endnote_10">10</a></sup></p>
<p>One must then show that the following law holds for any vertices <em>v</em>, <em>w</em> and paths <em>p</em> = <em><sub>v</sub></em>[<em>a</em><sub>1</sub>, <em>a</em><sub>2</sub>, <em>…, a<sub>m</sub></em>] and <em>q</em> = <em><sub>v</sub></em>[<em>a</em>′<sub>1</sub>, <em>a</em>′<sub>2</sub>, …, <em>a</em>′<em><sub>n</sub></em>] from <em>v</em> to <em>w</em>:</p>
<ol>
<li><p>If <em>p</em> ≃ <em>q</em>, then for all <em>x</em> ∈ PK(<em>v</em>), we have</p>
<p>FK(<em>a<sub>m</sub></em>) ○ · · · ○ FK(<em>a</em><sub>2</sub>) ○ FK(<em>a</em><sub>1</sub>)(<em>x</em>) = FK(<em>a</em>′<em><sub>n</sub></em>) ○ · · · ○ FK(<em>a</em>′<sub>2</sub>) ○ FK(<em>a</em>′<sub>1</sub>)(<em>x</em>) in PK(<em>w</em>).</p></li>
</ol>
<p><em>Exercise</em> 4.5.3.2.</p>
<p>Consider the olog in (<a href="chapter004.html#eq_4-20">4.20</a>):<sup><a href="chapter004.html#endnote_11">11</a></sup></p>
<p><img src="images/Art_P140.jpg" alt="art" /></p>
<p>It can be considered a schema of which the following is an instance:</p>
<p><img src="images/Art_P141.jpg" alt="art" /></p>
<p>a. What is the set PK(⌜an email⌝)?</p>
<p>b. What is the set PK(⌜a person⌝)?</p>
<p>c. What is the function FK(→is sent by):  PK(⌜an email⌝)→PK(⌜a person⌝)?</p>
<p>d. Interpret the sentences at the bottom of C as the Englishing of a simple path equivalence declaration (PED).</p>
<p>e. Is your PED satisfied by the instance (<a href="chapter004.html#eq_4-21">4.21</a>); that is, does law 1. from Definition <a href="chapter004.html#Def_4-5-3-1">4.5.3.1</a> hold?</p>
<p><em>Example</em> 4.5.3.3 (Monoid action table). In Example <a href="chapter004.html#Exa_4-1-2-9">4.1.2.9</a> we saw how a monoid M could be captured as an olog with only one object. As a database schema, this means there is only one table. Every generator of M would be a column of the table. The notion of database instance for such a schema (see Definition <a href="chapter004.html#Def_4-5-3-1">4.5.3.1</a>) matches perfectly with the notion of action table from Section <a href="chapter004.html#lev_4-1-3">4.1.3</a>. Note that a monoid can act on itself, in which case this action table is the monoid’s multiplication table, as in Example <a href="chapter004.html#Exa_4-1-3-2">4.1.3.2</a>, but it can also act on any other set, as in Example <a href="chapter004.html#Exa_4-1-3-1">4.1.3.1</a>. If M acts on a set <em>S</em>, then the set of rows in the action table will be <em>S</em>.</p>
<p><em>Exercise</em> 4.5.3.4.</p>
<p>Draw (as a graph) a schema for which table (<a href="chapter004.html#eq_4-1">4.1</a>), page 109, looks like an instance.</p>
<p><em>Exercise</em> 4.5.3.5.</p>
<p>Suppose that M is a monoid and some instance of it is written in table form, e.g., as in table (<a href="chapter004.html#eq_4-1">4.1</a>). It is possible that M is a group. What evidence in an instance table for M might suggest that M is a group?</p>
<h3 id="lev_4-5-3-6" class="level3"><strong>4.5.3.6   Paths through a database</strong></h3>
<p>Let C ≔ (<em>G</em>, ≃) be a schema, and let (PK, FK): C → <strong>Set</strong> be an instance on C. Then for every arrow <em>a</em>: <em>v</em> → <em>w</em> in <em>G</em> we get a function FK(<em>a</em>): PK(<em>v</em>) → PK(<em>w</em>). Functions can be composed, so in fact for every path through <em>G</em> we get a function. Namely, if <em>p</em> = <em>v</em><sub>0</sub>[<em>a</em><sub>1</sub>, <em>a</em><sub>2</sub>, …, <em>a<sub>n</sub></em>] is a path from <em>v</em><sub>0</sub> to <em>v<sub>n</sub></em>, then the instance provides a function</p>
<p>FK(p)≔FK(an)○⋯FK(a2)○FK(a1):PK(v0)→PK(vn),</p>
<p>which first made an appearance as part of Law 1 in Definition <a href="chapter004.html#Def_4-5-3-1">4.5.3.1</a>.</p>
<p><em>Example</em> 4.5.3.7. Consider the department store schema from Example <a href="chapter004.html#Exa_4-5-2-1">4.5.2.1</a>. More specifically consider the path<sub>Employee</sub>[worksIn, secretary, last] in (<a href="chapter004.html#eq_4-15">4.15</a>), which points from Employee to LastNameString. The instance lets us interpret this path as a function from the set of employees to the set of last names; this could be a useful function to have in real-life office settings. The instance from (<a href="chapter004.html#eq_4-12">4.12</a>) would yield the following function:</p>
<p>Employee</p>
<p><strong>ID</strong></p>
<p><strong>Secr. name</strong></p>
<p>101</p>
<p>Hillbert</p>
<p>102</p>
<p>Russell</p>
<p>103</p>
<p>Hillbert</p>
<p><em>Exercise</em> 4.5.3.8.</p>
<p>Consider the path <em>p</em> ≔ <sub><em>s</em></sub>[<em>f</em>, <em>f</em>] on the Loop schema in (<a href="chapter004.html#eq_4-16">4.16</a>). Using the instance from (<a href="chapter004.html#eq_4-17">4.17</a>), where PK(<em>s</em>) = {<em>A</em>, <em>B</em>, <em>C</em>, <em>D</em>, <em>E</em>, <em>F</em>, <em>G</em>, <em>H</em>}, interpret <em>p</em> as a function PK(<em>s</em>) → PK(<em>s</em>), and write this as a two-column table, as in Example <a href="chapter004.html#Exa_4-5-3-7">4.5.3.7</a>.</p>
<p><em>Exercise</em> 4.5.3.9.</p>
<p>Given an instance (PK, FK) on a schema C, and given a trivial path <em>p</em> (i.e., <em>p</em> has length 0; it starts at some vertex but does not go anywhere), what function does <em>p</em> yield as FK(<em>p</em>)?</p>
<p>__________________</p>
<p><a href="chapter004.html#endnote_ref_1"><sup>1</sup></a>Although the function ⋆: <em>M</em> × <em>M</em> → <em>M</em> is called the multiplication formula, it may have nothing to do with multiplication. It is just a formula for taking two inputs and returning an output.</p>
<p><a href="chapter004.html#endnote_ref_2"><sup>2</sup></a> Definition <a href="chapter004.html#Def_4-1-2-1">4.1.2.1</a> actually defines a <em>left action</em> of (<em>M</em>, <em>e</em>, ⋆) on <em>S</em>. A <em>right action</em> is like a left action except the order of operations is somehow reversed. We focus on left actions is in this text, but right actions are briefly defined here for completeness. The only difference is in the second condition. Using the same notation, we replace it by the condition that for all <em>m</em>, <em>n</em> ∈ <em>M</em> and all <em>s</em> ∈ <em>S</em>, we have</p>
<p><img src="images/Art_P143.jpg" alt="art" /></p>
<p><a href="chapter004.html#endnote_ref_3"><sup>3</sup></a>More precisely, the monoid homomorphism <em>F</em> sends a list [<em>t</em><sub>1</sub>, <em>t</em><sub>2</sub>, … , <em>t</em><sub><em>n</em></sub>] to the list [<em>r</em><sub>1,1</sub>, <em>r</em><sub>1,2</sub>, <em>r</em><sub>1,3</sub>, <em>r</em><sub>2,1</sub>, <em>r</em><sub>2,2</sub>, <em>r</em><sub>2,3</sub>, … , <em>r</em><sub><em>n</em>,1</sub>, <em>r</em><sub><em>n</em>,2</sub>, <em>r</em><sub><em>n</em>,3</sub>], where for each 0 ≤ <em>i</em> ≤ <em>n</em>, we have <em>t</em><sub><em>i</em></sub> = (<em>r</em><sub><em>i</em>,1</sub>, <em>r</em><sub><em>i</em>,2</sub>, <em>r</em><sub><em>i</em>,3</sub>).</p>
<p><a href="chapter004.html#endnote_ref_4"><sup>4</sup></a>Adding stop-codons to the mix, we can handle more of R, e.g., sequences that do not have a multiple-of-three many nucleotides.</p>
<p><a href="chapter004.html#endnote_ref_5"><sup>5</sup></a>If M is a group, then every element <em>m</em> has one and only one inverse.</p>
<p><a href="chapter004.html#endnote_ref_6"><sup>6</sup></a>It is worth noting the connection with <em>ev</em> : Hom<sub><strong>Set</strong></sub>(<em>X</em>, <em>X</em>) × <em>X</em> → <em>X</em> from (<a href="chapter003.html#lev_3-23">3.23</a>).</p>
<p><a href="chapter004.html#endnote_ref_7"><sup>7</sup></a>Use the displayed preorder, not any kind of completion of what is written there.</p>
<p><a href="chapter004.html#endnote_ref_8"><sup>8</sup></a>If we want nondeterminism, i.e., a probabilistic distribution as the next state, we can use monads. See Section <a href="chapter007.html#lev_7-3">7.3</a>.</p>
<p><a href="chapter004.html#endnote_ref_9"><sup>9</sup></a>The elements of PK(<em>v</em>) are listed as the rows of table <em>v</em>, or more precisely, as the leftmost cells of these rows.</p>
<p><a href="chapter004.html#endnote_ref_10"><sup>10</sup></a>The arrow <em>a</em> corresponds to a column, and to each row <em>r</em> ∈ PK(<em>v</em>) the (<em>r</em>, <em>a</em>) cell contains the datum FK(<em>a</em>)(<em>r</em>).</p>
<p><a href="chapter004.html#endnote_ref_11"><sup>11</sup></a>The text at the bottom of the box in (<a href="chapter004.html#eq_4-20">4.20</a>) is a summary of a fact, i.e., a path equivalence in the olog. Under the formal rules of Englishing a fact (see (<a href="chapter002.html#lev_2-20">2.20</a>)), it would read as follows. Given <em>x</em>, a self-email, consider the following. We know that <em>x</em> is a self-email, which is an email, which is sent by a person who we call <em>P</em>(<em>x</em>). We also know that <em>x</em> is a self-email, which is an email, which is sent to a person who we call <em>Q</em>(<em>x</em>). Fact: Whenever <em>x</em> is a self-email, we have <em>P</em>(<em>x</em>) = <em>Q</em>(<em>x</em>).</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter003.html">previous</a>, <a href="chapter005.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter004.html">previous</a>, <a href="chapter006.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<h1 class="chapter-number"><a href="toc.html#chap-5"><strong>Chapter 5</strong></a></h1>
<h1 class="chapter-title"><a href="toc.html#chap-5"><strong>Basic Category Theory</strong></a></h1>
<p>“<em>…We know only a very few—and, therefore, very precious—schemes whose unifying powers cross many realms.</em>”—Marvin Minsky.<sup><a href="chapter005.html#endnote_1">1</a></sup></p>
<p>Categories, or an equivalent notion, have already been introduced as ologs, or equivalently, as database schemas. One can think of a category as a graph (as in Section <a href="chapter004.html#lev_4-3">4.3</a>) in which certain paths have been declared congruent. (Ologs demand an extra requirement that everything be readable in natural language, and this cannot be part of the mathematical definition of category.) The formal definition of category is given in Definition <a href="chapter005.html#Def_5-1-1-1">5.1.1.1</a>, but it will not appear obvious that it is equivalent to the graph + congruence notion of schema, found in Definition <a href="chapter004.html#Def_4-5-2-7">4.5.2.7</a>. Once we know how different categories can be compared using functors (Definition <a href="chapter005.html#Def_5-1-2-1">5.1.2.1</a>), and how different schemas can be compared using schema mappings (Definition <a href="chapter005.html#Def_5-4-1-2">5.4.1.2</a>), we prove that the two notions are indeed equivalent (Theorem <a href="chapter005.html#The_5-4-2-3">5.4.2.3</a>).</p>
<h1 id="lev_5-1" class="level1"><a href="toc.html#Rlev_5-1"><strong>5.1   Categories and functors</strong></a></h1>
<p>This section gives the standard definition of categories and functors. These, together with natural transformations (Section <a href="chapter005.html#lev_5-3">5.3</a>), form the backbone of category theory. It also gives several examples.</p>
<h2 id="lev_5-1-1" class="level2"><strong>5.1.1   Categories</strong></h2>
<p>In everyday speech we think of a category as a kind of thing. A category consists of a collection of things, all of which are related in some way. In mathematics a category can also be construed as a collection of things and a type of relationship between pairs of such things. For this kind of thing-relationship duo to count as a category, we need to check two rules, which have the following flavor: every thing must be related to itself by simply being itself, and if one thing is related to another and the second is related to a third, then the first is related to the third. In a category the things are called <em>objects</em> and the relationships are called <em>morphisms</em>.</p>
<p>So far we have discussed things of various sorts, e.g., sets, monoids, graphs. In each case we discussed how such things should be appropriately compared as homomorphisms. In each case the things stand as the objects and the appropriate comparisons stand as the morphisms in the category. Here is the definition.</p>
<p><strong>Definition 5.1.1.1</strong>. A <em>category</em> C is defined as follows: One announces some constituents (A. objects, B. morphisms, C. identities, D. compositions) and shows that they conform to some laws (1. identity law, 2. associativity law). Specifically, one announces</p>
<p>A. a collection Ob(C), elements of which are called <em>objects</em>;</p>
<p>B. for every pair <em>x</em>, <em>y</em> ∈ Ob(C), a set HomC(x,y)∈Set; it is called the <em>hom-set from x to y</em>; its elements are called <em>morphisms from x to y</em>;<sup><a href="chapter005.html#endnote_2">2</a></sup></p>
<p>C. for every object x∈Ob(C), a specified morphism, denoted idx∈HomC(x,x), and called <em>the identity morphism on x</em>;</p>
<p>D. for every three objects x,y,z∈Ob(C), a function</p>
<p>○: HomC(y,z)×HomC(x,y)→HomC(x,z),</p>
<p>called <em>the composition formula</em>.</p>
<p>Given objects <em>x</em>, <em>y</em> ∈ Ob(C), we can denote a morphism f∈HomC(x,y) by <em>f</em>: <em>x</em> → <em>y</em>; we say that <em>x</em> is the <em>domain</em> of <em>f</em> and that <em>y</em> is the <em>codomain</em> of <em>f</em>. Given also <em>g</em>: <em>y</em> → <em>z</em>, the composition formula is written using infix notation, so <em>g</em> ○ <em>f</em>: <em>x</em> → <em>z</em> means ○(g,f)∈HomC(x,z).</p>
<p>One must then show that the following <em>category laws</em> hold:</p>
<ol>
<li><p>For every <em>x</em>, <em>y</em> ∈ Ob(C) and every morphism <em>f</em>: <em>x</em> → <em>y</em>, we have</p>
<p>f○idx=f        and        idy○f=f.</p></li>
<li>If <em>w</em>, <em>x</em>, <em>y</em>, <em>z</em> ∈ Ob(C) are any objects, and <em>f</em>: <em>w</em> → <em>x</em>, <em>g</em>: <em>x</em> → <em>y</em>, and <em>h</em>: <em>y</em> → <em>z</em> are any morphisms, then the two ways to compose yield the same element in HomC(w,z):</li>
</ol>
<p>(h○g)○f=h○(g○f)∈HomC(w,z).</p>
<p><em>Remark</em> 5.1.1.2. There is perhaps much that is unfamiliar about Definition <a href="chapter005.html#Def_5-1-1-1">5.1.1.1</a>, but there is also one thing that is strange about it. The objects Ob(C) of C are said to be a collection rather than a set. This is because we sometimes want to talk about the category of all sets, in which every possible set is an object, and if we try to say that the collection of sets is itself a set, we run into Russell’s paradox. Modeling this was a sticking point in the foundations of category theory, but it was eventually fixed by Grothendieck’s notion of expanding universes. Roughly, the idea is to choose some huge set <em>κ</em> (with certain properties making it a <em>universe</em>), to work entirely inside of it when possible, and to call anything in that world <em>κ-small</em> (or just <em>small</em> if <em>κ</em> is clear from context). When we need to look at <em>κ</em> itself, we choose an even bigger universe <em>κ</em>′ and work entirely within it.</p>
<p>A category in which the collection Ob(C) is a set (or a small set) is called a <em>small category</em>. From here on I do not take note of the difference; I refer to Ob(C) as a set. I do not think this will do any harm to scientists using category theory, at least not in the beginning phases of their learning.</p>
<p><em>Example</em> 5.1.1.3 (The category <strong>Set</strong> of sets). Chapters 2 and 3 were about the category of sets, denoted <strong>Set</strong>. The objects are the sets and the morphisms are the functions; and the current notation Hom<strong><sub>Set</sub></strong>(<em>X</em>, <em>Y</em>) was used to refer to the set of functions <em>X</em> → <em>Y</em>. The composition formula ○ is given by function composition, and for every set <em>X</em>, the identity function id<em><sub>X</sub></em>: <em>X</em> → <em>X</em> serves as the identity morphism for <em>X</em> ∈ Ob(<strong>Set</strong>). The two laws clearly hold, so <strong>Set</strong> is indeed a category.</p>
<p><em>Example</em> 5.1.1.4 (The category <strong>Fin</strong> of finite sets). Inside the category <strong>Set</strong> is a <em>subcategory</em> <strong>Fin</strong> ⊆ <strong>Set</strong>, called the <em>category of finite sets</em>. Whereas an object <em>S</em> ∈ Ob(<strong>Set</strong>) is a set that can have arbitrary cardinality, <strong>Fin</strong> is defined such that Ob(<strong>Fin</strong>) includes all (and only) those sets <em>S</em> having finitely many elements, i.e., |<em>S</em>| = <em>n</em> for some natural number <em>n</em> ∈ ℕ. Every object of <strong>Fin</strong> is an object of <strong>Set</strong>, but not vice versa.</p>
<p>Although <strong>Fin</strong> and <strong>Set</strong> have different collections of objects, their notions of morphism are in some sense the same. For any two finite sets <em>S</em>, <em>S</em>′ ∈ Ob(<strong>Fin</strong>), we can also think of <em>S</em>, <em>S</em>′ ∈ Ob(<strong>Set</strong>), and we have</p>
<p>HomFin(S,S′)=HomSet(S,S′).</p>
<p>That is, a morphism in <strong>Fin</strong> between finite sets <em>S</em> and <em>S</em>′ is simply a function <em>f</em>: <em>S</em> → <em>S</em>′.</p>
<p><em>Example</em> 5.1.1.5 (The category <strong>Mon</strong> of monoids). Monoids were defined in Definition <a href="chapter004.html#Def_4-1-1-1">4.1.1.1</a>, and monoid homomorphisms in Definition <a href="chapter004.html#Def_4-1-4-1">4.1.4.1</a>. Every monoid M≔(M,e,⋆M) has an identity homomorphism idM:M→M, given by the identity function id<em><sub>M</sub></em>: <em>M</em> → <em>M</em>. To compose two monoid homomorphisms f:M→M′ and g:M′→M″, we compose their underlying functions <em>f</em>: <em>M</em> → <em>M</em>′ and <em>g</em>: <em>M</em>′ → <em>M</em>″, and check that the result <em>g</em> ○ <em>f</em> is a monoid homomorphism. Indeed,</p>
<p>g○f(e)=g(e′)=e″,</p>
<p>g○f(m1 ⋆M m2)=g(f(m1)⋆M′ f(m2))=g○f(m1)⋆M″ g○f(m2).</p>
<p>It is clear that the two category laws (unit and associativity) hold, because monoid morphisms are special kinds of functions, and functions compose unitally and associatively. So <strong>Mon</strong> is a category.</p>
<p><em>Remark</em> 5.1.1.6. The following will be informal, but it can be formalized. Let’s define a <em>questionable category</em> to be the specification of A, B, C, D from Definition <a href="chapter005.html#Def_5-1-1-1">5.1.1.1</a>, without enforcing either of the category laws (1, 2). Suppose that Q is a questionable category and C is a category. If Q sits somehow inside of C, in the precise sense that</p>
<p>A. there is a function U:Ob(Q)→Ob(C),</p>
<p>B. for all a,b∈Ob(Q), we have an injection U:HomQ(a,b)↪HomC(U(a),U(b)),</p>
<p>C. for all a∈Ob(Q), both Q and C have the same version of the identity on <em>a</em>, i.e., <em>U</em>(id<em><sub>a</sub></em>) = id<sub><em>U</em>(<em>a</em>)</sub>,</p>
<p>D. for all <em>f</em>: <em>a</em> → <em>b</em> and <em>g</em>: <em>b</em> → <em>c</em> in Q, both Q and C have the same version of composition <em>g</em> ○ <em>f</em>, i.e., <em>U</em>(<em>g</em> ○ <em>f</em>) = <em>U</em>(<em>g</em>) ○ <em>U</em>(<em>f</em>),</p>
<p>then Q is a category (no longer questionable).</p>
<p>This fact was used in Example <a href="chapter005.html#Exa_5-1-1-5">5.1.1.5</a> for <strong>Mon</strong> ⊆ <strong>Set</strong>.</p>
<p><em>Exercise</em> 5.1.1.7.</p>
<p>Suppose we set out to define a category <strong>Grp</strong>, having groups as objects and group homomorphisms as morphisms (see Definition <a href="chapter004.html#Def_4-2-1-16">4.2.1.16</a>). Show that the rest of the conditions for <strong>Grp</strong> to be a category are satisfied.</p>
<p><em>Exercise</em> 5.1.1.8.</p>
<p>Suppose we set out to define a category <strong>PrO</strong>, having preorders as objects and preorder homomorphisms as morphisms (see Definition <a href="chapter004.html#Def_4-4-4-1">4.4.4.1</a>). Show (to the level of detail of Example <a href="chapter005.html#Exa_5-1-1-5">5.1.1.5</a>) that the rest of the conditions for <strong>PrO</strong> to be a category are satisfied.</p>
<p><em>Example</em> 5.1.1.9 (Noncategory 1). What is not a category? Two things can go wrong: either one fails to specify all the relevant constituents (A, B, C, D from Definition <a href="chapter005.html#Def_5-1-1-1">5.1.1.1</a>), or the constituents do not obey the category laws (1, 2).</p>
<p>Let <em>G</em> be the following graph:</p>
<p><img src="images/Art_P144.jpg" alt="art" /></p>
<p>Suppose we try to define a category G by faithfully recording vertices as objects and arrows as morphisms. Will that be a category?</p>
<p>Following that scheme, we put Ob(G)={a,b,c}. For all nine pairs of objects we need a hom-set. Since the only things we are calling morphisms are the arrows of <em>G</em>, we put</p>
<p>HomG(a,a)=∅HomG(a,b)={f}HomG(a,c)=∅HomG(b,a)=∅HomG(b,b)=∅HomG(b,c)={g}HomG(c,a)=∅HomG(c,b)=∅HomG(c,c)=∅(5.1*)</p>
<p>If we say we are done, the listener should object that we have given neither identities (C) nor a composition formula (D), and these are necessary constituents. Now we are at a loss: it is impossible to give identities under this scheme, because, e.g., HomG(a,a)=∅. So what we have for G is not a category.</p>
<p>Suppose we fix that problem, adding an element to each of the diagonals so that</p>
<p>HomG(a,a)={ida},            HomG(b,b)={idb},           and         HomG(c,c)={idc}.</p>
<p>But the listener still demands a composition formula. In particular, we need a function</p>
<p>HomG(b,c)×HomG(a,b)→HomG(a,c),</p>
<p>but the domain is nonempty (it is {(<em>f</em>, <em>g</em>)}) and the codomain HomG(a,c)=∅ is empty; there is no such function. In other words, to satisfy the listener we need to add a composite for the arrows <em>f</em> and <em>g</em>.</p>
<p>So again we must make a change, adding an element to make HomG(a,c)={h}. We can now say <em>g</em> ○ <em>f</em> = <em>h</em>. Finally, this does the trick and we have a category with the following morphisms:</p>
<p>HomG(a,a)={ida}HomG(a,b)={f}HomG(a,c)={h}HomG(b,a)=∅HomG(b,b)={idb}HomG(b,c)={g}HomG(c,a)=∅HomG(c,b)=∅HomG(c,c)={idc}</p>
<p>A computer could check this quickly, as can someone with good intuition for categories; for everyone else, it may be a painstaking process involving determining whether there is a unique composition formula for each of the 27 pairs of hom-sets and whether the associative law holds in the 81 necessary cases. Luckily this computation is sparse (lots of ∅’s).</p>
<p>If all the morphisms are drawn as arrows, the graph becomes:</p>
<p><img src="images/Art_P145.jpg" alt="art" /></p>
<p><em>Example</em> 5.1.1.10 (Noncategory 2). In this example, we make a faux category F with one object and many morphisms. The problem here is the composition formula.</p>
<p>Define F to have one object Ob(F)={☺}, and HomF(☺,☺)=ℕ . Define id<sub>☺</sub>= 1 ∈ ℕ. Define the composition formula ○: ℕ × ℕ → ℕ by the usual exponentiation function for natural numbers, <em>m</em> ○ <em>n</em> = <em>m<sup>n</sup></em>. This is a perfectly cromulent function, but it does not work right as a composition formula. Indeed, for the identity law to hold, we would need <em>m</em><sup>1</sup> = <em>m</em> = 1<em><sup>m</sup></em>, and one side of this is false. For the associativity law to hold, we would need (mn)p=m(np), but this is also not the case.</p>
<p>To fix this problem we must completely revamp the composition formula. It would work to use multiplication, <em>m</em> ○ <em>n</em> = <em>m</em> * <em>n</em>. Then the identity law would read 1 * <em>m</em> = <em>m</em> = <em>m</em> * 1, and that holds; and the associativity law would read (<em>m</em> * <em>n</em>) * <em>p</em> = <em>m</em> * (<em>n</em> * <em>p</em>), and that holds.</p>
<p><em>Example</em> 5.1.1.11 (The category of preorders with joins). Suppose we are only interested in preorders (<em>X</em>, ⩽) for which every pair of elements has a join. We saw in Exercise <a href="chapter004.html#Exe_4-4-2-3">4.4.2.3</a> that not all preorders have this property. However, we can create a category C in which every object does have this property. To begin, let’s put</p>
<p>C≔{(X, ⩽)∈Ob(PrO)|(X, ⩽) has all joins}</p>
<p>for the set of objects. What about morphisms?</p>
<p>One option would be to put in no morphisms (other than identities) and to just consider this collection of objects as having no structure other than a set. In other words, we can take C to be the discrete category on the preceding set Ob(C)=C.</p>
<p>Another option, say, C′ with objects Ob(C′)≔C, would be to put in exactly the same morphisms as in <strong>PrO</strong>: for any objects <em>a</em>, <em>b</em> ∈ <em>C</em>, we consider <em>a</em> and <em>b</em> as ordinary preorders and put HomC′(a,b)≔HomPrO(a,b). The resulting category C′ of preorders with joins is called the <em>full subcategory of</em> <strong>PrO</strong> <em>spanned by the preorders with joins</em>.<sup><a href="chapter005.html#endnote_3">3</a></sup></p>
<p>A third option, say, C″ with objects Ob(C″)≔C, would stand out to a category theorist. That is, the conscientious modeler takes the choice about how we define objects as a clue to how we should define morphisms.</p>
<p><em>Slogan</em> 5.1.1.12.</p>
<p><em>If you like joins so much, why don’t you marry them?</em></p>
<p>Morphisms are often billed as preserving all the structure we care about, so it is worth asking whether we want to enforce that constraint on morphisms. That is, suppose <em>f</em>: (<em>X</em>, ⩽<em><sub>X</sub></em>) → (<em>Y</em>, ⩽<em><sub>Y</sub></em>) is a morphism of preorders. We might want to condition the decision of whether to include <em>f</em> as a morphism in C″ on whether, for any join <em>w</em> = <em>x</em> ∨ <em>x</em>′ in <em>X</em>, it is the case that <em>f</em>(<em>w</em>) = <em>f</em>(<em>x</em>) ∨ <em>f</em>(<em>x</em>′) in <em>Y</em>. Concisely, we could define the morphisms in C″ by</p>
<p>HomC(a,b)≔{f∈HomPrO(a,b)|f preserves joins}.</p>
<p>One can check easily that the identity morphisms preserve joins and that compositions of join-preserving morphisms are join-preserving, so this version of homomorphisms makes C″ a well defined category.</p>
<p>These options are by no means comprehensive, and none of these options is better than any other. Which category to use is decided by whatever fits the situation being modeled.</p>
<p><em>Example</em> 5.1.1.13 (Category <strong>FLin</strong> of finite linear orders). We have a category <strong>PrO</strong> of preorders, and some of its objects are finite linear orders. Let <strong>FLin</strong> be the full subcategory of <strong>PrO</strong> spanned by the linear orders. That is, following Definition <a href="chapter004.html#Def_4-4-4-1">4.4.4.1</a>, given linear orders <em>X</em>, <em>Y</em> ∈ Ob(<strong>FLin</strong>), every morphism of preorders <em>X</em> → <em>Y</em> counts as a morphism in <strong>FLin</strong>:</p>
<p>HomFLin(X,Y)=HomPrO(X,Y).</p>
<p><em>Exercise</em> 5.1.1.14.</p>
<p>Let <strong>FLin</strong> be the category of finite linear orders, defined in Example <a href="chapter005.html#Exa_5-1-1-13">5.1.1.13</a>. For <em>n</em> ∈ ℕ, let [<em>n</em>] be the linear order defined in Example <a href="chapter004.html#Exa_4-4-1-7">4.4.1.7</a>. What are the cardinalities of the following sets?</p>
<p>a. Hom<strong><sub>FLin</sub></strong>([0], [3])</p>
<p>b. Hom<strong><sub>FLin</sub></strong>([3], [0])</p>
<p>c. Hom<strong><sub>FLin</sub></strong>([2], [3])</p>
<p>d. Hom<strong><sub>FLin</sub></strong>([1], [<em>n</em>])</p>
<p>e. (Challenge) Hom<strong><sub>FLin</sub></strong>([<em>m</em>], [<em>n</em>])</p>
<p>It turns out that the category <strong>FLin</strong> of linear orders is sufficiently rich that much of algebraic topology (the study of arbitrary spaces, such as Mobius strips and seven-dimensional spheres) can be understood in its terms. See Example <a href="chapter006.html#Exa_6-2-1-7">6.2.1.7</a>.</p>
<p><em>Example</em> 5.1.1.15 (Category of graphs). Graphs were defined in Definition <a href="chapter004.html#Def_4-3-1-1">4.3.1.1</a> and graph homomorphisms in Definition <a href="chapter004.html#Def_4-3-3-1">4.3.3.1</a>. To see that these are sufficient to form a category is considered routine to a seasoned category theorist, so let’s see why.</p>
<p>Since a morphism from G = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) to G′ = (<em>V</em>′, <em>A</em>′, <em>src</em>′, <em>tgt</em>′) involves two functions <em>f</em><sub>0</sub>: <em>V</em> → <em>V</em>′ and <em>f</em><sub>1</sub>: <em>A</em> → <em>A</em>′, the identity and composition formulas simply arise from the identity and composition formulas for sets. Associativity follow similarly. The only thing that needs to be checked is that the composition of two such morphisms, each satisfying (4.5), will itself satisfy (4.5). For completeness, we check that now.</p>
<p>Suppose that f=(f0,f1):G→G′ and g=(g0,g1):G′→G″ are graph homomorphisms, where G″=(V″,A″,src″,tgt″). Then in each diagram in (<a href="chapter005.html#eq_5-2">5.2</a>)</p>
<p><img src="images/Art_P146.jpg" alt="art" /></p>
<p>the left-hand square commutes because <em>f</em> is a graph homomorphism and the right-hand square commutes because <em>g</em> is a graph homomorphism. Thus the whole rectangle commutes, meaning that <em>g</em> ○ <em>f</em> is a graph homomorphism, as desired.</p>
<p>We denote the category of graphs and graph homomorphisms <strong>Grph</strong>.</p>
<p><em>Remark</em> 5.1.1.16. When one is struggling to understand basic definitions, notation, and style, a phase that naturally occurs when learning new mathematics (or any new language), the preceding example will probably appear long and tiring. I would say the reader has mastered the basics when the example seems straightforward. Around this time, I hope the reader will get a sense of the remarkable organizational potential of the categorical way of thinking.</p>
<p><em>Exercise</em> 5.1.1.17.</p>
<p>Let <em>F</em> be a vector field defined on all of ℝ<sup>2</sup>. Recall that for two points <em>x</em>, <em>x</em>′ ∈ ℝ<sup>2</sup>, any curve <em>C</em> with endpoints <em>x</em> and <em>x</em>′, and any parameterization <em>r</em>: [<em>a</em>, <em>b</em>] → <em>C</em>, the line integral ∫<em><sub>C</sub> F</em>(<em>r</em>)·<em>dr</em> returns a real number. It does not depend on <em>r</em>, except its orientation (direction). Therefore, if we think of <em>C</em> has having an orientation, say, going from <em>x</em> to <em>x</em>′, then ∫<em><sub>C</sub> F</em> is a well defined real number. If <em>C</em> goes from <em>x</em> to <em>x</em>′, let’s write <em>C</em>: <em>x</em> → <em>x</em>′. Define an equivalence relation ∼ on the set of oriented curves in ℝ<sup>2</sup> by saying <em>C</em> ∼ <em>C</em>′ if</p>
<ul>
<li><em>C</em> and <em>C</em>′ start at the same point;</li>
<li><em>C</em> and <em>C</em>′ end at the same point;</li>
<li>∫<em><sub>C</sub> F</em> = ∫<em><sub>C′</sub></em> <em>F</em>.</li>
</ul>
<p>Suppose we try to make a category CF as follows. Put Ob(CF)=ℝ2, and for every pair of points <em>x</em>, <em>x</em>′ ∈ ℝ<sup>2</sup>, let HomCF(x,x′)={C:x→x′}/~, where <em>C</em>: <em>x</em> → <em>x</em>′ is an oriented curve and ∼ means “same line integral,” as explained.</p>
<p>Is there an identity morphism and a composition formula that will make CF into a category?</p>
<p><em>Solution</em> 5.1.1.17.</p>
<p>Yes. For every object <em>x</em> ∈ ℝ<sup>2</sup>, the constant curve at <em>x</em> serves as the identity on <em>x</em>. If <em>C</em>: <em>x</em> → <em>y</em> and <em>C</em>′: <em>y</em> → <em>z</em> are curves, their composition is given by joining them to get a curve <em>x</em> → <em>z</em>.</p>
<h3 id="lev_5-1-1-18" class="level3"><strong>5.1.1.18   Isomorphisms</strong></h3>
<p>In any category we have a notion of isomorphism between objects.</p>
<p><strong>Definition 5.1.1.19</strong>. Let C be a category, and let X,Y∈Ob(C) be objects. An <em>isomorphism f from X to Y</em> is a morphism <em>f</em>: <em>X</em> → <em>Y</em> in C such that there exists a morphism <em>g</em>: <em>Y</em> → <em>X</em> in C with</p>
<p>g○f=idX         and         f○g=idY.</p>
<p>In this case we say that the morphism <em>f</em> is <em>invertible</em> and that <em>g</em> is the <em>inverse</em> of <em>f</em>. We may also say that the objects <em>X</em> and <em>Y</em> are <em>isomorphic</em>.</p>
<p><em>Example</em> 5.1.1.20. If C=Set is the category of sets, then Definition <a href="chapter005.html#Def_5-1-1-19">5.1.1.19</a> coincides precisely with the one given in Definition <a href="chapter002.html#Def_2-1-2-14">2.1.2.14</a>.</p>
<p><em>Exercise</em> 5.1.1.21.</p>
<p>Let C be a category, and let <em>c</em> ∈ Ob(C) be an object. Show that id<em><sub>c</sub></em> is an isomorphism.</p>
<p><em>Solution</em> 5.1.1.21.</p>
<p>We have a morphism id<em><sub>c</sub></em>: <em>c</em> → <em>c</em>. To show it is an isomorphism we just need to find a morphism <em>f</em>: <em>c</em> → <em>c</em> such that <em>f</em> ○ id<em><sub>c</sub></em> = id<em><sub>c</sub></em> and id<em><sub>c</sub></em> ○ <em>f</em> = id<em><sub>c</sub></em>. Taking <em>f</em> = id<em><sub>c</sub></em> works.</p>
<p><em>Exercise</em> 5.1.1.22.</p>
<p>Let C be a category, and let <em>f</em>: <em>X</em> → <em>Y</em> be a morphism. Suppose that both <em>g</em>: <em>Y</em> → <em>X</em> and <em>g</em>′: <em>Y</em> → <em>X</em> are inverses of <em>f</em>. Show that they are the same morphism, <em>g</em> = <em>g</em>′.</p>
<p><em>Exercise</em> 5.1.1.23.</p>
<p>Suppose that <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) and <em>G</em>′ = (<em>V</em>′, <em>A</em>′, <em>src</em>′, <em>tgt</em>′) are graphs and that <em>f</em> = (<em>f</em><sub>0</sub>, <em>f</em><sub>1</sub>): <em>G</em> → <em>G</em>′ is a graph homomorphism (as in Definition <a href="chapter004.html#Def_4-3-3-1">4.3.3.1</a>).</p>
<p>a. If <em>f</em> is an isomorphism in <strong>Grph</strong>, does this imply that <em>f</em><sub>0</sub>: <em>V</em> → <em>V</em>′ and <em>f</em><sub>1</sub>: <em>A</em> → <em>A</em>′ are isomorphisms in <strong>Set</strong>?</p>
<p>b. If so, why; if not, show a counterexample (where <em>f</em> is an isomorphism but either <em>f</em><sub>0</sub> or <em>f</em><sub>1</sub> is not).</p>
<p><em>Exercise</em> 5.1.1.24.</p>
<p>Suppose that <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) and <em>G</em>′ = (<em>V</em>′, <em>A</em>′, <em>src</em>′, <em>tgt</em>′) are graphs and that <em>f</em> = (<em>f</em><sub>0</sub>, <em>f</em><sub>1</sub>): <em>G</em> → <em>G</em>′ is a graph homomorphism (as in Definition <a href="chapter004.html#Def_4-3-3-1">4.3.3.1</a>).</p>
<p>a. If <em>f</em><sub>0</sub>: <em>V</em> → <em>V</em>′ and <em>f</em><sub>1</sub>: <em>A</em> → <em>A</em>′ are isomorphisms in <strong>Set</strong>, does this imply that <em>f</em> is an isomorphism in <strong>Grph</strong>?</p>
<p>b. If so, why; if not, show a counterexample (where <em>f</em><sub>0</sub> and <em>f</em><sub>1</sub> are isomorphisms but <em>f</em> is not).</p>
<p><strong>Proposition 5.1.1.25</strong>. <em>Let</em> C <em>be a category, and let</em> ≅ <em>be the relation on</em> Ob(C) <em>given by saying X</em> ≅ <em>Y iff X and Y are isomorphic. Then</em> ≅ <em>is an equivalence relation.</em></p>
<p><em>Proof.</em> The proof of Proposition <a href="chapter002.html#Pro_2-1-2-18">2.1.2.18</a> can be mimicked in this more general setting.</p>
<h3 id="lev_5-1-1-26" class="level3"><strong>5.1.1.26   Another viewpoint on categories</strong></h3>
<p>Here is an alternative definition of category, using the work done in Chapter 2.</p>
<p><em>Exercise</em> 5.1.1.27.</p>
<p>Suppose we begin our definition of category as follows.</p>
<p>A <em>category</em> C consists of a sequence (Ob(C),HomC,dom,cod,ids,comp), where</p>
<ul>
<li>Ob(C) is a set;<sup><a href="chapter005.html#endnote_4">4</a></sup></li>
<li>HomC is a set, and dom,cod:HomC→Ob(C) are functions;</li>
<li><em>ids</em>: Ob(C)→HomC is a function;</li>
<li><em>comp</em> is a function as depicted in the commutative diagram (<a href="chapter005.html#eq_5-3">5.3</a>)</li>
</ul>
<p><img src="images/Art_P147.jpg" alt="art" /></p>
<p>a. Add to diagram (<a href="chapter005.html#eq_5-3">5.3</a>) to express the fact that for any x∈Ob(C), the morphism id<em><sub>x</sub></em> points from <em>x</em> to <em>x</em>.</p>
<p>b. Express the condition that composing a morphism <em>f</em> with an appropriate identity morphism yields <em>f</em>.</p>
<p><em>Solution</em> 5.1.1.27.</p>
<p>a. This is expressed by the equations: dom○ids=idOb(C) and cod○ids=idOb(C). One could express this with the diagram:</p>
<p><img src="images/Art_P148.jpg" alt="art" /></p>
<p>b. We have idHomC:HomC→HomC and ids○cod:HomC→HomC, and these commute over Ob(C), meaning that for any morphism <em>f</em>: <em>A</em> → <em>B</em>, its codomain is the domain of id<em><sub>B</sub></em>. Thus a unique map</p>
<p>〈idHomC, ids○ cod〉Ob(C):HomC→HomC×Ob(C)HomC</p>
<p>is induced (see Proposition <a href="chapter003.html#Pro_3-2-1-15">3.2.1.15</a>). Similarly there is a function</p>
<p>〈idids○domHomC, Ob(C)〉: HomC→HomC×Ob(C)HomC.</p>
<p>When we compose either of these morphisms with <em>comp</em>, we are taking the composition of a morphism and the identity (either on the domain or the codomain). Thus, the fact that composing any morphism with an identity morphism returns that morphism is expressed by asserting two path equivalences,</p>
<p>HomC[〈idHomC, ids ○ cod〉, comp]≃HomC[],HomC[〈ids ○ dom, idHomC〉, comp]≃HomC[],</p>
<p>in the following diagram:</p>
<p><img src="images/Art_P149.jpg" alt="art" /></p>
<p><em>Example</em> 5.1.1.28 (Partial olog for a category). Diagram (<a href="chapter005.html#eq_5-4">5.4</a>) is an olog that captures some of the essential structures of a category:</p>
<p><img src="images/Art_P150.jpg" alt="art" /></p>
<p>Missing from (<a href="chapter005.html#eq_5-4">5.4</a>) is the notion of identity morphism (as an arrow from ⌜an object of C⌝ to ⌜a morphism in C⌝) and the associated path equivalences, as well as the identity and associativity laws. All of these can be added to the olog, at the expense of some clutter.</p>
<p><em>Remark</em> 5.1.1.29. Perhaps it is already clear that category theory is very interconnected. It may feel like everything relates to everything, and this feeling may intensify as you go on. However, the relationships between different notions are rigorously defined, not random. Moreover, almost everything presented in this book can be formalized in a proof system like Coq (the most obvious exceptions being things like the readability requirement of ologs and the modeling of scientific applications).</p>
<p>Whenever you feel cognitive vertigo, use the interplay between examples and formal definitions to solidify your understanding. Go through each example, making sure it conforms to the definitions or theorems it purports to exemplify.</p>
<h2 id="lev_5-1-2" class="level2"><strong>5.1.2   Functors</strong></h2>
<p>A category C=(Ob(C),HomC,dom,cod,ids,comp), involves a set of objects, a set of morphisms, a notion of domains and codomains, a notion of identity morphisms, and a composition formula. For two categories to be comparable, these various components should be appropriately comparable.</p>
<p><strong>Definition 5.1.2.1</strong>. Let C and C′ be categories. A <em>functor F from</em> C <em>to</em> C′, denoted F:C→C′, is defined as follows: One announces some constituents (A. on-objects part, B. on-morphisms part) and shows that they conform to some laws (1. preservation of identities, 2. preservation of composition). Specifically, one announces</p>
<p>A. a function Ob(F): Ob(C)→Ob(C′), sometimes denoted simply F: Ob(C)→Ob(C′);</p>
<p>B. for every pair of objects c,d∈Ob(C), a function</p>
<p>HomF(c,d): HomC(c,d)→HomC′(F(c),F(d)),</p>
<p>sometimes denoted simply F:HomC(c,d)→HomC′(F(c),F(d)).</p>
<p>One must then show that the following <em>functor laws</em> hold:</p>
<ol>
<li>Identities are preserved by <em>F</em>, that is, for any object c∈Ob(C), we have <em>F</em>(id<em><sub>c</sub></em>) = id<sub><em>F</em>(<em>c</em>)</sub>.</li>
<li>Composition is preserved by <em>F</em>, that is, for any objects b,c,d∈Ob(C) and morphisms <em>g</em>: <em>b</em> → <em>c</em> and <em>h</em>: <em>c</em> → <em>d</em>, we have <em>F</em>(<em>h</em> ○ <em>g</em>) = <em>F</em>(<em>h</em>) ○ <em>F</em>(<em>g</em>).</li>
</ol>
<p><em>Example</em> 5.1.2.2 (Monoids have underlying sets). Recall from Definition <a href="chapter004.html#Def_4-1-1-1">4.1.1.1</a> that if M = (<em>M</em>, <em>e</em>, ⋆) is a monoid, then <em>M</em> is a set. And recall from Definition <a href="chapter004.html#Def_4-1-4-1">4.1.4.1</a> that if f:M→M′ is a monoid homomorphism, then <em>f</em>: <em>M</em> → <em>M</em>′ is a function. Thus we can define a functor</p>
<p>U:Mon→Set</p>
<p>The on-objects part of <em>U</em> sends every monoid to its underlying set, U(M)=M, and sends every monoid homomorphism to its underlying function <em>U</em>(<em>f</em>) = <em>f</em>. It is easy to check that the functor laws hold, so <em>U</em> is indeed a functor.</p>
<p>Given two monoids M=(M,e,⋆) and M′=(M′,e′,⋆′), there may be many functions from <em>M</em> to <em>M</em>′ that do not arise from monoid homomorphisms. In other words, U:HomMon(M,M′)→HomSet(M,M′) may not be surjective. It is often useful to speak of such functions. For example, one could assign to every command in one video game <em>V</em> a command in another video game <em>V</em>′, but this may not work in accordance with the monoid laws when performing a sequence of commands. By being able to speak of <em>M</em> as a set or of M as a monoid, and understanding the relationship <em>U</em> between them, we can be clear about where we stand at all times in the discussion.</p>
<p><em>Example</em> 5.1.2.3 (Groups have underlying monoids). Recall that a group is just a monoid (<em>M</em>, <em>e</em>, ⋆) with the extra property that every element <em>m</em> ∈ <em>M</em> has an inverse <em>m</em>′ ⋆ <em>m</em> = <em>e</em> = <em>m</em> ⋆ <em>m</em>′. Thus to every group we can assign its <em>underlying monoid</em>. Similarly, a group homomorphism is just a monoid homomorphism of its underlying monoids. This means that there is a functor</p>
<p>U:Grp→Mon</p>
<p>that sends every group or group homomorphism to its underlying monoid or monoid homomorphism. Identity and composition are preserved.</p>
<p><em>Application</em> 5.1.2.4. Suppose you are a scientist working with symmetries. But then suppose that the symmetry breaks somewhere, or you add some extra observable that is not reversible under the symmetry. You want to seamlessly relax the requirement that every action be reversible without changing anything else. You want to know how you can proceed, or what is allowed. The answer is to simply pass from the category of groups (or group actions) to the category of monoids (or monoid actions).</p>
<p>We can also reverse this change of perspective. Recall that Example <a href="chapter004.html#Exa_4-1-2-9">4.1.2.9</a> discussed a monoid <em>M</em> controlling the actions of a video game character. The character position (<em>P</em>) could be moved up (<em>u</em>), moved down (<em>d</em>), or moved right (<em>r</em>). The path equivalences <em>P.u.d</em> = <em>P</em> and <em>P.d.u</em> = <em>P</em> imply that these two actions are mutually inverse, whereas moving right has no inverse. This, plus equivalences <em>P.r.u</em> = <em>P.u.r</em> and <em>P.r.d</em> = <em>P.d.r</em>, defined a monoid <em>M</em>.</p>
<p>Inside <em>M</em> is a submonoid <em>G</em>, which includes just upward and downward movement. It has one object, just like <em>M</em>, i.e., Ob(<em>M</em>) = {<em>P</em>} = Ob(<em>G</em>). But it has fewer morphisms. In fact, there is a monoid isomorphism <em>G</em> ≅ ℤ because we can assign to any movement in <em>G</em> the number of ups, e.g., <sub><em>P</em></sub>[<em>u</em>, <em>u</em>, <em>u</em>, <em>u</em>, <em>u</em>] is assigned the integer 5, <sub><em>P</em></sub>[<em>d</em>, <em>d</em>, <em>d</em>] is assigned the integer −3, and <sub><em>P</em></sub>[<em>d</em>, <em>u</em>, <em>u</em>, <em>d</em>, <em>d</em>, <em>u</em>] is assigned the integer 0 ∈ ℤ. But ℤ is a group, because every integer has an inverse.</p>
<p>The upshot is that we can use functors to compare groups and monoids.</p>
<p><em>Slogan</em> 5.1.2.5.</p>
<p><em>Out of all our available actions, some are reversible.</em></p>
<p><em>Example</em> 5.1.2.6. Recall that we have a category <strong>Set</strong> of sets and a category <strong>Fin</strong> of finite sets. We said that <strong>Fin</strong> was a subcategory of <strong>Set</strong>. In fact, we can think of this subcategory relationship in terms of functors, just as we thought of the subset relationship in terms of functions in Example <a href="chapter002.html#Exa_2-1-2-4">2.1.2.4</a>. Recall that if we have a subset <em>S</em> ⊆ <em>S</em>′, then every element <em>s</em> ∈ <em>S</em> is an element of <em>S</em>′, so we make a function <em>f</em>: <em>S</em> → <em>S</em>′ such that <em>f</em>(<em>s</em>) = <em>s</em> ∈ <em>S</em>′.</p>
<p>To give a functor <em>i</em>: <strong>Fin</strong> → <strong>Set</strong>, we have to announce how it works on objects and how it works on morphisms. We begin by announcing a function <em>i</em>: Ob(<strong>Fin</strong>) → Ob(<strong>Set</strong>). By analogy with the preceding, we have a subset Ob(<strong>Fin</strong>) ⊆ Ob(<strong>Set</strong>). Hence every element <em>s</em> ∈ Ob(<strong>Fin</strong>) is an element of Ob(<strong>Set</strong>), so we put <em>i</em>(<em>s</em>) = <em>s</em>. We also have to announce, for each pair of objects <em>s</em>, <em>s</em>′ ∈ Ob(<strong>Fin</strong>), a function</p>
<p>i:HomFin(s,s′)→HomSet(s,s′).</p>
<p>But again, that is easy because we know by definition (see Example <a href="chapter005.html#Exa_5-1-1-4">5.1.1.4</a>) that these two sets are equal, Hom<strong><sub>Fin</sub></strong>(<em>s</em>, <em>s</em>′) = Hom<strong><sub>Set</sub></strong>(<em>s</em>, <em>s</em>′). Hence we can simply take <em>i</em> to be the identity function on morphisms. It is evident that identities and compositions are preserved by <em>i</em>. Therefore, we have defined a functor <em>i</em>.</p>
<p><em>Remark</em> 5.1.2.7. Recall that any group is just a monoid, except that it has an extra property: every element has an inverse. Thus one can start with a group, “forget” the fact that it is a group and remember only that it is a monoid. Doing this is functorial—Example <a href="chapter005.html#Exa_5-1-2-3">5.1.2.3</a> discussed it as a functor <em>U</em>: <strong>Grp</strong> → <strong>Mon</strong>. We say that <em>U</em> is a <em>forgetful functor</em>. There is also a forgetful functor <strong>Mon</strong> → <strong>Set</strong> and so <strong>Grp</strong> → <strong>Set</strong>.</p>
<p><em>Slogan</em> 5.1.2.8.</p>
<p><em>You can use a smartphone as a paperweight.</em></p>
<p>Colloquially, people often say things like, “Carol wears many hats” to mean that Carol acts in different roles, even though substantively she is somehow the same. The <em>hat</em> Carol currently wears is the analogous to the category, or context of interaction, that she is currently in.</p>
<p><em>Exercise</em> 5.1.2.9.</p>
<p>A partial order is just a preorder with a special property. A linear order is just a partial order with a special property.</p>
<p>a. Is there a useful functor <strong>FLin</strong> → <strong>PrO</strong>?</p>
<p>b. Is there a useful functor <strong>PrO</strong> → <strong>FLin</strong>?</p>
<p><strong>Proposition 5.1.2.10</strong> (Preorders to graphs). <em>Let</em> <strong>PrO</strong> <em>be the category of preorders and</em> <strong>Grph</strong> <em>be the category of graphs. There is a functor P</em>: <strong>PrO</strong> → <strong>Grph</strong> <em>such that for any preorder</em> X=(X, ⩽), <em>the graph</em> P(X) <em>has vertices X</em>.</p>
<p><em>Proof.</em> Given a preorder X=(X, ⩽X), we can make a graph F(X) with vertices <em>X</em> and an arrow <em>x</em> → <em>x</em>′ whenever <em>x</em> ⩽<em><sub>X</sub> x</em>′, as in Remark <a href="chapter004.html#Rem_4-4-1-10">4.4.1.10</a>. More precisely, the preorder ⩽<em><sub>X</sub></em> is a relation, i.e., a subset RX⊆X×X, which we think of as a function i:RX→X×X. Composing with projections <em>π</em><sub>1</sub>, <em>π</em><sub>2</sub>: <em>X</em> × <em>X</em> → <em>X</em> gives</p>
<p>srcX≔π1○i:RX→XandtgtX≔π2○i:RX→X.</p>
<p>Then we put F(X)≔(X,RX,srcX,tgtX). This gives us a function <em>F</em>: Ob(<strong>PrO</strong>) → Ob(<strong>Grph</strong>).</p>
<p>Suppose now that f:X→Y is a preorder morphism, where Y=(Y, ⩽Y). This is a function <em>f</em>: <em>X</em> → <em>Y</em> such that for any (<em>x</em>, <em>x</em>′) ∈ <em>X</em> ×<em>X</em>, if <em>x</em> ⩽<em><sub>X</sub> x</em>′, then <em>f</em>(<em>x</em>) ⩽ <em>f</em>(<em>x</em>′). But that is the same as saying that there exists a dotted arrow making the following diagram of sets commute</p>
<p><img src="images/Art_P151.jpg" alt="art" /></p>
<p>(Note that there cannot be two different dotted arrows making that diagram commute because RY→Y×Y is a monomorphism.) This commutative square is precisely what is needed for a graph homomorphism, as shown in Exercise <a href="chapter004.html#Exe_4-3-3-7">4.3.3.7</a>. Thus, we have defined <em>F</em> on objects and on morphisms. It is clear that <em>F</em> preserves identity and composition.</p>
<p><em>Exercise</em> 5.1.2.11.</p>
<p>Proposition <a href="chapter005.html#Pro_5-1-2-10">5.1.2.10</a> gave a functor <em>P</em>: <strong>PrO</strong> → <strong>Grph</strong>.</p>
<p>a. Is every graph <em>G</em> ∈ Ob(<strong>Grph</strong>) in the image of <em>P</em> (or more precisely, is the function</p>
<p>Ob(P):Ob(PrO)→Ob(Grph)</p>
<p>surjective)?</p>
<p>b. If so, why; if not, name a graph not in the image.</p>
<p>c. Suppose that <em>G</em>′ and <em>H</em>′ are preorders with graph formats <em>P</em>(<em>G</em>′) = <em>G</em> and <em>P</em>(<em>H</em>′) = <em>H</em>. Is every graph homomorphism <em>f</em>: <em>G</em> → <em>H</em> in the image of</p>
<p>HomP:HomPrO(G′,H′)→HomGrph(G,H)?</p>
<p>In other words, does every graph homomorphism between <em>G</em> and <em>H</em> come from a preorder homomorphism between <em>G</em>′ and <em>H</em>′?</p>
<p><em>Remark</em> 5.1.2.12. There is a functor <em>W</em>: <strong>PrO</strong> → <strong>Set</strong> sending (<em>X</em>, ⩽) to <em>X</em>. There is a functor <em>T</em>: <strong>Grph</strong> → <strong>Set</strong> sending (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) to <em>V</em>. When we study the category of categories (see Section <a href="chapter005.html#lev_5-1-2-30">5.1.2.30</a>), it will be clear that Proposition <a href="chapter005.html#Pro_5-1-2-10">5.1.2.10</a> can be summarized as a commutative triangle in <strong>Cat</strong>,</p>
<p><img src="images/Art_P152.jpg" alt="art" /></p>
<p><em>Exercise</em> 5.1.2.13.</p>
<p>Recall from (<a href="chapter002.html#lev_2-3">2.3</a>) that every function <em>f</em>: <em>A</em> → <em>B</em> has an image, im<em><sub>f</sub></em>(<em>A</em>) ⊆ <em>B</em>. Use this idea and Example <a href="chapter004.html#Exa_4-4-1-16">4.4.1.16</a> to construct a functor <em>Im</em>: <strong>Grph</strong> → <strong>PrO</strong> such that for any graph <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>), the vertices of <em>G</em> are the elements of <em>Im</em>(<em>G</em>). That is, find some ordering ⩽<em><sub>G</sub></em>, such that we have <em>Im</em>(<em>G</em>) = (<em>V</em>, ⩽<em><sub>G</sub></em>).</p>
<p><em>Solution</em> 5.1.2.13.</p>
<p>Suppose given an object <em>G</em> ∈ Ob(<strong>Grph</strong>), i.e., a graph <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>). The source and target functions combine to give a function 〈<em>src</em>, <em>tgt</em>〉: <em>A</em> → <em>V</em> × <em>V</em>. Its image is a subset <em>R</em> ⊆ <em>V</em> × <em>V</em>, i.e., a binary relation. But <em>R</em> is not necessarily a preorder. We can remedy that by using the preorder R¯ generated by <em>R</em>, as in Example <a href="chapter004.html#Exa_4-4-1-16">4.4.1.16</a>. On objects we put <em>Im</em>(<em>G</em>) ≔ R¯. One way to understand this preorder is that it has as elements <em>V</em>, the vertices of <em>G</em>, and it has <em>v</em> ⩽ <em>v</em>′ if and only if there exists a path from <em>v</em> to <em>v</em>′ in <em>G</em>.</p>
<p>Given a morphism <em>f</em>: <em>G</em> → <em>G</em>′, we need to provide a preorder morphism <em>Im</em>(<em>G</em>) → <em>Im</em>(<em>G</em>′). The obvious choice is to use <em>f</em><sub>0</sub> (what <em>f</em> does on vertices), but we need to check that it preserves the order. This is clear because graph morphisms send paths to paths—if there was a path from <em>v</em> to <em>v</em>′ in <em>G</em>, there will be one from <em>f</em>(<em>v</em>) to <em>f</em>(<em>v</em>′). We need to check that <em>Im</em>(id<em><sub>G</sub></em>) = id<sub><em>Im</em>(<em>G</em>)</sub>, but this is straightforward.</p>
<p><em>Exercise</em> 5.1.2.14.</p>
<p>In Exercise <a href="chapter005.html#Exe_5-1-2-13">5.1.2.13</a> you constructed a functor <em>Im</em>: <strong>Grph</strong> → <strong>PrO</strong>. What is the preorder <em>Im</em>(<em>G</em>) when <em>G</em> ∈ Ob(<strong>Grph</strong>) is the following graph?</p>
<p><img src="images/Art_P153.jpg" alt="art" /></p>
<p><em>Exercise</em> 5.1.2.15.</p>
<p>Consider the functor <em>Im</em>: <strong>Grph</strong> → <strong>PrO</strong> constructed in Exercise <a href="chapter005.html#Exe_5-1-2-13">5.1.2.13</a>.</p>
<p>a. Is every preorder X∈Ob(PrO) in the image of <em>Im</em> (or more precisely, in the image of Ob(<em>Im</em>): Ob(<strong>Grph</strong>) → Ob(<strong>PrO</strong>))?</p>
<p>b. If so, why; if not, name a preorder not in the image.</p>
<p>c. Suppose that X′,Y′∈Ob(Grph) are graphs, with X≔Im(X′) and Y≔Im(Y′) in the preorder format. Is every preorder morphism f:X→Y in the image of</p>
<p>HomIm:HomGrph(X′,Y′)→HomPrO(X,Y)?</p>
<p>In other words, does every preorder homomorphism between X and Y come from a graph homomorphism between X′ and Y′?</p>
<p><em>Exercise</em> 5.1.2.16.</p>
<p>We have functors <em>P</em>: <strong>PrO</strong> → <strong>Grph</strong> and <em>Im</em>: <strong>Grph</strong> → <strong>PrO</strong>.</p>
<p>a. What can you say about <em>Im</em> ○ <em>P</em>: <strong>PrO</strong> → <strong>PrO</strong>?</p>
<p>b. What can you say about <em>P</em> ○ <em>Im</em>: <strong>Grph</strong> → <strong>Grph</strong>?</p>
<p><em>Exercise</em> 5.1.2.17.</p>
<p>Consider the functors <em>P</em>: <strong>PrO</strong> → <strong>Grph</strong> and <em>Im</em>: <strong>Grph</strong> → <strong>PrO</strong>. And consider the chain graph [<em>n</em>] of length <em>n</em> from Example <a href="chapter004.html#Exa_4-3-1-8">4.3.1.8</a> and the linear order [<em>n</em>] of length <em>n</em> from Example <a href="chapter004.html#Exa_4-4-1-7">4.4.1.7</a>. To differentiate the two, let’s rename them for this exercise as [<em>n</em>]<strong><sub>Grph</sub></strong> ∈ Ob(<strong>Grph</strong>) and [<em>n</em>]<strong><sub>PrO</sub></strong> ∈ Ob(<strong>PrO</strong>). We see a similarity between [<em>n</em>]<strong><sub>Grph</sub></strong> and [<em>n</em>]<strong><sub>PrO</sub></strong>, and we might hope that the functors help formalize this similarity. That is, we might hope that one of the following hold:</p>
<p>P([ n ]PrO)≅?[ n ]GrphorIm([ n ]Grph)≅?[ n ]PrO.</p>
<p>Do either, both, or neither of these hold?</p>
<p><em>Remark</em> 5.1.2.18. In the course announcement for MIT’s 18-S996 course, I wrote the following:</p>
<p>It is often useful to focus one’s study by viewing an individual thing, or a group of things, as though it exists in isolation. However, the ability to rigorously change our point of view, seeing our object of study in a different context, often yields unexpected insights. Moreover, this ability to change perspective is indispensable for effectively communicating with and learning from others. It is the relationships between things, rather than the things in and by themselves, that are responsible for generating the rich variety of phenomena we observe in the physical, informational, and mathematical worlds.</p>
<p>This holds at many different levels. For example, one can study a group (in the sense of Definition <a href="chapter004.html#Def_4-2-1-1">4.2.1.1</a>) in isolation, trying to understand its subgroups or its automorphisms, and this is mathematically interesting. But one can also view it as a quotient of something else, or as a subgroup of something else. One can view the group as a monoid and look at monoid homomorphisms to or from it. One can look at the group in the context of symmetries by seeing how it acts on sets. These changes of viewpoint are all clearly and formally expressible within category theory. We know how the different changes of viewpoint compose and how they fit together in a larger context.</p>
<p><em>Exercise</em> 5.1.2.19.</p>
<p>a. Is the preceding quotation also true in your scientific discipline of expertise? How so?</p>
<p>b. Can you imagine a way that category theory can help catalogue the kinds of relationships or changes of viewpoint that exist in your discipline?</p>
<p>c. What kinds of structures that you use often deserve to be better formalized?</p>
<p><em>Example</em> 5.1.2.20 (Free monoids). Let <em>G</em> be a set. Definition <a href="chapter004.html#Def_4-1-1-15">4.1.1.15</a> defined a monoid List(<em>G</em>), called the free monoid on <em>G</em>. Given a function <em>f</em>: <em>G</em> → <em>G</em>′, there is an induced function List(<em>f</em>): List(<em>G</em>) → List(<em>G</em>′), and this preserves the identity element [ ] and concatenation of lists, so List(<em>f</em>) is a monoid homomorphism. It is easy to check that List: <strong>Set</strong> → <strong>Mon</strong> is a functor.</p>
<p><em>Application</em> 5.1.2.21. Application <a href="chapter002.html#App_2-1-2-16">2.1.2.16</a> discussed an isomorphism Nuc<sub>DNA</sub> ≅ Nuc<sub>RNA</sub> given by RNA transcription. Applying the functor List, we get a function</p>
<p>List(NucDNA)→≅List(NucRNA),</p>
<p>which will send sequences of DNA nucleotides to sequences of RNA nucleotides, and vice versa. This is performed by polymerases.</p>
<p><em>Exercise</em> 5.1.2.22.</p>
<p>Let <em>G</em> = {1, 2, 3, 4, 5}, <em>G</em>′ = {<em>a</em>, <em>b</em>, <em>c</em>}, and let <em>f</em>: <em>G</em> → <em>G</em>′ be given by the sequence (<em>a</em>, <em>c</em>, <em>b</em>, <em>a</em>, <em>c</em>).<sup><a href="chapter005.html#endnote_5">5</a></sup> Then if <em>L</em> = [1, 1, 3, 5, 4, 5, 3, 2, 4, 1], what is List(<em>f</em>)(<em>L</em>)?</p>
<p><em>Solution</em> 5.1.2.22.</p>
<p>Use <em>f</em> to translate <em>L</em>, entry by entry:</p>
<p>List(f)( [ 1,1,3,5,4,5,3,2,4,1 ]=[ a,a,b,c,a,c,b,c,a,a ].</p>
<p><em>Remark</em> 5.1.2.23 (Questionable functor). Recall from Remark <a href="chapter005.html#Rem_5-1-1-6">5.1.1.6</a> that a questionable category is defined to be a structure that looks like a category (objects, morphisms, identities, composition formula), but which is not required to satisfy any laws. Similarly, given categories (or questionable categories) C and D, we can define a questionable functor <em>F</em>: C → D to consist of</p>
<p>A. a function Ob(F):Ob(C)→Ob(C′), sometimes denoted simply F:Ob(C)→Ob(C′);</p>
<p>B. for every pair of objects <em>c</em>, <em>d</em> ∈ Ob(C), a function</p>
<p>HomF(c,d):HomC(c,d)→HomC′(F(c),F(d)),</p>
<p>sometimes denoted simply F:HomC(c,d)→HomC′(F(c),F(d)).</p>
<p><em>Exercise</em> 5.1.2.24.</p>
<p>We can rephrase the notion of functor in terms compatible with Exercise <a href="chapter005.html#Exe_5-1-1-27">5.1.1.27</a>. We begin by saying that a functor F:C→C′ consists of two functions,</p>
<p>Ob(F):Ob(C)→Ob(C′)andHomF:HomC→HomC′ ,</p>
<p>called the <em>on-objects part</em> and the <em>on-morphisms part</em> respectively. They must follow some rules, expressed by the commutativity of the following squares in <strong>Set</strong>:</p>
<p><img src="images/Art_P154.jpg" alt="art" /></p>
<p><img src="images/Art_P154a.jpg" alt="art" /></p>
<p>a. In the right-hand diagram in (<a href="chapter005.html#eq_5-6">5.6</a>), where does the (unlabeled) left-hand function come from? Hint: Use Exercise <a href="chapter003.html#Exe_3-2-1-20">3.2.1.20</a>.</p>
<p>Consider diagram (<a href="chapter005.html#eq_5-3">5.3</a>); imagine it as though it were contained in a pane of glass. Then imagine a parallel pane of glass involving C′ in place of C everywhere.</p>
<p>b. Draw arrows from the C pane to the C′ pane, each labeled Ob(<em>F</em>), Hom<em><sub>F</sub></em>, and so on, as appropriate.</p>
<p>c. If <em>F</em> is a functor, i.e., it satisfies (<a href="chapter005.html#eq_5-5">5.5</a>) and (<a href="chapter005.html#eq_5-6">5.6</a>), do all the squares in your drawing commute?</p>
<p>d. Does the definition of functor involve anything not captured in this setup?</p>
<p><em>Solution</em> 5.1.2.24.</p>
<p>a. We have Hom<em><sub>F</sub></em>: Hom<em><sub>C</sub></em> → Hom<em><sub>C′</sub></em>, and since it commutes with <em>dom</em> and <em>cod</em>, we have the desired function, by Exercise <a href="chapter003.html#Exe_3-2-1-20">3.2.1.20</a>.</p>
<p>b. Let CPC=HomC×Ob(C)HomC denote the set of composable pairs of arrows in C (and similarly define CPC′ and CPF:CPC→CPC′). The two-pane diagram is a bit cluttered, but looks like this:</p>
<p><img src="images/Art_P155.jpg" alt="art" /></p>
<p>c. Yes.</p>
<p>d. No, this is all one needs: functions Ob(F):Ob(C)→Ob(C′) and HomF: HomC→HomC′ such that all the squares commute.</p>
<p><em>Example</em> 5.1.2.25 (Paths-graph). Let <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) be a graph. We have a set Path<em><sub>G</sub></em> of paths in <em>G</em>, and functions src, ¯tgt¯: PathG→V. That information is enough to define a new graph,</p>
<p>Paths(G)≔(V,PathG,src, ¯tgt¯).</p>
<p>Moreover, given a graph homomorphism <em>f</em>: <em>G</em> → <em>G</em>′, every path in <em>G</em> is sent under <em>f</em> to a path in <em>G</em>′. So Paths: <strong>Grph</strong> → <strong>Grph</strong> is a functor.</p>
<p><em>Exercise</em> 5.1.2.26.</p>
<p>a. Consider the graph <em>G</em> from Example <a href="chapter004.html#Exa_4-3-3-3">4.3.3.3</a>. Draw the paths-graph Paths(<em>G</em>) for <em>G</em>.</p>
<p>b. Repeating part (a) for <em>G</em>′ from the same example would be hard, because the paths-graph Paths(<em>G</em>′) has infinitely many arrows. However, the graph homomorphism <em>f</em>: <em>G</em> → <em>G</em>′ does induce a morphism of paths-graphs Paths(<em>f</em>): Paths(<em>G</em>) → Paths(<em>G</em>′). How does that act on the vertices and arrows of Paths(<em>G</em>)?</p>
<p>c. Given a graph homomorphism <em>f</em>: <em>G</em> → <em>G</em>′ and two paths <em>p</em>: <em>v</em> → <em>w</em> and <em>q</em>: <em>w</em> → <em>x</em> in <em>G</em>, is it true that Paths(<em>f</em>) preserves the concatenation? Explain also what it means to say Paths(<em>f</em>) preserves the concatenation.</p>
<p><em>Solution</em> 5.1.2.26.</p>
<p>a. Here are <em>G</em> and Paths(<em>G</em>).</p>
<p><img src="images/Art_P156.jpg" alt="art" /></p>
<p>b. For the reader’s convenience, here is a copy of <em>f</em>: <em>G</em> → <em>G</em>′:</p>
<p><img src="images/Art_P157.jpg" alt="art" /></p>
<p>By definition Paths(<em>f</em>) acts like <em>f</em> on the vertices, and arrow by arrow on paths. Here is the formal answer:</p>
<p><img src="images/Art_P158.jpg" alt="art" /></p>
<p>c. Yes, that is true. It means that <em>f</em>(<em>p</em>) ++<em>f</em>(<em>q</em>) = <em>f</em>(<em>p</em> ++<em>q</em>), where ++ denotes concatenation of paths.</p>
<p><em>Exercise</em> 5.1.2.27.</p>
<p>Suppose that C and D are categories, <em>c</em>, <em>c</em>′ ∈ Ob(C) are objects, and <em>F</em>: C → D is a functor. Suppose that <em>c</em> and <em>c</em>′ are isomorphic in C. Show that this implies that <em>F</em>(<em>c</em>) and <em>F</em>(<em>c</em>′) are isomorphic in D.</p>
<p><em>Solution</em> 5.1.2.27.</p>
<p>If <em>c</em> and <em>c</em>′ are isomorphic, that means there exists a morphism <em>f</em>: <em>c</em> → <em>c</em>′ and a morphism <em>f</em>′: <em>c</em>′ → <em>c</em> in C, such that <em>f</em>′ ○ <em>f</em> = id<em><sub>c</sub></em> and <em>f</em> ○ <em>f</em>′ = id<em><sub>c′</sub></em>. But then <em>F</em>(<em>f</em>): <em>F</em>(<em>c</em>) → <em>F</em>(<em>c</em>′) and <em>F</em>(<em>f</em>′): <em>F</em>(<em>c</em>′) → <em>F</em>(<em>c</em>) are mutually inverse morphisms between <em>F</em>(<em>c</em>) and <em>F</em>(<em>c</em>′). Indeed, since <em>F</em> preserves composition and identities, we have <em>F</em>(<em>f</em>′) ○ <em>F</em>(<em>f</em>) = <em>F</em>(<em>f</em>′ ○ <em>f</em>) = <em>F</em>(id<em><sub>c</sub></em>) = id<sub><em>F</em>(<em>c</em>)</sub> and <em>F</em>(<em>f</em>) ○ <em>F</em>(<em>f</em>′) = <em>F</em>(<em>f</em> ○ <em>f</em>′) = <em>F</em> (id<em><sub>c′</sub></em>) = id<em><sub>F</sub></em>(<em><sub>c′</sub></em>). So <em>F</em>(<em>f</em>) is an isomorphism, which means that <em>F</em>(<em>c</em>) and <em>F</em>(<em>c</em>′) are isomorphic in D.</p>
<p><em>Example</em> 5.1.2.28. For any graph <em>G</em>, we can assign its set of length 1 loops <em>Eq</em>(<em>G</em>) as in Exercise <a href="chapter004.html#Exe_4-3-1-12">4.3.1.12</a>. This assignment is functorial in that given a graph homomorphism <em>G</em> → <em>G</em>′, there is an induced function <em>Eq</em>(<em>G</em>) → <em>Eq</em>(<em>G</em>′). Similarly, we can functorially assign the set of connected components of the graph, <em>Coeq</em>(<em>G</em>). In other words, <em>Eq</em>: <strong>Grph</strong> → <strong>Set</strong> and <em>Coeq</em>: <strong>Grph</strong> → <strong>Set</strong> are functors. The assignment of vertex set and arrow set are two more functors <strong>Grph</strong> → <strong>Set</strong>.</p>
<p>Suppose you want to decide whether two graphs <em>G</em> and <em>G</em>′ are isomorphic. If the graphs have thousands of vertices and thousands of arrows, this could take a long time. However, the preceding functors, in combination with Exercise <a href="chapter005.html#Exe_5-1-2-27">5.1.2.27</a> give us some things to try.</p>
<p>The first thing to do is to count the number of loops of each, because these numbers are generally small. If the number of loops in <em>G</em> is different than the number of loops in <em>G</em>′, then because functors preserve isomorphisms, <em>G</em> and <em>G</em>′ cannot be isomorphic. Similarly, one can count the number of connected components, again generally a small number. If the number of components in <em>G</em> is different than the number of components in <em>G</em>′, then <em>G</em> ≇ <em>G</em>′. Similarly, one can simply count the number of vertices or the number of arrows in <em>G</em> and <em>G</em>′. These are all isomorphism invariants.</p>
<p>All this is a bit like trying to decide if a number is prime by checking if it is even, if its digits add up to a multiple of 3, or if it ends in a 5; these tests do not determine the answer, but they offer some level of discernment.</p>
<p><em>Remark</em> 5.1.2.29. As mentioned, functors allow ideas in one domain to be rigorously imported to another. Example <a href="chapter005.html#Exa_5-1-2-28">5.1.2.28</a> is a first taste. Because functors preserve isomorphisms, we can tell graphs apart by looking at them in a simpler category, <strong>Set</strong>, using various lenses (in that case, four). There is relatively simple theorem in <strong>Set</strong> that says that for different natural numbers <em>m</em>, <em>n</em> the sets <em>m</em> and <em>n</em> are never isomorphic. This theorem is transported via the four functors to four different theorems about telling graphs apart.</p>
<h3 id="lev_5-1-2-30" class="level3"><strong>5.1.2.30   The category of categories</strong></h3>
<p>Recall from Remark <a href="chapter005.html#Rem_5-1-1-2">5.1.1.2</a> that a small category C is one in which Ob(C) is a set. But everything said so far works whether or not C is small. The following definition gives more precision.</p>
<p><strong>Proposition 5.1.2.31</strong>. <em>There exists a category, called</em> the category of small categories <em>and denoted</em> <strong>Cat</strong>, <em>in which the objects are the small categories and the morphisms are the functors</em>,</p>
<p>HomCat(C,D)={ F:C→D|F is a functor }.</p>
<p><em>That is, there are identity functors, functors can be composed, and the identity and associativity laws hold.</em></p>
<p><em>Proof.</em> We follow Definition <a href="chapter005.html#Def_5-1-1-1">5.1.1.1</a>. We have already specified Ob(<strong>Cat</strong>) and Hom<strong><sub>Cat</sub></strong> in the statement of the proposition. Given a small category C, there is an identity functor idC:C→C that is identity on the set of objects and the set of morphisms. And given a functor F:C→D and a functor G:D→E, it is easy to check that G○F:C→E, defined by composition of functions Ob(G)○Ob(F):Ob(C)→Ob(E) and HomG○HomF:HomC→HomE (see Exercise <a href="chapter005.html#Exe_5-1-2-24">5.1.2.24</a>), is a functor; thus we have a composition formula. For the same reasons, one can show that functors, as morphisms, obey the identity law and the composition law. Therefore, this specification of <strong>Cat</strong> satisfies the definition of being a category.</p>
<p><em>Example</em> 5.1.2.32 (Categories have underlying graphs). Suppose given a category in the notation is as in Exercise <a href="chapter005.html#Exe_5-1-1-27">5.1.1.27</a>, C=(Ob(C),HomC,dom,cod,ids,comp). Then (Ob(C),HomC,dom,cod) is a graph, called the <em>graph underlying</em> C and denoted U(C)∈Ob(Grph). A functor F:C→D induces a graph morphism U(F):U(C)→U(D), as seen in (<a href="chapter005.html#eq_5-5">5.5</a>). So we have a functor,</p>
<p>U: Cat→Grph.</p>
<p><em>Example</em> 5.1.2.33 (Free category on a graph). Example <a href="chapter005.html#Exa_5-1-2-25">5.1.2.25</a> discussed a functor Paths: <strong>Grph</strong> → <strong>Grph</strong> that considered all the paths in a graph <em>G</em> as the arrows of a new graph Paths(<em>G</em>). In fact, Paths(<em>G</em>) could be construed as a category, denoted <em>F</em>(<em>G</em>) ∈ Ob(<strong>Cat</strong>) and called <em>the free category generated by G</em>.</p>
<p>The objects of the category <em>F</em>(<em>G</em>) are the vertices of <em>G</em>. For any two vertices <em>v</em>, <em>v</em>′, the hom-set Hom<em><sub>F</sub></em><sub>(<em>G</em>)</sub>(<em>v</em>, <em>v</em>′) is the set of paths in <em>G</em> from <em>v</em> to <em>v</em>′. The identity elements are given by the trivial paths, and the composition formula is given by concatenation of paths.</p>
<p>For the on-morphisms part of <em>F</em>, we need to see that a graph homomorphism <em>f</em>: <em>G</em> → <em>G</em>′ induces a functor <em>F</em>(<em>f</em>): <em>F</em>(<em>G</em>) → <em>F</em>(<em>G</em>′). But this was shown in Exercise <a href="chapter005.html#Exe_5-1-2-26">5.1.2.26</a>. Thus we have a functor</p>
<p>F: Grph→Cat</p>
<p>called <em>the free category</em> functor.</p>
<p><em>Exercise</em> 5.1.2.34.</p>
<p>Let <em>G</em> be the graph depicted</p>
<p><img src="images/Art_P159.jpg" alt="art" /></p>
<p>and let [1] ∈ Ob(<strong>Cat</strong>) denote the free category on <em>G</em>, i.e., [1] ≔ <em>F</em>(<em>G</em>), as in Example <a href="chapter005.html#Exa_5-1-2-33">5.1.2.33</a>. We call [1] the <em>free arrow category</em>.</p>
<p>a. What are the objects of [1]?</p>
<p>b. For every pair of objects in [1], write the hom-set.</p>
<p><em>Solution</em> 5.1.2.34.</p>
<p>a. Ob([1]) = {<em>v</em><sub>0</sub>, <em>v</em><sub>1</sub>}.</p>
<p>b. There are four pairs of objects, so the four hom-sets are:</p>
<p>Hom[ 1 ](υ0,υ0)={ idυ0 };Hom[ 1 ](υ0,υ1)={ e };Hom[ 1 ](υ1,υ0)=∅;Hom[ 1 ](υ1,υ1)={ idυ1 }.</p>
<p><em>Exercise</em> 5.1.2.35.</p>
<p>Let <em>G</em> be the graph whose vertices are all U.S. cities and whose arrows are airplane flights connecting the cities. What idea is captured by the free category on <em>G</em>?</p>
<p><em>Exercise</em> 5.1.2.36.</p>
<p>Let <em>F</em>: <strong>Grph</strong> → <strong>Cat</strong> denote the free category functor from Example <a href="chapter005.html#Exa_5-1-2-33">5.1.2.33</a>, and let <em>U</em>: <strong>Cat</strong> → <strong>Grph</strong> denote the underlying graph functor from Example <a href="chapter005.html#Exa_5-1-2-32">5.1.2.32</a>. What is the composition <em>U</em> ○ <em>F</em>: <strong>Grph</strong> → <strong>Grph</strong> called?</p>
<p><em>Solution</em> 5.1.2.36.</p>
<p>Since <em>F</em>: <strong>Grph</strong> → <strong>Cat</strong> freely adds all paths, one can check that <em>U</em>○<em>F</em>: <strong>Grph</strong> → <strong>Grph</strong> is the construction that takes a graph and adds all paths; i.e., <em>U</em> ○ <em>F</em> = Paths (see Example <a href="chapter005.html#Exa_5-1-2-25">5.1.2.25</a>).</p>
<p><em>Exercise</em> 5.1.2.37.</p>
<p>Recall the graph <em>G</em> from Example <a href="chapter004.html#Exa_4-3-1-2">4.3.1.2</a>. Let C = <em>F</em>(<em>G</em>) be the free category on <em>G</em>.</p>
<p>a. What is HomC(v,x)?</p>
<p>b. What is HomC(x,v)?</p>
<p><em>Example</em> 5.1.2.38 (Discrete graphs, discrete categories). There is a functor <em>Disc</em>: <strong>Set</strong> → <strong>Grph</strong> that sends a set <em>S</em> to the graph</p>
<p>Disc(S)≔(S,∅,!,!),</p>
<p>where !: ∅ → <em>S</em> is the unique function. We call <em>Disc</em>(<em>S</em>) the <em>discrete graph on the set S</em>. It is clear that a function <em>S</em> → <em>S</em>′ induces a morphism of discrete graphs. Now applying the free category functor <em>F</em>: <strong>Grph</strong> → <strong>Cat</strong>, we get the <em>discrete category on the set S</em>. This composition is also denoted <em>Disc</em>: <strong>Set</strong> → <strong>Cat</strong>.</p>
<p><em>Exercise</em> 5.1.2.39.</p>
<p>Recall from (<a href="chapter002.html#lev_2-4">2.4</a>) the definition of the set <em>n</em> for any natural number <em>n</em> ∈ ℕ, and let <em>D<sub>n</sub></em> ≔ <em>Disc</em>(<em>n</em>) ∈ Ob(<strong>Cat</strong>) be the discrete category on the set <em>n</em>, as in Example <a href="chapter005.html#Exa_5-1-2-38">5.1.2.38</a>.</p>
<p>a. List all the morphisms in <em>D</em><sub>4</sub>.</p>
<p>b. List all the functors <em>D</em><sub>3</sub> → <em>D</em><sub>2</sub>.</p>
<p><em>Exercise</em> 5.1.2.40.</p>
<p>Let C be a category. How many functors are there C → <em>D</em><sub>1</sub>, where <em>D</em><sub>1</sub> ≔ <em>Disc</em>(1) is the discrete category on one element?</p>
<p><em>Solution</em> 5.1.2.40.</p>
<p>There is always one functor C → <em>D</em><sub>1</sub>. There is no choice about where to send objects (all go to the object 1), and there is no choice about where to send morphisms (all go to the morphism id<sub>1</sub>).</p>
<p>We sometimes refer to <em>Disc</em>(1) as the <em>terminal category</em> (see Section <a href="chapter006.html#lev_6-1-3">6.1.3</a>) and for simplicity denote it 1. Its unique object is denoted 1.</p>
<p><em>Exercise</em> 5.1.2.41.</p>
<p>If someone said, “Ob is a functor from <strong>Cat</strong> to <strong>Set</strong>,” what might they mean?</p>
<p><em>Solution</em> 5.1.2.41.</p>
<p>They probably mean that there is a functor <strong>Cat</strong> → <strong>Set</strong> that sends a category C to its set of objects Ob(C). Since the speaker does not say what this functor, Ob, does on morphisms, he is suggesting it is obvious. A morphism in <strong>Cat</strong> is a functor <em>F</em>: C → D, which includes an on-objects part by definition. In other words, it is indeed obvious what Ob(<em>F</em>): Ob(C) → Ob(D) should mean because this is given in the specification of <em>F</em> (see Definition <a href="chapter005.html#Def_5-1-2-1">5.1.2.1</a>). It is not hard to check that Ob preserves identities and compositions, so it is indeed a functor.</p>
<p><em>Exercise</em> 5.1.2.42.</p>
<p>If someone said, “Hom is a functor from <strong>Cat</strong> to <strong>Set</strong>, where by Hom I mean the mapping that takes C to the set HomC, as in Exercise <a href="chapter005.html#Exe_5-1-1-27">5.1.1.27</a>,” what might they mean?</p>
<p><em>Solution</em> 5.1.2.42.</p>
<p>They probably mean that there is a functor <strong>Cat</strong> → <strong>Set</strong> that sends a category C to its set of morphisms HomC. Since the speaker does not indicate what this functor, Hom, does on morphisms, she is suggesting it is obvious. A morphism in <strong>Cat</strong> is a functor F:C→D, which includes an on-morphisms part by definition. In other words, it is indeed obvious what Hom(F):Hom(C)→Hom(D) should mean because this is given in the specification of <em>F</em> (see Definition <a href="chapter005.html#Def_5-1-2-1">5.1.2.1</a>). It is easy to check that Hom preserves identities and compositions, so it is indeed a functor.</p>
<h1 id="lev_5-2" class="level1"><a href="toc.html#Rlev_5-2"><strong>5.2   Common categories and functors from pure math</strong></a></h1>
<h2 id="lev_5-2-1" class="level2"><strong>5.2.1   Monoids, groups, preorders, and graphs</strong></h2>
<p>We saw in Section <a href="chapter005.html#lev_5-1-1">5.1.1</a> that there is a category <strong>Mon</strong> of monoids, a category <strong>Grp</strong> of groups, a category <strong>PrO</strong> of preorders, and a category <strong>Grph</strong> of graphs. This section shows that each monoid M, each group G, and each preorder P can be considered as its own category. If each object in <strong>Mon</strong> is a category, we might hope that each morphism in <strong>Mon</strong> is just a functor, and this is true. The same holds for <strong>Grp</strong> and <strong>PrO</strong>. We saw in Example <a href="chapter005.html#Exa_5-1-2-33">5.1.2.33</a> how each graph can be regarded as giving a free category. Another perspective on graphs (i.e., graphs as functors) is discussed in Section <a href="chapter005.html#lev_5-2-1-21">5.2.1.21</a>.</p>
<h3 id="lev_5-2-1-1" class="level3"><strong>5.2.1.1   Monoids as categories</strong></h3>
<p>Example <a href="chapter004.html#Exa_4-1-2-9">4.1.2.9</a> said that to olog a monoid, one should use only one box. And again Example <a href="chapter004.html#Exa_4-5-3-3">4.5.3.3</a> said that a monoid action could be captured by only one table. These ideas are encapsulated by the understanding that a monoid is perfectly modeled as a category with one object.</p>
<p><strong>Each monoid as a category with one object</strong> Let (<em>M</em>, <em>e</em>, ⋆) be a monoid. We consider it as a category M with one object, Ob(M) = {▲}, and</p>
<p>HomM(▲,▲)≔M.</p>
<p>The identity morphism id<sub>▲</sub> serves as the monoid identity <em>e</em>, and the composition formula</p>
<p>○:HomM(▲,▲)×HomM(▲,▲)→HomM(▲,▲)</p>
<p>is given by ⋆: <em>M</em> × <em>M</em> → <em>M</em>. The associativity and identity laws for the monoid match precisely with the associativity and identity laws for categories.</p>
<p>If a monoid is a category with one object, is there any categorical way of phrasing the notion of monoid homomorphism? Suppose that M = (<em>M</em>, <em>e</em>, ⋆) and M′ = (<em>M</em>′, <em>e</em>′, ⋆′). We know that a monoid homomorphism is a function <em>f</em> : <em>M</em> → <em>M</em>′ such that <em>f</em>(<em>e</em>) = <em>e</em>′ and such that for every pair <em>m</em><sub>0</sub>, <em>m</em><sub>1</sub> ∈ <em>M</em>, we have <em>f</em>(<em>m</em><sub>0</sub> ⋆ <em>m</em><sub>1</sub>) = <em>f</em>(<em>m</em><sub>0</sub>) ⋆′ <em>f</em>(<em>m</em><sub>1</sub>). What is a functor M → M′?</p>
<p><strong>Each monoid homomorphism as a functor between one-object categories</strong> Say that Ob(M) = {▲} and Ob(M′) = {▲′}, and we know that HomM(▲,▲)=M and HomM′(▲′,▲′)=M′. A functor F:M→M′ consists first of a function Ob(M) → Ob(M′), but these sets have only one element each, so there is nothing to say on that front: we must have <em>F</em>(▲) = ▲′. It also consists of a function HomM→hom⁡M′, but that is just a function <em>M</em> → <em>M</em>′. The identity and composition formulas for functors match precisely with the identity and composition formula for monoid homomorphisms. Thus a monoid homomorphism is nothing more than a functor between one-object categories.</p>
<p><em>Slogan</em> 5.2.1.2.</p>
<p><em>A monoid is a category with one object. A monoid homomorphism is just a functor between one-object categories.</em></p>
<p>This is formalized in the following theorem.</p>
<p><strong>Theorem 5.2.1.3</strong>. <em>There is a functor i</em> : <strong>Mon</strong> → <strong>Cat</strong> <em>with the following properties:</em></p>
<ul>
<li><p><em>For every monoid</em> M∈Ob(Mon), <em>the category</em> i(M)∈Ob(Cat) <em>itself has exactly one object,</em></p>
<p>|Ob(i(M)) |=1.</p></li>
<li><p><em>For every pair of monoids</em> M,M′∈Ob(Mon), <em>the function</em></p>
<p>HomMon(M,M′)→≅HomCat(i(M),i(M′)),</p>
<p><em>induced by the functor i, is a bijection.</em></p></li>
</ul>
<p><em>Proof.</em> This is basically the content of the preceding paragraphs. The functor <em>i</em> sends a monoid to the corresponding category with one object and <em>i</em> sends a monoid homomorphism to the corresponding functor. One can check that <em>i</em> preserves identities and compositions.</p>
<p>Theorem <a href="chapter005.html#The_5-2-1-3">5.2.1.3</a> situates the theory of monoids very nicely within the world of categories. But we have other ways of thinking about monoids, namely, their actions on sets. It would greatly strengthen the story if we could subsume monoid actions within category theory also, and we can.</p>
<p><strong>Each monoid action as a set-valued functor</strong> Recall from Definition <a href="chapter004.html#Def_4-1-2-1">4.1.2.1</a> that if (<em>M</em>, <em>e</em>, ⋆) is a monoid, an action consists of a set <em>S</em> and a function <img src="images/Art_P160.jpg" alt="art" /> such that <img src="images/Art_P161.jpg" alt="art" /> and <img src="images/Art_P162.jpg" alt="art" /> for all <em>s</em> ∈ <em>S</em>. How might we relate the notion of monoid actions to the notion of functors? Since monoids act on sets, one idea is to try asking what a functor F:M→Set is; this idea will work.</p>
<p>The monoid-as-category M has only one object, ▲, so <em>F</em> provides one set, <em>S</em> ≔ <em>F</em>(▲) ∈ Ob(<strong>Set</strong>). It also provides a function HomF:HomM(▲,▲)→HomSet(F(▲),F(▲)), or more concisely, a function</p>
<p>HF:M→HomSet(S,S).</p>
<p>By currying (see Proposition <a href="chapter003.html#Pro_3-4-2-3">3.4.2.3</a>), this is the same as a function <img src="images/Art_P163.jpg" alt="art" />. The first monoid action law, that <img src="images/Art_P164.jpg" alt="art" />, becomes the law that functors preserve identities, Hom<em><sub>F</sub></em> (id<sub>▲</sub>) = id<em><sub>S</sub></em>. The other monoid action law is equivalent to the composition law for functors.</p>
<h3 id="lev_5-2-1-4" class="level3"><strong>5.2.1.4   Groups as categories</strong></h3>
<p>A group is just a monoid (<em>M</em>, <em>e</em>, ⋆) in which every element <em>m</em> ∈ <em>M</em> is invertible, meaning there exists some <em>m</em>′ ∈ <em>M</em> with <em>m</em> ⋆ <em>m</em>′ = <em>e</em> = <em>m</em>′ ⋆ <em>m</em>. If a monoid is the same thing as a category M with one object, then a group must be a category with one object and with an additional property having to do with invertibility. The elements of <em>M</em> are the morphisms of the category M, so we need a notion of invertibility for morphisms. Luckily we have such a notion already, namely, isomorphism.</p>
<p><em>Slogan</em> 5.2.1.5.</p>
<p><em>A group is a category G with one object, such that every morphism in G is an isomorphism. A group homomorphism is just a functor between such categories.</em></p>
<p><strong>Theorem 5.2.1.6</strong>. <em>There is a functor i</em> : <strong>Grp</strong> → <strong>Cat</strong> <em>with the following properties:</em></p>
<ul>
<li><em>For every group</em> G∈Ob(Grp), <em>the category</em> i(G)∈Ob(Cat) <em>itself has exactly one object, and every morphism m in</em> i(G) <em>is an isomorphism.</em></li>
<li><p><em>For every pair of groups</em> G,G′∈Ob(Grp), <em>the function</em></p>
<p>HomGrp(G,G′)→≅HomCat(i(G),i(G′)),</p>
<p><em>induced by the functor i, is a bijection.</em></p></li>
</ul>
<p>Just as with monoids, an action of some group (<em>G</em>, <em>e</em>, ⋆) on a set <em>S</em> ∈ Ob(<strong>Set</strong>) is the same thing as a functor G→Set sending the unique object of G to the set <em>S</em>.</p>
<h3 id="lev_5-2-1-7" class="level3"><strong>5.2.1.7   A monoid and a group stationed at each object in any category</strong></h3>
<p>If a monoid is just a category with one object, we can locate monoids in any category C by focusing on one object in C. Similarly for groups.</p>
<p><em>Example</em> 5.2.1.8 (Endomorphism monoid). Let C be a category and x∈Ob(C) an object. Let M=HomC(x,x). Note that for any two elements <em>f</em>, <em>g</em> ∈ <em>M</em>, we have <em>f</em> ○ <em>g</em> : <em>x</em> → <em>x</em> in <em>M</em>. Let M = (<em>M</em>, id<em><sub>x</sub></em>, ○). It is easy to check that M is a monoid; it is called the <em>endomorphism monoid of x in</em> C, denoted End(<em>x</em>).</p>
<p><em>Example</em> 5.2.1.9 (Automorphism group). Let C be a category and x∈Ob(C) an object. Let G={f∈HomC(x,x)|f is an isomorphism}. Let G=(G,idx,○). One can check that G is a group; it is called the <em>automorphism group of x in</em> C denoted Aut(<em>x</em>).</p>
<p><em>Exercise</em> 5.2.1.10.</p>
<p>Let <em>S</em> = {1, 2, 3, 4} ∈ Ob(<strong>Set</strong>).</p>
<p>a. What is the automorphism group Aut(<em>S</em>) of <em>S</em> in <strong>Set</strong>, and how many elements does this group have?</p>
<p>b. What is the endomorphism monoid End(<em>S</em>) of <em>S</em> in <strong>Set</strong>, and how many elements does this monoid have?</p>
<p>c. Recall from Example <a href="chapter005.html#Exa_5-1-2-3">5.1.2.3</a> that every group has an underlying monoid <em>U</em>(<em>G</em>). Is the endomorphism monoid of <em>S</em> the underlying monoid of the automorphism group of <em>S</em>? That is, is it the case that End(<em>S</em>) = <em>U</em>(Aut(<em>S</em>))?</p>
<p><em>Exercise</em> 5.2.1.11.</p>
<p>Consider the following graph <em>G</em>, which has four vertices and eight arrows:</p>
<p><img src="images/Art_P165.jpg" alt="art" /></p>
<p>What is the automorphism group Aut(<em>G</em>) of <em>G</em> ∈ Ob(<strong>Grph</strong>) Hint: Every automorphism of <em>G</em> will induce an automorphism of the set {1, 2, 3, 4}; which ones will preserve the endpoints of arrows?</p>
<p><em>Solution</em> 5.2.1.11.</p>
<p>We use visual perception to guide us. The graph <em>G</em> has the shape of a square. Of the 4! different possible automorphisms of {1, 2, 3, 4}, only those preserving the square shape will be automorphisms of <em>G</em>. The group of automorphisms of <em>G</em> is called the dihedral group of order 8 (see Example <a href="chapter004.html#Exa_4-2-1-4">4.2.1.4</a>). It has eight elements,</p>
<p>{e,r,r2,r3,f,fr,fr2,fr3},</p>
<p>where <em>r</em> means rotate the square clockwise 90°, and <em>f</em> means flip the square horizontally. For example, flipping the square vertically can be obtained by flipping horizontally and then rotating twice: <em>fr</em><sup>2</sup>.</p>
<h3 id="lev_5-2-1-12" class="level3"><strong>5.2.1.12   Preorders as categories</strong></h3>
<p>A preorder (<em>X</em>, ⩽) consists of a set <em>X</em> and a binary relation ⩽ that is reflexive and transitive. We can make from (<em>X</em>, ⩽) ∈ Ob(<strong>PrO</strong>) a category X∈Ob(Cat) as follows. Define Ob(X)=X and for every two objects <em>x</em>, <em>y</em> ∈ <em>X</em>, define</p>
<p>HomX(x,y)={{“x ⩽y”}ifx ⩽y,∅ifx≰y.</p>
<p>To clarify: if <em>x</em> ⩽ <em>y</em>, we assign HomX(x,y) to be the set containing only one element, namely, the string “<em>x</em> ⩽ <em>y</em>.”<sup><a href="chapter005.html#endnote_6">6</a></sup> If the pair (<em>x</em>, <em>y</em>) is not in relation ⩽, then we assign HomX(x,y) to be the empty set. The composition formula</p>
<p>○:HomX(x,y)×HomX(y,z)→HomX(x,z)(5.7)</p>
<p>is completely determined because either one of two possibilities occurs. One possibility is that the left-hand side is empty (if either <em>x</em> ≰ <em>y</em> or <em>y</em> ≰ <em>z</em>; in this case there is a unique function ○ as in (<a href="chapter005.html#eq_5-7">5.7</a>)). The other possibility is that the left-hand side is not empty in case <em>x</em> ⩽ <em>y</em> and <em>y</em> ⩽ <em>z</em>, which implies <em>x</em> ⩽ <em>z</em>, so the right-hand side has exactly one element “<em>x</em> ⩽ <em>z</em>” in which case again there is a unique function ○ as in (<a href="chapter005.html#eq_5-7">5.7</a>).</p>
<p>On the other hand, if C is a category having the property that for every pair of objects x,y∈Ob(C), the set HomC(x,y) is either empty or has one element, then we can form a preorder out of C. Namely, take X=Ob(C) and say <em>x</em> ⩽ <em>y</em> if there exists a morphism <em>x</em> → <em>y</em> in C.</p>
<p><strong>Proposition 5.2.1.13</strong>. <em>There is a functor i</em>: <strong>PrO</strong> → <strong>Cat</strong> <em>with the following properties for every preorder</em> (<em>X</em>, ⩽)<em>:</em></p>
<ol>
<li><em>the category</em> X≔i(X, ⩽) <em>has objects</em> Ob(X)=X.</li>
<li><em>For each pair of elements</em> x,x′∈Ob(X), <em>the set</em> HomX(x,x′) <em>has at most one element</em>.</li>
</ol>
<p><em>Moreover, any category with property</em> 2 <em>is in the image of the functor i</em>.</p>
<p><em>Proof</em>. To specify a functor <em>i</em> : <strong>PrO</strong> → <strong>Cat</strong>, we need to say what it does on objects and on morphisms. To an object (<em>X</em>, ⩽) in <strong>PrO</strong>, we assign the category X with objects <em>X</em> and a unique morphism <em>x</em> → <em>x</em>′ if <em>x</em> ⩽ <em>x</em>′. To a morphism <em>f</em> : (<em>X</em>, ⩽<em><sub>X</sub></em>) → (<em>Y</em>, ⩽<em><sub>Y</sub></em>) of preorders, we must assign a functor i(f):X→Y. Again, to specify a functor, we need to say what it does on objects and morphisms of X. To an object x∈Ob(X)=X, we assign the object f(x)∈Y=Ob(Y). Given a morphism <em>f</em> : <em>x</em> → <em>x</em>′ in X, we know that <em>x</em> ⩽ <em>x</em>′, so by Definition <a href="chapter004.html#Def_4-4-4-1">4.4.4.1</a> we have that <em>f</em>(<em>x</em>) ⩽ <em>f</em>(<em>x</em>′), and we assign to <em>f</em> the unique morphism <em>f</em>(<em>x</em>) → <em>f</em>(<em>x</em>′) in Y. To check that the rules of functors (preservation of identities and composition) are obeyed is routine.</p>
<p><em>Slogan</em> 5.2.1.14.</p>
<p><em>A preorder is a category in which every hom-set has either 0 elements or 1 element. A preorder morphism is just a functor between such categories</em>.</p>
<p><em>Exercise</em> 5.2.1.15.</p>
<p>Suppose that C is a preorder (considered as a category). Let x,y∈Ob(C) be objects such that <em>x</em> ⩽ <em>y</em> and <em>y</em> ⩽ <em>x</em>. Prove that there is an isomorphism <em>x</em> → <em>y</em> in C.</p>
<p><em>Exercise</em> 5.2.1.16.</p>
<p>Proposition <a href="chapter005.html#Pro_5-2-1-13">5.2.1.13</a> stated that a preorder can be considered as a category P. Recall from Definition <a href="chapter004.html#Def_4-4-1-1">4.4.1.1</a> that a partial order is a preorder with an additional property. Phrase the defining property for partial orders in terms of isomorphisms in the category P.</p>
<p><em>Example</em> 5.2.1.17. The olog from Example <a href="chapter004.html#Exa_4-4-1-3">4.4.1.3</a> depicted a partial order, call it P. In it we have</p>
<p>HomP(⌜a diamond⌝,⌜a red card⌝)={is}</p>
<p>and</p>
<p>HomP(⌜a black queen⌝,⌜a card⌝)≅{is○is}.</p>
<p>Both of these sets contain exactly one element; the name is not important. The set HomP(⌜a 4⌝,⌜a 4 of diamonds⌝)=∅.</p>
<p><em>Exercise</em> 5.2.1.18.</p>
<p>Every linear order is a preorder with a special property. Using the categorical interpretation of preorders, can you phrase the property of being a linear order in terms of hom-sets?</p>
<p><em>Exercise</em> 5.2.1.19.</p>
<p>Recall the functor <em>P</em> : <strong>PrO</strong> → <strong>Grph</strong> from Proposition <a href="chapter005.html#Pro_5-1-2-10">5.1.2.10</a>, the functors <em>F</em> : <strong>Grph</strong> → <strong>Cat</strong> and <em>U</em> : <strong>Cat</strong> → <strong>Grph</strong> from Example <a href="chapter005.html#Exe_5-1-2-36">5.1.2.36</a>, and the functor <em>i</em>: <strong>PrO</strong> → <strong>Cat</strong> from Proposition <a href="chapter005.html#Pro_5-2-1-13">5.2.1.13</a>.</p>
<p>a. Do either of the following diagrams of categories commute?</p>
<p><img src="images/Art_P166.jpg" alt="art" /></p>
<p>b. We also gave a functor <em>Im</em>: <strong>Grph</strong> → <strong>PrO</strong> in Exercise <a href="chapter005.html#Exe_5-1-2-13">5.1.2.13</a>. Does the following diagram of categories commute?</p>
<p><img src="images/Art_P167.jpg" alt="art" /></p>
<p><strong>Proposition 5.2.1.20</strong>. <em>There is a unique functor R</em>: <strong>Cat</strong> → <strong>PrO</strong> <em>with the following properties:</em></p>
<ol>
<li><em>For each category</em> C, <em>the preorder</em> (X, ⩽)≔R(C) <em>has the same set of objects</em>, X=Ob(C).</li>
<li><em>For each pair of objects</em> x,y∈Ob(C), <em>we have x</em> ⩽ <em>y in R</em>(<em>C</em>) <em>if and only if the hom-set</em> HomC(x,y)≠∅ <em>is nonempty</em>.</li>
</ol>
<p><em>Furthermore, if i</em>: <strong>PrO</strong> → <strong>Cat</strong> <em>is the inclusion from Proposition</em> <a href="chapter005.html#Pro_5-2-1-13">5.2.1.13</a>, <em>we have R</em> ○ <em>i</em> = id<strong><sub>PrO</sub></strong>.</p>
<p><em>Proof</em>. Given a category C, we define a preorder R(C)≔(Ob(C), ⩽), where <em>x</em> ⩽ <em>y</em> if and only if HomC(x,y)≠∅. This is indeed a preorder because the identity law and composition law for a category ensure the reflexivity and transitivity properties of preorders hold. Given a functor F:C→D (i.e., a morphism in <strong>Cat</strong>), we get Ob(F):Ob(C)→Ob(C′), and for <em>R</em> to be defined on morphisms, we need to check that this function preserves order. If <em>x</em> ⩽ <em>y</em> in R(C), then there is a morphism <em>g</em> : <em>x</em> → <em>y</em> in C, so there is a morphism <em>F</em>(<em>g</em>) : <em>F</em>(<em>x</em>) → <em>F</em>(<em>y</em>), which means <em>F</em>(<em>x</em>) ⩽ <em>F</em>(<em>y</em>) in C′. It is straightforward to see now that <em>R</em> is a functor, and there was no other way to construct <em>R</em> satisfying the desired properties. It is also easy to see that <em>R</em> ○ <em>i</em> = id<strong><sub>PrO</sub></strong>.</p>
<h3 id="lev_5-2-1-21" class="level3"><strong>5.2.1.21   Graphs as functors</strong></h3>
<p>Let C denote the category depicted as follows:</p>
<p><img src="images/Art_P168.jpg" alt="art" /></p>
<p>Then a functor <em>G</em> : <strong>GrIn</strong> → <strong>Set</strong> is the same thing as two sets <em>G</em>(<em>Ar</em>), <em>G</em>(<em>Ve</em>) and two functions <em>G</em>(<em>src</em>) : <em>G</em>(<em>Ar</em>) → <em>G</em>(<em>Ve</em>) and <em>G</em>(<em>tgt</em>) : <em>G</em>(<em>Ar</em>) → <em>G</em>(<em>Ve</em>). This is precisely what is needed for a graph; see Definition <a href="chapter004.html#Def_4-3-1-1">4.3.1.1</a>. We call <strong>GrIn</strong> the <em>graph-indexing category</em>.</p>
<p><em>Exercise</em> 5.2.1.22.</p>
<p>Consider the terminal category, 1, also known as the discrete category on one element (see Exercise <a href="chapter005.html#Exe_5-1-2-40">5.1.2.40</a>). Let <strong>GrIn</strong> be as in (<a href="chapter005.html#eq_5-8">5.8</a>) and consider the functor <em>i</em><sub>0</sub> : 1 → <strong>GrIn</strong> sending the unique object of 1 to the object <em>V e</em> ∈ Ob(<strong>GrIn</strong>).</p>
<p>a. If <em>G</em> : <strong>GrIn</strong> → <strong>Set</strong> is a graph, what is the composite <em>G</em> ○ <em>i</em><sub>0</sub>? It consists of only one set; in terms of the graph <em>G</em>, what set is it?</p>
<p>b. As an example, what set is it when <em>G</em> is the graph from Example <a href="chapter004.html#Exa_4-3-3-3">4.3.3.3</a>?</p>
<p>If a graph is a functor <strong>GrIn</strong> → <strong>Set</strong>, what is a graph homomorphism? Example <a href="chapter005.html#Exa_5-3-1-20">5.3.1.20</a> shows that graph homomorphisms are homomorphisms between functors, which are called natural transformations. (Natural transformations are the highest-level structure in ordinary category theory.)</p>
<p><em>Example</em> 5.2.1.23. Let <strong>SGrIn</strong> be the category depicted as follows:</p>
<p><img src="images/Art_P169.jpg" alt="art" /></p>
<p>with the following composition formula:</p>
<p>ρ○ρ=idA;  src○ρ=tgt;  and tgt○ρ=src.</p>
<p>The idea here is that the morphism <em>ρ</em>: <em>A</em> → <em>A</em> reverses arrows. The PED <sub><em>A</em></sub>[<em>ρ</em>, <em>ρ</em>] = <em><sub>A</sub></em>[ ] forces the fact that the reverse of the reverse of an arrow yields the original arrow. The PEDs <sub><em>A</em></sub>[<em>ρ</em>, <em>src</em>] = <sub><em>A</em></sub>[<em>tgt</em>] and <sub><em>A</em></sub>[<em>ρ</em>, <em>tgt</em>] = <sub><em>A</em></sub>[<em>src</em>] force the fact that when we reverse an arrow, its source and target switch roles.</p>
<p>This category <strong>SGrIn</strong> is the <em>symmetric graph-indexing category</em>. Just as any graph can be understood as a functor <strong>GrIn</strong> → <strong>Set</strong>, where <strong>GrIn</strong> is the graph-indexing category displayed in (<a href="chapter005.html#eq_5-8">5.8</a>), any symmetric graph can be understood as a functor <strong>SGrIn</strong> → <strong>Set</strong>, where <strong>SGrIn</strong> is the category drawn in (<a href="chapter005.html#eq_5-9">5.9</a>). Given a functor <em>G</em> : <strong>SGrIn</strong> → <strong>Set</strong>, we will have a set of arrows, a set of vertices, a source operation, a target operation, and a reverse-direction operation (<em>ρ</em>) that all behave as expected.</p>
<p>It is customary to draw the connections in a symmetric graph <em>G</em> as line segments rather than arrows between vertices. However, a better heuristic is to think that each connection between vertices in <em>G</em> consists of two arrows, one pointing in each direction.</p>
<p><em>Slogan</em> 5.2.1.24.</p>
<p><em>In a symmetric graph, every arrow has an equal and opposite arrow</em>.</p>
<p><em>Exercise</em> 5.2.1.25.</p>
<p>Which of the following graphs are symmetric:</p>
<p>a. The graph <em>G</em> from (4.3)?</p>
<p>b. The graph <em>G</em> from Exercise <a href="chapter004.html#Exe_4-3-1-10">4.3.1.10</a>?</p>
<p>c. The graph <em>G</em>′ from (4.6)?</p>
<p>d. The graph Loop from (4.16), i.e., the graph having exactly one vertex and one arrow?</p>
<p>e. The graph <em>G</em> from Exercise <a href="chapter005.html#Exe_5-2-1-11">5.2.1.11</a>?</p>
<p><em>Exercise</em> 5.2.1.26.</p>
<p>Let <strong>GrIn</strong> be the graph-indexing category shown in (<a href="chapter005.html#eq_5-8">5.8</a>), and let <strong>SGrIn</strong> be the symmetric graph-indexing category displayed in (<a href="chapter005.html#eq_5-9">5.9</a>).</p>
<p>a. How many functors are there of the form <strong>GrIn</strong> → <strong>SGrIn</strong>?</p>
<p>b. Is one more reasonable than the others? If so, call it <em>i</em> : <strong>GrIn</strong> → <strong>SGrIn</strong>, and write how it acts on objects and morphisms.</p>
<p>c. Choose a functor <em>i</em> : <strong>GrIn</strong> → <strong>SGrIn</strong>, the most reasonable one, if such a thing exists. seems most reasonable and call it <em>i</em> : <strong>GrIn</strong> → <strong>SGrIn</strong>. If a symmetric graph is a functor <em>S</em> : <strong>SGrIn</strong> → <strong>Set</strong>, you can compose with <em>i</em> to get a functor <em>S</em> ○ <em>i</em> : <strong>GrIn</strong> → <strong>Set</strong>. This is a graph; what graph is it? What has changed?</p>
<p><em>Example</em> 5.2.1.27. Let C be a category, and consider the set of isomorphisms in C. Each isomorphism <em>f</em> : <em>c</em> → <em>c</em>′ in C has an inverse as well as a domain (<em>c</em>) and a codomain (<em>c</em>′). Thus we can build a symmetric graph I(C):SGrIn→Set. Its vertices are the objects in C, and its arrows are the isomorphisms in C.</p>
<h2 id="lev_5-2-2" class="level2"><strong>5.2.2   Database schemas present categories</strong></h2>
<p>Recall from Definition <a href="chapter004.html#Def_4-5-2-7">4.5.2.7</a> that a database schema (or schema, for short) consists of a graph together with a certain kind of equivalence relation, namely a congruence, on its paths. Section <a href="chapter005.html#lev_5-4-1">5.4.1</a> defines a category <strong>Sch</strong> that has schemas as objects and appropriately modified graph homomorphisms as morphisms. Section <a href="chapter005.html#lev_5-4-2">5.4.2</a> proves that the category of schemas is equivalent (in the sense of Definition <a href="chapter005.html#Def_5-3-4-1">5.3.4.1</a>) to the category of categories,</p>
<p>Sch≃Cat.</p>
<p>The difference between schemas and categories is like the difference between monoid presentations, given by generators and relations as in Definition <a href="chapter004.html#Def_4-1-1-19">4.1.1.19</a>, and the monoids themselves. The same monoid has (infinitely) many different presentations, and so it is for categories: many different schemas can <em>present</em> the same category. Computer scientists may think of the schema as <em>syntax</em> and the category it presents as the corresponding <em>semantics</em>. A schema is a compact form and can be specified in finite space and time, whereas the category it generates can be infinite.</p>
<p><em>Slogan</em> 5.2.2.1.</p>
<p><em>A database schema is a category presentation</em>.</p>
<p>Section <a href="chapter005.html#lev_5-4-2">5.4.2</a> formally shows how to turn a schema into a category (the category it <em>presents</em>). For now, it seems better not to be so formal, because the idea is fairly straightforward. Suppose given a schema S, which consists of a graph <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) equipped with a congruence ~ (see Definition <a href="chapter004.html#Def_4-5-2-3">4.5.2.3</a>). It presents a category C defined as follows. The set of objects in C is defined to be the vertices <em>V</em>; the set of morphisms in C is defined to be the quotient Paths(<em>G</em>)/ ~; and the composition formula is given by concatenation of paths. The path equivalences making up ~ become commutative diagrams in C.</p>
<p><em>Example</em> 5.2.2.2. The following schema Loop has no path equivalence declarations. As a graph it has one vertex and one arrow.</p>
<p><img src="images/Art_P170.jpg" alt="art" /></p>
<p>The category it generates, however, is the free monoid on one generator, ℕ. It has one object <em>s</em>, but a morphism <em>f<sup>n</sup></em> : <em>s</em> → <em>s</em> for every natural number <em>n</em> ∈ ℕ, thought of as “how many times to go around the loop <em>f</em>.” Clearly, the schema is more compact than the infinite category it generates.</p>
<p><em>Exercise</em> 5.2.2.3.</p>
<p>Consider the olog from Exercise <a href="chapter004.html#Exe_4-5-2-19">4.5.2.19</a>, which says that for any father <em>x</em>, his youngest child’s father is <em>x</em> and his tallest child’s father is <em>x</em>. It is redrawn here as a schema S, which includes the desired path equivalence declarations, <sub><em>F</em></sub>[<em>t</em>, <em>f</em>] = <em><sub>F</sub></em> [ ] and <sub><em>F</em></sub>[<em>y</em>, <em>f</em>] = <em><sub>F</sub></em> [ ].</p>
<p><img src="images/Art_P171.jpg" alt="art" /></p>
<p>How many morphisms are there (total) in the category presented by S?</p>
<p><em>Solution</em> 5.2.2.3.</p>
<p>There are seven. Let S¯ be the category presented by S. We have</p>
<p>HomS¯(F,F)={F[]};  HomS¯(F,C)={F[t], F[y]};HomS¯(C,F)={C[f]};  HomS¯(C,C)={C[], C[f,t], C[f,y]}.</p>
<p>Given a child, the three morphisms <em>C</em> → <em>C</em> respectively return the child herself, her tallest sibling (technically, her father’s tallest child), and her youngest sibling (technically, her father’s youngest child).</p>
<p><em>Exercise</em> 5.2.2.4.</p>
<p>Suppose that <em>G</em> is a graph and that G is the schema generated by <em>G</em> with no PEDs. What is the relationship between the category generated by G and the free category <em>F</em>(<em>G</em>) ∈ Ob(<strong>Cat</strong>), as defined in Example <a href="chapter005.html#Exa_5-1-2-33">5.1.2.33</a>?</p>
<p><em>Exercise</em> 5.2.2.5.</p>
<p>Let C=(G,≃) be a schema. A leaf table is an object c∈Ob(C) with no outgoing arrows.</p>
<p>a. Express the condition of being a leaf table mathematically in three different languages: that of graphs (using symbols <em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>), that of categories (using HomC, etc.), and that of tables (in terms of columns, tables, rows, etc.).</p>
<p>b. In the language of categories, is there a difference between a terminal object and a leaf table? Explain.</p>
<h3 id="lev_5-2-2-6" class="level3"><strong>5.2.2.6   Instances on a schema</strong> C</h3>
<p>If schemas are like categories, what are instances? Recall that an instance <em>I</em> on a schema S=(G,≃) assigns to each vertex <em>v</em> in <em>G</em> a set of rows, say, <em>I</em>(<em>v</em>) ∈ Ob(<strong>Set</strong>). And to every arrow <em>a</em> : <em>v</em> → <em>v</em>′ in <em>G</em> the instance assigns a function <em>I</em>(<em>a</em>): <em>I</em>(<em>v</em>) → <em>I</em>(<em>v</em>′). The rule is that given two equivalent paths, their compositions must give the same function. Concisely, an instance is a functor I:S→Set.</p>
<p><em>Example</em> 5.2.2.7. We have seen that a monoid is just a category M with one object and that a monoid action is a functor M → <strong>Set</strong>. With database schemas as categories, M is a schema, and so an action becomes an instance of that schema. The monoid action table from Example <a href="chapter004.html#Exa_4-1-3-1">4.1.3.1</a> was simply a manifestation of the database instance according to the Rules <a href="chapter004.html#rul_4-5-2-9">4.5.2.9</a>.</p>
<p><em>Exercise</em> 5.2.2.8.</p>
<p>Section <a href="chapter005.html#lev_5-2-1-21">5.2.1.21</a> discussed how each graph is a functor <strong>GrIn</strong> → <strong>Set</strong> for the graph-indexing category depicted here:</p>
<p><img src="images/Art_P172.jpg" alt="art" /></p>
<p>But now we know that if a graph is a set-valued functor, then we can consider <strong>GrIn</strong> as a database schema.</p>
<p>a. How many tables, and how many foreign key columns of each should there be (if unsure, consult Rules <a href="chapter004.html#rul_4-5-2-9">4.5.2.9</a>)?</p>
<p>b. Write the table view of graph <em>G</em> from Example <a href="chapter004.html#Exa_4-3-3-3">4.3.3.3</a>.</p>
<h2 id="lev_5-2-3" class="level2"><strong>5.2.3   Spaces</strong></h2>
<p>Category theory was invented for use in algebraic topology, and in particular, to discuss natural transformations between certain functors. Section <a href="chapter005.html#lev_5-3">5.3</a> discusses natural transformations more formally. It suffices now to say a natural transformation is some kind of morphism between functors. In the original use, Eilenberg and Mac Lane were interested in functors that connect topological spaces (e.g., shapes such as spheres) to algebraic systems (e.g., groups).</p>
<p>For example, there is a functor that assigns to each space <em>X</em> its group <em>π</em><sub>1</sub>(<em>X</em>) of round-trip voyages (starting and ending at some chosen point <em>x</em> ∈ <em>X</em>), modulo some equivalence relation. There is another functor that assigns to every space its group <em>H</em>ℤ<sub>1</sub>(<em>X</em>) of ways to drop some (positive or negative) number of circles on <em>X</em>.</p>
<p>These two functors, <em>π</em><sub>1</sub> and <em>H</em>ℤ<sub>1</sub> are related, but they are not equal. For example, when <em>X</em> is the figure-8 space (two circles joined at a point) the group <em>π</em><sub>1</sub>(<em>X</em>) is much bigger than the group <em>H</em>ℤ<sub>1</sub>(<em>X</em>). Indeed, <em>π</em><sub>1</sub>(<em>X</em>) includes information about the order and direction of loops traveled during the voyage, whereas the group <em>H</em>ℤ<sub>1</sub>(<em>X</em>) includes only information about how many times one goes around each loop. However, there is a natural transformation of functors <em>π</em><sub>1</sub> → <em>H</em>ℤ<sub>1</sub>, called the Hurewicz transformation, which takes <em>π</em><sub>1</sub>’s voyage, counts how many times it went around each loop, and delivers that information to <em>H</em>ℤ<sub>1</sub>.</p>
<p><em>Example</em> 5.2.3.1. Given a set <em>X</em>, recall that ℙ(<em>X</em>) denotes the preorder of subsets of <em>X</em>. A <em>topology</em> on <em>X</em> is a choice of which subsets <em>U</em> ∈ ℙ(<em>X</em>) will be called <em>open sets</em>. To be a topology, these open sets must follow two rules. Namely, the union of any number of open sets must be considered to be an open set, and the intersection of any finite number of open sets must be considered open. One could say succinctly that a topology on <em>X</em> is a suborder Open(<em>X</em>) ⊆ ℙ(<em>X</em>) that is closed under taking finite meets and infinite joins.</p>
<p>A <em>topological space</em> is a pair (<em>X</em>, Open(<em>X</em>)), where <em>X</em> is a set and Open(<em>X</em>) is a topology on <em>X</em>. The elements of the set <em>X</em> are called <em>points</em>. A <em>morphism of topological spaces</em> (also called a <em>continuous map</em>) is a function <em>f</em> : <em>X</em> → <em>Y</em> such that for every <em>V</em> ∈ Open(<em>Y</em>), the preimage <em>f</em><sup>−1</sup>(<em>V</em>) ∈ ℙ(<em>X</em>) is actually in Open(<em>X</em>), that is, such that there exists a dashed arrow making the following diagram commute:</p>
<p><img src="images/Art_P173.jpg" alt="art" /></p>
<p>The <em>category of topological spaces</em>, denoted <strong>Top</strong>, is the category having the preceding objects and morphisms.</p>
<p><em>Exercise</em> 5.2.3.2.</p>
<p>a. Explain how looking at points gives a functor <strong>Top</strong> → <strong>Set</strong>.</p>
<p>b. Does looking at open sets give a functor <strong>Top</strong> → <strong>PrO</strong>?</p>
<p><em>Solution</em> 5.2.3.2.</p>
<p>a. A topological space (<em>X</em>, Open(<em>X</em>)) includes a set <em>X</em> ∈ Ob(<strong>Set</strong>) of points. A morphism (<em>X</em>, Open(<em>X</em>)) → (<em>Y</em>, Open(<em>Y</em>)) of spaces includes a function <em>X</em> → <em>Y</em> . Thus we have a functor <strong>Top</strong> → <strong>Set</strong>, because the identity morphisms and compositions of morphisms in <strong>Top</strong> are sent to their counterparts in <strong>Set</strong>.</p>
<p>b. No. A morphism (<em>X</em>, Open(<em>X</em>)) → (<em>Y</em>, Open(<em>Y</em>)) includes a preorder morphism in the direction Open(<em>Y</em>) → Open(<em>X</em>), not the other way around. Definition <a href="chapter006.html#Def_6-2-1-1">6.2.1.1</a> shows that every category C has an opposite category Cop. Looking at open sets does give a functor Open: <strong>Top</strong><sup>op</sup> → <strong>PrO</strong>.</p>
<p><em>Example</em> 5.2.3.3 (Continuous dynamical systems). The set ℝ can be given a topology in a standard way.<sup><a href="chapter005.html#endnote_7">7</a></sup> But (ℝ, 0, +) is also a monoid. Moreover, for every <em>x</em> ∈ ℝ, the monoid operation + : ℝ × ℝ → ℝ is continuous.<sup><a href="chapter005.html#endnote_8">8</a></sup> So we say that R≔(ℝ,0,+) is a <em>topological monoid</em>, or that it is a monoid <em>enriched in topological spaces</em>.</p>
<p>Recall from Section <a href="chapter005.html#lev_5-2-1-1">5.2.1.1</a> that an action of R is a functor R→Set. Imagine a functor <em>a</em> : R→Top. Since R is a category with one object, this amounts to an object <em>X</em> ∈ Ob(<strong>Top</strong>), a space. And for every real number <em>t</em> ∈ ℝ, we obtain a continuous map <em>a</em>(<em>t</em>): <em>X</em> → <em>X</em>. Further we can ask this <em>a</em>(<em>t</em>) to vary continuously as <em>t</em> moves around in ℝ. If we consider <em>X</em> as the set of states of some system and ℝ as the time line, we have modeled what is called a <em>continuous dynamical system</em>.</p>
<p><em>Example</em> 5.2.3.4. Recall (see Axler [3]) that a <em>real vector space</em> is a set <em>X</em>, elements of which are called <em>vectors</em>, which is closed under addition and scalar multiplication. For example, ℝ<sup>3</sup> is a vector space. A <em>linear transformation f from X to Y</em> is a function <em>f</em> : <em>X</em> → <em>Y</em> that appropriately preserves addition and scalar multiplication. The <em>category of real vector spaces</em>, denoted <strong>Vect</strong><sub>ℝ</sub>, has as objects the real vector spaces and as morphisms the linear transformations.</p>
<p>There is a functor <strong>Vect</strong><sub>ℝ</sub> → <strong>Grp</strong> sending a vector space to its underlying group of vectors, where the group operation is addition of vectors and the group identity is the 0-vector.</p>
<p><em>Exercise</em> 5.2.3.5.</p>
<p>Every vector space has vector subspaces, ordered by inclusion (the origin is inside of any line that is inside of certain planes, and all are inside of the whole space <em>V</em>). If you know about this topic, answer the following questions.</p>
<p>a. Does a linear transformation <em>V</em> → <em>V</em>′ induce a morphism of these orders? In other words, is there a functor subspaces: <strong>Vect</strong><sub>ℝ</sub> → <strong>PrO</strong>?</p>
<p>b. Would you guess that there is a nice functor <strong>Vect</strong><sub>ℝ</sub> → <strong>Top</strong>? By “nice functor” I mean a substantive one. For example, there is a functor <strong>Vect</strong><sub>ℝ</sub> → <strong>Top</strong> that sends every vector space to the empty topological space; if someone asked for a functor <strong>Vect</strong><sub>ℝ</sub> → <strong>Top</strong> for their birthday, this functor would make them sad. Give a functor <strong>Vect</strong><sub>ℝ</sub> → <strong>Top</strong> that would make them happy.</p>
<p>There is a functor | · |: <strong>Vect</strong><sub>ℝ</sub> → <strong>Set</strong> sending every vector space <em>X</em> to its set |<em>X</em>| of vectors. A categorically nice way to understand this functor is as HomVectℝ(ℝ,−), which sends <em>X</em> to the set of linear transformations ℝ → <em>X</em>. Each linear transformation ℝ → <em>X</em> is completely determined by where it sends 1 ∈ ℝ, which can be any vector in <em>X</em>. Thus we get the bijection | X |≅HomVectℝ(ℝ,X).</p>
<p><em>Exercise</em> 5.2.3.6.</p>
<p>Suppose we think of <strong>Vect</strong><sub>ℝ</sub> as a database schema, and we think of | · |: <strong>Vect</strong><sub>ℝ</sub> → <strong>Set</strong> as an instance (see Section <a href="chapter004.html#lev_4-5">4.5</a>). Of course, the schema and the instance are both infinite, but let’s not worry about that.</p>
<p>a. Pick two objects <em>x</em>, <em>y</em> and two morphisms <em>f</em>, <em>g</em> : <em>x</em> → <em>y</em> from <strong>Vect</strong><sub>ℝ</sub>, actual vector spaces and linear transformations, and call this your subschema. Draw it as dots and arrows.</p>
<p>b. Write four rows in each table of the instance | · | on your subschema.</p>
<h3 id="lev_5-2-3-7" class="level3"><strong>5.2.3.7   Groupoids</strong></h3>
<p>Groupoids are like groups except a groupoid can have more than one object.</p>
<p><strong>Definition 5.2.3.8</strong>. A <em>groupoid</em> is a category C such that every morphism is an isomorphism. If C and D are groupoids, a <em>morphism of groupoids</em>, denoted F:C→D, is simply a functor. The category of groupoids is denoted <strong>Grpd</strong>.</p>
<p><em>Example</em> 5.2.3.9. There is a functor <strong>Grpd</strong> → <strong>Cat</strong>, sending a groupoid to its underlying category. There is also a functor <strong>Grp</strong> → <strong>Grpd</strong> sending a group to itself as a groupoid with one object.</p>
<p>There is also a functor Core: <strong>Cat</strong> → <strong>Grpd</strong>, sending a category C to the largest groupoid inside C, called its <em>core</em>. That is, Ob(Core(C))=Ob(C) and</p>
<p>HomCore(C)(x,y)={f∈HomC(x,y)|f is an isomorphism}.</p>
<p><em>Application</em> 5.2.3.10. Let <em>M</em> be a material in some original state <em>s</em><sub>0</sub>.<sup><a href="chapter005.html#endnote_9">9</a></sup> Construct a category SM whose objects are the states of <em>M</em> (which are obtained by pulling on <em>M</em> in different ways, heating it up, and so on). Include a morphism from state <em>s</em> to state <em>s</em>′ for every physical transformation from <em>s</em> to <em>s</em>′. Physical transformations can be performed one after another, so we can compose morphisms, and perhaps we can agree this composition is associative. Note that there is a morphism <em>i<sub>s</sub></em> : <em>s</em><sub>0</sub> → <em>s</em> representing any physical transformation that can bring <em>M</em> from its initial state <em>s</em><sub>0</sub> to <em>s</em>.</p>
<p>The elastic deformation region of the material is the set of states <em>s</em> such that there exists an inverse <em>s</em> → <em>s</em><sub>0</sub> to the morphism <em>i<sub>s</sub></em>. A transformation is irreversible if its representing morphism has no inverse. If a state <em>s</em><sub>1</sub> is not in the elastic deformation region, we can still talk about the region that is (inventing a term) elastically equivalent to <em>s</em><sub>1</sub>. It is all the objects in SM that are isomorphic to <em>s</em><sub>1</sub>. If we consider only elastic equivalences in SM, we are looking at a groupoid inside it, namely, the core Core(SM), as in Example <a href="chapter005.html#Exa_5-2-3-9">5.2.3.9</a>.</p>
<p><em>Example</em> 5.2.3.11. Alan Weinstein [45] explains groupoids in terms of tiling patterns on a bathroom floor. This is worth reading.</p>
<p><em>Example</em> 5.2.3.12. Let <em>I</em> = {<em>x</em> ∈ ℝ | 0 ⩽ <em>x</em> ⩽ 1} denote the unit interval. It can be given a topology in a standard way, as a subset of ℝ (see Example <a href="chapter005.html#Exa_5-2-3-3">5.2.3.3</a>).</p>
<p>For any topological space <em>X</em>, a <em>path in X</em> is a continuous map <em>I</em> → <em>X</em>. Two paths are called <em>homotopic</em> if one can be continuously deformed to the other, where the deformation occurs completely within <em>X</em>.<sup><a href="chapter005.html#endnote_10">10</a></sup> One can prove that being homotopic is an equivalence relation on paths.</p>
<p>Paths in <em>X</em> can be composed, one after the other, and the composition is associative (up to homotopy). Moreover, for any point <em>x</em> ∈ <em>X</em>, there is a trivial path (that stays at <em>x</em>). Finally every path is invertible (by traversing it backward) up to homotopy.</p>
<p>This all means that to any space <em>X</em> ∈ Ob(<strong>Top</strong>) we can associate a groupoid, called the <em>fundamental groupoid of X</em> and denoted Π<sub>1</sub>(<em>X</em>) ∈ Ob(<strong>Grpd</strong>). The objects of Π<sub>1</sub>(<em>X</em>) are the points of <em>X</em>; the morphisms in Π<sub>1</sub>(<em>X</em>) are the paths in <em>X</em> (up to homotopy). A continuous map <em>f</em> : <em>X</em> → <em>Y</em> can be composed with any path <em>I</em> → <em>X</em> to give a path <em>I</em> → <em>Y</em>, and this preserves homotopy. So, in fact, Π<sub>1</sub> : <strong>Top</strong> → <strong>Grpd</strong> is a functor.</p>
<p><em>Exercise</em> 5.2.3.13.</p>
<p>Let <em>T</em> denote the surface of a doughnut, i.e., a torus. Choose two points <em>p</em>, <em>q</em> ∈ <em>T</em>. Since Π<sub>1</sub>(<em>T</em>) is a groupoid, it is also a category. What would the hom-set HomΠ1(T)(p,q) represent?</p>
<p><em>Exercise</em> 5.2.3.14.</p>
<p>Let <em>U</em> ⊆ ℝ<sup>2</sup> be an open subset of the plane, and let <em>F</em> be an irrotational vector field on <em>U</em> (i.e., one with curl(<em>F</em>) = 0). Following Exercise <a href="chapter005.html#Exe_5-1-1-17">5.1.1.17</a>, we have a category CF. If two curves <em>C</em>, <em>C</em>′ in <em>U</em> are homotopic, then they have the same line integral, ∫<sub><em>C</em></sub> <em>F</em> = ∫<sub><em>C</em>′</sub> <em>F</em>.</p>
<p>We also have a category Π<sub>1</sub><em>U</em>, given by the fundamental groupoid, as in Example <a href="chapter005.html#Exa_5-2-3-12">5.2.3.12</a>. Both categories have the same objects, Ob(CF)=|U|=Ob(Π1U), the set of points in <em>U</em>.</p>
<p>a. Is there a functor CF→?Π1U or a functor Π1U→?CF that is identity on the underlying objects?</p>
<p>b. Let CF′⊆CF denote the subcategory with the same objects but only those morphisms corresponding to curves <em>C</em> with ∫<em><sub>C</sub></em> <em>F</em> = 0. Is CF′ a groupoid?</p>
<p>c. If <em>F</em> is a conservative vector field, what is CF?</p>
<p>d. If <em>F</em> is a conservative vector field, how does CF compare with Π<sub>1</sub><em>U</em>?</p>
<p><em>Exercise</em> 5.2.3.15.</p>
<p>Consider the set <em>A</em> of all (well-formed) arithmetic expressions that can be written with the symbols</p>
<p>{0,1,2,3,4,5,6,7,8,9,+,−,*,(,)}.</p>
<p>For example, here are four different elements of <em>A</em> :</p>
<p>52, 52−7, 45+0, 50+3*(6−2).</p>
<p>We can say that an equivalence between two arithmetic expressions is a justification that they give the same final answer, e.g., 52 + 60 is equivalent to 10 * (5 + 6) + (2 + 0), which is equivalent to 10 * 11 + 2.</p>
<p>a. I have basically described a category <em>G</em>. What are its objects, and what are its morphisms?</p>
<p>b. Is <em>G</em> a groupoid?</p>
<h2 id="lev_5-2-4" class="level2"><strong>5.2.4   Logic, set theory, and computer science</strong></h2>
<h3 id="lev_5-2-4-1" class="level3"><strong>5.2.4.1   The category of propositions</strong></h3>
<p>Given a domain of discourse, a logical proposition is a statement that is evaluated in any model of that domain as either true or not always true, which the black-and-white thinker might dub “false.” For example, in the domain of real numbers we might have the proposition</p>
<p>For any real number <em>x</em> ∈ ℝ, there exists a real number <em>y</em> ∈ ℝ such that <em>y</em> &gt; 3<em>x</em>.</p>
<p>That is true: for <em>x</em> = 22, we can offer <em>y</em> = 100. But the following proposition is not true:</p>
<p>Every integer <em>x</em> ∈ ℤ is divisible by 2 or 3.</p>
<p>It is true for the majority of integers, but not for all integers; thus it is dubbed false.</p>
<p>We say that one logical proposition <em>P implies</em> another proposition <em>Q</em>, denoted <em>P</em> ⇒ <em>Q</em>, if for every model in which <em>P</em> is true, so is <em>Q</em>. There is a category <strong>Prop</strong> whose objects are logical propositions and whose morphisms are proofs that one statement implies another. Crudely, one might say that <em>B holds at least as often as A</em> if there is a morphism <em>A</em> → <em>B</em> (meaning in any model for which <em>A</em> holds, so does <em>B</em>). So the proposition “<em>x</em> ≠ <em>x</em>” holds very seldom, and the proposition “<em>x</em> = <em>x</em>” holds very often.</p>
<p><em>Example</em> 5.2.4.2. We can repeat this idea for nonmathematical statements. Take the set of all possible statements that are verifiable by experiment as the objects of a category. Given two such statements, it may be that one implies the other (e.g., “If the speed of light is fixed, then there are relativistic effects”). Every statement implies itself (identity) and implication is transitive, so we have a category.</p>
<p>Let’s consider differences in proofs to be irrelevant, in which case the category <strong>Prop</strong> is simply a preorder (<strong>Prop</strong>, ⇒): either <em>A</em> implies <em>B</em> or it does not. Then it makes sense to discuss meets and joins. It turns out that meets are “and’s,” and joins are “or’s.” That is, given propositions <em>A</em>, <em>B</em>, the meet <em>A</em> ∧ <em>B</em> is defined to be a proposition that holds as often as possible subject to the constraint that it implies both <em>A</em> and <em>B</em>; the proposition “<em>A</em> holds and <em>B</em> holds” fits the bill. Similarly, the join <em>A</em> ∨ <em>B</em> is given by “<em>A</em> holds or <em>B</em> holds.”</p>
<p><em>Exercise</em> 5.2.4.3.</p>
<p>Consider the set of possible laws (most likely an infinite set) that can be dictated to hold throughout a jurisdiction. Consider each law as a proposition (“such and such is the case”), i.e., as an object of the preorder <strong>Prop</strong>. Given a jurisdiction <em>V</em>, and a set of laws {<em>ℓ</em><sub>1</sub>, <em>ℓ</em><sub>2</sub>, …, <em>ℓ<sub>n</sub></em>} that are dictated to hold throughout <em>V</em>, we take their meet <em>L</em>(<em>V</em>) ≔ <em>ℓ</em><sub>1</sub> ∧ <em>ℓ</em><sub>2</sub> ∧ ⋯ ∧ <em>ℓ<sub>n</sub></em> and consider it to be the single law of the land <em>V</em>. Suppose that <em>V</em> is a jurisdiction and <em>U</em> is a subjurisdiction (e.g., <em>U</em> is a county and <em>V</em> is a state); write <em>U</em> ⊆ <em>V</em>. Then any law dictated by the large jurisdiction (the state) must also hold throughout the small jurisdiction (the county). Let <em>J</em> be the set of jurisdictions, so that (<em>J</em>, ⊆) is a preorder.</p>
<p>a. If <em>V</em> ⊆ <em>U</em> are jurisdictions, what is the relation in <strong>Prop</strong> between <em>L</em>(<em>U</em>) and <em>L</em>(<em>V</em>)?</p>
<p>b. Consider the preorder (<em>J</em>, ⊆) of jurisdictions. Is the law of the land a morphism of preorders <em>J</em> → <strong>Prop</strong>? That is, considering both <em>J</em> and <strong>Prop</strong> to be categories (by Proposition <a href="chapter005.html#Pro_5-2-1-13">5.2.1.13</a>), we have a function <em>L</em> : Ob(<em>J</em>) → Ob(<strong>Prop</strong>); does <em>L</em> extend to a functor <em>J</em> → <strong>Prop</strong>.</p>
<p><em>Solution</em> 5.2.4.3.</p>
<p>This exercise is strangely tricky, so we go through it slowly.</p>
<p>a. Suppose that the proposition <em>L</em>(<em>V</em>) is true, i.e., we are in a model where all <em>V</em>’s laws are being followed. Does this imply that <em>L</em>(<em>U</em>) is true? Since <em>V</em> ⊆ <em>U</em>, every law of <em>U</em> is a law of <em>V</em> (e.g., if one may not own slaves anywhere in the United States, one may not own slaves in Maine). So indeed <em>L</em>(<em>U</em>) is true; thus we have <em>L</em>(<em>V</em>) ⇒ <em>L</em>(<em>U</em>).</p>
<p>b. Yes, <em>L</em> extends to a preorder morphism <em>L</em> : <em>J</em> → <strong>Prop</strong> because if <em>V</em> ⊆ <em>U</em>, then <em>L</em>(<em>V</em>) ⇒ <em>L</em>(<em>U</em>).</p>
<p><em>Exercise</em> 5.2.4.4.</p>
<p>Take again the preorder (<em>J</em>, ⊆) of jurisdictions from Exercise <a href="chapter005.html#Exe_5-2-4-3">5.2.4.3</a> and the idea that laws are propositions. But this time, let <em>R</em>(<em>V</em>) be the set of all possible laws (not just those dictated to hold) that are, in actuality, being respected, i.e., followed, by all people in <em>V</em>. This assigns to each jurisdiction a set. Does the “set of respected laws” function <em>R</em> : Ob(<em>J</em>) → Ob(<strong>Set</strong>) extend to a functor <em>J</em> → <strong>Set</strong>?</p>
<p><em>Solution</em> 5.2.4.4.</p>
<p>If <em>V</em> ⊆ <em>U</em>, then any law respected throughout <em>U</em> is respected throughout <em>V</em>, i.e., <em>R</em>(<em>U</em>) ⊆ <em>R</em>(<em>V</em>). In other words, <em>R</em> is <em>contravariant</em> (see Section <a href="chapter006.html#lev_6-2-1">6.2.1</a>), meaning it constitutes a functor <em>R</em> : <em>J</em><sup>op</sup> → <strong>Set</strong>. (Every law is being respected throughout the jurisdiction ∅, and physicists want to know what laws are being respected throughout the universe-as-jurisdiction.)</p>
<h3 id="lev_5-2-4-5" class="level3"><strong>5.2.4.5   A categorical characterization of Set</strong></h3>
<p>The category <strong>Set</strong> of sets is fundamental in mathematics, but instead of thinking of it as something given or somehow special, it can be shown to merely be a category with certain properties, each of which can be phrased purely categorically. This was shown by Lawvere [23]. A very readable account is given in [26].</p>
<h3 id="lev_5-2-4-6" class="level3"><strong>5.2.4.6   Categories in computer science</strong></h3>
<p>Computer science makes heavy use of trees, graphs, orders, lists, and monoids. All of these can be understood in the context of category theory, although it seems the categorical interpretation is rarely mentioned explicitly in computer science textbooks. However, categories are used explicitly in the theory of programming languages (PL). Researchers in that field attempt to understand the connection between what programs are supposed to do (their denotation) and what they actually cause to occur (their operation). Category theory provides a useful mathematical formalism in which to study this.</p>
<p>The kind of category most often considered by a PL researcher is known as a <em>Cartesian closed category</em>, or CCC, which means a category T that has products (like <em>A</em> × <em>B</em> in <strong>Set</strong>) and exponential objects (like <em>B<sup>A</sup></em> in <strong>Set</strong>). So <strong>Set</strong> is an example of a CCC, but there are others that are more appropriate for actual computation. The objects in a PL person’s CCC represent the <em>types</em> of the programming language, types such as integers, strings, floats. The morphisms represent computable functions, e.g., length: strings→integers. The products allow one to discuss pairs (<em>a</em>, <em>b</em>), where <em>a</em> is of one type and <em>b</em> is of another type. Exponential objects allow one to consider computable functions as things that can be input to a function (e.g., given any computable function floats→integers, one can consistently multiply its results by 2 and get a new computable function floats→integers). Products are studied in Section <a href="chapter006.html#Def_6-1-1-8">6.1.1.8</a> and exponential objects in Section <a href="chapter005.html#lev_5-3-2">5.3.2</a>.</p>
<p>But category theory does not only offer a language for thinking about programs, it offers an unexpected tool called monads. The CCC model for types allows researchers only to discuss functions, leading to the notion of functional programming languages; however, not all things that a computer does are functions. For example, reading input and output, changing internal state, and so on, are operations that can be performed on a computer but that ruin the functional aspect of programs. Monads were found in 1991 by Moggi [33] to provide a powerful abstraction that opens the doors to such nonfunction operations without forcing the developer to leave the category-theoretic paradise. Monads are discussed in Section <a href="chapter007.html#lev_7-3">7.3</a>.</p>
<p>Section <a href="chapter005.html#lev_5-2-2">5.2.2</a> showed that databases are well captured by the language of categories (this is formalized in Section <a href="chapter005.html#lev_5-4">5.4</a>). Databases are used in this book to bring clarity to concepts within standard category theory.</p>
<h2 id="lev_5-2-5" class="level2"><strong>5.2.5   Categories applied in science</strong></h2>
<p>Categories are used throughout mathematics to relate various subjects as well as to draw out the essential structures within these subjects. For example, there is active research in categorifying classical theories like that of knots, links, and braids (Khovanov [21]). It is similarly applied in science to clarify complex subjects. Here are some very brief descriptions of scientific disciplines to which category theory is applied.</p>
<p>Quantum field theory was categorified by Atiyah [2] in the late 1980s, with much success (at least in producing interesting mathematics). In this domain, one takes a category in which an object is a reasonable space, called a manifold, and a morphism is a manifold connecting two manifolds, like a cylinder connecting two circles. Such connecting manifolds are called cobordisms and the category of manifolds and cobordisms is denoted <strong>Cob</strong>. Topological quantum field theory is the study of functors <strong>Cob</strong> → <strong>Vect</strong> that assign a vector space to each manifold and a linear transformation of vector spaces to each cobordism.</p>
<p>Samson Abramsky [1] showed a relationship between database theory, category theory, and quantum physics. He used the notion of sheaves on a database (see Section <a href="chapter007.html#lev_7-2-3">7.2.3</a>) and the sheaf cohomology thereof, to derive Bell’s theorem, which roughly states that certain variables that can be observed locally do not extend to globally observable variables.</p>
<p>Information theory, invented in 1948 by Claude Shannon, is the study of how to ideally compress messages so that they can be sent quickly and accurately across a noisy channel.<sup><a href="chapter005.html#endnote_11">11</a></sup> Its main quantity of interest is the number of bits necessary to encode a piece of information. For example, the amount of information in an English sentence can be greatly reduced. The fact that <em>t</em>’s are often followed by <em>h</em>’s, or that <em>e</em>’s are much more common than <em>z</em>’s, implies that letters are not being used as efficiently as possible. The amount of bits necessary to encode a message is called its <em>entropy</em> and has been linked to the commonly used notion of the same name in physics.</p>
<p>Baez, Fritz, and Leinster [7] show that entropy can be captured quite cleanly using category theory. They make a category FinProb whose objects are finite sets equipped with a probability measure, and whose morphisms are probability-preserving functions. They characterize <em>information loss</em> as a way to assign numbers to such morphisms, subject to certain explicit constraints. They then show that the entropy of an object in FinProb is the amount of information lost under the unique map to the singleton set {☺}. This approach explicates (by way of the explicit constraints for information loss functions) the essential idea of Shannon’s information theory, allowing it to be generalized to categories other than FinProb. Thus Baez and colleagues effectively <em>categorified</em> information theory.</p>
<p>Robert Rosen proposed in the 1970s that category theory could play a major role in biology. That is only now starting to be fleshed out. There is a categorical account of evolution and memory, called <em>Memory Evolutive Systems</em> [15]. There is also a paper [10] by Brown and Porter with applications to neuroscience.</p>
<h1 id="lev_5-3" class="level1"><a href="toc.html#Rlev_5-3"><strong>5.3   Natural transformations</strong></a></h1>
<p>The Big 3 of category theory are categories, functors, and natural transformations. This section introduces the last of these, natural transformations. Category theory was originally invented to discuss natural transformations. These were sufficiently conceptually challenging that they required formalization and thus the invention of category theory. If we think of categories as domains (e.g., of discourse, interaction, comparability) and functors as translations between different domains, the natural transformations compare different translations.</p>
<p>Natural transformations can seem a bit abstruse at first, but hopefully some examples and exercises may help.</p>
<h2 id="lev_5-3-1" class="level2"><strong>5.3.1   Definition and examples</strong></h2>
<p>Let’s begin with an example. There is a functor List: <strong>Set</strong> → <strong>Set</strong>, which sends a set <em>X</em> to the set List(<em>X</em>) consisting of all lists whose entries are elements of <em>X</em>. Given a morphism <em>f</em> : <em>X</em> → <em>Y</em>, we can transform a list with entries in <em>X</em> into a list with entries in <em>Y</em> by applying <em>f</em> to each entry (see Exercise <a href="chapter005.html#Exe_5-1-2-22">5.1.2.22</a>). Call this process translating the list.</p>
<p>It may seem a strange thing to contemplate, but there is also a functor List○List: <strong>Set</strong> → <strong>Set</strong> that sends a set <em>X</em> to the set of lists of lists in <em>X</em>. If <em>X</em> = {<em>a</em>, <em>b</em>, <em>c</em>}, then List ○ List(<em>X</em>) contains elements like [[<em>a</em>, <em>b</em>], [<em>a</em>, <em>c</em>, <em>a</em>, <em>b</em>, <em>c</em>], [<em>c</em>]] and [[ ]] and [[<em>a</em>], [ ], [<em>a</em>, <em>a</em>, <em>a</em>]]. We can <em>naturally transform</em> a list of lists into a list by concatenation. In other words, for any set <em>X</em> there is a function <em>µ<sub>X</sub></em> : List ○ List(<em>X</em>) → List(<em>X</em>), which sends that list of lists to [<em>a</em>, <em>b</em>, <em>a</em>, <em>c</em>, <em>a</em>, <em>b</em>, <em>c</em>, <em>c</em>] and [ ] and [<em>a</em>, <em>a</em>, <em>a</em>, <em>a</em>] respectively. In fact, even if we use a function <em>f</em> : <em>X</em> → <em>Y</em> to translate a list of <em>X</em>’s into a list of <em>Y</em>’s (or a list of lists of <em>X</em>’s into a list of lists of <em>Y</em>’s), the concatenation works correctly.</p>
<p><em>Slogan</em> 5.3.1.1.</p>
<p><em>What does it mean to say that concatenation of lists is natural with respect to translation? It means that concatenating then translating is the same thing as translating then concatenating</em>.</p>
<p>Let’s make this concrete. Let <em>X</em> = {<em>a</em>, <em>b</em>, <em>c</em>}, let <em>Y</em> = {1, 2, 3}, and let <em>f</em> : <em>X</em> → <em>Y</em> assign <em>f</em>(<em>a</em>) = 1, <em>f</em>(<em>b</em>) = 1, <em>f</em>(<em>c</em>) = 2. The naturality condition says the following for any list of lists of <em>X</em>’s, in particular, for [[<em>a</em>, <em>b</em>], [<em>a</em>, <em>c</em>, <em>a</em>, <em>b</em>, <em>c</em>], [<em>c</em>]] ∈ List ○ List(<em>X</em>):</p>
<p><img src="images/Art_P174.jpg" alt="art" /></p>
<p>The top right path is concatenating then translating, and the left bottom path is translating then concatenating, and one sees here that they do the same thing.</p>
<p>Here is how the preceding example fits with the terminology of Definition <a href="chapter005.html#Def_5-3-1-2">5.3.1.2</a>. The categories C and D are both <strong>Set</strong>, the functor F:C→D is List ○ List, and the functor G:C→D is List. The natural transformation is <em>µ</em> : List○List → List. It can be depicted:</p>
<p><img src="images/Art_P175.jpg" alt="art" /></p>
<p><strong>Definition 5.3.1.2</strong>. Let C and D be categories, and let F:C→D and G:C→D be functors. A <em>natural transformation α from F to G</em>, denoted <em>α</em> : <em>F</em> → <em>G</em> and depicted</p>
<p><img src="images/Art_P176.jpg" alt="art" /></p>
<p>is defined as follows. One announces some constituents (A. components) and shows that they conform to a law (1. naturality squares). Specifically, one announces</p>
<p>A. for each object X∈Ob(C), a morphism <em>α<sub>X</sub></em> : <em>F</em> (<em>X</em>) → <em>G</em>(<em>X</em>) in D, called <em>the X-component of α</em>.</p>
<p>One must then show that the following <em>natural transformation law</em> holds:</p>
<ol>
<li><p>For every morphism <em>f</em> : <em>X</em> → <em>Y</em> in C, the square (<a href="chapter005.html#eq_5-10">5.10</a>), called the <em>naturality square for f</em>, must commute:</p>
<p><img src="images/Art_P177.jpg" alt="art" /></p></li>
</ol>
<p>The set of natural transformations <em>F</em> → <em>G</em> is denoted Nat(<em>F</em>, <em>G</em>).</p>
<p><em>Remark</em> 5.3.1.3. If we have two functors F, G:C→D, providing a morphism <em>α<sub>X</sub></em> : <em>F</em>(<em>X</em>) → <em>G</em>(<em>X</em>) for every object X∈Ob(C) is called a <em>questionably natural transformation</em>. Once we check the commutativity of all the naturality squares, i.e., once we know it satisfies Definition <a href="chapter005.html#Def_5-3-1-2">5.3.1.2</a>, we drop the “questionably” part.</p>
<p><em>Example</em> 5.3.1.4. Consider the following categories C≅[1] and D≅[2]:</p>
<p><img src="images/Art_P178.jpg" alt="art" /></p>
<p>Consider the functors <em>F</em>, <em>G</em> : [1] → [2], where <em>F</em>(0) = <em>A</em>, <em>F</em>(1) = <em>B</em>, <em>G</em>(0) = <em>A</em>, and <em>G</em>(1) = <em>C</em>. It turns out that there is only one possible natural transformation <em>F</em> → <em>G</em>; we call it <em>α</em> and explore its naturality square. The components of <em>α</em> : <em>F</em> → <em>G</em> are shown in green. These components are <em>α</em><sub>0</sub> = id<em><sub>A</sub></em> : <em>F</em>(0) → <em>G</em>(0) and <em>α</em><sub>1</sub> = <em>g</em> : <em>F</em>(1) → <em>G</em>(1). The naturality square for <em>p</em> : 0 → 1 is shown twice below, once with notation following that in (<a href="chapter005.html#eq_5-10">5.10</a>) and once in local notation:</p>
<p><img src="images/Art_P179.jpg" alt="art" /></p>
<p>It is clear that this diagram commutes, so the components <em>α</em><sub>0</sub> and <em>α</em><sub>1</sub> satisfy the law of Definition <a href="chapter005.html#Def_5-3-1-2">5.3.1.2</a>, making <em>α</em> a natural transformation.</p>
<p><strong>Proposition 5.3.1.5</strong>. <em>Let</em> C <em>and</em> D <em>be categories, let</em> F,G:C→D <em>be functors, and for every object</em> c∈Ob(C), <em>let</em> αc:F(c)→G(c) <em>be a morphism in</em> D. <em>Suppose given a path</em> c0→ f1 c1→ f2 ⋯→ fn cn <em>such that for each arrow f<sub>i</sub> in it, the following naturality square commutes:</em></p>
<p><img src="images/Art_P180.jpg" alt="art" /></p>
<p><em>Then the naturality square for the composite p</em> ≔ <em>f<sub>n</sub></em> ○ ⋯ ○ <em>f</em><sub>2</sub> ○ <em>f</em><sub>1</sub> : <em>c</em><sub>0</sub> → <em>c<sub>n</sub></em></p>
<p><img src="images/Art_P181.jpg" alt="art" /></p>
<p><em>also commutes. In particular, the naturality square commutes for every identity morphism</em> id<em><sub>c</sub></em>.</p>
<p><em>Proof</em>. When <em>n</em> = 0, we have a path of length 0 starting at each c∈Ob(C). It vacuously satisfies the condition, so we need to see that its naturality square</p>
<p><img src="images/Art_P182.jpg" alt="art" /></p>
<p>commutes. But this is clear because functors preserve identities.</p>
<p>The rest of the proof follows by induction on <em>n</em>. Suppose <em>q</em> = <em>f</em><sub><em>n</em>−1</sub> ○ ⋯ ○ <em>f</em><sub>2</sub> ○ <em>f</em><sub>1</sub> : <em>c</em><sub>0</sub> → <em>c</em><sub><em>n</em>−1</sub> and <em>p</em> = <em>f<sub>n</sub></em> ○ <em>q</em> and that the naturality squares for <em>q</em> and for <em>f<sub>n</sub></em> commute; we need only show that the naturality square for <em>p</em> commutes. That is, we assume the two small squares commute; it follows that the large rectangle does too, completing the proof.</p>
<p><img src="images/Art_P183.jpg" alt="art" /></p>
<p><em>Example</em> 5.3.1.6. Let C=D=[1] be the linear order of length 1, thought of as a category (by Proposition <a href="chapter005.html#Pro_5-2-1-13">5.2.1.13</a>). There are three functors C→D, which we can write as (0, 0), (0, 1), and (1, 1); these are depicted left to right as follows:</p>
<p><img src="images/Art_P184.jpg" alt="art" /></p>
<p>These are just functors so far. What are the natural transformations say, <em>α</em> : (0, 0) → (0, 1)? To specify a natural transformation, we must specify a component for each object in C. In this case <em>α</em><sub>0</sub> : 0 → 0 and <em>α</em><sub>1</sub> : 0 → 1. There is only one possible choice: <em>α</em><sub>0</sub> = id<sub>0</sub> and <em>α</em><sub>1</sub> = <em>f</em>. Now that we have chosen components, we need to check the naturality squares.</p>
<p>There are three morphisms in C, namely, id<sub>0</sub>, <em>f</em>, id<sub>1</sub>. By Proposition <a href="chapter005.html#Pro_5-3-1-5">5.3.1.5</a>, we need only check the naturality square for <em>f</em>. We write it twice, once in abstract notation and once in concrete notation:</p>
<p><img src="images/Art_P185.jpg" alt="art" /></p>
<p>This commutes, so <em>α</em> is indeed a natural transformation.</p>
<p><em>Exercise</em> 5.3.1.7.</p>
<p>With notation as in Example <a href="chapter005.html#Exa_5-3-1-6">5.3.1.6</a>, we have three functors C→D, namely, (0, 0), (0, 1), and (1, 1). How many natural transformations are there from <em>F</em> to <em>G</em>, i.e., what is the cardinality of Nat(<em>F</em>, <em>G</em>)</p>
<p>a. when <em>F</em> = (0, 0) and <em>G</em> = (1, 1)?</p>
<p>b. when <em>F</em> = (0, 0) and <em>G</em> = (0, 0)?</p>
<p>c. when <em>F</em> = (0, 1) and <em>G</em> = (0, 0)?</p>
<p>d. when <em>F</em> = (0, 1) and <em>G</em> = (1, 1)?</p>
<p><em>Exercise</em> 5.3.1.8.</p>
<p>Let 1 denote the discrete category on one object, Ob(1) = {1}, and let Loop denote the category with one object Ob(Loop)={s} and HomLoop(s,s)=ℕ (see Example <a href="chapter005.html#Exa_5-2-2-2">5.2.2.2</a>). There is exactly one functor S:1¯→Loop. Characterize the natural transformations <em>α</em> : <em>S</em> → <em>S</em>.</p>
<p><em>Exercise</em> 5.3.1.9.</p>
<p>Let [1] denote the free arrow category,</p>
<p><img src="images/Art_P186.jpg" alt="art" /></p>
<p>as in Exercise <a href="chapter005.html#Exe_5-1-2-34">5.1.2.34</a>, and let Loop be as in Example <a href="chapter005.html#Exa_5-2-2-2">5.2.2.2</a>.</p>
<p>a. What are all the functors [1] → Loop?</p>
<p>b. For any two functors <em>F</em>, <em>G</em> : [1] → Loop, characterize the set Nat(<em>F</em>, <em>G</em>) of natural transformations <em>F</em> → <em>G</em>.</p>
<p><em>Exercise</em> 5.3.1.10.</p>
<p>Consider the functor List: <strong>Set</strong> → <strong>Set</strong> sending a set <em>X</em> to the set List(<em>X</em>) of lists with entries in <em>X</em>. There is a natural transformation List○List → List given by concatenation.</p>
<p>a. If someone said, “Singleton lists give a natural transformation <em>σ</em> from id<strong><sub>Set</sub></strong> to List,” what might she mean? That is, for a set <em>X</em>, what component <em>σ<sub>X</sub></em> might she be suggesting?</p>
<p>b. Do these components satisfy the necessary naturality squares for functions <em>f</em> : <em>X</em> → <em>Y</em>? In other words, given your interpretation of what the person is saying, is she correct?</p>
<p><em>Exercise</em> 5.3.1.11.</p>
<p>Let C and D be categories, and suppose that d∈Ob(D) is a terminal object. Consider the constant functor {d}C:C→D, which sends each object c∈Ob(C) to <em>d</em> and each morphism in C to the identity morphism id<em><sub>d</sub></em> on <em>d</em>.</p>
<p>a. For any other functor F:C→D, how many natural transformations are there F​→{d}C?</p>
<p>b. Let D=Set, and let <em>d</em> = {☺}, which is a terminal object in <strong>Set</strong> (see Exercise <a href="chapter003.html#Exe_3-2-3-5">3.2.3.5</a> or Warning <a href="chapter006.html#war_6-1-3-14">6.1.3.14</a>). If C=[1] is the linear order of length 1, and F:C→Set is any functor, what does it mean to give a natural transformation {d}C→F?</p>
<p><em>Application</em> 5.3.1.12. <a href="chapter004.html#Fig_4-2">Figure 4.2</a> showed a finite state machine on alphabet Σ = {<em>a</em>, <em>b</em>}, and Example <a href="chapter004.html#Exa_4-1-3-1">4.1.3.1</a> shows its associated action table. Imagine this was your model for understanding the behavior of some system when acted on by commands <em>a</em> and <em>b</em>. Suppose a colleague tells you he has a more refined model that fits with the same data. His model has six states rather than three, but it is compatible. What might that mean?</p>
<p>Both the original state machine, <em>X</em>, the proposed model, <em>Y</em>, and their associated action tables are shown in <a href="chapter005.html#Fig_5-1">Figure 5.1</a> (see page 247).</p>
<p>How are these models compatible? In the table for <em>Y</em>, if one removes the distinction between states 1A, 1B, 1C and between states 2A and 2B, then one returns with the table for <em>X</em>. The table for <em>Y</em> is more specific, but it is fully compatible with the table for <em>X</em>. The sense in which it is compatible is precisely the sense defined by there being a natural transformation.</p>
<p>Recall that M=(List(∑),[],++) is a monoid, and that a monoid is simply a category with one object, say, Ob(M)={▲} (see Section <a href="chapter005.html#lev_5-2-1">5.2.1</a>). With Σ = {<em>a</em>, <em>b</em>}, the monoid M can be visualized as follows:</p>
<p><img src="images/Art_P187.jpg" alt="art" /></p>
<p>Recall also that a state machine on M is simply a functor M→Set. We thus have two such functors, <em>X</em> and <em>Y</em>. A natural transformation <em>α</em> : <em>Y</em> → <em>X</em> would consist of a component <em>α<sub>m</sub></em> for every object m∈Ob(M) such that certain diagrams commute. But M having only one object, we need only one function <em>α</em><sub>▲</sub> : <em>Y</em>(▲) → <em>X</em>(▲), where <em>Y</em>(▲) is the set of (6) states of <em>Y</em> and <em>X</em>(▲) is the set of (3) states of <em>X</em>.</p>
<p>The states of <em>Y</em> have been named so as to make the function <em>α</em><sub>▲</sub> particularly easy to guess.<sup><a href="chapter005.html#endnote_12">12</a></sup> We need to check that two squares commute:</p>
<p><img src="images/Art_P188.jpg" alt="art" /></p>
<p>This can only be checked by going through and making sure that certain things match, as specified by (<a href="chapter005.html#eq_5-11">5.11</a>); this is spelled out in detail. The columns that should match are those whose entries are written in blue. These correspond to the left bottom composites being matched with the top right composites in the naturality squares of (<a href="chapter005.html#eq_5-11">5.11</a>).</p>
<p><img src="images/Art_P189.jpg" alt="art" /></p>
<p><img src="images/Art_P190.jpg" alt="art" /></p>
<p>To recap, scientists may often have the idea that two models <em>Y</em> and <em>X</em> are compatible, and such notions of compatibility may be broadly agreed upon. However, these notions can at the same time be challenging to explain to an outsider, e.g., a regulatory body or auditor, especially in more complex situations. On the other hand, it is unambiguous to simply claim “there is a natural transformation from <em>Y</em> to <em>X</em>.” If, in a given domain, the notion of natural transformation captures the essence of compatible models, it may bring clarity.</p>
<p><em>Exercise</em> 5.3.1.13.</p>
<p>Let F:C→D be a functor. Suppose someone said, “The identity on <em>F</em> is a natural transformation from <em>F</em> to itself.”</p>
<p>a. What might he mean?</p>
<p>b. What components is he suggesting?</p>
<p>c. Are the components natural?</p>
<p><em>Solution</em> 5.3.1.13.</p>
<p>a. He is certainly telling us about a natural transformation <em>α</em> : <em>F</em> → <em>F</em>, and he seems to be telling us that it will somehow act like an identity.</p>
<p>b. To give a questionably natural transformation, we need to provide, for every c∈Ob(C) a morphism <em>α<sub>c</sub></em> : <em>F</em>(<em>c</em>) → <em>F</em>(<em>c</em>) in D. Since we have in mind the word <em>identity</em>, we could take <em>α<sub>c</sub></em> ≔ id<sub><em>F</em>(<em>c</em>)</sub> for all <em>c</em>. This is probably what the person means.</p>
<p>c. For <em>α</em> to be natural we need to check that the following square commutes for any <em>f</em> : <em>c</em> → <em>c</em>′ in C:</p>
<p><img src="images/Art_P191.jpg" alt="art" /></p>
<p>It clearly does commute, so <em>α</em> is natural. This natural transformation <em>α</em> is usually denoted id<em><sub>F</sub></em> : <em>F</em> → <em>F</em>.</p>
<p><em>Example</em> 5.3.1.14. Let [1] ∈ Ob(<strong>Cat</strong>) be the free arrow category described in Exercise <a href="chapter005.html#Exe_5-1-2-34">5.1.2.34</a>, and let D be any category. To specify a functor F:[1]→D requires the specification of two objects, F(v1),F(v2)∈Ob(D) and a morphism <em>F</em>(<em>e</em>): <em>F</em>(<em>v</em><sub>1</sub>) → <em>F</em>(<em>v</em><sub>2</sub>) in D . The identity and composition formulas are taken care of once that much is specified. To recap, a functor F:[1]→D is the same thing as a morphism in D .</p>
<p>Thus, choosing two functors F,G:[1]→D is precisely the same thing as choosing two morphisms in D . Let us call them <em>f</em> : <em>a</em><sub>0</sub> → <em>a</em><sub>1</sub> and <em>g</em> : <em>b</em><sub>0</sub> → <em>b</em><sub>1</sub>, where we have <em>f</em> = <em>F</em>(<em>e</em>), <em>a</em><sub>0</sub> = <em>F</em>(<em>v</em><sub>0</sub>), <em>a</em><sub>1</sub> = <em>F</em>(<em>v</em><sub>1</sub>) and <em>g</em> = <em>G</em>(<em>e</em>), <em>b</em><sub>0</sub> = <em>G</em>(<em>v</em><sub>0</sub>), <em>b</em><sub>1</sub> = <em>G</em>(<em>v</em><sub>1</sub>).</p>
<p>A natural transformation <em>α</em> : <em>F</em> → <em>G</em> consists of two components, i.e., morphisms αv0:a0→b0 and αv1:a1→b1, drawn as dashed lines:</p>
<p><img src="images/Art_P192.jpg" alt="art" /></p>
<p>The condition for <em>α</em> to be a natural transformation is that this square commutes.</p>
<p>In other words, a functor [1]→D is a morphism in D and a natural transformation between two such functors is just a commutative square in D .</p>
<p><em>Example</em> 5.3.1.15. Recall that to any graph <em>G</em> we can associate the paths-graph Paths(<em>G</em>) (see Example <a href="chapter005.html#Exa_5-1-2-25">5.1.2.25</a>). This is a functor Paths: <strong>Grph</strong> → <strong>Grph</strong>. There is also an identity functor id<strong><sub>Grph</sub></strong> : <strong>Grph</strong> → <strong>Grph</strong>. A natural transformation <em>η</em> : id<strong><sub>Grph</sub></strong> → Paths would consist of a graph homomorphism <em>η<sub>G</sub></em> : id<strong><sub>Grph</sub></strong>(<em>G</em>) → Paths(<em>G</em>) for every graph <em>G</em>. But id<strong><sub>Grph</sub></strong>(<em>G</em>) = <em>G</em> by definition, so we need <em>η<sub>G</sub></em> : <em>G</em> → Paths(<em>G</em>). Recall that Paths(<em>G</em>) has the same vertices as <em>G</em>, and every arrow in <em>G</em> counts as a path (of length 1). So there is an obvious graph homomorphism from <em>G</em> to Paths(<em>G</em>). It is not hard to see that the necessary naturality squares commute.</p>
<p><em>Example</em> 5.3.1.16. For any graph <em>G</em> we can associate the paths-graph Paths(<em>G</em>), and can do that twice to yield a new graph Paths(Paths(<em>G</em>)). Let’s think through what a path of paths in <em>G</em> is. It is a head-to-tail sequence of arrows in Paths(<em>G</em>), meaning a head-to-tail sequence of paths in <em>G</em>. These composable sequences of paths (or “paths of paths”) are the individual arrows in Paths(Paths(<em>G</em>)). The vertices in Paths(<em>G</em>) and Paths(Paths(<em>G</em>)) are the same as those in <em>G</em>, and all source and target functions are as expected.</p>
<p>Clearly, given such a sequence of paths in <em>G</em>, we could compose them to one big path in <em>G</em> with the same endpoints. In other words, for every <em>G</em> ∈ Ob(<strong>Grph</strong>), there is graph homomorphism <em>µ<sub>G</sub></em> : Paths(Paths(<em>G</em>)) → Paths(<em>G</em>) that is called <em>concatenation</em>. In fact, this concatenation extends to a natural transformation</p>
<p>μ:Paths○Paths→Paths</p>
<p>between functors <strong>Grph</strong> → <strong>Grph</strong>. Example <a href="chapter005.html#Exa_5-3-1-15">5.3.1.15</a> compared a graph to its paths-graph using a natural transformation id<strong><sub>Grph</sub></strong> → Paths; here we are making a similar kind of comparison.</p>
<p><em>Remark</em> 5.3.1.17. Example <a href="chapter005.html#Exa_5-3-1-15">5.3.1.15</a> showed that there is a natural transformation comparing each graph to its paths-graph. There is a formal sense in which a category is nothing more than a kind of reverse mapping. That is, to specify a category is the same thing as to specify a graph <em>G</em> together with a graph homomorphism Paths(<em>G</em>) → <em>G</em>. The formalities involve monads (see Section <a href="chapter007.html#lev_7-3">7.3</a>).</p>
<p><em>Exercise</em> 5.3.1.18.</p>
<p>Let <em>X</em> and <em>Y</em> be sets, and let <em>h</em> : <em>X</em> → <em>Y</em>. There is a functor <em>C<sub>X</sub></em> : <strong>Grph</strong> → <strong>Set</strong> that sends every graph to the set <em>X</em> and sends every morphism of graphs to the identity morphism id<em><sub>X</sub></em> : <em>X</em> → <em>X</em>. This functor is called <em>the constant functor at X</em>. Similarly, there is a constant functor <em>C<sub>Y</sub></em> : <strong>Grph</strong> → <strong>Set</strong>.</p>
<p>a. Use <em>h</em> to construct the components of a questionably natural transformation <em>α</em> : <em>C<sub>X</sub></em> → <em>C<sub>Y</sub></em>.</p>
<p>b. Is <em>α</em> natural?</p>
<p><em>Exercise</em> 5.3.1.19.</p>
<p>For any graph (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) we can extract the set of arrows or the set of vertices. Since each morphism of graphs includes a function between their arrow sets and a function between their vertex sets, we actually have functors <em>Ar</em> : <strong>Grph</strong> → <strong>Set</strong> and <em>Ve</em> : <strong>Grph</strong> → <strong>Set</strong>.</p>
<p>a. If someone said, “Taking source vertices gives a natural transformation from <em>Ar</em> to <em>Ve</em>,” what questionably natural transformation might she be referring to?</p>
<p>b. Is she correct, i.e., is it natural?</p>
<p>c. If a different person, say, from a totally different city and in a totally different frame of mind, were to hear this and say, “Taking target vertices also gives a natural transformation from <em>Ar</em> to <em>Ve</em>,” would they also be correct?</p>
<p><em>Example</em> 5.3.1.20 (Graph homomorphisms are natural transformations). As discussed (see diagram (<a href="chapter005.html#eq_5-8">5.8</a>)), there is a category <strong>GrIn</strong> for which a functor <em>G</em> : <strong>GrIn</strong> → <strong>Set</strong> is the same thing as a graph. Namely, we have</p>
<p><img src="images/Art_P193.jpg" alt="art" /></p>
<p>A natural transformation of two such functors <em>α</em> : <em>G</em> → <em>G</em>′ involves two components, <em>α<sub>Ar</sub></em> : <em>G</em>(<em>Ar</em>) → <em>G</em>′(<em>Ar</em>) and <em>α<sub>Ve</sub></em> : <em>G</em>(<em>Ve</em>) → <em>G</em>′(<em>Ve</em>), and two naturality squares, one for <em>src</em> and one for <em>tgt</em>. This is precisely the same thing as a graph homomorphism, as defined in Definition <a href="chapter004.html#Def_4-3-3-1">4.3.3.1</a>.</p>
<h2 id="lev_5-3-2" class="level2"><strong>5.3.2   Vertical and horizontal composition</strong></h2>
<p>This section discusses two types of compositions for natural transformations. The terms <em>vertical</em> and <em>horizontal</em> are used to describe them; these terms come from the following pictures:</p>
<p><img src="images/Art_P194.jpg" alt="art" /></p>
<p>We use the symbol ○ to denote vertical composition, so we have <em>β</em> ○ <em>α</em> : <em>F</em> → <em>H</em> in the left-hand diagram. We use the symbol ◇ for horizontal composition, so we have <em>γ</em><sub>2</sub> ◇ <em>γ</em><sub>1</sub> : <em>F</em><sub>2</sub> ○ <em>F</em><sub>1</sub> → <em>G</em><sub>2</sub> ○ <em>G</em><sub>1</sub> in the right-hand diagram. Of course, the actual arrangement of things on a page of text does not correlate with verticality or horizontality—these are just names. We define them more carefully in the following.</p>
<h3 id="lev_5-3-2-1" class="level3"><strong>5.3.2.1   Vertical composition of natural transformations</strong></h3>
<p>The following proposition proves that functors and natural transformations (using vertical composition) form a category.</p>
<p><strong>Proposition 5.3.2.2</strong>. <em>Let</em> C <em>and</em> D <em>be categories. There exists a category, called</em> the category of functors from C to D <em>and denoted</em> Fun(C,D), <em>whose objects are the functors</em> C→D <em>and whose morphisms are the natural transformations</em>,</p>
<p>HomFun(C,D)(F,G)={α:F→G|α is a natural transformation}.</p>
<p><em>Under this setup, there are indeed identity natural transformations and a composition formula for natural transformations, so we have defined a questionable category</em> Fun(C,D). <em>The category laws hold, so it is indeed a category</em>.</p>
<p><em>Proof</em>. Exercise <a href="chapter005.html#Exe_5-3-1-13">5.3.1.13</a> showed that for any functor F:C→D, there is an identity natural transformation id<em><sub>F</sub></em> : <em>F</em> → <em>F</em> (its component at c∈Ob(C) is id<sub><em>F</em>(<em>c</em>)</sub> : <em>F</em>(<em>c</em>) → <em>F</em>(<em>c</em>)).</p>
<p>Given a natural transformation <em>α</em> : <em>F</em> → <em>G</em> and a natural transformation <em>β</em> : <em>G</em> → <em>H</em>, we need a composite <em>β</em> ○ <em>α</em>. We propose the transformation <em>γ</em> : <em>F</em> → <em>H</em> having components <em>β<sub>c</sub></em> ○ <em>α<sub>c</sub></em> for every c∈Ob(C). To see that <em>γ</em> is indeed a natural transformation, one simply puts together naturality squares for <em>α</em> and <em>β</em> to get naturality squares for <em>β</em> ○ <em>α</em>.</p>
<p>One proves the associativity and identity laws in Fun(C,D) using the fact that they hold in D.</p>
<p><em>Notation</em> 5.3.2.3. We sometimes denote the category Fun(C,D) by DC.</p>
<p><em>Example</em> 5.3.2.4. Recall from Exercise <a href="chapter005.html#Exe_5-1-2-41">5.1.2.41</a> that there is a functor Ob: <strong>Cat</strong> → <strong>Set</strong> sending a category to its set of objects. And recall from Example <a href="chapter005.html#Exa_5-1-2-38">5.1.2.38</a> that there is a functor Set→DiscCat sending a set to the discrete category with that set of objects (all morphisms in <em>Disc</em>(<em>S</em>) are identity morphisms). Let <em>P</em> : <strong>Cat</strong> → <strong>Cat</strong> be the composition <em>P</em> = <em>Disc</em> ○ Ob. Then <em>P</em> takes a category and makes a new category with the same objects but no morphisms. It is like crystal meth for categories.</p>
<p>Let id<strong><sub>Cat</sub></strong> : <strong>Cat</strong> → <strong>Cat</strong> be the identity functor. There is a natural transformation <em>i</em> : <em>P</em> → id<strong><sub>Cat</sub></strong>. For any category C, the component iC:P(C)→C is pretty easily understood. It is a morphism of categories, i.e., a functor. The two categories P(C) and C have the same set of objects, namely, Ob(C), so the functor is identity on objects; and P(C) has no nonidentity morphisms, so nothing else needs be specified.</p>
<p><em>Exercise</em> 5.3.2.5.</p>
<p>Let <img src="images/Art_P195.jpg" alt="art" /> be the category with Ob(D)={A}, and HomD(A,A)={idA}. What is Fun(D,Set)? In particular, characterize the objects and the morphisms.</p>
<p><em>Notation</em> 5.3.2.6. Recall from Notation <a href="chapter002.html#Not_2-1-2-9">2.1.2.9</a> that if <em>X</em> is a set, we can represent an element <em>x</em> ∈ <em>X</em> as a function {☺}→xX. Similarly, suppose that C is a category and c∈Ob(C) is an object. There is a functor 1¯→C that sends 1 ↦ <em>c</em>. We say that this functor <em>represents</em> c∈Ob(C). We may denote it c:1¯→C.</p>
<p><em>Exercise</em> 5.3.2.7.</p>
<p>Let <em>n</em> ∈ ℕ, and let <em>n</em> be the set with <em>n</em> elements, considered as a discrete category.<sup><a href="chapter005.html#endnote_13">13</a></sup> In other words, we write <em>n</em> to mean what should really be called <em>Disc</em>(<em>n</em>). Describe the category Fun(3, 2).</p>
<p><em>Example</em> 5.3.2.8. Let 1 denote the discrete category with one object (also known as the trivial monoid). For any category C, we investigate the category D≔Fun(C,1¯). Its objects are functors C→1¯. Such a functor <em>F</em> assigns to each object in C an object in 1, of which there is one; so there is no choice in what <em>F</em> does on objects. And there is only one morphism in 1, so there is no choice in what <em>F</em> does on morphisms. The upshot is that there is only one object in D, let’s call it <em>F</em>, so D is a monoid. What are its morphisms?</p>
<p>A morphism <em>α</em> : <em>F</em> → <em>F</em> in D is a natural transformation of functors. For every c∈Ob(C), we need a component <em>α<sub>c</sub></em> : <em>F</em> (<em>c</em>) → <em>F</em> (<em>c</em>), which is a morphism 1 → 1 in 1. But there is only one morphism in 1, namely, id<sub>1</sub>, so there is no choice about what these components should be: they are all id<sub>1</sub>. The necessary naturality squares commute, so <em>α</em> is indeed a natural transformation. Thus the monoid D is the trivial monoid; that is, Fun(C,1¯)≅1¯ for any category C.</p>
<p><em>Exercise</em> 5.3.2.9.</p>
<p>Let 0 represent the discrete category on 0 objects; it has no objects and no morphisms. Let C be any category.</p>
<p>a. What is Fun(0¯,C)?</p>
<p>b. What is Fun(C,0¯)?</p>
<p><em>Exercise</em> 5.3.2.10.</p>
<p>Let [1] denote the free arrow category as in Exercise <a href="chapter005.html#Exe_5-1-2-34">5.1.2.34</a>, and let <strong>GrIn</strong> be the graph-indexing category (see (<a href="chapter005.html#eq_5-8">5.8</a>). Draw the underlying graph of the category Fun([1], <strong>GrIn</strong>).</p>
<h3 id="lev_5-3-2-11" class="level3"><strong>5.3.2.11   Natural isomorphisms</strong></h3>
<p>Let C and D be categories. We have defined a category Fun(C,D) whose objects are functors C→D and whose morphisms are natural transformations. What are the isomorphisms in this category?</p>
<p><strong>Proposition 5.3.2.12</strong> (Natural isomorphism). <em>Let</em> C <em>and</em> D <em>be categories, and let</em> F,G:C→D <em>be functors. A natural transformation α</em> : <em>F</em> → <em>G is an isomorphism in</em> Fun(C,D) <em>if and only if the component α<sub>c</sub></em> : <em>F</em>(<em>c</em>) → <em>G</em>(<em>c</em>) <em>is an isomorphism for each object</em> c∈Ob(C). <em>In this case α is called a</em> natural isomorphism.</p>
<p><em>Proof</em>. First, suppose that <em>α</em> is an isomorphism with inverse <em>β</em> : <em>G</em> → <em>F</em>, and let <em>β<sub>c</sub></em> : <em>G</em>(<em>c</em>) → <em>F</em> (<em>c</em>) denote its <em>c</em> component. We know that <em>α</em> ○ <em>β</em> = id<em><sub>G</sub></em> and <em>β</em> ○ <em>α</em> = id<em><sub>F</sub></em>. Using the definitions of composition and identity given in Proposition <a href="chapter005.html#Pro_5-3-2-2">5.3.2.2</a>, this means that for every c∈Ob(C), we have <em>α<sub>c</sub></em> ○ <em>β<sub>c</sub></em> = id<sub><em>G</em>(<em>c</em>)</sub> and <em>β<sub>c</sub></em> ○ <em>α<sub>c</sub></em> = id<sub><em>F</em>(<em>c</em>)</sub>; in other words, <em>α<sub>c</sub></em> is an isomorphism.</p>
<p>Second, suppose that each <em>α<sub>c</sub></em> is an isomorphism with inverse <em>β<sub>c</sub></em> : <em>G</em>(<em>c</em>) → <em>F</em>(<em>c</em>). We need to see that these components assemble into a natural transformation, i.e., for every morphism <em>h</em> : <em>c</em> → <em>c</em>′ in C, the right-hand square</p>
<p><img src="images/Art_P196.jpg" alt="art" /></p>
<p>commutes. We know that the left-hand square commutes because <em>α</em> is a natural transformation; each square is labeled with a ? or a ✓ accordingly. In the following diagram we want to show that the left-hand square commutes. We know that the middle square commutes.</p>
<p><img src="images/Art_P197.jpg" alt="art" /></p>
<p>To complete the proof we need only show that <em>F</em>(<em>h</em>) ○ <em>β<sub>c</sub></em> = <em>β<sub>c′</sub></em> ○ <em>G</em>(<em>h</em>). This can be shown by a “diagram chase.” We go through it symbolically, for demonstration. The following three equalities come from the three check marks in the (<a href="chapter005.html#eq_5-14">5.14</a>).</p>
<p>F(h)○βc=βc′○αc′○F(h)○βc=βc′○G(h)○αc○βc=βc′○G(h).</p>
<p><em>Exercise</em> 5.3.2.13.</p>
<p>Recall from Application <a href="chapter005.html#App_5-3-1-12">5.3.1.12</a> that a finite state machine on alphabet Σ can be understood as a functor M→Set, where M=List(Σ) is the free monoid generated by Σ. That example also discussed how natural transformations provide a language for changing state machines. Describe what kinds of changes are made by natural isomorphisms.</p>
<h3 id="lev_5-3-2-14" class="level3"><strong>5.3.2.14   Horizontal composition of natural transformations</strong></h3>
<p><em>Example</em> 5.3.2.15 (Whiskering). Suppose that M=List(a,b) and M′=List(m,n,p) are free monoids, and let F:M′→M be given by sending [<em>m</em>] ↦ [<em>a</em>], [<em>n</em>] ↦ [<em>b</em>], and [<em>p</em>] ↦ [<em>b</em>, <em>a</em>, <em>a</em>]. An application of this might be if the sequence [<em>b</em>, <em>a</em>, <em>a</em>] were commonly used in practice and one wanted to add a new button just for that sequence.</p>
<p>Recall Application <a href="chapter005.html#App_5-3-1-12">5.3.1.12</a> and <a href="chapter005.html#Fig_5-1">Figure 5.1</a>, which is reproduced here. Let X:M→Set and Y:M→Set be the functors, and let <em>α</em> : <em>Y</em> → <em>X</em> be the natural transformation.</p>
<p><img src="images/Art_P198.jpg" alt="art" /></p>
<p>We can compose <em>X</em> and <em>Y</em> with <em>F</em> as in the diagram below</p>
<p><img src="images/Art_P199.jpg" alt="art" /></p>
<p>to get functors <em>Y</em> ○ <em>F</em> and <em>X</em> ○ <em>F</em>, both of type M′→Set. These would be as follows:<sup><a href="chapter005.html#endnote_14">14</a></sup></p>
<p><img src="images/Art_P200.jpg" alt="art" /></p>
<p>The map <em>α</em> is what sent both State 1A and State 1B in <em>Y</em> to State 1 in <em>X</em>, and so on. We can see that the same <em>α</em> works now: the <em>p</em> columns of the tables respect that mapping; that is, they act like [<em>b</em>, <em>a</em>, <em>a</em>] or equivalently [<em>n</em>, <em>m</em>, <em>m</em>]. This is called <em>whiskering</em>. We used <em>α</em> : <em>Y</em> → <em>X</em> to get a natural transformation <em>Y</em> ○ <em>F</em> → <em>X</em> ○ <em>F</em> . It is a kind of horizontal composition of natural transformation.</p>
<p><strong>Definition 5.3.2.16</strong> (Whiskering). Let B,C,D, and E be categories, let G1,G2:C→D be functors, and let <em>α</em> : <em>G</em><sub>1</sub> → <em>G</em><sub>2</sub> be a natural transformation. Suppose that F:B→C (resp. H:D→E) is a functor as depicted here:</p>
<p><img src="images/Art_P201.jpg" alt="art" /></p>
<p>Then the <em>prewhiskering of α by F</em>, denoted <em>α</em> ◇ <em>F</em> : <em>G</em><sub>1</sub> ○ <em>F</em> → <em>G</em><sub>2</sub> ○ <em>F</em> (resp. the <em>post-whiskering of α by H</em>, denoted <em>H</em> ◇ <em>α</em> : <em>H</em> ○ <em>G</em><sub>1</sub> → <em>H</em> ○ <em>G</em><sub>2</sub>),</p>
<p><img src="images/Art_P202.jpg" alt="art" /></p>
<p>is defined as follows.</p>
<p>For each b∈Ob(B) the component (<em>α</em> ◇ <em>F</em>)<em><sub>b</sub></em> : <em>G</em><sub>1</sub> ○ <em>F</em>(<em>b</em>) → <em>G</em><sub>2</sub> ○ <em>F</em>(<em>b</em>) is defined to be <em>α</em><sub><em>F</em>(<em>b</em>)</sub> (resp. for each c∈Ob(C), the component (<em>H</em> ◇ <em>α</em>)<em><sub>c</sub></em> : <em>H</em> ○ <em>G</em><sub>1</sub>(<em>c</em>) → <em>H</em> ○ <em>G</em><sub>2</sub>(<em>c</em>) is defined to be <em>H</em>(<em>α<sub>c</sub></em>)). Checking that the naturality squares commute (in each case) is straightforward.</p>
<p><em>Exercise</em> 5.3.2.17.</p>
<p>Suppose given functors B→FC→GD, and let id<em><sub>G</sub></em> : <em>G</em> → <em>G</em> be the identity natural isomorphism. Show that id<em><sub>G</sub></em> ◇ <em>F</em> = id<sub><em>G</em>○<em>F</em></sub>.</p>
<p><em>Solution</em> 5.3.2.17.</p>
<p>By Definition <a href="chapter005.html#Def_5-3-2-16">5.3.2.16</a>, for each object b∈Ob(B), the component (id<em><sub>G</sub></em> ◇ <em>F</em>)<em><sub>b</sub></em> is the identity morphism (id<em><sub>G</sub></em>)<sub><em>F</em>(<em>b</em>)</sub> : <em>G</em>(<em>F</em>(<em>b</em>)) → <em>G</em>(<em>F</em>(<em>b</em>)). But there can be only one identity morphism, so (id<em><sub>G</sub></em>)<sub><em>F</em>(<em>b</em>)</sub> = id<sub><em>G</em>○<em>F</em>(<em>b</em>)</sub> = id<sub><em>G</em>○<em>F</em>(<em>b</em>)</sub>.</p>
<p><strong>Definition 5.3.2.18</strong> (Horizontal composition of natural transformations). Let B, C, and D be categories, let F1,F2:B→C and G1,G2:C→D be functors, and let <em>α</em> : <em>F</em><sub>1</sub> → <em>F</em><sub>2</sub> and <em>β</em> : <em>G</em><sub>1</sub> → <em>G</em><sub>2</sub> be natural transformations, as depicted here:</p>
<p><img src="images/Art_P203.jpg" alt="art" /></p>
<p>By pre- and postwhiskering in one order or the other we get the following diagram:</p>
<p><img src="images/Art_P204.jpg" alt="art" /></p>
<p>It is straightforward to show that this diagram commutes, so we can take the composition to be the definition of the horizontal composition:</p>
<p>β◇α:G1○F1→G2○F2.</p>
<p><em>Remark</em> 5.3.2.19. Whiskering a natural transformation <em>α</em> with a functor <em>F</em> is the same thing as horizontally composing <em>α</em> with the identity natural transformation id<em><sub>F</sub></em> . This is true for both pre- and postwhiskering. For example, in the notation of Definition <a href="chapter005.html#Def_5-3-2-16">5.3.2.16</a>, we have</p>
<p>α◇F=α◇idF  and   H◇α=idH◇α.</p>
<p><strong>Theorem 5.3.2.20</strong> (Interchange).</p>
<p><img src="images/Art_P205.jpg" alt="art" /></p>
<p><em>Given a setup of categories, functors, and natural transformations as shown, we have</em></p>
<p>(β2○β1)◇(α2○α1)=(β2◇α2)○(β1◇α1).</p>
<p><em>Proof</em>. One need only observe that each square commutes in the following diagram, so taking either outer path to get (<em>β</em><sub>2</sub> ○ <em>β</em><sub>1</sub>) ◇ (<em>α</em><sub>2</sub> ○ <em>α</em><sub>1</sub>) yields the same morphism as taking the diagonal path, (<em>β</em><sub>2</sub> ◇ <em>α</em><sub>2</sub>) ○ (<em>β</em><sub>1</sub> ◇ <em>α</em><sub>1</sub>):</p>
<p><img src="images/Art_P206.jpg" alt="art" /></p>
<p><em>Exercise</em> 5.3.2.21.</p>
<p>Suppose given categories, functors, and natural transformations as shown:</p>
<p><img src="images/Art_P207.jpg" alt="art" /></p>
<p>such that <em>α</em> : <em>F</em> → <em>F</em>′ and <em>β</em> : <em>G</em> → <em>G</em>′ are natural isomorphisms. Show that <em>β</em>◇<em>α</em> : <em>G</em>○<em>F</em> → <em>G</em>′ ○ <em>F</em>′ is a natural isomorphism.</p>
<p><em>Solution</em> 5.3.2.21.</p>
<p>Let <em>α</em>′ : <em>F</em>′ → <em>α</em> and <em>β</em>′ : <em>G</em>′ → <em>G</em> be the inverses of <em>α</em> and <em>β</em> respectively. To check that <em>β</em> ◇ <em>α</em> is an isomorphism, we use Theorem <a href="chapter005.html#The_5-3-2-20">5.3.2.20</a> (and Exercise <a href="chapter005.html#Exe_5-3-2-17">5.3.2.17</a>) to see that</p>
<p>(β◇α)○(β′◇α′)=(β○β′)◇(α○α′)=idG′◇idF′=idG′○F′</p>
<p>and similarly for the other order, (<em>β</em>′ ◇ <em>α</em>′) ○ (<em>β</em> ◇ <em>α</em>) = id<sub><em>G</em>○<em>f</em></sub>.</p>
<h2 id="lev_5-3-3" class="level2"><strong>5.3.3   The category of instances on a database schema</strong></h2>
<p>Section <a href="chapter005.html#lev_5-2-2">5.2.2</a> showed that schemas are presentations of categories, and Section <a href="chapter005.html#lev_5-4">5.4</a> shows that in fact the category of schemas is equivalent to the category of categories. This section therefore takes license to blur the distinction between schemas and categories.</p>
<p>If C is a schema, i.e., a category, then as discussed in Section <a href="chapter005.html#lev_5-2-2-6">5.2.2.6</a>, an instance on C is a functor I:C→Set. But now we have a notion beyond categories and functors, namely, that of natural transformations. So we make the following definition.</p>
<p><strong>Definition 5.3.3.1</strong>. Let C be a schema (or category). The <em>category of instances on</em> C, denoted C−Set, is Fun(C,Set). Its objects are C-instances (i.e., functors C→Set), and its morphisms are natural transformations.</p>
<p><em>Remark</em> 5.3.3.2. One might object to Definition <a href="chapter005.html#Def_5-3-3-1">5.3.3.1</a> on the grounds that database instances should not be infinite. This is a reasonable perspective, and the definition can be modified easily to accommodate it. The subcategory <strong>Fin</strong> (see Example <a href="chapter005.html#Exa_5-1-1-4">5.1.1.4</a>) of finite sets can be substituted for <strong>Set</strong> in Definition <a href="chapter005.html#Def_5-3-3-1">5.3.3.1</a>. One could define the <em>category of finite instances on</em> C as C−Fin=Fun(C,Fin). Almost all of the ideas in this book will make perfect sense in C−Fin.</p>
<p>Natural transformations should serve as some kind of morphism between instances on the same schema. How are we to interpret a natural transformation <em>α</em> : <em>I</em> → <em>J</em> between database instances I,J:C→Set?</p>
<p>A first clue comes from Application <a href="chapter005.html#App_5-3-1-12">5.3.1.12</a>. There we considered the case of a monoid M, and we thought about a natural transformation between two functors X,Y:M→Set, considered as different finite state machines. The notion of natural transformation captured the idea of one model being a refinement of another. This same kind of idea works for databases with more than one table (categories with more than one object). Let’s work it through slowly.</p>
<p><em>Example</em> 5.3.3.3. Consider the terminal schema, <img src="images/Art_P208.jpg" alt="art" />. An instance is a functor 1 → <strong>Set</strong>, which represents a set (see Notation <a href="chapter005.html#Not_5-3-2-6">5.3.2.6</a>). A natural transformation <em>α</em> : <em>I</em> → <em>J</em> is a function from set <em>I</em> to set <em>J</em>. In the standard table view, we might have <em>I</em> and <em>J</em> as shown here:</p>
<p><img src="images/Art_P209.jpg" alt="art" /></p>
<p>There are 343 natural transformations <em>I</em> → <em>J</em>. Perhaps some of them make more sense than others, e.g., we could hope that the numbers in <em>I</em> corresponded to the numbers after the hyphen in <em>J</em> or perhaps to what seems to be the date in January. Knowing something like this would reduce this to only a few options out of 343 possible mappings. But it could be that the rows in <em>J</em> correspond to batches, and all three grapes in <em>I</em> are part of the first batch on Jan-01.</p>
<p>The point is that the notion of natural transformation is a mathematical one; it has nothing to do with the kinds of associations we might find natural, unless we have found a categorical encoding for this intuition.</p>
<p><em>Exercise</em> 5.3.3.4.</p>
<p>Recall the notion of set-indexed sets from Definition <a href="chapter003.html#Def_3-4-6-11">3.4.6.11</a>. Let <em>A</em> be a set, and devise a schema A such that instances on A are <em>A</em>-indexed sets. Is our current notion of morphism between instances (i.e., natural transformations) well aligned with this definition of mapping of <em>A</em>-indexed sets?</p>
<p><em>Solution</em> 5.3.3.4.</p>
<p>Definition <a href="chapter003.html#Def_3-4-6-11">3.4.6.11</a> actually gives us the objects and morphisms of a category, say, the <em>category of A-indexed sets</em>, in that it tells us that the objects and morphisms are merely the <em>A</em>-indexed sets and the <em>A</em>-indexed functions. Let us denote the category of <em>A</em>-indexed sets <em>A</em>–<strong>Set</strong>; this exercise is asking for a category A for which there is an isomorphism</p>
<p>A−Set→ ≅ Fun(A,Set).</p>
<p>And indeed there is. Let A=Disc(A) be the discrete category on <em>A</em> objects. Then a functor S:A→Set is just a set <em>S</em>(<em>a</em>) for every <em>a</em> ∈ <em>A</em>, and a morphism <em>S</em> → <em>S</em>′ is just a component <em>f<sub>a</sub></em> : <em>S</em>(<em>a</em>) → <em>S</em>′(<em>a</em>) for each <em>a</em> ∈ <em>A</em>. These coincide exactly with the notions of <em>A</em>-indexed set and of mappings between them.</p>
<p>For a general schema (or category) C, let us think through what a morphism <em>α</em> : <em>I</em> → <em>J</em> between instances I,J:C→Set is. For each object c∈Ob(C), there is a component <em>α<sub>c</sub></em> : <em>I</em>(<em>c</em>) → <em>J</em>(<em>c</em>). This means that just as in Example <a href="chapter005.html#Exa_5-3-3-3">5.3.3.3</a>, there is for each table <em>c</em> a function from the rows in <em>I</em>’s manifestation of <em>c</em> to the rows in <em>J</em>’s manifestation of <em>c</em>. So to make a natural transformation, such a function has to be specified table by table. But then we have to contend with naturality squares, one for every arrow in C. Arrows in C correspond to foreign key columns in the database. The naturality requirement was already covered in Application <a href="chapter005.html#App_5-3-1-12">5.3.1.12</a> (see especially how (<a href="chapter005.html#eq_5-11">5.11</a>) is checked in (<a href="chapter005.html#eq_5-12">5.12</a>) and (<a href="chapter005.html#eq_5-13">5.13</a>)).</p>
<p><em>Example</em> 5.3.3.5. We saw in Section <a href="chapter005.html#lev_5-2-1-21">5.2.1.21</a> that graphs can be regarded as functors G→Set, where G≅GrIn is the schema for graphs shown here:</p>
<p><img src="images/Art_P210.jpg" alt="art" /></p>
<p>A database instance I:G→Set on G consists of two tables. Here is an example instance:</p>
<p><img src="images/Art_P211.jpg" alt="art" /></p>
<p>To discuss natural transformations, we need two instances. Here is another, J:G→Set:</p>
<p><img src="images/Art_P212.jpg" alt="art" /></p>
<p>To give a natural transformation <em>α</em> : <em>I</em> → <em>J</em>, we give two components: one for Arrow and one for Vertex. We need to say where each vertex in <em>I</em> goes in <em>J</em>, and we need to say where each arrow in <em>I</em> goes in <em>J</em>. The naturality squares insist that if we specify that <em>g</em> ↦ <em>j</em>, for example, then we had better specify that <em>w</em> ↦ <em>r</em> and that <em>x</em> ↦ <em>s</em>. What a computer is very good at, but a human is fairly slow at, is checking that a given pair of components (arrows and vertices) really is natural.</p>
<p>There are 8000 ways to devise component functions <em>α</em><sub>Arrow</sub> and <em>α</em><sub>Vertex</sub>, but precisely six natural transformations, i.e., six graph homomorphisms, <em>I</em> → <em>J</em>; the other 7,994 are haphazard flingings of arrows to arrows and vertices to vertices without any regard to sources and targets. The six are briefly described now. The reader should look at the graph diagrams of <em>I</em> and <em>J</em> while following along.</p>
<p>Every vertex in <em>I</em> has to be sent to some vertex in <em>J</em>, so we think about where to send <em>v</em> and proceed from there.</p>
<ul>
<li>If we try to send <em>v</em> ↦<sup>?</sup> <em>u</em>, we fail because <em>u</em> touches no arrows, so there is nowhere for <em>f</em> to go. (0)</li>
<li>If we send <em>v</em> ↦ <em>q</em>, then <em>f</em> must map to <em>i</em>, and <em>w</em> must map to <em>r</em>, and both <em>g</em> and <em>h</em> must map to <em>j</em>, and <em>x</em> must map to <em>s</em>. (1)</li>
<li>If we send <em>v</em> ↦ <em>r</em>, then there are two choices for <em>g</em> times two choices for <em>h</em>. (4)</li>
<li>If we send <em>v</em> ↦ <em>s</em>, then there is one way to obtain a graph morphism. (1)</li>
<li>If we try to send <em>v</em> ↦<sup>?</sup> <em>t</em>, we fail as before. (0)</li>
</ul>
<p>Humans may follow the diagrams better than the tables, whereas computers probably understand the tables better.</p>
<p><em>Exercise</em> 5.3.3.6.</p>
<p>If I,J:G→Set, as in Example <a href="chapter005.html#Exa_5-3-3-5">5.3.3.5</a>, how many natural transformations are there <em>J</em> → <em>I</em>?</p>
<p><em>Exercise</em> 5.3.3.7.</p>
<p>Let <strong>GrIn</strong> be the graph-indexing category, and let <em>Y<sub>A</sub></em> : <strong>GrIn</strong> → <strong>Set</strong> denote the following instance:</p>
<p><img src="images/Art_P213.jpg" alt="art" /></p>
<p>Let <em>I</em> : <strong>GrIn</strong> → <strong>Set</strong> be as in Example <a href="chapter005.html#Exa_5-3-3-5">5.3.3.5</a>.</p>
<p>a. How many natural transformations are there <em>Y<sub>A</sub></em> → <em>I</em>?</p>
<p>b. With <em>J</em> as previously, how many natural transformations are there <em>Y<sub>A</sub></em> → <em>J</em>?</p>
<p>c. Do you have any conjecture about the way natural transformations <em>Y<sub>A</sub></em> → <em>X</em> behave for arbitrary graphs X:G→Set?</p>
<p><em>Solution</em> 5.3.3.7.</p>
<p>It is useful to see <em>Y<sub>A</sub></em> as a graph so we can visualize the graph morphisms <em>Y<sub>A</sub></em> → <em>I</em> or <em>Y<sub>A</sub></em> → <em>J</em>.</p>
<p><img src="images/Art_P214.jpg" alt="art" /></p>
<p>a. A graph morphism <em>Y<sub>A</sub></em> → <em>I</em> amounts to an arrow in graph <em>I</em>. In other words, there is a natural isomorphism</p>
<p>Nat(YA,I)≅{f,g,h}.</p>
<p>How does this works? What might <em>g</em> mean as a natural transformation <em>Y<sub>A</sub></em> → <em>I</em>?</p>
<p>To give a questionably natural transformation <em>α</em> : <em>Y<sub>A</sub></em> → <em>I</em>, we need to give a component <em>α<sub>Ar</sub></em> : {<em>a</em>} → {<em>f</em>, <em>g</em>, <em>h</em>} and a component <em>α<sub>Ve</sub></em> : {<em>v</em><sub>0</sub>, <em>v</em><sub>1</sub>} → {<em>v</em>, <em>w</em>, <em>x</em>}. Since we have <em>g</em> in mind, let’s put <em>α<sub>Ar</sub></em>(<em>a</em>) ≔ <em>g</em>. There are 3<sup>2</sup> choices for <em>α<sub>Ve</sub></em>, but only one is natural because the two morphisms <em>src</em>, <em>tgt</em> : <em>Ar</em> → <em>Ve</em> demand two naturality equations,</p>
<p>αVe(v0)=αVe○src(a)=src○αAr(a)=src(g)=w;αVe(v1)=αVe○tgt(a)=tgt○αAr(a)=tgt(g)=x.</p>
<p>In other words, once we choose <em>α<sub>Ar</sub></em>(<em>a</em>) to be <em>g</em>, the rest is forced on us. In the same way, we could have chosen <em>α<sub>Ar</sub></em>(<em>a</em>) to be any of <em>f</em>, <em>g</em>, <em>h</em>, which is why we said Nat(<em>Y<sub>A</sub></em>, <em>I</em>) ≅ {<em>f</em>, <em>g</em>, <em>h</em>}.</p>
<p>b. There are four, Nat(<em>Y<sub>A</sub></em>, <em>J</em>) ≅ {<em>i</em>, <em>j</em>, <em>k</em>, <em>ℓ</em>}.</p>
<p>In terms of databases, this notion of instance morphism <em>α</em> : <em>I</em> → <em>J</em> on a schema C is sometimes called a <em>database homomorphism</em>. It is related to what is known as <em>provenance</em>, in that it tells us how every row in <em>I</em> relates to a counterpart row in <em>J</em>. More precisely, for every table in C, the morphism <em>α</em> gives a mapping from the set of rows in <em>I</em>’s version of the table to <em>J</em>’s version of the table, such that all the foreign keys are respected. This notion of morphism has excellent formal properties, so projections, unions, and joins of tables (the typical database operations) would be predicted to be interesting by a category theorist who has no idea what a database is.<sup><a href="chapter005.html#endnote_15">15</a></sup></p>
<h2 id="lev_5-3-4" class="level2"><strong>5.3.4   Equivalence of categories</strong></h2>
<p>We have a category <strong>Cat</strong> of categories, and in every category there is a notion of isomorphism between objects: one morphism each way, such that each round-trip composition is the identity. An isomorphism in <strong>Cat</strong>, therefore, takes place between two categories, say, C and D: it is a functor F:C→D and a functor G:D→C such that G○F=idC and F○G=idD.</p>
<p>It turns out that categories are often similar enough to be considered equivalent without being isomorphic. For this reason, the notion of isomorphism is considered too strong to be useful for categories, akin to saying that two material samples are the same if there is an atom by atom matching, or that two words are the same if they are written in the same font and size, by the same person, in the same state of mind.</p>
<p>As reasonable as isomorphism is as a notion <em>in</em> most categories, it fails to be the right notion <em>about</em> categories. The reason is that <em>in</em> categories there are objects and morphisms, whereas when we talk <em>about</em> categories, we have categories and functors plus natural transformations. Natural transformations serve as mappings between mappings, and this is not part of the structure of an ordinary category. In cases where a category C does have such mappings between mappings, it is often best to take that extra structure into account, as we do for C=Cat. This whole subject leads to the study of 2-categories (or <em>n</em>-categories, or ∞-categories), not discussed in this book. See, for example, Leinster [25] for an introduction.</p>
<p>The purpose now is to explain this “good notion” of sameness for categories, namely, <em>equivalence of categories</em>, which appropriately takes natural transformations into account. Instead of functors going both ways with round-trips equal to identity, which is required in order to be an isomorphism of categories, equivalence of categories demands functors going both ways with roundtrips <em>naturally isomorphic</em> to identity.</p>
<p><strong>Definition 5.3.4.1</strong> (Equivalence of categories). Let C and C′ be categories. A functor F:C→C′ is called <em>an equivalence of categories</em> and denoted F:C→≃C′<sup><a href="chapter005.html#endnote_16">16</a></sup> if there exists a functor F′:C′→C and natural isomorphisms α:idC→ ≅ F′○F and α′:idC′→ ≅ F○F′. In this case we say that <em>F</em> and <em>F</em>′ are <em>mutually inverse equivalences</em>.</p>
<p>Suppose we are given functors F:C→C′ and F′:C′→C. We want to know something about the round-trips on C and on C′; we want to know the same kind of information about each round-trip, so let’s concentrate on the C side. We want to know something about F′○F:C→C, so let’s name it i:C→C; we want to know that <em>i</em> is a natural isomorphism. That is, for every c∈Ob(C), we want an isomorphism αc:c→ ≅ i(c), and we want to know that these isomorphisms are picked carefully enough that given <em>g</em> : <em>c</em> → <em>c</em>′ in C, the choice of isomorphisms for <em>c</em> and <em>c</em>′ are compatible:</p>
<p><img src="images/Art_P215.jpg" alt="art" /></p>
<p>To be an equivalence, the same has to hold for the other round-trip, i′=F○F′:C′→C′.</p>
<p><em>Exercise</em> 5.3.4.2.</p>
<p>Let C and C′ be categories. Suppose that F:C→C′ is an isomorphism of categories.</p>
<p>a. Is it an equivalence of categories?</p>
<p>b. If not, why? If so, what are the components of <em>α</em> and <em>α</em>′ (with notation as in Definition <a href="chapter005.html#Def_5-3-4-1">5.3.4.1</a>)?</p>
<p><em>Solution</em> 5.3.4.2.</p>
<p>a. Yes.</p>
<p>b. If a functor F:C→C′ is an isomorphism of categories, then there exists a functor F′:C′→C such that F′○F=idC and F○F′=idC′. We might hope that <em>F</em> and <em>F</em>′ are mutually inverse equivalences of categories as well. We need natural transformations α:idC→F′○F and α′:idC′→F○F′. But since F′○F=idC and F○F′=idC′, we can take <em>α</em> and <em>α</em>′ to be the identity transformations. Thus <em>F</em> and <em>F</em>′ are indeed mutually inverse equivalences of categories.</p>
<p><em>Example</em> 5.3.4.3. Let <em>S</em> be a set, and let <em>S</em> × <em>S</em> ⊆ <em>S</em> × <em>S</em> be the complete relation on <em>S</em>, which is a preorder <em>K<sub>S</sub></em>. Recall from Proposition <a href="chapter005.html#Pro_5-2-1-13">5.2.1.13</a> that there is a functor <em>i</em> : <strong>PrO</strong> → <strong>Cat</strong>, and the resulting category <em>i</em>(<em>K<sub>S</sub></em>) is called the <em>indiscrete category on S</em>; it has objects <em>S</em> and a single morphism between every pair of objects. Here is a diagram of <em>K</em><sub>{1,2,3}</sub>:</p>
<p><img src="images/Art_P216.jpg" alt="art" /></p>
<p>It is easy check that <em>K</em><sub>1</sub>, the indiscrete category on one element, is isomorphic to 1, the discrete category on one object, also known as the terminal category (see Exercise <a href="chapter005.html#Exe_5-1-2-40">5.1.2.40</a>). The category 1 consists of one object, its identity morphism, and nothing else. Let’s think about the difference between isomorphism and equivalence using <em>K<sub>S</sub></em> ∈ Ob(<strong>Cat</strong>).</p>
<p>The only way that <em>K<sub>S</sub></em> can be isomorphic to 1 is if <em>S</em> has one element.<sup><a href="chapter005.html#endnote_17">17</a></sup> On the other hand, there is an equivalence of categories</p>
<p>KS≃1¯</p>
<p>for every set <em>S</em> ≠ ∅. So for example, <em>K</em><sub>{1,2,3}</sub> from (<a href="chapter005.html#eq_5-15">5.15</a>) is equivalent to the terminal category, 1.</p>
<p>In fact, there are many such equivalences, one for each element of <em>S</em>. To see this, let <em>S</em> be a nonempty set, and choose an element <em>s</em><sub>0</sub> ∈ <em>S</em>. For every <em>s</em> ∈ <em>S</em>, there is a unique isomorphism ks:s→ ≅ s0 in <em>K<sub>S</sub></em>. Let <em>F</em> : <em>K<sub>S</sub></em> → 1 be the only possible functor (see Exercise <a href="chapter005.html#Exe_5-1-2-40">5.1.2.40</a>), and let <em>F</em>′ : 1 → <em>K<sub>S</sub></em> represent the object <em>s</em><sub>0</sub>. Note that <em>F</em>′ ○ <em>F</em> = id<sub>1</sub> : 1 → 1 is the identity, but that <em>F</em> ○ <em>F</em>′ : <em>K<sub>S</sub></em> → <em>K<sub>S</sub></em> sends everything to <em>s</em><sub>0</sub>. So <em>F</em> is not an isomorphism. We need to show that it is an equivalence.</p>
<p>Let <em>α</em> = id<sub>1</sub>, and define α′:idKS→F○F′ by αs′=ks. Note that αs′ is an isomorphism for each <em>s</em> ∈ Ob(<em>K<sub>S</sub></em>) and that <em>α</em>′ is a natural transformation (hence, a natural isomorphism) because every possible square commutes in <em>K<sub>S</sub></em>. This completes the proof, initiated in the preceding paragraph, that the category <em>K<sub>S</sub></em> is equivalent to 1 for every nonempty set <em>S</em> and that this fact can be witnessed by any element <em>s</em><sub>0</sub> ∈ <em>S</em>.</p>
<p><em>Example</em> 5.3.4.4. Consider the category <strong>FLin</strong>, described in Example <a href="chapter005.html#Exa_5-1-1-13">5.1.1.13</a>, of finite nonempty linear orders. For every natural number <em>n</em> ∈ ℕ, let [<em>n</em>] ∈ Ob(<strong>FLin</strong>) denote the linear order shown in Example <a href="chapter004.html#Exa_4-4-1-7">4.4.1.7</a>. Define a category <strong>Δ</strong> whose objects are given by Ob(<strong>Δ</strong>) = {[<em>n</em>] | <em>n</em> ∈ ℕ} and with Hom<strong><sub>Δ</sub></strong>([<em>m</em>], [<em>n</em>]) = Hom<strong><sub>FLin</sub></strong>([<em>m</em>], [<em>n</em>]). The difference between <strong>FLin</strong> and <strong>Δ</strong> is only that objects in <strong>FLin</strong> may have odd labels, e.g.,</p>
<p>•5→      •x→      •“Sam”</p>
<p>whereas objects in <strong>Δ</strong> all have standard labels, e.g.,</p>
<p>•0→      •1→      •2</p>
<p>Clearly, <strong>FLin</strong> is a much larger category, and yet it feels as if it is pretty much the same as <strong>Δ</strong>. Actually, they are equivalent, <strong>FLin</strong> ≃ <strong>Δ</strong>. We will find functors <em>F</em> and <em>F</em>′ which witness this equivalence.</p>
<p>Let <em>F</em>′ : <strong>Δ</strong> → <strong>FLin</strong> be the inclusion; and let <em>F</em> : <strong>FLin</strong> → <strong>Δ</strong> send every finite nonempty linear order <em>X</em> ∈ Ob(<strong>FLin</strong>) to the object <em>F</em>(<em>X</em>) ≔ [<em>n</em>] ∈ <strong>Δ</strong>, where Ob(<em>X</em>) ≅ {0, 1, … , <em>n</em>}. For each such <em>X</em>, there is a unique isomorphism <em>α<sub>X</sub></em> : X→≅[n] , and these fit together into<sup><a href="chapter005.html#endnote_18">18</a></sup> the required natural isomorphism id<strong><sub>FLin</sub></strong> → <em>F</em>′ ○ <em>F</em>. The other natural isomorphism <em>α</em>′ : id<strong><sub>Δ</sub></strong> → <em>F</em> ○ <em>F</em>′ is the identity.</p>
<p><em>Exercise</em> 5.3.4.5.</p>
<p>Recall from Definition <a href="chapter002.html#Def_2-1-2-23">2.1.2.23</a> that a set <em>X</em> is called finite if there exists a natural number <em>n</em> ∈ ℕ and an isomorphism of sets <em>X</em> → <em>n</em>. Let <strong>Fin</strong> denote the category whose objects are the finite sets and whose morphisms are the functions. Let S denote the category whose objects are the sets <em>n</em> and whose morphisms are again the functions. The difference between <strong>Fin</strong> and S is that every object in S is one of these <em>n</em>’s, whereas every object in <strong>Fin</strong> is just isomorphic to one of these <em>n</em>’s.</p>
<p>For every object <em>X</em> ∈ Ob(<strong>Fin</strong>), there exists an isomorphism <em>p<sub>X</sub></em> : X→≅m¯ for some unique object m¯∈Ob(S). Find an equivalence of categories Fin→≃S.</p>
<p><em>Exercise</em> 5.3.4.6.</p>
<p>We say that two categories C and D are equivalent if there exists an equivalence of categories between them. Show that the relation of being equivalent is an equivalence relation on Ob(<strong>Cat</strong>).</p>
<p><em>Example</em> 5.3.4.7. Consider the group ℤ<sub>2</sub> ≔ ({0, 1}, 0, +), where 1 + 1 = 0. As a category, ℤ<sub>2</sub> has one object ▲ and two morphisms, namely, 0, 1, such that 0 is the identity. Since ℤ<sub>2</sub> is a group, every morphism is an isomorphism.</p>
<p>Let C=1¯ be the terminal category, as in Exercise <a href="chapter005.html#Exe_5-1-2-40">5.1.2.40</a>. One might accidentally believe that C is equivalent to ℤ<sub>2</sub>, but this is not the case. The argument in favor of the accidental belief is that we have unique functors F:ℤ2→C and F′:C→ℤ2 (and this is true); the round-trip F○F′:C→C is the identity (and this is true); and for the round-trip <em>F</em>′ ○ <em>F</em> : ℤ<sub>2</sub> → ℤ<sub>2</sub> both morphisms in ℤ<sub>2</sub> are isomorphisms, so any choice of morphism <em>α</em><sub>▲</sub>: ▲ → <em>F</em>′ ○ <em>F</em>(▲) will be an isomorphism (and this is true). The problem is that whatever one does with <em>α</em><sub>▲</sub>, one gets a questionably natural isomorphism, but it will never be natural.</p>
<p>When we round-trip <em>F</em>′ ○ <em>F</em> : ℤ<sub>2</sub> → ℤ<sub>2</sub>, the image of 1: ▲ → ▲ is <em>F</em>′ ○ <em>F</em>(1) = 0 = id<sub>▲</sub>. So the naturality square for the morphism 1 looks like this:</p>
<p><img src="images/Art_P217.jpg" alt="art" /></p>
<p>where it is undecided whether <em>α</em><sub>▲</sub> is to be 0 or 1. Unfortunately, neither choice works (i.e., for neither choice will the diagram commute) because <em>x</em> + 1 ≠ <em>x</em> + 0 in ℤ<sub>2</sub>.</p>
<p><strong>Definition 5.3.4.8</strong> (Full and faithful functors). Let C and D be categories, and let F:C→D be a functor. For any two objects c,c′∈Ob(C), there is a function</p>
<p>HomF(c,c′):HomC(c,c′)→HomD(F(c),F(c′))</p>
<p>guaranteed by the definition of functor. We say that <em>F</em> is <em>a full functor</em> if Hom<em><sub>F</sub></em>(<em>c</em>, <em>c</em>′) is surjective for every c,c′∈Ob(C). We say that <em>F</em> is <em>a faithful functor</em> if Hom<em><sub>F</sub></em>(<em>c</em>, <em>c</em>′) is injective for every <em>c</em>, <em>c</em>′. We say that <em>F</em> is <em>a fully faithful functor</em> if Hom<em><sub>F</sub></em>(<em>c</em>, <em>c</em>′) is bijective for every <em>c</em>, <em>c</em>′.</p>
<p><em>Exercise</em> 5.3.4.9.</p>
<p>Let 1 and 2 be the discrete categories on one and two objects respectively. There is only one functor <em>F</em> : 2 → 1.</p>
<p>a. Is it full?</p>
<p>b. Is it faithful?</p>
<p><em>Exercise</em> 5.3.4.10.</p>
<p>Let 0 denote the empty category, and let C be any category. There is a unique functor F:0¯→C.</p>
<p>a. For general C, will <em>F</em> be full?</p>
<p>b. For general C, will <em>F</em> be faithful?</p>
<p>c. For general C, will <em>F</em> be an equivalence of categories?</p>
<p><strong>Proposition 5.3.4.11</strong>. <em>Let</em> C <em>and</em> C′ <em>be categories, and let</em> F:C→C′ <em>be an equivalence of categories. Then F is fully faithful.</em></p>
<p><em>Sketch of proof.</em> Suppose <em>F</em> is an equivalence, so we can find a functor F′:C′→C and natural isomorphisms α:idC→≅F′○F and α′:idC′→≅F○F′. We need to know that for any objects c,d∈Ob(C), the map</p>
<p>HomF(c,d):HomC(c,d)→HomC′(Fc,Fd)</p>
<p>is bijective. Consider the following diagram</p>
<p><img src="images/Art_P218.jpg" alt="art" /></p>
<p>One can check that HomC(αc−1,αd) is bijective, so the vertical function is surjective by Exercise <a href="chapter003.html#Exe_3-4-5-3">3.4.5.3</a>. The fact that HomC′((αFC′)−1,αFD′) is bijective implies that the vertical function is injective. Thus we know that Hom<em><sub>F</sub></em>′ (<em>Fc</em>, <em>Fd</em>) is bijective. This implies that Hom<em><sub>F</sub></em>(<em>c</em>, <em>d</em>) is bijective as well.</p>
<p><em>Exercise</em> 5.3.4.12.</p>
<p>Let ℤ<sub>2</sub> be the group (as category) from Example <a href="chapter005.html#Exa_5-3-4-7">5.3.4.7</a>. Are there any fully faithful functors ℤ<sub>2</sub> → 1?</p>
<h1 id="lev_5-4" class="level1"><a href="toc.html#Rlev_5-4"><strong>5.4   Categories and schemas are equivalent, Cat ≃ Sch</strong></a></h1>
<p>Perhaps it is intuitively clear that schemas are somehow equivalent to categories. In fact, this is a reason that so much attention has been given to databases (and ologs). This section makes the equivalence between schemas and categories precise; it is proved in Section <a href="chapter005.html#lev_5-4-2">5.4.2</a>. The basic idea was laid out in Section <a href="chapter005.html#lev_5-2-2">5.2.2</a>.</p>
<h2 id="lev_5-4-1" class="level2"><strong>5.4.1   The category Sch of schemas</strong></h2>
<p>Recall from Definition <a href="chapter004.html#Def_4-5-2-7">4.5.2.7</a> that a schema consists of a pair C≔(G,≃), where <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) is a graph and ≃ is a congruence, meaning a kind of equivalence relation on the paths in <em>G</em> (see Definition <a href="chapter004.html#Def_4-5-2-3">4.5.2.3</a>). If we think of a schema as being analogous to a category, what in schema-land should fulfill the role of functors? That is, what are to be the morphisms in <strong>Sch</strong>?</p>
<p>Unfortunately, one’s first guess may give the wrong idea if we want an equivalence <strong>Sch</strong> ≃ <strong>Cat</strong>. Since an object in <strong>Sch</strong> is a graph with a congruence, one might imagine that a morphism C→C′ in <strong>Sch</strong> should be a graph homomorphism (as in Definition <a href="chapter004.html#Def_4-3-3-1">4.3.3.1</a>) that preserves the congruence. But graph homomorphisms require that arrows be sent to arrows, whereas we are more interested in paths than in individual arrows—the arrows are merely useful for presentation.</p>
<p>If instead we define morphisms between schemas to be maps that send paths in C to paths in C′, subject to the requirements that path endpoints, path concatenations, and path equivalences are preserved, this will turn out to give the correct notion. In fact, since a path is a concatenation of its arrows, it is more concise to give a function <em>F</em> from the arrows of C to the paths of C′. This is how we proceed.</p>
<p>Recall from Examples <a href="chapter005.html#Exa_5-1-2-25">5.1.2.25</a> and <a href="chapter005.html#Exa_5-3-1-16">5.3.1.16</a> the paths-graph functor Paths: <strong>Grph</strong> → <strong>Grph</strong>, the paths of paths functor Paths ○ Paths: <strong>Grph</strong> → <strong>Grph</strong>, and the natural transformations for any graph <em>G</em>,</p>
<p>ηG:G→Paths(G)andμG:Paths(Paths(G))→Paths(G).(5.16)</p>
<p>The function <em>η<sub>G</sub></em> spells out the fact that every arrow in <em>G</em> counts as a path in <em>G</em>, and the function <em>μ<sub>G</sub></em> spells out the fact that a head-to-tail sequence of paths (a path of paths) in <em>G</em> can be concatenated to a single path in <em>G</em>.</p>
<p><em>Exercise</em> 5.4.1.1.</p>
<p>Let [2] denote the graph •0→e1•1→e2•2, and let Loop denote the unique graph having one vertex and one arrow</p>
<p><img src="images/Art_P219.jpg" alt="art" /></p>
<p>a. Find a graph homomorphism <em>f</em> : [2] → Paths(Loop) that is injective on arrows (i.e., such that no two arrows in the graph [2] are sent by <em>f</em> to the same arrow in Paths(Loop)).</p>
<p>b. The graph [2] has six paths, so Paths([2]) has six arrows. What are the images of these arrows under the graph homomorphism Paths(<em>f</em>): Paths([2]) → Paths(Paths(Loop)), where <em>f</em> is the morphism you chose in part (a)?</p>
<p>c. Finally, using <em>μ<sub>Loop</sub></em> : Paths(Paths(Loop)) → Paths(Loop), a path of paths in Loop can be concatenated to a path. Write what the composite graph homomorphism</p>
<p>Paths([2])→Paths(f)Paths(Paths(Loop))→μLoopPaths(ℒoop)</p>
<p>does to the six arrows in Paths([2]).</p>
<p>Before we look at the definition of schema morphism, let’s return to the original question. Given graphs <em>G</em>, <em>G</em>′ (underlying schemas C, C′) we wanted a function from the paths in <em>G</em> to the paths in <em>G</em>′, but it was more concise to speak of a function from arrows in <em>G</em> to paths in <em>G</em>′. How do we get what we originally wanted from the concise version?</p>
<p>Given a graph homomorphism <em>f</em> : <em>G</em> → Paths(<em>G</em>′), we use (<a href="chapter005.html#eq_5-16">5.16</a>) to form the following composition, denoted simply Paths<em><sub>f</sub></em> : Paths(<em>G</em>) → Paths(<em>G</em>′):</p>
<p>Paths(G)→Paths(f)Paths(Paths(G′))→μG′Paths(G′) (5.17)</p>
<p>This says that given a function from arrows in <em>G</em> to paths in <em>G</em>′, a path in <em>G</em> becomes a path of paths in <em>G</em>′, which can be concatenated to a path in <em>G</em>′.</p>
<p><strong>Definition 5.4.1.2</strong> (Schema morphism). Let <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) and <em>G</em>′ = (<em>V</em>′, <em>A</em>′, <em>src</em>′, <em>tgt</em>′) be graphs, and let C=(G,≃G) and C′=(G′,≃G′) be schemas. A <em>schema morphism F from</em> C <em>to</em> D, denoted F:C→D, is a graph homomorphism <sup><a href="chapter005.html#endnote_19">19</a></sup></p>
<p>F:G→Paths(G′)</p>
<p>that satisfies the following condition for any paths <em>p</em> and <em>q</em> in <em>G</em>:</p>
<p>if  p≃G q  then  PathsF(p) ≃G′ PathsF(q).(5.18)</p>
<p>Two schema morphisms E,F:C→C′ are considered identical if they agree on vertices (i.e., <em>E</em><sub>0</sub> = <em>F</em><sub>0</sub>) and if, for every arrow <em>f</em> in <em>G</em>, there is a path equivalence in <em>G</em>′</p>
<p>E1(f)≃G′F1(f).</p>
<p>We now define the <em>category of schemas</em>, denoted <strong>Sch</strong>, to be the category whose objects are schemas as in Definition <a href="chapter004.html#Def_4-5-2-7">4.5.2.7</a> and whose morphisms are schema morphisms, as in Definition <a href="chapter005.html#Def_5-4-1-2">5.4.1.2</a>. The identity morphism on schema C=(G,≃G) is the schema morphism idC≔ηG:G→Paths(G), as defined in Equation (<a href="chapter005.html#eq_5-16">5.16</a>). We need only understand how to compose schema morphisms F:C→C′ and F′:C′→C″. On objects their composition is clear. Given an arrow in C, it is sent to a path in C′; each arrow in that path is sent to a path in C″. We then have a path of paths, which we can concatenate (via <em>μ</em><sub><em>G</em>″</sub> : Paths(Paths(<em>G</em>″)) → Paths(<em>G</em>″), as in (<a href="chapter005.html#eq_5-16">5.16</a>)) to get a path in C″ as desired.</p>
<p><em>Slogan</em> 5.4.1.3.</p>
<p><em>A schema morphism sends vertices to vertices, arrows to paths, and path equivalences to path equivalences</em>.</p>
<p><em>Example</em> 5.4.1.4. Let [2] be the linear order graph of length 2, at the left, and let C denote the diagram at the right:</p>
<p><img src="images/Art_P220.jpg" alt="art" /></p>
<p>We impose on C the path equivalence declaration <sub><em>a</em></sub>[<em>g</em>, <em>h</em>] ≃<sub><em>a</em></sub>[<em>i</em>] and show that in this case C and [2] are isomorphic in <strong>Sch</strong>. There is a unique schema morphism F:[2]→C such that 0 ↦<em>a</em>, 1 ↦<em>b</em>, 2 ↦<em>c</em>; it sends each arrow in [2] to a path of length 1 in C. And we have a schema morphism F′:C→[2], which reverses this mapping on vertices; note that <em>F</em>′ must send the arrow <em>i</em> in C to the path <sub>0</sub>[<em>f</em><sub>1</sub>, <em>f</em><sub>2</sub>] in [2], which is okay. The round-trip <em>F</em> ′ ○ <em>F</em> : [2] → [2] is identity. The round-trip F○F′:C→C may look like it is not the identity; indeed it sends vertices to themselves and sends <em>i</em> to the path <sub><em>a</em></sub>[<em>g</em>, <em>h</em>]. But according to Definition <a href="chapter005.html#Def_5-4-1-2">5.4.1.2</a>, this schema morphism is considered identical to idC because there is a path equivalence idC(i)=[i]a≃[g,h]a=F○F′(i).</p>
<p><em>Exercise</em> 5.4.1.5.</p>
<p>Consider the schema [2] and the schema C pictured in (<a href="chapter005.html#eq_5-19">5.19</a>); this time we <em>do not</em> impose any path equivalence declarations on C, so <sub><em>a</em></sub>[<em>g</em>, <em>h</em>] ≄ <em><sub>a</sub></em>[<em>i</em>] in the current version of C.</p>
<p>a. How many schema morphisms are there [2]→C that send 0 to <em>a</em>?</p>
<p>b. How many schema morphisms are there C→[2] that send <em>a</em> to 0?</p>
<p><em>Exercise</em> 5.4.1.6.</p>
<p>Consider the graph Loop as follows:</p>
<p><img src="images/Art_P221.jpg" alt="art" /></p>
<p>and for any natural number <em>n</em> ∈ ℕ, let Ln denote the schema (Loop, ≃<em><sub>n</sub></em>), where ≃<em><sub>n</sub></em> is the PED <em>f</em><sup><em>n</em>+1</sup> ≃ <em>f<sup>n</sup></em>. Then Ln is the “finite hierarchy of height <em>n</em>” schema of Example <a href="chapter004.html#Exa_4-5-2-12">4.5.2.12</a>. Let 1 denote the graph with one vertex and no arrows; consider it a schema.</p>
<p>a. Is 1 isomorphic to L1 in <strong>Sch</strong>?</p>
<p>b. Is 1 isomorphic to any (other) Ln?</p>
<p><em>Solution</em> 5.4.1.6.</p>
<p>a. No. The schema L1 is the graph Loop with the PED <em>f</em><sup>2</sup> = <em>f</em>, so there is still one nontrivial arrow in L1, namely, <em>f</em><sup>1</sup> ≄ <em>f</em><sup>0</sup>, whereas 1 has only the identity arrow.</p>
<p>b. Yes, there is an isomorphism of schemas 1 ≅ L0, because <em>f</em> ≃ <em>f</em><sup>0</sup> = id<em><sub>s</sub></em> in L0.</p>
<p><em>Exercise</em> 5.4.1.7.</p>
<p>Let Loop and Ln be schemas as defined in Exercise <a href="chapter005.html#Exe_5-4-1-6">5.4.1.6</a>.</p>
<p>a. What is the cardinality of the set Hom<strong><sub>Sch</sub></strong>(L3, L5)?</p>
<p>b. What is the cardinality of the set Hom<strong><sub>Sch</sub></strong>(L5, L3)? Hint: The cardinality of the set Hom<strong><sub>Sch</sub></strong>(L4, L9) is 8.</p>
<h2 id="lev_5-4-2" class="level2"><strong>5.4.2   Proving the equivalence</strong></h2>
<p>This section proves the equivalence of categories, <strong>Sch</strong> ≃ <strong>Cat</strong>. We construct the two functors <strong>Sch</strong> → <strong>Cat</strong> and <strong>Cat</strong> → <strong>Sch</strong> and then prove that these are mutually inverse equivalences (see Theorem <a href="chapter005.html#The_5-4-2-3">5.4.2.3</a>).</p>
<p><em>Construction</em> 5.4.2.1 (From schema to category). We first define a functor <em>L</em> : <strong>Sch</strong> → <strong>Cat</strong>. Let C=(G,≃) be a schema, where <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>). Define L(C) to be the category with Ob(L(C))=V, and with HomL(C)(v1,v2)≔PathG(v,w)/≃, i.e., the set of paths in <em>G</em> modulo the path equivalence relation for C. The composition of morphisms is defined by concatenation of paths, and part (4) of Definition <a href="chapter004.html#Def_4-5-2-3">4.5.2.3</a> implies that such composition is well defined. We have thus defined <em>L</em> on objects of <strong>Sch</strong>.</p>
<p>Given a schema morphism F:C→C′, where C′=( G′,≃′), we need to produce a functor L(F):L(C)→L(C′). The objects of L(C) and L(C′) are the vertices of <em>G</em> and <em>G</em>′ respectively, and <em>F</em> provides the necessary function on objects. Diagram (<a href="chapter005.html#eq_5-17">5.17</a>) provides a function Paths<em><sub>F</sub></em> : Paths(<em>G</em>) → Paths(<em>G</em>′) provides the requisite function for morphisms.</p>
<p>A morphism in L(C) is an equivalence class of paths in C. For any representative path <em>p</em> ∈ Paths(<em>G</em>), we have Paths<em><sub>F</sub></em>(<em>p</em>) ∈ Paths(<em>G</em>′), and if <em>p</em> ≃ <em>q</em>, then Paths<em><sub>F</sub></em>(<em>p</em>) ≃′ Paths<em><sub>F</sub></em>(<em>q</em>) by condition (<a href="chapter005.html#eq_5-18">5.18</a>). Thus Paths<em><sub>F</sub></em> indeed provides us with a function HomL(C)→HomL(C′). This defines <em>L</em> on morphisms in <strong>Sch</strong>. It is clear that <em>L</em> preserves composition and identities, so it is a functor.</p>
<p><em>Construction</em> 5.4.2.2 (From category to schema). We first define a functor <em>R</em> : <strong>Cat</strong> → <strong>Sch</strong>. Let C=(Ob(C),HomC,dom,cod,ids,comp) be a category (see Exercise <a href="chapter005.html#Exe_5-1-1-27">5.1.1.27</a>). Let R(C)=(G,≃), where <em>G</em> is the graph</p>
<p>G=(Ob(C),HomC,dom,cod),</p>
<p>and with ≃ defined as the congruence generated by the following path equivalence declarations: for any composable sequence of morphisms <em>f</em><sub>1</sub>, <em>f</em><sub>2</sub>, …, <em>f<sub>n</sub></em> (with <em>dom</em>(<em>f</em><sub><em>i</em>+1</sub>) = <em>cod</em>(<em>f<sub>i</sub></em>) for each 1 ⩽ <em>i</em> ⩽ <em>n</em> − 1), we put</p>
<p>[f1,f2,…,fn]dom(f1)≃[fn○⋯○f2○f1]dom(f1), (5.20)</p>
<p>equating a path of length <em>n</em> with a path of length 1. This defines <em>R</em> on objects of <strong>Cat</strong>.</p>
<p>A functor F:C→D induces a schema morphism R(F):R(C)→R(D), because vertices are sent to vertices, arrows are sent to arrows (as paths of length 1), and path equivalence is preserved by (<a href="chapter007.html#eq_7-17">7.17</a>) and the fact that <em>F</em> preserves the composition formula. This defines <em>R</em> on morphisms in <strong>Cat</strong>. It is clear that <em>R</em> preserves compositions, so it is a functor.</p>
<p><strong>Theorem 5.4.2.3</strong>. <em>The functors</em></p>
<p>L:Sch⇄Cat:R</p>
<p><em>are mutually inverse equivalences of categories.</em></p>
<p><em>Sketch of proof.</em> It is clear that there is a natural isomorphism α:idCat→≅L○R; i.e., for any category C, there is an isomorphism C≅L(R(C)).</p>
<p>Before giving an isomorphism β:idSch→≅R○L, we look at R(L(G))≕( G′,≃′) for a schema G=(G,≃). Write <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) and <em>G</em>′ = (<em>V</em> ′, <em>A</em>′, <em>src</em>′, <em>tgt</em>′). On vertices we have <em>V</em> = <em>V</em>′. On arrows we have <em>A</em>′ = Path<em><sub>G</sub></em>/≃. The congruence ≃′ for R(L(G)) is imposed in (<a href="chapter005.html#eq_5-20">5.20</a>). Under ≃′, every path of paths in <em>G</em> is made equivalent to its concatenation, considered as a single path of length 1 in <em>G</em>′.</p>
<p>There is a natural transformation <em>β</em> : id<strong><sub>Sch</sub></strong> → <em>R</em> ○ <em>L</em> whose G component sends each arrow in <em>G</em> to a certain path of length 1 in <em>G</em>′. We need to see that βG has an inverse. But this is straightforward: every arrow <em>f</em> in R○L(G) is an equivalence class of paths in G; choose any one, and have <em>β</em><sup>−1</sup> send <em>f</em> there; by Definition <a href="chapter005.html#Def_5-4-1-2">5.4.1.2</a>, any other choice will give the identical morphism of schemas. It is easy to show that each round-trip is equal to the identity (again up to the notion of equality of schema morphism given in Definition <a href="chapter005.html#Def_5-4-1-2">5.4.1.2</a>).</p>
<p><img src="images/Art_P222.jpg" alt="art" /></p>
<p><strong>Figure 5.1</strong> Finite state machines <em>X</em> and <em>Y</em> with alphabet Σ = {<em>a</em>, <em>b</em>} and three states (left) or six states (right), and their associated action tables.</p>
<p>__________________</p>
<p><a href="chapter005.html#endnote_ref_1"><sup>1</sup></a>In <em>Society of Mind</em> [32].</p>
<p><a href="chapter005.html#endnote_ref_2"><sup>2</sup></a>The reason for the notation Hom and the word <em>hom-set</em> is that morphisms are often called <em>homomorphisms</em>, e.g., in group theory.</p>
<p><a href="chapter005.html#endnote_ref_3"><sup>3</sup></a>Full subcategory will be defined in Definition <a href="chapter006.html#Def_6-2-3-1">6.2.3.1</a>.</p>
<p><a href="chapter005.html#endnote_ref_4"><sup>4</sup></a>See Remark <a href="chapter005.html#Rem_5-1-1-2">5.1.1.2</a>.</p>
<p><a href="chapter005.html#endnote_ref_5"><sup>5</sup></a>See Exercise <a href="chapter002.html#Exe_2-1-2-22">2.1.2.22</a> if there is any confusion about this.</p>
<p><a href="chapter005.html#endnote_ref_6"><sup>6</sup></a>The name of this morphism is unimportant. What matters is that HomX(x,y) has exactly one element iff <em>x</em> ≤ <em>y</em>.</p>
<p><a href="chapter005.html#endnote_ref_7"><sup>7</sup></a>The topology is given by saying that <em>U</em> ⊆ ℝ is open iff for every <em>x</em> ∈ <em>U</em>, there exists <em>ϵ</em> &gt; 0 such that {<em>y</em> ∈ ℝ | |<em>y</em> − <em>x</em>| &lt; <em>ϵ</em>} ⊆ <em>U</em>}. One says, “<em>U</em> ⊆ ℝ is open if every point in <em>U</em> has an epsilon-neighborhood fully contained in <em>U</em>.”</p>
<p><a href="chapter005.html#endnote_ref_8"><sup>8</sup></a>The topology on ℝ × ℝ is similar; a subset <em>U</em> ⊆ ℝ × ℝ is open if every point <em>x</em> ∈ <em>U</em> has an epsilon-neighborhood (a disk around <em>x</em> of some positive radius) fully contained in <em>U</em>.</p>
<p><a href="chapter005.html#endnote_ref_9"><sup>9</sup></a>This example may be somewhat crude, in accordance with the crudeness of my understanding of materials science.</p>
<p><a href="chapter005.html#endnote_ref_10"><sup>10</sup></a> Let <em>I</em> × <em>I</em> = {(<em>x</em>, <em>y</em>) ∈ ℝ<sup>2</sup> | 0 ≤ <em>x</em> ≤ 1 and 0 ≤ <em>y</em> ≤ 1} denote the square. There are two inclusions <em>i</em><sub>0</sub>, <em>i</em><sub>1</sub> : <em>I</em> → <em>S</em> that put the interval inside the square at the left and right sides. Two paths <em>f</em><sub>0</sub>, <em>f</em><sub>1</sub> : <em>I</em> → <em>X</em> are homotopic if there exists a continuous map <em>f</em> : <em>I</em> × <em>I</em> → <em>X</em> such that <em>f</em><sub>0</sub> = <em>f</em> ○ <em>i</em><sub>0</sub> and <em>f</em><sub>1</sub> = <em>f</em> ○ <em>i</em><sub>1</sub>,</p>
<p>I⇉      i1i0I×I→  f    X</p>
<p><a href="chapter005.html#endnote_ref_11"><sup>11</sup></a>The discipline called <em>information theory</em>, invented by Claude Shannon, is concerned only with ideal compression schemes. It does not pay attention to the content of the messages—what they mean—as Shannon says specifically in his seminal paper: “Frequently the messages have meaning; that is they refer to or are correlated according to some system with certain physical or conceptual entities. These semantic aspects of communication are irrelevant to the engineering problem.” Thus I think the subject is badly named. It should be called compression theory or redundancy theory.</p>
<p>Information is inherently meaningful—that is its purpose—so a theory unconcerned with meaning is not really studying information per se. (The people who decide on speed limits for roads and highways may care about human health, but a study limited to understanding ideal speed limit schemes would not be called “human health theory.”)</p>
<p>Information theory is extremely important in a diverse array of fields, including computer science [28], neuroscience [5], [27], and physics [16]. I am not trying to denigrate the field; I only disagree with its name.</p>
<p><a href="chapter005.html#endnote_ref_12"><sup>12</sup></a>The function <em>α</em><sub>▲</sub> : <em>Y</em> (▲) → <em>X</em>(▲) makes the following assignments: State 0 ↦ State 0, State 1A ↦ State 1, State 1B ↦ State 1, State 1C ↦ State 1, State 2A ↦ State 2, State 2B ↦ State 2.</p>
<p><a href="chapter005.html#endnote_ref_13"><sup>13</sup></a>When we have a functor, such as <em>Disc</em> : <strong>Set</strong> → <strong>Cat</strong>, we sometimes say, “Let <em>S</em> be a set, considered as a category.” This means that we want to take ideas and methods available in <strong>Cat</strong> and use them on the set <em>S</em>. Having the functor <em>Disc</em>, we use it to move <em>S</em> into <strong>Cat</strong>, as <em>Disc</em>(<em>S</em>) ∈ Ob(<strong>Cat</strong>), upon which we can use the intended methods. However, <em>Disc</em>(<em>S</em>) is bulky, e.g., Fun(<em>Disc</em>(3), <em>Disc</em>(2)) is harder to read than Fun(3, 2). So we abuse notation and write <em>S</em> instead of <em>Disc</em>(<em>S</em>), and talk about <em>S</em> as though it were still a set, e.g., discussing its elements rather than its objects. This kind of conceptual abbreviation is standard practice in mathematical discussion because it eases the mental burden, but when one says “Let <em>S</em> be an <em>X</em> considered as a <em>Y</em>,” the other may always ask, “How are you considering <em>X</em>’s to be <em>Y</em>’s?” and expect a functor.</p>
<p><a href="chapter005.html#endnote_ref_14"><sup>14</sup></a>The <em>p</em> column comes from applying <em>b</em>, then <em>a</em>, then <em>a</em>, as specified by <em>F</em>.</p>
<p><a href="chapter005.html#endnote_ref_15"><sup>15</sup></a>More precisely, given a functor between schemas F:C→D, the pullback ΔF:D−Set→C−Set, its left Σ<em><sub>F</sub></em> and its right adjoint Π<em><sub>F</sub></em> constitute these important queries. See Section <a href="chapter007.html#lev_7-1-4">7.1.4</a>.</p>
<p><a href="chapter005.html#endnote_ref_16"><sup>16</sup></a>The notation ≃ has already been used for equivalences of paths in a schema. I do not mean to equate these ideas; I am just reusing the symbol. Hopefully, no confusion will arise.</p>
<p><a href="chapter005.html#endnote_ref_17"><sup>17</sup></a>One way to see this is that by Exercise <a href="chapter005.html#Exe_5-1-2-41">5.1.2.41</a>, we have a functor Ob: <strong>Cat</strong> → <strong>Set</strong>, and we know by Exercise <a href="chapter005.html#Exe_5-1-2-27">5.1.2.27</a> that functors preserve isomorphisms, so an isomorphism between categories must restrict to an isomorphism between their sets of objects. The only sets that are isomorphic to 1 have one element.</p>
<p><a href="chapter005.html#endnote_ref_18"><sup>18</sup></a>The phrase “these fit together into” is shorthand for, and can be replaced by, “the naturality squares commute for these components, so together they constitute.”</p>
<p><a href="chapter005.html#endnote_ref_19"><sup>19</sup></a>By Definition <a href="chapter004.html#Def_4-3-3-1">4.3.3.1</a>, a graph homomorphism <em>F</em> : <em>G</em> → Paths(<em>G</em>′) will consist of a vertex part <em>F</em><sub>0</sub> : <em>V</em> → <em>V</em>′ and an arrows part <em>F</em><sub>1</sub> : <em>E</em> → Path(<em>G</em>′). See also Definition <a href="chapter004.html#Def_4-3-2-1">4.3.2.1</a>.</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter004.html">previous</a>, <a href="chapter006.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter005.html">previous</a>, <a href="chapter007.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<h1 class="chapter-number"><a href="toc.html#chap-6"><strong>Chapter 6</strong></a></h1>
<h1 class="chapter-title"><a href="toc.html#chap-6"><strong>Fundamental Considerations of Categories</strong></a></h1>
<p>This chapter focuses mainly on limits and colimits in a given category C. It also discusses other important and interesting categorical constructions, such as the simple notion of opposite categories and the Grothendieck construction, which gives something like the histogram of a set-valued functor. As usual, the work relies as often as possible on a grounding in databases.</p>
<p>This chapter is in some sense parallel to Chapter 3, Fundamental Considerations in <strong>Set</strong>. When attention is restricted to C=Set, the discussion of limits and colimits in this chapter subsumes the earlier work (which focused on certain finite limits and colimits). Also, this chapter ends with a section called Arithmetic of Categories, Section <a href="chapter006.html#lev_6-2-5">6.2.5</a>, which is tightly parallel with Section <a href="chapter003.html#lev_3-4-3">3.4.3</a>. This shows that in terms of grade school arithmetic expressions like</p>
<p>A×(B+C)=?(C×A)+(B×A),</p>
<p>the behavior of categories is predictable: the rules for categories are well aligned with those of sets, which are well aligned with those of natural numbers.</p>
<h1 id="lev_6-1" class="level1"><a href="toc.html#Rlev_6-1"><strong>6.1   Limits and colimits</strong></a></h1>
<p>Limits and colimits are universal constructions, meaning they represent certain ideals of behavior in a category. When it comes to sets that map to <em>A</em> and <em>B</em>, the <em>A</em> × <em>B</em> grid is ideal—it projects on to both <em>A</em> and <em>B</em> as straightforwardly as possible. When it comes to sets that can interpret the elements of both <em>A</em> and <em>B</em>, the disjoint union <em>A</em>⊔<em>B</em> is ideal—it includes both <em>A</em> and <em>B</em> without confusion or superfluity. These are limits and colimits in <strong>Set</strong>. Limits and colimits exist in other categories as well.</p>
<p>Limits in a preorder are meets; colimits in a preorder are joins. Limits and colimits also exist for database instances and monoid actions, allowing us to discuss, for example, the product or union of different finite state machines. Limits and colimits exist for topological spaces, giving rise to products and unions as well as to quotients.</p>
<p>Limits and colimits do not exist in every category. However, when C is complete with respect to limits (or colimits), these limits always seem to mean something valuable to human intuition. For example, when a subject had already been studied for a long time before category theory came to promenance, it often turned out that classically interesting constructions in the subject corresponded with limits and colimits in its categorification C. For example, products, unions, and quotients by equivalence relations are classical ideas in set theory that are naturally captured by limits and colimits in <strong>Set</strong>.</p>
<h2 id="lev_6-1-1" class="level2"><strong>6.1.1   Products and coproducts in a category</strong></h2>
<p><a href="chapter003.html#lev_3-1">Section 3.1</a> discussed products and coproducts in the category <strong>Set</strong> of sets. Now we discuss the same notions in an arbitrary category. For both products and coproducts, we begin with examples and then write the general concept.</p>
<h3 id="lev_6-1-1-1" class="level3"><strong>6.1.1.1   Products</strong></h3>
<p>The product of two sets is a grid, which projects down onto each of the two sets. This is a good intuition for products in general.</p>
<p><em>Example</em> 6.1.1.2. Given two preorders, X1≔(X1,⩽1) and X2≔(X2,⩽2), we can take their product and get a new preorder X1×X2. Both X1 and X2 have underlying sets (namely, <em>X</em><sub>1</sub> and <em>X</em><sub>2</sub>), so we might hope that the underlying set of X1× X2 is the set <em>X</em><sub>1</sub> × <em>X</em><sub>2</sub> of ordered pairs, and this turns out to be true. We have a notion of less-than on X1, and we have a notion of less-than on X2; we need to construct a notion of less-than on X1× X2. So, given two ordered pairs (<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>) and (x1′,x2′), when should we say that (x1,x2)⩽1,2(x1′,x2′) holds? A guess is that it holds iff both x1⩽1x1′ and x2⩽2x2′ hold, and this works:<sup><a href="chapter006.html#endnote_1">1</a></sup></p>
<p>X1×X2≔(X1×X2,⩽1,2).</p>
<p>Note that the projection functions <em>X</em><sub>1</sub> × <em>X</em><sub>2</sub> → <em>X</em><sub>1</sub> and <em>X</em><sub>1</sub> × <em>X</em><sub>2</sub> → <em>X</em><sub>2</sub> induce morphisms of preorders. That is, if (x1,x2)⩽1,2(x1′,x2′), then in particular, x1⩽1x1′ and x2⩽2x2′. So we have preorder morphisms</p>
<p><img src="images/Art_P223.jpg" alt="art" /></p>
<p><em>Exercise</em> 6.1.1.3.</p>
<p>Suppose you have a partial order S=(S,⩽S) on songs (you prefer some songs over others, but sometimes you cannot compare). And suppose you have a partial order A=(A,⩽A) on pieces of art. You are about to be given two pairs (<em>s</em>, <em>a</em>) and (<em>s</em>′, <em>a</em>′), each including a song and an art piece. Does the product partial order S×A provide a reasonable guess for your preferences on these pairs?</p>
<p><em>Exercise</em> 6.1.1.4.</p>
<p>Consider the partial order ⩽ on ℕ given by standard less-than-or-equal-to, so 5 ⩽ 9, and let divides be the partial order from Example <a href="chapter004.html#Exa_4-4-3-2">4.4.3.2</a>, where 6 divides 12. If we call the product order (<em>X</em>, ≤) ≔ (ℕ, ⩽) × (ℕ, divides), which of the following are true?</p>
<p>(2,4)≤(3,4)(2,4)≤(3,5)(2,4)≤(8,0)(2,4)≤(0,0)</p>
<p><em>Example</em> 6.1.1.5. Given two graphs <em>G</em><sub>1</sub> = (<em>V</em><sub>1</sub>, <em>A</em><sub>1</sub>, <em>src</em><sub>1</sub>, <em>tgt</em><sub>1</sub>) and <em>G</em><sub>2</sub> = (<em>V</em><sub>2</sub>, <em>A</em><sub>2</sub>, <em>src</em><sub>2</sub>, <em>tgt</em><sub>2</sub>), we can take their product and get a new graph <em>G</em><sub>1</sub> × <em>G</em><sub>2</sub>. The vertices are the grid of vertices <em>V</em><sub>1</sub> × <em>V</em><sub>2</sub>, so each vertex in <em>G</em><sub>1</sub> × <em>G</em><sub>2</sub> is labeled by a pair of vertices, one from <em>G</em><sub>1</sub> and one from <em>G</em><sub>2</sub>. When should an arrow connect (<em>v</em><sub>1</sub>, <em>v</em><sub>2</sub>) to (v1′,v2′)? Whenever we can find an arrow in <em>G</em><sub>1</sub> connecting <em>v</em><sub>1</sub> to v1′ and we can find an arrow in <em>G</em><sub>2</sub> connecting <em>v</em><sub>2</sub> to v2′. It turns out there is a simple formula for the set of arrows in <em>G</em><sub>1</sub> × <em>G</em><sub>2</sub>, namely, <em>A</em><sub>1</sub> × <em>A</em><sub>2</sub>.</p>
<p>Let’s write <em>G</em> ≔ <em>G</em><sub>1</sub> × <em>G</em><sub>2</sub> and say, <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>). We said that <em>V</em> = <em>V</em><sub>1</sub> × <em>V</em><sub>2</sub> and <em>A</em> = <em>A</em><sub>1</sub> × <em>A</em><sub>2</sub>. What should the source and target functions <em>A</em> → <em>V</em> be? Given a function <em>src</em><sub>1</sub> : <em>A</em><sub>1</sub> → <em>V</em><sub>1</sub> and a function <em>src</em><sub>2</sub> : <em>A</em><sub>2</sub> → <em>V</em><sub>2</sub>, the universal property for products in <strong>Set</strong> (Proposition <a href="chapter003.html#Pro_3-1-1-10">3.1.1.10</a> or, better, Example <a href="chapter003.html#Exa_3-1-1-15">3.1.1.15</a>) provides a unique function</p>
<p>src≔src1×src2:A1×A2→V1×V2.</p>
<p>Namely, the source of arrow (<em>a</em><sub>1</sub>, <em>a</em><sub>2</sub>) will be the vertex (<em>src</em><sub>1</sub>(<em>a</em><sub>1</sub>), <em>src</em><sub>2</sub>(<em>a</em><sub>2</sub>)). Similarly, we have a ready-made choice of target function <em>tgt</em> = <em>tgt</em><sub>1</sub> × <em>tgt</em><sub>2</sub>. We have now defined the product graph,</p>
<p>G=G1×G2=(V1×V2,A1×A2,src1×src2,tgt1×tgt2).</p>
<p>Here is a concrete example. Let <em>I</em> and <em>J</em> be drawn as follows:</p>
<p><img src="images/Art_P224.jpg" alt="art" /></p>
<p>The product <em>I</em> × <em>J</em> has, as expected, 3 * 4 = 12 vertices and 3 * 4 = 12 arrows:</p>
<p><img src="images/Art_P225.jpg" alt="art" /></p>
<p>Here is the most important thing to notice. Look at the Arrow table for <em>I</em> × <em>J</em>, and for each ordered pair, look only at the first entry in all three columns; you will see something that matches with the Arrow table for <em>I</em>. For example, in the <em>I</em> × <em>J</em> table, the first row’s first entries are <em>f</em>, <em>v</em>, <em>w</em>. Then do the same for the second entry in each column, and again you will see a match with the Arrow table for <em>J</em>. These matches are readily visible graph homomorphisms <em>I</em> × <em>J</em> → <em>I</em> and <em>I</em> × <em>J</em> → <em>J</em> in <strong>Grph</strong>.</p>
<p><em>Exercise</em> 6.1.1.6.</p>
<p>Let [1] denote the linear order graph of length 1,</p>
<p><img src="images/Art_P226.jpg" alt="art" /></p>
<p>and let <em>P</em> = Paths([1]) be its paths-graph, as in Example <a href="chapter005.html#Exa_5-1-2-25">5.1.2.25</a> (so <em>P</em> should have three arrows and two vertices). Draw the graph <em>P</em> × <em>P</em>.</p>
<p><em>Exercise</em> 6.1.1.7.</p>
<p>Recall from Example <a href="chapter004.html#Exa_4-5-2-10">4.5.2.10</a> that a discrete dynamical system (DDS) is a set <em>s</em> together with a function <em>f</em> : <em>s</em> → <em>s</em>. It is clear that if</p>
<p><img src="images/Art_P227.jpg" alt="art" /></p>
<p>is the loop schema, then a DDS is simply an instance (a functor) <em>I</em> : Loop → <strong>Set</strong>. We have not yet discussed DDS products, but perhaps you can guess how they should work. For example, consider these instances <em>I</em>, <em>J</em> : Loop → <strong>Set</strong>:</p>
<p><img src="images/Art_P228.jpg" alt="art" /></p>
<p>a. Make a guess and tabulate <em>I</em> × <em>J</em>. Then draw it.<sup><a href="chapter006.html#endnote_2">2</a></sup></p>
<p>b. Recall the notion of natural transformations between functors (see Example <a href="chapter005.html#Exa_5-3-3-5">5.3.3.5</a>), which in the case of functors Loop → <strong>Set</strong> are the morphisms of instances. Do you see clearly that there is a morphism of instances <em>I</em> × <em>J</em> → <em>I</em> and <em>I</em> × <em>J</em> → <em>J</em>? Check that if you look only at the left-hand coordinates in your <em>I</em> × <em>J</em>, you see something compatible with <em>I</em>.</p>
<p>In each case what is most important to recognize is that there are projection maps <em>I</em> × <em>J</em> → <em>I</em> and <em>I</em> × <em>J</em> → <em>J</em>, and that the construction of <em>I</em> × <em>J</em> seems as straightforward as possible, subject to having these projections.</p>
<p><strong>Definition 6.1.1.8</strong>. Let C be a category, and let X,Y∈Ob(C) be objects. A <em>span on X and Y</em> consists of three constituents (<em>Z</em>, <em>p</em>, <em>q</em>), where Z∈Ob(C) is an object, and where <em>p</em> : <em>Z</em> → <em>X</em> and <em>q</em> : <em>Z</em> → <em>Y</em> are morphisms in C.</p>
<p><img src="images/Art_P229.jpg" alt="art" /></p>
<p><em>A product of X and Y</em> is a span X←π1X×Y→π2Y, such that for any other span X←pZ→qY there <em>exists a unique</em> morphism <em>t</em><sub><em>p</em>,<em>q</em></sub> : <em>Z</em> → <em>X</em> × <em>Y</em> such that the following diagram commutes:<sup><a href="chapter006.html#endnote_3">3</a></sup></p>
<p><img src="images/Art_P230.jpg" alt="art" /></p>
<p>We often denote the morphism <em>t</em><sub><em>p</em>,<em>q</em></sub> by 〈<em>p</em>, <em>q</em>〉: <em>Z</em> → <em>X</em> × <em>Y</em> .</p>
<p><em>Remark</em> 6.1.1.9. Definition <a href="chapter006.html#Def_6-1-1-8">6.1.1.8</a> endows the product of two objects with a <em>universal property</em>. It says that a product of two objects <em>X</em> and <em>Y</em> maps to those two objects and serves as a gateway for all that do the same. “None shall map to <em>X</em> and <em>Y</em> except through me!” This grandiose property is held by products in all the various categories discussed so far. It is what is meant by “<em>X</em> × <em>Y</em> maps to both <em>X</em> and <em>Y</em> and does so as straightforwardly as possible.” The grid of dots obtained as the product of two sets has such a property (see Example <a href="chapter003.html#Exa_3-1-1-11">3.1.1.11</a>).</p>
<p><em>Example</em> 6.1.1.10. Example <a href="chapter006.html#Exa_6-1-1-2">6.1.1.2</a> discussed products of preorders. This example discusses products in an individual preorder. That is, by Proposition <a href="chapter005.html#Pro_5-2-1-13">5.2.1.13</a>, there is a functor <strong>PrO</strong> → <strong>Cat</strong> that realizes each individual preorder as a category. If P=(P,≤) is a preorder, what are products in P? Given two objects a,b∈Ob(P), we first consider {<em>a</em>, <em>b</em>} spans, i.e., <em>a</em> ← <em>z</em> → <em>b</em>. That is some <em>z</em> such that <em>z</em> ≤ <em>a</em> and <em>z</em> ≤ <em>b</em>. The product is a span <em>a</em> ≥ <em>a</em> × <em>b</em> ≤ <em>b</em>, but such that every other spanning object <em>z</em> is less than or equal to <em>a</em> × <em>b</em>. In other words, <em>a</em> × <em>b</em> is as big as possible subject to the condition of being less than <em>a</em> and less than <em>b</em>. This is precisely their meet, <em>a</em> ∧ <em>b</em> (see Definition <a href="chapter004.html#Def_4-4-2-1">4.4.2.1</a>).</p>
<p><em>Example</em> 6.1.1.11. Note that the product of two objects in a category C may not exist. Let’s return to preorders to see this phenomenon.</p>
<p>Consider the set ℝ<sup>2</sup>, and say that (<em>x</em><sub>1</sub>, <em>y</em><sub>1</sub>) ≤ (<em>x</em><sub>2</sub>, <em>y</em><sub>2</sub>) if there exists <em>ℓ</em> ≥ 1 such that <em>x</em><sub>1</sub><em>ℓ</em> = <em>x</em><sub>2</sub> and <em>y</em><sub>1</sub><em>ℓ</em> = <em>y</em><sub>2</sub>; in other words, point <em>p</em> is less than point <em>q</em> if, in order to travel from <em>q</em> to the origin along a straight line, one must pass through <em>p</em> along the way.<sup><a href="chapter006.html#endnote_4">4</a></sup> We have given a perfectly good partial order, but <em>p</em> ≔ (1, 0) and <em>q</em> ≔ (0, 1) do not have a product. Indeed, it would have to be a nonzero point that was on the same line through the origin as <em>p</em> and the same line through the origin as <em>q</em>, of which there are none.</p>
<p><em>Example</em> 6.1.1.12. Note that there can be more than one product of two objects in a category C but that any two choices will be canonically isomorphic. Let’s return once more to preorders to see this phenomenon.</p>
<p>Consider the set ℝ<sup>2</sup>, and say that (<em>x</em><sub>1</sub>, <em>y</em><sub>1</sub>) ≤ (<em>x</em><sub>2</sub>, <em>y</em><sub>2</sub>) if x12+y12≤x22+y22, in other words, if the former is closer to the origin. For any point <em>p</em> = (<em>x</em><sub>0</sub>, <em>y</em><sub>0</sub>), let Cp={(x,y)∈ℝ2|x2+y2=x02+y02)}, and call it the orbit circle of <em>p</em>.</p>
<p>For any two points <em>p</em>, <em>q</em>, there will be lots of points that serve as products <em>p</em> × <em>q</em>: any point <em>a</em> on the smaller of their two orbit circles will suffice. Given any two points <em>a</em>, <em>a</em>′ on this smaller circle, we have a unique isomorphism <em>a</em> ≅ <em>a</em>′ because <em>a</em> ≤ <em>a</em>′ and <em>a</em>′ ≤ <em>a</em>.</p>
<p><em>Exercise</em> 6.1.1.13.</p>
<p>Consider the preorder P of cards in a deck, shown in Example <a href="chapter004.html#Exa_4-4-1-3">4.4.1.3</a>; it is not the whole story of cards in a deck, but take it to be so. Consider this preorder P as a category (by way of the functor <strong>PrO</strong> → <strong>Cat</strong>).</p>
<p>a. For each of the following pairs, what is their product in P (if it exists)?</p>
<p>⌜a diamond⌝×⌜a heart⌝⌜a queen⌝×⌜a black card⌝⌜a card⌝×⌜a red card⌝⌜a face card⌝×⌜a black card⌝</p>
<p>b. How would these answers differ if P were completed to the “whole story” partial order classifying cards in a deck?</p>
<p><em>Exercise</em> 6.1.1.14.</p>
<p>Let <em>X</em> be a set, and consider it as a discrete category. Given two objects <em>x</em>, <em>y</em> ∈ Ob(<em>X</em>), under what conditions will there exist a product <em>x</em> × <em>y</em> in <em>X</em>?</p>
<p><em>Exercise</em> 6.1.1.15.</p>
<p>Let <em>f</em> : ℝ → ℝ be a function like one that you would see in grade school (e.g., <em>f</em>(<em>x</em>) = <em>x</em>+7). A typical thing to do is to graph <em>f</em> as a curve running through the plane ℝ<sup>2</sup> ≔ ℝ×ℝ. For example, <em>f</em> is graphed as a straight line with slope 1 and <em>y</em>-intercept 7. In general, the graph of <em>f</em> is a curve that be understood as a function <em>F</em> : ℝ → ℝ<sup>2</sup>.</p>
<p>a. For an arbitrary function <em>f</em> : ℝ → ℝ with graph <em>F</em> : ℝ → ℝ<sup>2</sup> and an arbitrary <em>r</em> ∈ ℝ, what are the (<em>x</em>, <em>y</em>) coordinates of <em>F</em> (<em>r</em>) ∈ ℝ<sup>2</sup>?</p>
<p>b. Obtain <em>F</em> : ℝ → ℝ<sup>2</sup> using the universal property given in Definition <a href="chapter006.html#Def_6-1-1-8">6.1.1.8</a>.</p>
<p><em>Exercise</em> 6.1.1.16.</p>
<p>Consider the preorder (ℕ, divides), discussed in Example <a href="chapter004.html#Exa_4-4-3-2">4.4.3.2</a>, where, e.g., 5 ≤ 15, but 5 ≰ 6. Consider it as a category, using the functor <strong>PrO</strong> → <strong>Cat</strong>.</p>
<p>a. What is the product of 9 and 12 in this category?</p>
<p>b. Is there a standard name for products in this category?</p>
<p><em>Example</em> 6.1.1.17. Products do not have to exist in an arbitrary category, but they do exist in <strong>Cat</strong>, the category of categories. That is, given two categories C and D, there is a product category C×D. We have Ob(C×D)=Ob(C)×Ob(D), and for any two objects (<em>c</em>, <em>d</em>) and (<em>c</em>′, <em>d</em>′), we have</p>
<p>HomC×D((c,d),(c′,d′))=HomC(c,c′)×HomC(d,d′).</p>
<p>The composition formula is clear.</p>
<p>Let [1] ∈ Ob(<strong>Cat</strong>) denote the linear order category of length 1:</p>
<p><img src="images/Art_P231.jpg" alt="art" /></p>
<p>As a schema it has one arrow, but as a category it has three morphisms. So we expect [1]×[1] to have nine morphisms, and that is true. In fact, [1]×[1] looks like a commutative square:</p>
<p><img src="images/Art_P232.jpg" alt="art" /></p>
<p>We see only four morphisms here, but there are also four identities and one morphism (0, 0) → (1, 1) given by composition of either direction. It is a minor miracle that the categorical product somehow “knows” that this square should commute; however, this is not a mere preference but follows rigorously from the definitions we already gave of <strong>Cat</strong> and products.</p>
<h3 id="lev_6-1-1-18" class="level3"><strong>6.1.1.18   Coproducts</strong></h3>
<p>The coproduct of two sets is their disjoint union, which includes nonoverlapping copies of each of the two sets. This is a good intuition for coproducts in general.</p>
<p><em>Example</em> 6.1.1.19. Given two preorders, X1≔(X1,≤1) and X2≔(X2,≤2), we can take their coproduct and get a new preorder X1⊔ X2. Both X1 and X2 have underlying sets (namely, <em>X</em><sub>1</sub> and <em>X</em><sub>2</sub>), so we might hope that the underlying set of X1× X2 is the disjoint union <em>X</em><sub>1</sub> ⊔ <em>X</em><sub>2</sub>, and that turns out to be true. We have a notion of less-than on X1 and a notion of less-than on X2.</p>
<p>Given an element <em>x</em> ∈ <em>X</em><sub>1</sub> ⊔ <em>X</em><sub>2</sub> and an element <em>x</em>′ ∈ <em>X</em><sub>1</sub> ⊔ <em>X</em><sub>2</sub>, how can we use ≤<sub>1</sub> and ≤<sub>2</sub> to compare <em>x</em><sub>1</sub> and <em>x</em><sub>2</sub>? The relation ≤<sub>1</sub> only knows how to compare elements of <em>X</em><sub>1</sub>, and the relation ≤<sub>2</sub> only knows how to compare elements of <em>X</em><sub>2</sub>. But <em>x</em> and <em>x</em>′ may come from different homes, e.g., <em>x</em> ∈ <em>X</em><sub>1</sub> and <em>x</em>′ ∈ <em>X</em><sub>2</sub>, in which case neither ≤<sub>1</sub> nor ≤<sub>2</sub> gives any clue about which should be bigger.</p>
<p>So when should we say that <em>x</em> ≤<sub>1⊔2</sub> <em>x</em>′ holds? The obvious guess is to say that <em>x</em> is less than <em>x</em>′ iff both <em>x</em> and <em>x</em>′ are from the same home and the local ordering has <em>x</em> ≤ <em>x</em>′. To be precise, we say <em>x</em> ≤<sub>1⊔2</sub> <em>x</em>′ if and only if either one of the following conditions hold:</p>
<ul>
<li><em>x</em> ∈ <em>X</em><sub>1</sub> and <em>x</em>′ ∈ <em>X</em><sub>1</sub> and <em>x</em> ≤<sub>1</sub> <em>x</em>′, or</li>
<li><em>x</em> ∈ <em>X</em><sub>2</sub> and <em>x</em>′ ∈ <em>X</em><sub>2</sub> and <em>x</em> ≤<sub>2</sub> <em>x</em>′.</li>
</ul>
<p>With ≤<sub>1⊔2</sub> so defined, one checks that it is not only a preorder but that it serves as a coproduct of X1 and X2,<sup><a href="chapter006.html#endnote_5">5</a></sup></p>
<p>X1⊔X2≔(X1⊔X2,≤1⊔2).</p>
<p>Note that the inclusion functions <em>X</em><sub>1</sub> → <em>X</em><sub>1</sub> ⊔ <em>X</em><sub>2</sub> and <em>X</em><sub>2</sub> → <em>X</em><sub>1</sub> ⊔ <em>X</em><sub>2</sub> induce morphisms of preorders. That is, if <em>x</em>, <em>x</em>′ ∈ <em>X</em><sub>1</sub> are elements such that <em>x</em> ≤<sub>1</sub> <em>x</em>′ in X1, then the same will hold in X1⊔ X2, and similarly for X2. So we have preorder morphisms</p>
<p><img src="images/Art_P233.jpg" alt="art" /></p>
<p><em>Exercise</em> 6.1.1.20.</p>
<p>Suppose you have a partial order A≔(A,≤A) on apples (you prefer some apples to others, but sometimes you cannot compare). And suppose you have a partial order O≔(O,≤O) on oranges. You are about to be given two pieces of fruit from a basket of apples and oranges. Is the coproduct partial order A⊔O a reasonable guess for your preferences, or does it seem biased?</p>
<p><em>Example</em> 6.1.1.21. Given two graphs <em>G</em><sub>1</sub> = (<em>V</em><sub>1</sub>, <em>A</em><sub>1</sub>, <em>src</em><sub>1</sub>, <em>tgt</em><sub>1</sub>) and <em>G</em><sub>2</sub> = (<em>V</em><sub>2</sub>, <em>A</em><sub>2</sub>, <em>src</em><sub>2</sub>, <em>tgt</em><sub>2</sub>), we can take their coproduct and get a new graph <em>G</em><sub>1</sub>⊔<em>G</em><sub>2</sub>. The vertices will be the disjoint union of vertices <em>V</em><sub>1</sub> ⊔ <em>V</em><sub>2</sub>, so each vertex in <em>G</em><sub>1</sub> ⊔ <em>G</em><sub>2</sub> is labeled either by a vertex in <em>G</em><sub>1</sub> or by one in <em>G</em><sub>2</sub> (if any labels are shared, then something must be done to differentiate them). When should an arrow connect <em>v</em> to <em>v</em>′? Whenever both are from the same component (i.e., either <em>v</em>, <em>v</em>′ ∈ <em>V</em><sub>1</sub> or <em>v</em>, <em>v</em>′ ∈ <em>V</em><sub>2</sub>) and we can find an arrow connecting them in that component. It turns out there is a simple formula for the set of arrows in <em>G</em><sub>1</sub> ⊔ <em>G</em><sub>2</sub>, namely, <em>A</em><sub>1</sub> ⊔ <em>A</em><sub>2</sub>.</p>
<p>Let’s write <em>G</em> ≔ <em>G</em><sub>1</sub> ⊔ <em>G</em><sub>2</sub> and say, <em>G</em> = (<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>). We now know that <em>V</em> = <em>V</em><sub>1</sub> ⊔ <em>V</em><sub>2</sub> and <em>A</em> = <em>A</em><sub>1</sub> ⊔ <em>A</em><sub>2</sub>. What should the source and target functions <em>A</em> → <em>V</em> be? Given a function <em>src</em><sub>1</sub> : <em>A</em><sub>1</sub> → <em>V</em><sub>1</sub> and a function <em>src</em><sub>2</sub> : <em>A</em><sub>2</sub> → <em>V</em><sub>2</sub>, the universal property for coproducts in <strong>Set</strong> can be used to specify a unique function</p>
<p>src≔src1⊔src2:A1⊔A2→V1⊔V2.</p>
<p>Namely, for any arrow <em>a</em> ∈ <em>A</em>, we know either <em>a</em> ∈ <em>A</em><sub>1</sub> or <em>a</em> ∈ <em>A</em><sub>2</sub> (and not both), so the source of <em>a</em> will be the vertex <em>src</em><sub>1</sub>(<em>a</em>) if <em>a</em> ∈ <em>A</em><sub>1</sub> and <em>src</em><sub>2</sub>(<em>a</em>) if <em>a</em> ∈ <em>A</em><sub>2</sub>. Similarly, we have a ready-made choice of target function <em>tgt</em> = <em>tgt</em><sub>1</sub> ⊔ <em>tgt</em><sub>2</sub>. We have now defined the coproduct graph.</p>
<p>Here is an example. Let <em>I</em> and <em>J</em> be as in Example <a href="chapter005.html#Exa_5-3-3-5">5.3.3.5</a>:</p>
<p><img src="images/Art_P234.jpg" alt="art" /></p>
<p>The coproduct <em>I</em> ⊔ <em>J</em> has, as expected, 3 + 5 = 8 vertices and 3 + 4 = 7 arrows:</p>
<p><img src="images/Art_P235.jpg" alt="art" /></p>
<p>Here is the most important thing to notice. Look at the Arrow tables and notice that there is a way to send each row in <em>I</em> to a row in <em>I</em> ⊔ <em>J</em> such that all the foreign keys match, and similarly for <em>J</em>. This also works for the vertex tables. These matches are readily visible graph homomorphisms <em>I</em> → <em>I</em> ⊔ <em>J</em> and <em>J</em> → <em>I</em> ⊔ <em>J</em> in <strong>Grph</strong>.</p>
<p><em>Exercise</em> 6.1.1.22.</p>
<p>Recall from Example <a href="chapter004.html#Exa_4-5-2-10">4.5.2.10</a> that a discrete dynamical system (DDS) is a set <em>s</em> together with a function <em>f</em> : <em>s</em> → <em>s</em>; if</p>
<p><img src="images/Art_P236.jpg" alt="art" /></p>
<p>is the loop schema, then a DDS is simply an instance (a functor) <em>I</em> : Loop → <strong>Set</strong>. We have not yet discussed DDS coproducts but perhaps you can guess how they should work. For example, consider these instances <em>I</em>, <em>J</em> : Loop → <strong>Set</strong>:</p>
<p><img src="images/Art_P237.jpg" alt="art" /></p>
<p>Make a guess and tabulate <em>I</em> ⊔ <em>J</em>. Then draw it.</p>
<p>In each case (preorders, graphs, DDSs), what is most important to recognize is that there are inclusion maps <em>I</em> → <em>I</em> ⊔ <em>J</em> and <em>J</em> → <em>I</em> ⊔ <em>J</em>, and that the construction of <em>I</em> ⊔ <em>J</em> seems as straightforward as possible, subject to having these inclusions.</p>
<p><strong>Definition 6.1.1.23</strong>. Let C be a category, and let X,Y∈Ob(C) be objects. A <em>cospan on X and Y</em> consists of three constituents (<em>Z</em>, <em>i</em>, <em>j</em>), where Z∈Ob(C) is an object, and where <em>i</em> : <em>X</em> → <em>Z</em> and <em>j</em> : <em>Y</em> → <em>Z</em> are morphisms in C.</p>
<p><img src="images/Art_P238.jpg" alt="art" /></p>
<p><em>A coproduct of X and Y</em> is a cospan X→ι1X⊔Y←ι2Y, such that for any other cospan X→iZ←jY there <em>exists a unique</em> morphism <em>s</em><sub><em>i</em>,<em>j</em></sub> : <em>X</em> ⊔ <em>Y</em> → <em>Z</em> such that the following diagram commutes:<sup><a href="chapter006.html#endnote_6">6</a></sup></p>
<p><img src="images/Art_P239.jpg" alt="art" /></p>
<p>The morphism <em>s</em><sub><em>i</em>,<em>j</em></sub> is often denoted {ij :X⊔Y→Z .</p>
<p><em>Remark</em> 6.1.1.24. Definition <a href="chapter006.html#Def_6-1-1-8">6.1.1.8</a> endows the coproduct of two objects with a <em>universal property</em>. It says that a coproduct of two objects <em>X</em> and <em>Y</em> receives maps from those two objects, and serves as a gateway for all that do the same. “None shall receive maps from <em>X</em> and <em>Y</em> except through me!” This grandiose property is held by all the coproducts discussed so far. It is what is meant by “<em>X</em> ⊔ <em>Y</em> receives maps from both <em>X</em> and <em>Y</em> and does so as straightforwardly as possible.” The disjoint union of dots obtained as the coproduct of two sets has such a property (see Example <a href="chapter003.html#Exa_3-1-2-5">3.1.2.5</a>).</p>
<p><em>Example</em> 6.1.1.25. By Proposition <a href="chapter005.html#Pro_5-2-1-13">5.2.1.13</a>, there is a functor <strong>PrO</strong> → <strong>Cat</strong> that realizes every preorder as a category. If P=(P,≤) is a preorder, what are coproducts in P? Given two objects a,b∈Ob(P), we first consider {<em>a</em>, <em>b</em>} cospans, i.e., <em>a</em> → <em>z</em> ← <em>b</em>. A cospan of <em>a</em> and <em>b</em> is any <em>z</em> such that <em>a</em> ≤ <em>z</em> and <em>b</em> ≤ <em>z</em>. The coproduct will be such a cospan <em>a</em> ≤ <em>a</em> ⊔ <em>b</em> ≥ <em>b</em>, but such that every other cospanning object <em>z</em> is greater than or equal to <em>a</em> ⊔ <em>b</em>. In other words, <em>a</em> ⊔ <em>b</em> is as small as possible subject to the condition of being bigger than <em>a</em> and bigger than <em>b</em>. This is precisely their join, <em>a</em> ∨ <em>b</em> (see Definition <a href="chapter004.html#Def_4-4-2-1">4.4.2.1</a>).</p>
<p>Just as for products, the coproduct of two objects in a category C may not exist, or it may not be unique. The nonuniqueness is much less “bad” because given two candidate coproducts, they will be canonically isomorphic. They may not be equal, but they are isomorphic. But coproducts might not exist at all in certain categories.</p>
<p><em>Example</em> 6.1.1.26. Consider the set ℝ<sup>2</sup> and partial order from Example <a href="chapter006.html#Exa_6-1-1-11">6.1.1.11</a>, where (<em>x</em><sub>1</sub>, <em>y</em><sub>1</sub>) ≤ (<em>x</em><sub>2</sub>, <em>y</em><sub>2</sub>) if there exists <em>ℓ</em> ≥ 1 such that <em>x</em><sub>1</sub><em>ℓ</em> = <em>x</em><sub>2</sub> and <em>y</em><sub>1</sub><em>ℓ</em> = <em>y</em><sub>2</sub>. Again the points <em>p</em> ≔ (1, 0) and <em>q</em> ≔ (0, 1) do not have a coproduct. Indeed, it would have to be a nonzero point that was on the same line through the origin as <em>p</em> and the same line through the origin as <em>q</em>, of which there are none.</p>
<p><em>Exercise</em> 6.1.1.27.</p>
<p>Consider the preorder P of cards in a deck, shown in Example <a href="chapter004.html#Exa_4-4-1-3">4.4.1.3</a>; it is not the whole story of cards in a deck, but take it to be so. Consider this preorder P as a category (by way of the functor <strong>PrO</strong> → <strong>Cat</strong>).</p>
<p>a. For each of the following pairs, what is their coproduct in P (if it exists)?</p>
<p>⌜a diamond⌝⊔⌜a heart⌝⌜a queen⌝⊔⌜a black card⌝⌜a card⌝⊔⌜a red card⌝⌜a face card⌝⊔⌜a black card⌝</p>
<p>b. How would these answers differ if P were completed to the “whole story” partial order classifying cards in a deck?</p>
<p><em>Exercise</em> 6.1.1.28.</p>
<p>Let <em>X</em> be a set, and consider it as a discrete category. Given two objects <em>x</em>, <em>y</em> ∈ Ob(<em>X</em>), under what conditions will there exist a coproduct <em>x</em> ⊔ <em>y</em>?</p>
<p><em>Exercise</em> 6.1.1.29.</p>
<p>Consider the preorder (ℕ, divides), discussed in Example <a href="chapter004.html#Exa_4-4-3-2">4.4.3.2</a>, where, e.g., 5 ≤ 15, but 5 ≰ 6.</p>
<p>a. What is the coproduct of 9 and 12 in that category?</p>
<p>b. Is there a standard name for coproducts in that category?</p>
<h2 id="lev_6-1-2" class="level2"><strong>6.1.2   Diagrams in a category</strong></h2>
<p>Diagrams have illustrated the text throughout the book. What is the mathematical foundation of these illustrations? The answer is functors.</p>
<p><strong>Definition 6.1.2.1</strong> (Diagrams). Let C and <em>I</em> be categories. An <em>I-shaped diagram in</em> C is simply a functor d:I→C. In this case <em>I</em> is called the <em>indexing category</em> for the diagram.<sup><a href="chapter006.html#endnote_7">7</a></sup></p>
<p>Here are some rules for drawing diagrams as in Definition <a href="chapter006.html#Def_6-1-2-1">6.1.2.1</a>.</p>
<p><em>Rules of good practice</em> 6.1.2.2. Suppose given an indexing category <em>I</em> and an <em>I</em>-shaped diagram X:I→C. One draws this as follows:</p>
<p>(i) For each object in <em>q</em> ∈ <em>I</em>, draw a dot labeled by <em>X</em>(<em>q</em>); if several objects in <em>I</em> point to the same object in C, then several dots are labeled the same way.</p>
<p>(ii) For each morphism <em>f</em> : <em>q</em> → <em>q</em>′ in <em>I</em>, draw an arrow between dots <em>X</em>(<em>q</em>) and <em>X</em>(<em>q</em>′), and label it <em>X</em>(<em>f</em>) in C. Again, if several morphisms in <em>I</em> are sent to the same morphism in C, then several arrows are labeled the same way.</p>
<p>(iii) One can abridge this process by not drawing <em>every</em> morphism in <em>I</em>, as long as every morphism in <em>I</em> is represented by a unique path in C, i.e., as long as the drawing is sufficiently unambiguous as a depiction of X:I→C.</p>
<p>(iv) One may choose to draw a dash box around the finished diagram <em>X</em> to indicate that it is referencing an ambient category C.</p>
<p><em>Example</em> 6.1.2.3. Consider the commutative diagram in <strong>Set</strong>:</p>
<p><img src="images/Art_P240.jpg" alt="art" /></p>
<p>This is the drawing of a functor <em>d</em> : [1] × [1] → <strong>Set</strong> (see Example <a href="chapter006.html#Exa_6-1-1-17">6.1.1.17</a>). With notation for the objects and morphisms of [1] × [1], as shown in diagram (<a href="chapter006.html#eq_6-1">6.1</a>), we have <em>d</em>(0, 0) = <em>d</em>(0, 1) = <em>d</em>(1, 0) = ℕ and <em>d</em>(1, 1) = ℤ (for some reason) and <em>d</em>(id<sub>0</sub>, <em>f</em>): ℕ → ℕ given by <em>n</em> ↦ <em>n</em> + 1, and so on. The fact that <em>d</em> is a functor means it must respect composition formulas, which implies that diagram (<a href="chapter006.html#eq_6-2">6.2</a>) commutes. We call [1] × [1] the <em>commutative square indexing category</em>. <sup><a href="chapter006.html#endnote_8">8</a></sup></p>
<p><em>Example</em> 6.1.2.4. Recall from Section <a href="chapter002.html#lev_2-2">2.2</a> that not all diagrams commute; one must specify that a given diagram commutes if one wishes to communicate this fact. But then, how is a <em>noncommuting diagram</em> to be understood as a functor?</p>
<p>Let <em>G</em> ∈ Ob(<strong>Grph</strong>) denote the following graph:</p>
<p><img src="images/Art_P241.jpg" alt="art" /></p>
<p>Recall the free category functor <em>F</em> : <strong>Grph</strong> → <strong>Cat</strong> (see Example <a href="chapter005.html#Exa_5-1-2-33">5.1.2.33</a>). The free category <em>F</em> (<em>G</em>) ∈ Ob(<strong>Cat</strong>) on <em>G</em> looks almost like [1]×[1] in Example <a href="chapter006.html#Exa_6-1-2-3">6.1.2.3</a> except that since <sub>(0,0)</sub>[<em>f</em>, <em>g</em>] is a different path in <em>G</em> than is <sub>(0,0)</sub>[<em>h</em>, <em>i</em>], they become different morphisms in <em>F</em>(<em>G</em>). A functor <em>F</em>(<em>G</em>) → <strong>Set</strong> might be drawn the same way that (<a href="chapter006.html#eq_6-2">6.2</a>) is, but it would be a diagram that would <em>not</em> be said to commute.</p>
<p><em>Exercise</em> 6.1.2.5.</p>
<p>Consider [2], the linear order category of length 2.</p>
<p>a. Is [2] the appropriate indexing category for commutative triangles?</p>
<p>b. If not, what is? If so, what might lead someone to be skeptical, and why would the skeptic be wrong?</p>
<p><em>Example</em> 6.1.2.6. Recall that an equalizer in <strong>Set</strong> is a diagram of sets that looks like this:</p>
<p><img src="images/Art_P242.jpg" alt="art" /></p>
<p>where <em>g</em><sub>1</sub> ○ <em>f</em> = <em>g</em><sub>2</sub> ○ <em>f</em>. What is the indexing category for such a diagram? It is the schema (<a href="chapter006.html#eq_6-3">6.3</a>) with the PED <sub><em>E</em></sub>[<em>f</em>, <em>g</em><sub>1</sub>] ≃ <sub><em>E</em></sub>[<em>f</em>, <em>g</em><sub>2</sub>]. That is, in some sense one sees the indexing category, but the PED needs to be declared.</p>
<p><em>Exercise</em> 6.1.2.7.</p>
<p>Let C be a category, A∈Ob(C) an object, and <em>f</em> : <em>A</em> → <em>A</em> a morphism in C. Consider the following two diagrams in C:</p>
<p><img src="images/Art_P243.jpg" alt="art" /></p>
<p>a. Should these two diagrams have the same indexing category?</p>
<p>b. Write the indexing category for both.</p>
<p>c. If they have the same indexing category, what is causing or allowing the pictures to appear different?</p>
<p>d. If they do not have the same indexing category, what coincidence makes the two pictures have so much in common?</p>
<p><strong>Definition 6.1.2.8</strong>. Let <em>I</em> ∈ Ob(<strong>Cat</strong>) be a category. The <em>left cone on I</em>, denoted <em>I</em><sup>◅</sup>, is the category defined as follows. On objects we put Ob(<em>I</em><sup>◅</sup>) = {<em>LC<sub>I</sub></em>} ⊔ Ob(<em>I</em>), and we call the new object <em>LC<sub>I</sub></em> the <em>cone point of I</em><sup>◅</sup>. On morphisms we add a single new morphism <em>s<sub>b</sub></em> : <em>LC<sub>I</sub></em> → <em>b</em> for every object <em>b</em> ∈ Ob(<em>I</em>); more precisely,</p>
<p>HomI◅(a,b)={HomI(a,b)if a,b∈Ob(I),{sb}if a=LCI,b∈Ob(I),{idLCI}if a=b=LCI∅if a∈Ob(I),b=LCI.</p>
<p>The composition formula is in some sense obvious. To compose two morphisms both in <em>I</em>, compose as dictated by <em>I</em>; if one has <em>LC<sub>I</sub></em> as source, then there will be a unique choice of composite.</p>
<p>There is an obvious inclusion of categories,</p>
<p>I→I◅.(6.4)</p>
<p><em>Remark</em> 6.1.2.9. Note that the specification of <em>I</em><sup>◅</sup> given in Definition <a href="chapter006.html#Def_6-1-2-8">6.1.2.8</a> works just as well if <em>I</em> is considered a schema and we are constructing a schema <em>I</em><sup>◅</sup>: add the new object <em>LC<sub>I</sub></em> and the new arrows <em>s<sub>b</sub></em> : <em>LC<sub>I</sub></em> → <em>b</em> for each <em>b</em> ∈ Ob(<em>I</em>), and for every morphism <em>f</em> : <em>b</em> → <em>b</em>′ in <em>I</em>, add a PED [sb′]LCI ≃[sb,f]LCI . We generally do not distinguish between categories and schemas, since they are equivalent, by Theorem <a href="chapter005.html#The_5-4-2-3">5.4.2.3</a>.</p>
<p><em>Example</em> 6.1.2.10. For a natural number <em>n</em> ∈ ℕ, define the <em>n-leaf star schema</em>, denoted <strong>Star</strong><em><sub>n</sub></em>, to be the category (or schema; see Remark <a href="chapter006.html#Rem_6-1-2-9">6.1.2.9</a>) <em>n</em><sup>◅</sup>, where <em>n</em> is the discrete category on <em>n</em> objects. The following illustrate the categories <strong>Star</strong><sub>0</sub>, <strong>Star</strong><sub>1</sub>, <strong>Star</strong><sub>2</sub>, and <strong>Star</strong><sub>3</sub>:</p>
<p><img src="images/Art_P244.jpg" alt="art" /></p>
<p><em>Exercise</em> 6.1.2.11.</p>
<p>Let C0≔0¯ denote the empty category, and for any natural number <em>n</em> ∈ ℕ, let Cn+1=(Cn)◅. Draw C4.</p>
<p><em>Exercise</em> 6.1.2.12.</p>
<p>Let C be the graph-indexing schema as in (5.8). What is C◅, and how does it compare to the indexing category for equalizers, (<a href="chapter006.html#eq_6-3">6.3</a>)?</p>
<p><em>Solution</em> 6.1.2.12.</p>
<p>They are the same,</p>
<p><img src="images/Art_P245.jpg" alt="art" /></p>
<p>where the latter is understood to include the PED <sub><em>E</em></sub>[<em>f</em>, <em>g</em><sub>1</sub>] = <sub><em>E</em></sub>[<em>f</em>, <em>g</em><sub>2</sub>].</p>
<p><strong>Definition 6.1.2.13</strong>. Let <em>I</em> ∈ Ob(<strong>Cat</strong>) be a category. The <em>right cone on I</em>, denoted <em>I</em><sup>▻</sup>, is the category defined as follows. On objects we put Ob(<em>I</em><sup>▻</sup>) = Ob(<em>I</em>) ⊔ {<em>RC<sub>I</sub></em>}, and we call the new object <em>RC<sub>I</sub></em> the <em>cone point of I</em><sup>▻</sup>. On morphisms we add a single new morphism <em>t<sub>b</sub></em> : <em>b</em> → <em>RC<sub>I</sub></em> for every object <em>b</em> ∈ Ob(<em>I</em>); more precisely,</p>
<p>HomI▻(a,b)={HomI(a,b)if a,b∈Ob(I),{tb}if a∈Ob(I),b=RCI,{idRCI}if a=b=RCI,∅if a=RCI,b∈Ob(I).</p>
<p>The composition formula is in some sense obvious. To compose two morphisms both in <em>I</em>, compose as dictated by <em>I</em>; if one has <em>RC<sub>I</sub></em> as target, then there will be a unique choice of composite.</p>
<p>There is an obvious inclusion of categories <em>I</em> → <em>I</em><sup>▻</sup>.</p>
<p><em>Exercise</em> 6.1.2.14.</p>
<p>Let C be the category (2<sup>◅</sup>)<sup>▻</sup>, where 2 is the discrete category on two objects. Then C is somehow square-shaped, but what category is it exactly? Is C the commutative square indexing category [1] × [1] (see Example <a href="chapter006.html#Exa_6-1-2-3">6.1.2.3</a>), is it the noncommutative square indexing category <em>F</em> (<em>G</em>) (see Example <a href="chapter006.html#Exa_6-1-2-4">6.1.2.4</a>), or is it something else?</p>
<p><em>Exercise</em> 6.1.2.15.</p>
<p>Let <em>I</em> = 2, let C be an arbitrary category, and let D=Fun(I◅,C).</p>
<p>a. Using Rules <a href="chapter006.html#rul_6-1-2-2">6.1.2.2</a>, draw an object <em>d</em> ∈ Ob(<em>D</em>).</p>
<p>b. How might you draw a morphism <em>f</em> : <em>d</em> → <em>d</em>′ in <em>D</em>?</p>
<p><em>Solution</em> 6.1.2.15.</p>
<p>a. We have <em>I</em><sup>◅</sup> = <strong>Star</strong><sub>2</sub>, as in Example <a href="chapter006.html#Exa_6-1-2-10">6.1.2.10</a>. We can draw an object d:I◅→C as a span,</p>
<p>d1←id0→jd2.</p>
<p>b. We could draw <em>f</em> : <em>d</em> → <em>d</em>′ as</p>
<p><img src="images/Art_P246.jpg" alt="art" /></p>
<h2 id="lev_6-1-3" class="level2"><strong>6.1.3   Limits and colimits in a category</strong></h2>
<p>Let C be a category, let <em>I</em> be an indexing category (which means that <em>I</em> is a category that we use as the indexing category for a diagram), and let D:I→C be an <em>I</em>-shaped diagram (which means a functor). It is in relation to this setup that we can discuss the limit or colimit. In general, the limit of a diagram D:I→C is a <em>I</em><sup>◅</sup> shaped diagram, lim D:I◅→C. In the case of products we have <em>I</em> = 2, and the limit looks like a span, the shape of <em>I</em><sup>◅</sup> (see Exercise <a href="chapter006.html#Exe_6-1-2-15">6.1.2.15</a>). For general <em>I</em>, <em>D</em> we may have many <em>I</em><sup>◅</sup>-shaped diagrams; which of them is the limit of <em>D</em>? Answer: The one with the universal gateway property; see Remark <a href="chapter006.html#Rem_6-1-1-9">6.1.1.9</a>.</p>
<h3 id="lev_6-1-3-1" class="level3"><strong>6.1.3.1   Universal objects</strong></h3>
<p><strong>Definition 6.1.3.2</strong>. Let C be a category. An object a∈Ob(C) is called <em>initial</em> if, for all objects c∈Ob(C), there exists a unique morphism <em>a</em> → <em>c</em>, i.e., |HomC(a,c)|=1. An object z∈Ob(C) is called <em>terminal</em> if, for all objects c∈Ob(C), there is exists a unique morphism <em>c</em> → <em>z</em>, i.e., |HomC(c,z)|=1.</p>
<p><em>Example</em> 6.1.3.3. For any category <em>I</em>, the left cone <em>I</em><sup>◅</sup> has a unique initial object, and the right cone <em>I</em><sup>▻</sup> has a unique terminal object; in both cases it is the cone point. See Definitions <a href="chapter006.html#Def_6-1-2-8">6.1.2.8</a> and <a href="chapter006.html#Def_6-1-2-13">6.1.2.13</a>.</p>
<p><em>Example</em> 6.1.3.4. The initial object in <strong>Set</strong> is the set <em>a</em> for which there is always one way to map from <em>a</em> to anything else. Given <em>c</em> ∈ Ob(<strong>Set</strong>), there is exactly one function Ø → <em>c</em>, because there are no choices to be made, so the empty set Ø is the initial object in <strong>Set</strong>.</p>
<p>The terminal object in <strong>Set</strong> is the set <em>z</em> for which there is always one way to map to <em>z</em> from anything else. Given <em>c</em> ∈ Ob(<strong>Set</strong>), there is exactly one function <em>c</em> → {☺}, where {☺} is any set with one element, because there are no choices to be made: everything in <em>c</em> must be sent to the single element in {☺}. There are lots of terminal objects in <strong>Set</strong>, and they are all isomorphic to 1.</p>
<p><em>Example</em> 6.1.3.5. The initial object in <strong>Grph</strong> is the graph <em>a</em> for which there is always one way to map from <em>a</em> to anything else. Given <em>c</em> ∈ Ob(<strong>Grph</strong>), there is exactly one graph homomorphism Ø → <em>c</em>, where Ø ∈ Ob(<strong>Grph</strong>) is the empty graph; so Ø is the initial object.</p>
<p>The terminal object in <strong>Grph</strong> is more interesting. It is</p>
<p><img src="images/Art_P247.jpg" alt="art" /></p>
<p>the graph with one vertex and one arrow. In fact, there are infinitely many terminal objects in <strong>Grph</strong>, but all of them are isomorphic to Loop, meaning one can change the names of the vertex (<em>s</em>) and the arrow (<em>f</em>) and get another terminal object.</p>
<p><em>Exercise</em> 6.1.3.6.</p>
<p>Let <em>X</em> be a set, let ℙ(<em>X</em>) be the set of subsets of <em>X</em> (see Definition <a href="chapter003.html#Def_3-4-4-9">3.4.4.9</a>). We can regard ℙ(<em>X</em>) as a preorder under inclusion of subsets (see, for example, Section <a href="chapter004.html#lev_4-4-2">4.4.2</a>). And we can regard preorders as categories using a functor <strong>PrO</strong> → <strong>Cat</strong> (see Proposition <a href="chapter005.html#Pro_5-2-1-13">5.2.1.13</a>).</p>
<p>a. What is the initial object in ℙ(<em>X</em>)?</p>
<p>b. What is the terminal object in ℙ(<em>X</em>)?</p>
<p><em>Example</em> 6.1.3.7. The initial object in the category <strong>Mon</strong> of monoids is the trivial monoid, 1. Indeed, for any monoid <em>M</em>, a morphism of monoids 1 → <em>M</em> is a functor between one-object categories and these are determined by where they send morphisms. Since 1 has only the identity morphism and functors must preserve identities, there is no choice involved in finding a monoid morphism 1 → <em>M</em>.</p>
<p>Similarly, the terminal object in <strong>Mon</strong> is also the trivial monoid, 1. For any monoid <em>M</em>, a morphism of monoids <em>M</em> → 1 sends everything to the identity; there is no choice.</p>
<p><em>Exercise</em> 6.1.3.8.</p>
<p>a. What is the initial object in <strong>Grp</strong>, the category of groups?</p>
<p>b. What is the terminal object in <strong>Grp</strong>?</p>
<p><em>Example</em> 6.1.3.9. Recall the preorder <strong>Prop</strong> of logical propositions from Section <a href="chapter005.html#lev_5-2-4-1">5.2.4.1</a>. The initial object is a proposition that implies all others. It turns out that “FALSE” is such a proposition. The proposition “FALSE” is like “1 ≠ 1”; in logical formalism it can be shown that if “FALSE” is true, then everything is true.</p>
<p>The terminal object in <strong>Prop</strong> is a proposition that is implied by all others. It turns out that “TRUE” is such a proposition. In logical formalism, everything implies that “TRUE” is true.</p>
<p><em>Example</em> 6.1.3.10. The discrete category 2 has no initial object and no terminal object. The reason is that it has two objects 1, 2, but no maps from one to the other, so Hom<sub>2</sub>(1, 2) = Hom<sub>2</sub>(2, 1) = Ø.</p>
<p><em>Exercise</em> 6.1.3.11.</p>
<p>Recall the divides preorder (see Example <a href="chapter004.html#Exa_4-4-3-2">4.4.3.2</a>), where 5 divides 15.</p>
<p>a. Considering this preorder as a category, does it have an initial object?</p>
<p>b. Does it have a terminal object?</p>
<p><em>Exercise</em> 6.1.3.12.</p>
<p>Let M = (List({<em>a</em>, <em>b</em>}), [ ], ++) denote the free monoid on the set {<em>a</em>, <em>b</em>} (see Definition <a href="chapter004.html#Def_4-1-1-15">4.1.1.15</a>) considered as a category via the functor <strong>Mon</strong> → <strong>Cat</strong> (see Theorem <a href="chapter005.html#The_5-2-1-3">5.2.1.3</a>).</p>
<p>a. Does M have an initial object?</p>
<p>b. Does M have a terminal object?</p>
<p>c. Which monoids M, considered as one-object categories, have initial (resp. terminal) objects?</p>
<p><em>Exercise</em> 6.1.3.13.</p>
<p>Let <em>S</em> be a set, and consider the indiscrete category <em>K<sub>S</sub></em> ∈ Ob(<strong>Cat</strong>) on objects <em>S</em> (see Example <a href="chapter005.html#Exa_5-3-4-3">5.3.4.3</a>).</p>
<p>a. For what <em>S</em> does <em>K<sub>S</sub></em> have an initial object?</p>
<p>b. For what <em>S</em> does <em>K<sub>S</sub></em> have a terminal object?</p>
<p>An object in a category is sometimes called <em>universal</em> if it is either initial or terminal, but we rarely use that term in practice, preferring to be specific about whether the object is initial or terminal. The word <em>final</em> is synonymous with the word <em>terminal</em>, but we will use the latter.</p>
<p><em>Universal properties</em> refer to either initial or terminal objects in a specially-designed category. Colimits end up having an initial sort of universal property, and limits end up having a terminal sort of universal property. See Section <a href="chapter006.html#lev_6-1-3-16">6.1.3.16</a>.</p>
<p><em>Warning</em> 6.1.3.14. A category C may have more than one initial object; similarly a category C may have more than one terminal object. As shown in Example <a href="chapter006.html#Exa_6-1-3-4">6.1.3.4</a>, any set with one element, e.g., {*} or {☺} or {43}, is a terminal object in <strong>Set</strong>. Each of these terminal sets has the same number of elements, i.e., there exists an isomorphism between them, but they are not exactly the same set.</p>
<p>In fact, Proposition <a href="chapter006.html#Pro_6-1-3-15">6.1.3.15</a> shows that in any category C, any two terminal objects in C are isomorphic (similarly, any two initial objects in C are isomorphic). While there are many isomorphisms in <strong>Set</strong> between {1, 2, 3} and {<em>a</em>, <em>b</em>, <em>c</em>}, there is only one isomorphism between {*} and {☺}. This is always the case for universal objects: there is a unique isomorphism between any two terminal (resp. initial) objects in any category.</p>
<p>As a result, we often speak of <em>the</em> initial object in C or <em>the</em> terminal object in C, as though there were only one. “It is unique up to unique isomorphism” is put forward as the justification for using <em>the</em> rather than <em>a</em>. This is not too misleading, because just as a person today does not contain exactly the same atoms as that person yesterday, the difference is unimportant.</p>
<p>This book uses either the definite or the indefinite article, as is convenient, when speaking about initial or terminal objects. For example, Example <a href="chapter006.html#Exa_6-1-3-4">6.1.3.4</a> discussed <em>the</em> initial object in <strong>Set</strong> and <em>the</em> terminal object in <strong>Set</strong>. This usage is common throughout mathematical literature.</p>
<p><strong>Proposition 6.1.3.15</strong>. <em>Let</em> C <em>be a category, and let</em> a1,a2∈Ob(C) <em>both be initial objects. Then there is a unique isomorphism</em> f:a1→≅a2. <em>(Similarly, for any two terminal objects in</em> C, <em>there is a unique isomorphism between them.)</em></p>
<p><em>Proof.</em> Suppose <em>a</em><sub>1</sub> and <em>a</em><sub>2</sub> are initial. Since <em>a</em><sub>1</sub> is initial, there is a unique morphism <em>f</em> : <em>a</em><sub>1</sub> → <em>a</em><sub>2</sub>; there is also a unique morphism <em>a</em><sub>1</sub> → <em>a</em><sub>1</sub>, which must be id<sub><em>a</em>1</sub>. Since <em>a</em><sub>2</sub> is initial, there is a unique morphism <em>g</em> : <em>a</em><sub>2</sub> → <em>a</em><sub>1</sub>; there is also a unique morphism <em>a</em><sub>2</sub> → <em>a</em><sub>2</sub>, which must be id<sub><em>a</em>2</sub>. So <em>g</em> ○ <em>f</em> = id<sub><em>a</em>1</sub> and <em>f</em> ○ <em>g</em> = id<sub><em>a</em>2</sub>, which means that <em>f</em> is the desired (unique) isomorphism.</p>
<p>The proof for terminal objects is appropriately dual.</p>
<h3 id="lev_6-1-3-16" class="level3"><strong>6.1.3.16   Examples of limits</strong></h3>
<p>We are moving toward defining limits and colimits in full generality. We have assembled most of the pieces we will need: indexing categories, their left and right cones, and the notion of initial and terminal objects. Relying on the now familiar notion of products, we put these pieces in place and motivate one more construction, the slice category over a diagram.</p>
<p>Let C be a category, and let X,Y∈Ob(C) be objects. Definition <a href="chapter006.html#Def_6-1-1-8">6.1.1.8</a> defines a product of <em>X</em> and <em>Y</em> to be a span X←π1X×Y→π2Y such that for every other span X←pZ→qY, there exists a unique morphism <em>Z</em> → <em>X</em> × <em>Y</em> making the triangles commute. It turns out that we can enunciate this in the language of universal objects by saying that the span X←π1X×Y→π2Y is itself a terminal object in the category of {<em>X</em>, <em>Y</em>} spans. Phrasing the definition of products in this way is generalizable to defining arbitrary limits.</p>
<p><em>Construction</em> 6.1.3.17 (Products). Let C be a category, and let <em>X</em><sub>1</sub>, <em>X</em><sub>2</sub> be objects. We can consider this setup as a diagram X:2¯→C, where <em>X</em>(1) = <em>X</em><sub>1</sub> and <em>X</em>(2) = <em>X</em><sub>2</sub>. Consider the category 2<sup>◅</sup> = <strong>Star</strong><sub>2</sub> (see Example <a href="chapter006.html#Exa_6-1-2-10">6.1.2.10</a>), the inclusion <em>i</em> : 2 → 2<sup>◅</sup> (see (<a href="chapter006.html#eq_6-4">6.4</a>)), and the category of functors Fun(2¯◅,C ). The objects in Fun(2¯◅,C ) are spans in C, and the morphisms are natural transformations between them (see Exercise <a href="chapter006.html#Exe_6-1-2-15">6.1.2.15</a>).</p>
<p>Given a functor S:2¯◅→C, we can compose with <em>i</em> : 2 → 2<sup>◅</sup> to get a functor 2¯→C. We want that to be <em>X</em>. That is, to get the product of <em>X</em><sub>1</sub> and <em>X</em><sub>2</sub>, we are looking among those S:2¯◅→C for which the following diagram commutes:</p>
<p><img src="images/Art_P248.jpg" alt="art" /></p>
<p>We are ready to define the category of {<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>} spans.</p>
<p>Define the <em>category of X spans in</em> C, <em>denoted</em> C/X, to be the category whose objects and morphisms are as follows:</p>
<p>Ob(C/X)={S:2¯◅→C|S○i=X}HomC/X(S,S′)={α:S→S′|α◇i=idX}.(6.5)</p>
<p>The product of <em>X</em><sub>1</sub> and <em>X</em><sub>2</sub> was defined in Definition <a href="chapter006.html#Def_6-1-1-8">6.1.1.8</a>; we can now recast <em>X</em><sub>1</sub> × <em>X</em><sub>2</sub> as the terminal object in C/X.</p>
<p>An object in C/X can be pictured as a diagram in C of the following form:</p>
<p>X1←pZ→qX2</p>
<p>In other words, the objects of C/X are spans. A morphism in C/X from object X1←pZ→qX2 to object X1← p′ Z′→ q′X2 consists of a morphism <em>ℓ</em> : <em>Z</em> → <em>Z</em>′, such that <em>p</em>′ ○ <em>ℓ</em> = <em>p</em> and <em>q</em>′ ○ <em>ℓ</em> = <em>q</em>. So the set of such morphisms in C/X are all the <em>ℓ</em>’s that make both squares commute in the right-hand diagram:</p>
<p><img src="images/Art_P249.jpg" alt="art" /></p>
<p>Each object in C/X is a span on <em>X</em><sub>1</sub> and <em>X</em><sub>2</sub>, and each morphism in C/X is a morphism of cone points in C making everything commute. The terminal object in C/X is the product of <em>X</em><sub>1</sub> and <em>X</em><sub>2</sub> (see Definition <a href="chapter006.html#Def_6-1-1-8">6.1.1.8</a>).</p>
<p>It may be strange to have a category in which the objects are spans in another category. But once one admits this possibility, the notion of morphism between spans becomes totally sensible.</p>
<p><em>Example</em> 6.1.3.18. Consider the following arbitrary six-object category C, in which the three diagrams that can commute do so:</p>
<p><img src="images/Art_P250.jpg" alt="art" /></p>
<p>Let X:2¯→C be given by <em>X</em>(1) = <em>X</em><sub>1</sub> and <em>X</em>(2) = <em>X</em><sub>2</sub>. Then the category of <em>X</em> spans might be drawn</p>
<p><img src="images/Art_P251.jpg" alt="art" /></p>
<h3 id="lev_6-1-3-19" class="level3"><strong>6.1.3.19   Definition of limit</strong></h3>
<p>A product of two objects <em>X</em>, <em>Y</em> ∈ Ob() is a special case of a limit, namely, one in which the indexing category is 2. To handle arbitrary limits, we replace 2 with an arbitrary indexing category <em>I</em>, and use the following definition to generalize the category of spans, defined in (<a href="chapter006.html#eq_6-5">6.5</a>).</p>
<p><strong>Definition 6.1.3.20</strong>. Let C be a category, let <em>I</em> be a category. Let <em>I</em><sup>◅</sup> be the left cone on <em>I</em>, and let <em>i</em> : <em>I</em> → <em>I</em><sup>◅</sup> be the inclusion. Suppose that X:I→C is an <em>I</em>-shaped diagram in C. The <em>slice category of</em> C <em>over X</em>, denoted C/X, is the category whose objects and morphisms are as follows:</p>
<p>Ob(C/X)={S:I◅→C|S○i=X}; HomC/X(S,S′)={α:S→S′|α○i=idX}.</p>
<p>A <em>limit of X</em>, denoted lim<em><sub>I</sub></em> <em>X</em> or lim <em>X</em>, is a terminal object in C/X.</p>
<p><em>Remark</em> 6.1.3.21. Perhaps the following diagram will be helpful for understanding limits. Given a functor X:I→C, what is its limit? The solid-arrow part of the figure is the data we start with, i.e., the category C, the indexing category <em>I</em>, and the diagram X:I→C, as well as the part we automatically add, the cone <em>I</em><sup>◅</sup> with the inclusion I→iI◅. The category C/X is found in the dotted arrow part: its objects are the dotted arrows S:I◅→C that make the following triangle commute, and its morphisms are the natural transformations <em>α</em> : <em>S</em> → <em>S</em>′x between them:</p>
<p><img src="images/Art_P252.jpg" alt="art" /></p>
<p>The limit of <em>X</em> is the initial object in this category.</p>
<p><strong>Pullbacks</strong> The relevant indexing category for pullbacks is the cospan, <em>I</em> = 2<sup>▻</sup>, drawn as on the left:</p>
<p><img src="images/Art_P253.jpg" alt="art" /></p>
<p>A <em>I</em>-shaped diagram in C is a functor X:I→C, which might be drawn as on the right (e.g., X0∈Ob(C)).</p>
<p>An object <em>S</em> in the slice category C/X is a commutative diagram <em>S</em> : <em>I</em><sup>◅</sup> → C over <em>X</em>, which looks like the left-hand box:</p>
<p><img src="images/Art_P254.jpg" alt="art" /></p>
<p>A morphism in C/X is drawn as in the right-hand box. A terminal object in C/X is precisely the gateway we want, i.e., the limit of <em>X</em> is the pullback X0×X2X1 (see Remark <a href="chapter006.html#Rem_6-1-1-9">6.1.1.9</a>).</p>
<p><em>Remark</em> 6.1.3.22. Let C be a category, and suppose given a functor X:I→C. Its limit is a certain functor lim X:I◅→C. The category <em>I</em><sup>◅</sup> looks basically the same as <em>I</em>, except it has an extra cone point <em>LC<sub>I</sub></em> mapping to everything in <em>I</em> (see Definition <a href="chapter006.html#Def_6-1-2-8">6.1.2.8</a>). The functor lim <em>X</em> can be applied to this object in <em>I</em><sup>◅</sup> to get an object in C, and it is this object that people often refer to as the limit of <em>X</em>. We call it the <em>limit set</em> of <em>X</em>.</p>
<p>For example, if <em>I</em> = 2 then a functor X:2¯→C consists of two objects in C, say <em>X</em><sub>1</sub> and <em>X</em><sub>2</sub>. The left cone 2<sup>◅</sup> is the span category, so the limit of <em>X</em> is a span, in particular it is the product span <em>X</em><sub>1</sub> ← <em>X</em><sub>1</sub> × <em>X</em><sub>2</sub> → <em>X</em><sub>2</sub>. But people often speak of the product as if it was just <em>X</em><sub>1</sub> × <em>X</em><sub>2</sub>, the cone point of the span.</p>
<p><em>Exercise</em> 6.1.3.23.</p>
<p>Let <strong>GrIn</strong> be the graph-indexing category (see (5.8)).</p>
<p>a. What is <strong>GrIn</strong><sup>◅</sup>?</p>
<p>b. Let <em>G</em> : <strong>GrIn</strong> → <strong>Set</strong> be the graph from Example <a href="chapter004.html#Exa_4-3-1-2">4.3.1.2</a>. Give an example of an object in <strong>Set</strong><sub>/<em>G</em></sub>.</p>
<p><em>Exercise</em> 6.1.3.24.</p>
<p>Let C be a category, and let <em>I</em> = 0 be the empty category. There is a unique functor X:0¯→C.</p>
<p>a. What is the slice category C/X?</p>
<p>b. What is a limit of <em>X</em>?</p>
<p><em>Solution</em> 6.1.3.24.</p>
<p>a. The left cone of 0 is the terminal category 0<sup>◅</sup> = 1, and since every diagram</p>
<p><img src="images/Art_P255.jpg" alt="art" /></p>
<p>commutes, we have an isomorphism Fun(1¯,C)→≅C/X. But by (<strong>??</strong>), we have an isomorphism C→≅Fun(1¯,C), so in fact C/X≅C.</p>
<p>b. A limit of <em>X</em> is defined to be a terminal object in C/X, which is a terminal object in C, if it exists. In other words, terminal objects in a category give us a canonical example of limits. This was hinted at in Exercise <a href="chapter003.html#Exe_3-2-3-5">3.2.3.5</a>.</p>
<p><em>Example</em> 6.1.3.25. In the course of doing math, random-looking diagrams sometimes come up, for which one wants to take the limit. We have now constructed the limit for any shape diagram. For example, if we wanted to take the product of more than two, say, <em>n</em>, objects, we could use the diagram shape <em>I</em> = <em>n</em>. A functor <em>X</em> : <em>n</em> → <strong>Set</strong> is <em>n</em> sets <em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, … , <em>X<sub>n</sub></em>, and their limit is a functor lim <em>X</em> : <em>n</em><sup>◅</sup> → <strong>Set</strong>,</p>
<p><img src="images/Art_P256.jpg" alt="art" /></p>
<p>which, of course, is the product, XLCn¯=X1×X2×⋯×Xn.</p>
<p><em>Example</em> 6.1.3.26. We have now defined limits in any category, so we have defined limits in <strong>Cat</strong>. Let [1] denote the category depicted</p>
<p>•0→e•1</p>
<p>and let C be an arbitrary category. Naming two categories is the same thing as naming a functor <em>X</em> : 2 → <strong>Cat</strong>; consider the functor <em>X</em>(1) = [1], X(2)=C. The limit of <em>X</em> is a product of categories (see Example <a href="chapter006.html#Exa_6-1-1-17">6.1.1.17</a>); it is denoted [1]×C. It turns out that [1]×C looks like a C-shaped prism. It consists of two panes, front and back, say, each having the precise shape as C (same objects, same arrows, same composition) as well as morphisms from the front pane to the back pane making all front-to-back squares commute. For example, if C was the category generated by the left-hand schema , then C×[1] would be the category generated by the right-hand schema:</p>
<p><img src="images/Art_P257.jpg" alt="art" /></p>
<p>It turns out that a natural transformation <em>α</em> : <em>F</em> → <em>G</em> between functors F,G:C→D is the same thing as a functor C×[1]→D such that the front pane is sent via <em>F</em> and the back pane is sent via <em>G</em>. The components are captured by the front-to-back morphisms, and the naturality is captured by the commutativity of the front-to-back squares in C×[1].</p>
<p><em>Exercise</em> 6.1.3.27.</p>
<p>Recall that Section <a href="chapter003.html#lev_3-4-6-5">3.4.6.5</a> described relative sets. In fact, Definition <a href="chapter003.html#Def_3-4-6-6">3.4.6.6</a> basically defines a category of relative sets over any fixed set <em>B</em>. Let <em>B</em> : 1 → <strong>Set</strong> be the functor representing the object <em>B</em> ∈ Ob(<strong>Set</strong>).</p>
<p>a. What is the relationship between the slice category <strong>Set</strong><sub>/<em>B</em></sub>, as defined in Definition <a href="chapter006.html#Def_6-1-3-20">6.1.3.20</a>, and the category of relative sets over <em>B</em>?</p>
<p>b. What is the limit of the functor <em>B</em> : 1 → <strong>Set</strong>?</p>
<p><strong>Theorem 6.1.3.28</strong>. <em>Let I be a category and let F</em> : <em>I</em> → <strong>Set</strong> <em>be a functor. Then its limit set</em> lim<em><sub>I</sub> F</em> ∈ Ob(<strong>Set</strong>) <em>exists and one can find its elements as follows. An element of the set</em> lim<em><sub>I</sub> F is given by choosing an element of x<sub>i</sub></em> ∈ <em>F</em> (<em>i</em>) <em>for each object i</em> ∈ Ob(<em>I</em>) <em>such that, for each f</em> : <em>i</em> → <em>i</em>′ <em>one has F</em>(<em>f</em>)(<em>x<sub>i</sub></em>) = <em>x</em><sub><em>i</em>′</sub>.</p>
<p><em>Proof.</em> See [29].</p>
<p><em>Exercise</em> 6.1.3.29.</p>
<p>Let <em>I</em> be the category given by the following schema:</p>
<p><img src="images/Art_P258.jpg" alt="art" /></p>
<p>Let <em>X</em> : <em>I</em> → <strong>Set</strong> be given on objects by <em>X</em>(<em>a</em>) ≔ 2, <em>X</em>(<em>b</em>) ≔ 1, <em>X</em>(<em>c</em>) ≔ 3, <em>X</em>(<em>d</em>) = 2, and given (in sequence notation) on morphisms by <em>X</em>(<em>f</em>) = (1, 1), <em>X</em>(<em>g</em>) = (1, 1, 1), <em>X</em>(<em>h</em>) = (1, 2, 1). What is the limit lim<sub><em>I</em></sub> <em>X</em>.</p>
<h3 id="lev_6-1-3-30" class="level"><strong>6.1.3.30   Definition of colimit</strong></h3>
<p>The definition of colimits is appropriately dual to the definition of limits. Instead of looking at left cones, we look at right cones; instead of being interested in terminal objects, we are interested in initial objects.</p>
<p><strong>Definition 6.1.3.31</strong>. Let C be a category, let <em>I</em> be a category; let <em>I</em><sup>▻</sup> be the right cone on <em>I</em>, and let <em>i</em> : <em>I</em> → <em>I</em><sup>▻</sup> be the inclusion. Suppose that X:I→C is an <em>I</em>-shaped diagram in C. The <em>coslice category of</em> C <em>over X</em>, denoted CX/, is the category whose objects and morphisms are as follows:</p>
<p>Ob(CX/)={S:I⊳→C|S○i=X};HomCX/(S,S′)={α:S→S′|α⋄i=idX}.</p>
<p>A <em>colimit of X</em>, denoted colim<sub><em>I</em></sub> <em>X</em> or colim <em>X</em>, is an initial object in CX/.</p>
<p><em>Remark</em> 6.1.3.32. Perhaps the following diagram will be helpful for understanding colimits. Given a functor X:I→C, what is its colimit? The solid-arrow part of the figure is the data we start with, i.e., the category C, the indexing category <em>I</em>, and the diagram X:I→C, as well as the part we automatically add, the cone <em>I</em><sup>▻</sup> with the inclusion I→iI⊳. The category CX/ is found in the dotted arrow part: its objects are the dotted arrows S:I⊳→C that make the following triangle commute, and its morphisms are the natural transformations <em>α</em> : <em>S</em> → <em>S</em>′ between them:</p>
<p><img src="images/Art_P259.jpg" alt="art" /></p>
<p>The colimit of <em>X</em> is the initial object in this category.</p>
<p><strong>Pushouts</strong> The relevant indexing category for pushouts is the span, <em>I</em> = 2<sup>◅</sup> drawn as on the left:</p>
<p><img src="images/Art_P260.jpg" alt="art" /></p>
<p>An <em>I</em>-shaped diagram in C is a functor X:I→C, which might be drawn as on the right (e.g., X0∈Ob(C)).</p>
<p>An object <em>S</em> in the coslice category CX/ is a commutative diagram S:I⊳→C over <em>X</em>, which looks like the left-hand box:</p>
<p><img src="images/Art_P261.jpg" alt="art" /></p>
<p>A morphism in CX/ is drawn as in right-hand box. An initial object in CX/ is precisely the gateway we want, i.e., the colimit of <em>X</em> is the pushout, X1⊔X0X2.</p>
<p><em>Exercise</em> 6.1.3.33.</p>
<p>Let <strong>GrIn</strong> be the graph-indexing category (see (5.8)).</p>
<p>a. What is <strong>GrIn</strong><sup>▻</sup>?</p>
<p>b. Let <em>G</em> : <strong>GrIn</strong> → <strong>Set</strong> be the graph from Example <a href="chapter004.html#Exa_4-3-1-2">4.3.1.2</a>. Give an example of an object in <strong>Set</strong><sub><em>G</em>/</sub>.</p>
<p><em>Exercise</em> 6.1.3.34.</p>
<p>Let C be a category, and let <em>I</em> = 0 be the empty category. There is a unique functor X:0¯→C.</p>
<p>a. What is the coslice category CX/?</p>
<p>b. What is a colimit of <em>X</em> (assuming it exists)?</p>
<p><em>Solution</em> 6.1.3.34.</p>
<p>a. The right cone of 0 is the terminal category 0<sup>▻</sup> ≅ 1, and since every diagram</p>
<p><img src="images/Art_P262.jpg" alt="art" /></p>
<p>commutes, we have an isomorphism Fun(1¯,C)→≅CX/. But by (<strong>??</strong>), we have an isomorphism C→≅Fun(1¯,C), so in fact C≅CX/.</p>
<p>b. A colimit of <em>X</em> is defined to be an initial object in CX/, which is an initial object in C, if it exists. In other words, initial objects in a category give us a canonical example of colimits. This was hinted at in Exercise <a href="chapter003.html#Exe_3-3-3-4">3.3.3.4</a>.</p>
<p><strong>Theorem 6.1.3.35</strong>. <em>Let I be a category and let F</em> : <em>I</em> → <strong>Set</strong> <em>be a functor. Then its colimit set</em> colim<em><sub>I</sub> F</em> ∈ Ob(<strong>Set</strong>) <em>exists and one can find its elements as follows. An element of the set</em> colim<em><sub>I</sub> F is given by choosing any i</em> ∈ Ob(<em>I</em>) <em>and any element of x<sub>i</sub></em> ∈ <em>F</em>(<em>i</em>), <em>and then considering two such elements equivalent if there exists f</em> : <em>i</em> → <em>i</em>′ <em>such that X</em>(<em>f</em>)(<em>x<sub>i</sub></em>) = <em>x</em><sub><em>i</em>′</sub>.</p>
<p><em>Proof.</em> See [29].</p>
<p><em>Exercise</em> 6.1.3.36.</p>
<p>Let <em>I</em> be the category given by the following schema:</p>
<p><img src="images/Art_P263.jpg" alt="art" /></p>
<p>Let <em>X</em> : <em>I</em> → <strong>Set</strong> be given on objects by <em>X</em>(<em>a</em>) ≔ 2, <em>X</em>(<em>b</em>) ≔ 2, <em>X</em>(<em>c</em>) ≔ 4, <em>X</em>(<em>d</em>) = 3, and given (in sequence notation) on morphisms by <em>X</em>(<em>f</em>) = (1, 2), <em>X</em>(<em>g</em>) = (1, 2, 1), <em>X</em>(<em>h</em>) = (1, 2, 4). What is the colimit colim<em><sub>I</sub> X</em>.</p>
<p><em>Remark</em> 6.1.3.37. Definition <a href="chapter006.html#Def_6-1-3-31">6.1.3.31</a> defined what it means to be a colimit in any category; however, in any particular category, some colimits may not exist. It is like defining the quotient of any two natural numbers <em>r</em>, <em>s</em> ∈ ℕ by <em>r</em> ÷ <em>s</em> = <em>q</em> if and only if q∗s=r. We have defined what it means to be a quotient, but that doesn’t mean the quotient of any two numbers exists, e.g. if <em>r</em> = 7 and <em>s</em> = 2.</p>
<p>The same goes for limits. A category C in which every diagram is guaranteed to have a limit is called <em>complete</em>. A category C in which every diagram is guaranteed to have a colimit is called <em>cocomplete</em>.</p>
<p><em>Example</em> 6.1.3.38 (Cone as colimit). It turns out that <strong>Cat</strong> is cocomplete, meaning every diagram in C has a colimit. We give an example of a colimit in <strong>Cat</strong>.</p>
<p>Let C be a category, and recall from Example <a href="chapter006.html#Exa_6-1-3-26">6.1.3.26</a> the category C×[1]. The inclusion of the front pane is a functor i0:C→C×[1]. (Similarly, the inclusion of the back pane is a functor i1:C→C×[1].) Finally, let t:C→1¯ be the unique functor to the terminal category (see Exercise <a href="chapter005.html#Exe_5-1-2-40">5.1.2.40</a>). We now have a diagram in <strong>Cat</strong> of the form</p>
<p><img src="images/Art_P264.jpg" alt="art" /></p>
<p>The colimit (i.e., the pushout) of this diagram in <strong>Cat</strong> slurps down the entire front pane of C×[1] to a point, and the resulting category is isomorphic to C◅. The diagrams in (<a href="chapter006.html#eq_6-7">6.7</a>) illustrate this phenomenon.</p>
<p><img src="images/Art_P265.jpg" alt="art" /></p>
<p>The category C is shown in the upper left-hand corner of (<a href="chapter006.html#eq_6-7">6.7</a>). The left cone C◅ on C is obtained as a pushout in <strong>Cat</strong>. We first make a prism C×[1] and then identify the front pane with a point. (Similarly, the pushout of an analogous diagram for <em>i</em><sub>1</sub> would give C▻.)</p>
<p><em>Example</em> 6.1.3.39. Consider the category <strong>Top</strong> of topological spaces. The (unfilled) circle is a topological space, which people often denote by <em>S</em><sup>1</sup> (for one-dimensional sphere). Topologically, it is equivalent to an oval, as shown in <a href="chapter006.html#Fig_6-1">Figure 6.1</a>. The filled-in circle, also called a two-dimensional disk, is denoted <em>D</em><sup>2</sup>. The inclusion of the circle into the disk, as its boundary, is continuous, so we have a morphism in <strong>Top</strong> of the form <em>i</em> : <em>S</em><sup>1</sup> → <em>D</em><sup>2</sup>. The terminal object in <strong>Top</strong> is the one-point space ●, so there is a unique morphism <em>t</em> : <em>S</em><sup>1</sup> → ●.</p>
<p>The pushout of the diagram D2←iS1→t• is isomorphic to the two-dimensional sphere (the exterior of a tennis ball), <em>S</em><sup>2</sup>. The reason is that we have slurped the entire bounding circle of <em>D</em><sup>2</sup> to a point, which becomes, say, the south pole, and the interior area of <em>D</em><sup>2</sup> becomes the surface area of the sphere. Mathematically, the category of topological spaces has the right morphisms to ensure that this intuitive picture is correct.</p>
<p><img src="images/Art_P266.jpg" alt="art" /></p>
<p><strong>Figure 6.1</strong> A pushout of topological spaces. A circle <em>S</em><sup>1</sup> is both included as the boundary of a disk <em>D</em><sup>2</sup> and sent to a single point ●. The resulting pushout is a 2-dimensional sphere <em>S</em><sup>2</sup>, formed by sewing the boundary circle of a disk all together into a single point.</p>
<p><em>Application</em> 6.1.3.40. Consider the symmetric graph <em>G<sub>n</sub></em> consisting of a chain of <em>n</em> vertices,</p>
<p><img src="images/Art_P267.jpg" alt="art" /></p>
<p>Think of this as modeling a subway line. There are <em>n</em>-many graph homomorphisms <em>G</em><sub>1</sub> → <em>G<sub>n</sub></em> given by the various vertices. One can create transit maps using colimits. For example, the colimit of the left-hand diagram is the symmetric graph drawn at the right:</p>
<p><img src="images/Art_P268.jpg" alt="art" /></p>
<h1 id="lev_6-2" class="level1"><a href="toc.html#Rlev_6-2"><strong>6.2   Other notions in Cat</strong></a></h1>
<p>This section discusses some additional notions about categories. Section <a href="chapter006.html#lev_6-2-1">6.2.1</a> explains a kind of duality for categories, in which arrows are flipped. Reversing the order in a preorder is an example of this duality, as is the similarity between the definitions of limit and colimit. Section <a href="chapter006.html#lev_6-2-2">6.2.2</a> discusses the Grothendieck construction, which in some sense makes a histogram for a set-valued functor, and shows that this idea is useful for transforming databases into the kind of format (RDF) used in scraping data off web pages. Some ways of creating new categories from old are explained in Sections <a href="chapter006.html#lev_6-2-3">6.2.3</a> and <a href="chapter006.html#lev_6-2-4">6.2.4</a>. Finally, Section <a href="chapter006.html#lev_6-2-5">6.2.5</a> shows that precisely the same arithmetic statements that held for sets (see Section <a href="chapter003.html#lev_3-4-3">3.4.3</a>) hold for categories.</p>
<h2 id="lev_6-2-1" class="level2"><strong>6.2.1   Opposite categories</strong></h2>
<p>In the early days of category theory, and still today, people would sometimes discuss two different kinds of functors between categories: <em>covariant functors</em> and <em>contravariant functors</em>. Covariant functors are what this book calls functors. The reader may have come across the idea of contravariance when considering Exercise <a href="chapter005.html#Exe_5-2-3-2">5.2.3.2</a>,<sup><a href="chapter006.html#endnote_9">9</a></sup> which showed that a continuous mapping of topological spaces <em>f</em> : <em>X</em> → <em>Y</em> does not induce a morphism of orders on their open sets Open(<em>X</em>) → Open(<em>Y</em>); that is not required by the notion of continuity. Instead, a morphism of topological spaces <em>f</em> : <em>X</em> → <em>Y</em> induces a morphism of orders Open(<em>Y</em>) → Open(<em>X</em>), going backward. So we do not have a functor <strong>Top</strong> → <strong>PrO</strong> in this way, but it is quite close. It used to be said that Open is a <em>contravariant functor</em> <strong>Top</strong> → <strong>PrO</strong>.</p>
<p>As important and common as contravariance is, one finds that keeping track of which functors were covariant and which were contravariant is a big hassle. Luckily, there is a simple work-around, which simplifies everything: the notion of opposite categories.</p>
<p><strong>Definition 6.2.1.1</strong>. Let C be a category. The <em>opposite category</em> of C, denoted Cop, has the same objects as C, i.e., Ob(Cop)=Ob(C), and for any two objects <em>c</em>, <em>c</em>′, one defines</p>
<p>HomCop(c,c′)≔HomC(c′,c).</p>
<p><em>Example</em> 6.2.1.2. If <em>n</em> ∈ ℕ is a natural number and <em>n</em> the corresponding discrete category, then <em>n</em><sup>op</sup> = <em>n</em>. Recall the span category <em>I</em> = 2<sup>◅</sup> from Definition <a href="chapter006.html#Def_6-1-1-8">6.1.1.8</a>. Its opposite is the cospan category <em>I</em><sup>op</sup> = 2<sup>▻</sup>, from Definition <a href="chapter006.html#Def_6-1-1-23">6.1.1.23</a>.</p>
<p><em>Exercise</em> 6.2.1.3.</p>
<p>Let C be the category from Example <a href="chapter006.html#Exa_6-1-3-18">6.1.3.18</a>. Draw Cop.</p>
<p><strong>Proposition 6.2.1.4</strong>. <em>Let</em> C <em>and</em> D <em>be categories. One has</em> (Cop)op=C. <em>Also one has a canonical isomorphism</em> Fun(C,D)≅Fun(Cop,Dop). <em>This implies that a functor</em> Cop→D <em>can be identified with a functor</em> C→Dop.</p>
<p><em>Proof.</em> This follows straightforwardly from the definitions.</p>
<p><em>Exercise</em> 6.2.1.5.</p>
<p>If C is a category and c∈Ob(C) is an initial object, does this imply that <em>c</em> is a terminal object in Cop?</p>
<p><em>Exercise</em> 6.2.1.6.</p>
<p>In Exercises <a href="chapter005.html#Exe_5-2-3-2">5.2.3.2</a>, <a href="chapter005.html#Exe_5-2-4-3">5.2.4.3</a>, and <a href="chapter005.html#Exe_5-2-4-4">5.2.4.4</a> there were questions about whether a certain function Ob(C)→Ob(D) extended to a functor C→D.</p>
<p>a. Does the function Open: Ob(<strong>Top</strong>) → Ob(<strong>PrO</strong>) extend to a functor Open: <strong>Top</strong><sup>op</sup> → <strong>PrO</strong>?</p>
<p>b. Does the function <em>L</em> : Ob(<em>J</em>) → Ob(<strong>Prop</strong>) extend to a functor <em>L</em> : <em>J</em><sup>op</sup> → <strong>Prop</strong>?</p>
<p>c. Does the function <em>R</em> : Ob(<em>J</em>) → Ob(<strong>Set</strong>) extend to a functor <em>R</em> : <em>J</em><sup>op</sup> → <strong>Set</strong>?</p>
<p><em>Example</em> 6.2.1.7 (Simplicial sets). Recall from Example <a href="chapter005.html#Exa_5-3-4-4">5.3.4.4</a> the category <strong>Δ</strong> of linear orders [<em>n</em>]. For example, [1] is the linear order 0 ⩽ 1, and [2] is the linear order 0 ⩽ 1 ⩽ 2. Both [1] and [2] are objects of <strong>Δ</strong>. There are 6 morphisms from [1] to [2], which could be denoted</p>
<p>HomΔ([1],[2])={(0,0),(0,1),(0,2),(1,1),(1,2),(2,2)}.</p>
<p>The category <strong>Δ</strong><sup>op</sup> turns out to be quite useful in algebraic topology. It is the indexing category for a combinatorial approach to the homotopy theory of spaces. That is, we can represent something like the category of spaces and continuous maps using the functor category Fun(<strong>Δ</strong><sup>op</sup>, <strong>Set</strong>), which is called the <em>category of simplicial sets</em>.</p>
<p>This may seem very complicated compared to simplicial complexes (see Section <a href="chapter003.html#lev_3-4-4-3">3.4.4.3</a>). But simplicial sets have excellent formal properties that simplicial complexes do not. We do not go further with this here, but through the work of Dan Kan, André Joyal, Jacob Lurie, and many others, simplicial sets have allowed category theory to pierce deeply into the realm of topology, and vice versa.</p>
<h2 id="lev_6-2-2" class="level2"><strong>6.2.2   Grothendieck construction</strong></h2>
<p>Let C be a database schema (or category), and let J:C→Set be an instance. We have been drawing this in table form, but there is another standard way of laying out the data in <em>J</em>, called the <em>resource descriptive framework</em>, or RDF. Developed for the World Wide Web, RDF is a useful format when one does not have a schema in hand. For example, when scraping information off a website, one does not know which schema will be best. In these cases information is stored in RDF triples, which are of the form</p>
<p>〈Subject,Predicate,Object〉.</p>
<p>For example, one might see something like</p>
<p><img src="images/Art_P269.jpg" alt="art" /></p>
<p>This might be an RDF interpretation of the sentence “On January 14, 2013, Barack Obama told congress to raise the debt ceiling.”</p>
<p>Category-theoretically, it is quite simple to convert a database instance J:C→Set into an RDF triple store. To do so, we use the <em>Grothendieck construction</em>, also known as the <em>category of elements</em>.</p>
<p><strong>Definition 6.2.2.1</strong>. Let C be a category, and let J:C→Set be a functor. The <em>category of elements of J</em>, denoted ∫CJ, is defined as follows:</p>
<p>       Ob(∫CJ)≔{(C,x)|C∈Ob(C),x∈J(C)};Hom∫CJ((C,x),(C′,x′))≔{f:C→C′|J(f)(x)=x′}.</p>
<p>There is a natural functor πJ:∫CJ→C. It sends each object (C,x)∈Ob(∫CJ) to the object C∈Ob(C). And it sends each morphism <em>f</em> : (<em>C</em>, <em>x</em>) → (<em>C</em>′, <em>x</em>′) to the morphism <em>f</em> : <em>C</em> → <em>C</em>′. We call <em>π<sub>J</sub></em> the <em>projection functor</em>.</p>
<p><em>Example</em> 6.2.2.2. Let <em>A</em> be a set, and consider it as a discrete category. We saw in Exercise <a href="chapter005.html#Exe_5-3-3-4">5.3.3.4</a> that a functor <em>S</em> : <em>A</em> → <strong>Set</strong> is the same thing as an <em>A</em>-indexed set, as discussed in Section <a href="chapter003.html#lev_3-4-6-9">3.4.6.9</a>. We follow Definition <a href="chapter003.html#Def_3-4-6-11">3.4.6.11</a> and, for each <em>a</em> ∈ <em>A</em>, write <em>S<sub>a</sub></em> ≔ <em>S</em>(<em>a</em>).</p>
<p>What is the category of elements of a functor <em>S</em> : <em>A</em> → <strong>Set</strong>? The objects of ∫<sub><em>A</em></sub> <em>S</em> are pairs (<em>a</em>, <em>s</em>), where <em>a</em> ∈ <em>A</em> and <em>s</em> ∈ <em>S</em>(<em>a</em>). Since <em>A</em> has nothing but identity morphisms, ∫<em><sub>A</sub> S</em> has nothing but identity morphisms, i.e., it is the discrete category on a set. In fact, that set is the disjoint union</p>
<p>∫AS=∐a∈ASa.</p>
<p>The functor <em>π<sub>S</sub></em>: ∫<em><sub>A</sub> S</em>→ <em>A</em> sends each element in <em>S<sub>a</sub></em> to the element <em>a</em> ∈ <em>A</em>.</p>
<p>One can see this as a kind of histogram. For example, let <em>A</em> = {BOS, NYC, LA, DC}, and let <em>S</em> : <em>A</em> → <strong>Set</strong> assign</p>
<p>SBOS={Abby, Bob, Casandra},SNYC=∅,SLA={John, Jim},SDC={Abby, Carla}.</p>
<p>Then the category of elements of <em>S</em> would look like the (discrete) category at the top:</p>
<p><img src="images/Art_P270.jpg" alt="art" /></p>
<p>We also see that the category of elements construction has converted an <em>A</em>-indexed set into a relative set over <em>A</em>, as in Definition <a href="chapter003.html#Def_3-4-6-6">3.4.6.6</a>.</p>
<p>The preceding example does not show how the Grothendieck construction transforms a database instance into an RDF triple store. The reason is that the database schema was <em>A</em>, a discrete category that specifies no connections between data (it simply collects the data into bins). So let’s examine a more interesting database schema and instance. This is taken from Spivak [39].</p>
<p><em>Application</em> 6.2.2.3. Consider the following schema, first encountered in Example <a href="chapter004.html#Exa_4-5-2-1">4.5.2.1</a>:</p>
<p><img src="images/Art_P271.jpg" alt="art" /></p>
<p>And consider the instance J:C→Set, which we first encountered in (4.12) and (4.14):</p>
<p><img src="images/Art_P272.jpg" alt="art" /></p>
<p>The category of elements of J:C→Set looks like this:</p>
<p><img src="images/Art_P273.jpg" alt="art" /></p>
<p>In Diagram (<a href="chapter006.html#eq_6-11">6.11</a>) of ∫CJ, ten arrows were omitted for ease of readability, for example, arrow •102 →first •Bertrand was omitted.</p>
<p>How do we see the category of elements ∫CJ as an RDF triple store? For each arrow in ∫CJ, we take the triple consisting of the source vertex, the arrow name, and the target vertex. So the triple store would include triples such as 〈101 worksIn q10〉 and 〈q10 name Production〉. Note that if C were an olog, we could read off these triples (and concatenations of them) as English sentences. For example, the preceding two triples could be Englished as follows:</p>
<p>Employee 101 works in Department q10, which has as name Production.</p>
<p><em>Exercise</em> 6.2.2.4.</p>
<p>Devise a schema C for which you can imagine an instance I:C→Set such that the category of elements ∫(<em>I</em>) is the triple store in (<a href="chapter006.html#eq_6-8">6.8</a>).</p>
<p><em>Slogan</em> 6.2.2.5.</p>
<p><em>The Grothendieck construction takes structured, tabulated data and flattens it by throwing it all into one big space. The projection functor is then tasked with remembering which box each datum originally came from.</em></p>
<p><em>Exercise</em> 6.2.2.6.</p>
<p>Recall from Section <a href="chapter004.html#lev_4-1-2-10">4.1.2.10</a> that a finite state machine is a free monoid (List(Σ), [ ], ++) acting on a set <em>X</em>. Recall also that we can consider a monoid as a category M with one object, and we can consider a monoid action as a set-valued functor <em>F</em>: M → <strong>Set</strong> (see Section <a href="chapter005.html#lev_5-2-1-1">5.2.1.1</a>). In the case of <a href="chapter004.html#Fig_4-2">Figure 4.2</a> the monoid is List(<em>a</em>, <em>b</em>), which can be drawn as the schema</p>
<p><img src="images/Art_P274.jpg" alt="art" /></p>
<p>and the functor F:M→Set is recorded in an action table in Example <a href="chapter004.html#Exa_4-1-3-1">4.1.3.1</a>. What is ∫MF? How does it relate to <a href="chapter004.html#Fig_4-2">Figure 4.2</a>?</p>
<h2 id="lev_6-2-3" class="level2"><strong>6.2.3   Full subcategory</strong></h2>
<p><strong>Definition 6.2.3.1</strong>. Let C be a category, and let X⊆Ob(C) be a set of objects in C. The <em>full subcategory of</em> C <em>spanned by X</em> is the category, denoted COb=X, with objects Ob(COb=X)≔X and with morphisms HOMCOb=X(x,x′)≔HOMC(x,x′).</p>
<p><em>Example</em> 6.2.3.2. The following are examples of full subcategories. For example, the category <strong>Fin</strong> of finite sets is the full subcategory of <strong>Set</strong> spanned by the finite sets.</p>
<ul>
<li>If <em>X</em> = {<em>s</em> ∈ Ob(<strong>Set</strong>) | <em>s</em> is finite}, then <strong>Fin</strong> = <strong>Set</strong><sub>Ob=<em>X</em></sub>.</li>
<li>If <em>X</em> = {<em>P</em> ∈ Ob(<strong>PrO</strong>) | <em>P</em> is a finite linear order)}, then <strong>FLin</strong> = <strong>PrO</strong><sub>Ob=<em>X</em></sub>.</li>
<li>If <em>X</em> = {[<em>n</em>] ∈ <strong>FLin</strong> | <em>n</em> ∈ ℕ} (see Example <a href="chapter005.html#Exa_5-3-4-4">5.3.4.4</a>), then <strong>Δ</strong> = <strong>FLin</strong><sub>Ob=<em>X</em></sub>.</li>
<li>If <em>X</em> = {<em>M</em> ∈ Ob(<strong>Mon</strong>) | M is a group}, then <strong>Grp</strong> = <strong>Mon</strong><sub>Ob=<em>X</em></sub>.</li>
<li>If X={C∈Ob(Cat)|C has one object}, then <strong>Mon</strong> = <strong>Cat</strong><sub>Ob=<em>X</em></sub>.</li>
<li>If <em>X</em> = {<em>n</em> ∈ Ob(<strong>Fin</strong>) | <em>n</em> ∈ ℕ}, then there is an equivalence of categories <strong>Fin</strong> ≃ <strong>Fin</strong><sub>Ob=<em>X</em></sub>.</li>
<li>If <em>X</em> = {(<em>V</em>, <em>A</em>, <em>src</em>, <em>tgt</em>) ∈ Ob(<strong>Grph</strong>) | <em>A</em> = ∅}, then <strong>Set</strong> ≅ <strong>Grph</strong><sub>Ob=<em>X</em></sub>.</li>
<li>If X={C∈Cat|C is discrete}, then <strong>Set</strong> ≅ <strong>Cat</strong><sub>Ob=<em>X</em></sub>.</li>
</ul>
<p><em>Remark</em> 6.2.3.3. A subcategory C⊆D is (up to isomorphism) just a functor i:C→D that happens to be injective on objects and arrows. The subcategory is full if and only if <em>i</em> is a full functor in the sense of Definition <a href="chapter005.html#Def_5-3-4-8">5.3.4.8</a>.</p>
<p><em>Example</em> 6.2.3.4. Let C be a category, let X⊆Ob(C) be a set of objects, and let COb=X denote the full subcategory of C spanned by <em>X</em>. We can realize this as a fiber product of categories. Indeed, recall that for any set, we can form the indiscrete category on that set (see Example <a href="chapter005.html#Exa_5-3-4-3">5.3.4.3</a>). In fact, we have a functor <em>Ind</em>: <strong>Set</strong> → <strong>Cat</strong>. Thus the function X→Ob(C) can be converted into a functor between indiscrete categories Ind(X)→Ind(Ob(C)). There is also a unique functor C→Ind(Ob(C)) sending each object to itself. Then the full subcategory of C spanned by <em>X</em> is the fiber product of categories,</p>
<p><img src="images/Art_P275.jpg" alt="art" /></p>
<p><em>Exercise</em> 6.2.3.5.</p>
<p>Recall the sets 0, 1, 2 ∈ Ob(<strong>Set</strong>) from Notation <a href="chapter002.html#Not_2-1-2-21">2.1.2.21</a>. Including all identities and all compositions, how many morphisms are there in the full subcategory <strong>Set</strong><sub>Ob={0,1,2}</sub>?</p>
<h2 id="lev_6-2-4" class="level2"><strong>6.2.4   Comma categories</strong></h2>
<p>Category theory includes a highly developed and interoperable catalogue of materials (categories such as [<em>n</em>], <strong>GrIn</strong>, <strong>PrO</strong>, etc.) and production techniques for making new categories from old. One such was the full subcategory idea in the previous section—given any category and any subset of objects, one can form a new category to restrict attention to the subset. Another is the comma category construction.</p>
<p><strong>Definition 6.2.4.1</strong>. Let A→FC←GB be a cospan of categories. The <em>comma category of</em> C <em>morphisms from F to G</em>, denoted (F↓CG) or simply (<em>F</em> ↓ <em>G</em>), is the category with objects</p>
<p>Ob(F↓G)={(a,b,f)|a∈Ob(A),b∈Ob(B),f:F(a)→G(b) in C},</p>
<p>and for any two objects (<em>a</em>, <em>b</em>, <em>f</em>) and (<em>a</em>′, <em>b</em>′, <em>f</em>′) the set Hom<sub>(<em>F</em>↓<em>G</em>)</sub> ((<em>a</em>, <em>b</em>, <em>f</em>), (<em>a</em>′, <em>b</em>′, <em>f</em>′)) of morphisms (<em>a</em>, <em>b</em>, <em>f</em>) → (<em>a</em>′, <em>b</em>′, <em>f</em>′) is</p>
<p>{(q,r)|q:a→a′ in A, r:b→b′ in B, such that f′○F(q)=G(r)○f}.</p>
<p>In diagram form,</p>
<p><img src="images/Art_P276.jpg" alt="art" /></p>
<p>There is a canonical functor (F↓G)→A, called <em>left projecton</em>, sending (<em>a</em>, <em>b</em>, <em>f</em>) to <em>a</em>, and a canonical functor (F↓G)→B, called <em>right projection</em>, sending (<em>a</em>, <em>b</em>, <em>f</em>) to <em>b</em>.</p>
<p>A cospan A→FC←GB is reversible, i.e., we can flip it to obtain B→GC←FA. However, note that (<em>F</em> ↓ <em>G</em>) is different than (i.e., almost never equivalent to) (<em>G</em> ↓ <em>F</em>).</p>
<p><em>Slogan</em> 6.2.4.2.</p>
<p><em>When two categories</em> A<em>, ℬ can be interpreted in a common setting</em> C<em>, the comma category integrates them by recording how to move from</em> A <em>to</em> B <em>inside</em> C.</p>
<p><em>Example</em> 6.2.4.3. Let C be a category and I:C→Set a functor. This example shows that the comma category construction captures the notion of taking the category of elements ∫CI (see Definition <a href="chapter006.html#Def_6-2-2-1">6.2.2.1</a>).</p>
<p>Consider the set 1, the category <em>Disc</em>(1), and the functor <em>F</em> : <em>Disc</em>(1) → <strong>Set</strong> sending the unique object to the set 1. We use the cospan Disc(1¯)→FSet←IC. There is an isomorphism of categories</p>
<p>∫CI≅(F↓I).</p>
<p>Indeed, an object in (<em>F</em> ↓ <em>I</em>) is a triple (<em>a</em>, <em>b</em>, <em>f</em>), where <em>a</em> ∈ Ob(<em>Disc</em>(1)), b∈Ob(C), and <em>f</em> : <em>F</em>(<em>a</em>) → <em>I</em>(<em>b</em>) is a morphism in <strong>Set</strong>. There is only one object in <em>Disc</em>(1), so this reduces to a pair (<em>b</em>, <em>f</em>), where b∈Ob(C) and <em>f</em> : {☺} → <em>I</em>(<em>b</em>). The set of functions {☺} → <em>I</em>(<em>b</em>) is isomorphic to <em>I</em>(<em>b</em>) (see Exercise <a href="chapter002.html#Exe_2-1-2-20">2.1.2.20</a>). So we have reduced Ob(<em>F</em> ↓ <em>I</em>) to the set of pairs (<em>b</em>, <em>x</em>), where b∈Ob(C) and <em>x</em> ∈ <em>I</em>(<em>b</em>); this is Ob(∫CI). Because there is only one function 1 → 1, a morphism (<em>b</em>, <em>x</em>) → (<em>b</em>′, <em>x</em>′) in (<em>F</em> ↓ <em>I</em>) boils down to a morphism <em>r</em> : <em>b</em> → <em>b</em>′ such that the diagram</p>
<p><img src="images/Art_P277.jpg" alt="art" /></p>
<p>commutes. But such diagrams are in one-to-one correspondence with the diagrams defining morphisms in ∫CI.</p>
<p><em>Exercise</em> 6.2.4.4.</p>
<p>Let C be a category, and let c,c′∈Ob(C) be objects represented by the functors c,c′:1¯→C. Consider the cospan 1¯→cC←c′1¯. What is the comma category (<em>c</em> ↓ <em>c</em>′)?</p>
<p><em>Exercise</em> 6.2.4.5.</p>
<p>Let C and D be categories, and let !:C→1¯ and !:D→!¯ be the unique functors to the terminal category. What is the comma category for C→!1¯←!D?</p>
<p><em>Exercise</em> 6.2.4.6.</p>
<p>Let C be a category.</p>
<p>a. If c∈C is an initial object, what is the comma category for the cospan 1¯→cC←idCC?</p>
<p>b. If d∈C is a terminal object, what is the comma category for the cospan C→idCC←dC?</p>
<h2 id="lev_6-2-5" class="level2"><strong>6.2.5   Arithmetic of categories</strong></h2>
<p>Section <a href="chapter003.html#lev_3-4-3">3.4.3</a> summarized some of the properties of products, coproducts, and exponentials for sets, showing that they lined up precisely with familiar arithmetic properties of natural numbers. We can do the same for categories.</p>
<p>In the following proposition, we denote the coproduct of two categories A and B by the notation A+B rather than A⊔B. We also denote the functor category Fun(A,B) by BA. Finally, we use 0 and 1 to refer to the discrete category on 0 objects and on 1 object respectively.</p>
<p><strong>Proposition 6.2.5.1</strong>. <em>The following isomorphisms exist for any small categories</em> A,B,and C.</p>
<ul>
<li>A+0¯≅A.</li>
<li>A+B≅B+A.</li>
<li>(A+B)+C≅A+(B+C).</li>
<li>A×0¯≅0¯.</li>
<li>A×1¯≅A.</li>
<li>A×B≅B×A.</li>
<li>(A×B)×C≅A×(B×C).</li>
<li>A×(B+C)≅(A×B)+(A×C).</li>
<li>A0¯≅1¯.</li>
<li>A1¯≅A.</li>
<li>0¯A≅0¯, if A≠0¯.</li>
<li>1¯A≅1¯.</li>
<li>AB+C≅AB×AC.</li>
<li>(AB)C≅AB×C.</li>
<li>(A×B)C≅AC×BC.</li>
</ul>
<p><em>Proof</em>. These are standard results; see Mac Lane [29].</p>
<p>__________________</p>
<p><a href="chapter006.html#endnote_ref_1"><sup>1</sup></a>Given <em>R</em><sub>1</sub> ⊆ <em>X</em><sub>1</sub> × <em>X</em><sub>1</sub>, <em>R</em><sub>2</sub> ⊆ <em>X</em><sub>2</sub> × <em>X</em><sub>2</sub>, take <em>R</em><sub>1</sub> × <em>R</em><sub>2</sub> ⊆ (<em>X</em><sub>1</sub> × <em>X</em><sub>2</sub>) × (<em>X</em><sub>1</sub> × <em>X</em><sub>2</sub>).</p>
<p><a href="chapter006.html#endnote_ref_2"><sup>2</sup></a>The result is not necessarily inspiring, but at least computing it is straightforward.</p>
<p><a href="chapter006.html#endnote_ref_3"><sup>3</sup></a>The names <em>X</em> × <em>Y</em> and <em>π</em><sub>1</sub>, <em>π</em><sub>2</sub> are not mathematically important; they are pedagogically useful.</p>
<p><a href="chapter006.html#endnote_ref_4"><sup>4</sup></a>Note that (0, 0) is not related to anything else.</p>
<p><a href="chapter006.html#endnote_ref_5"><sup>5</sup></a>Given <em>R</em><sub>1</sub> ⊆ <em>X</em><sub>1</sub> × <em>X</em><sub>1</sub>, <em>R</em><sub>2</sub> ⊆ <em>X</em><sub>2</sub> × <em>X</em><sub>2</sub>, take</p>
<p>R1⊔R2⊆(X1×X1)⊔(X2×X2)⊆(X1×X1)⊔(X2×X2)⊔(X2×X1)⊔(X2×X2)≅(X1⊔X1)×(X1⊔X2).</p>
<p><a href="chapter006.html#endnote_ref_6"><sup>6</sup></a>The names <em>X</em> ⊔ <em>Y</em> and <em>ı</em><sub>1</sub>, <em>ı</em><sub>2</sub> are not mathematically important; they are pedagogically useful.</p>
<p><a href="chapter006.html#endnote_ref_7"><sup>7</sup></a>The indexing category <em>I</em> is usually assumed to be small in the sense of Remark <a href="chapter005.html#Rem_5-1-1-2">5.1.1.2</a>, meaning that its collection of objects is a set.</p>
<p><a href="chapter006.html#endnote_ref_8"><sup>8</sup></a>What is here denoted <em>F</em> (<em>G</em>) might be called the <em>noncommutative square indexing category</em>.</p>
<p><a href="chapter006.html#endnote_ref_9"><sup>9</sup></a>Similarly, see Exercise <a href="chapter005.html#Exe_5-2-4-4">5.2.4.4</a>.</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter005.html">previous</a>, <a href="chapter007.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter006.html">previous</a>, <a href="reference.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<h1 class="chapter-number"><a href="toc.html#chap-7"><strong>Chapter 7</strong></a></h1>
<h1 class="chapter-title"><a href="toc.html#chap-7"><strong>Categories at Work</strong></a></h1>
<p>The reader should now have an understanding of the basic notions of category theory: categories, functors, natural transformations, and universal properties. As well, we have discussed many sources of examples: orders, graphs, monoids, and databases. This chapter begins with the notion of <em>adjoint functors</em> (also known as <em>adjunctions</em>), which are like dictionaries translating back and forth between different categories.</p>
<h1 id="lev_7-1" class="level1"><a href="toc.html#Rlev_7-1"><strong>7.1   Adjoint functors</strong></a></h1>
<p>How far can we take this dictionary analogy?</p>
<p>In the common understanding of dictionaries, we assume that two languages (say, French and English) are equally expressive and that a good dictionary will assist in an even exchange of ideas. But in category theory we often have two categories that are not on the same conceptual level. This is most clear in the case of <em>free-forgetful adjunctions</em>. Section <a href="chapter007.html#lev_7-1-1">7.1.1</a> explores the sense in which each adjunction provides a dictionary between two categories that are not necessarily on an equal footing, so to speak.</p>
<h2 id="lev_7-1-1" class="level2"><strong>7.1.1   Discussion and definition</strong></h2>
<p>Consider the category of monoids and the category of sets. A monoid (<em>M</em>, <em>e</em>, ⋆) is a set with a unit element and a multiplication formula that is associative. A set is just a set. A dictionary between <strong>Mon</strong> and <strong>Set</strong> should not be required to set up an even exchange but rather an exchange that is appropriate to the structures at hand. It will be in the form of two functors, denoted <em>L</em>: <strong>Set</strong> → <strong>Mon</strong> and <em>R</em>: <strong>Mon</strong> → <strong>Set</strong>. So we can translate back and forth, but to say what kind of exchange is appropriate will require more work.</p>
<p>An extended analogy will introduce the subject. A one-year-old can make repeatable noises, and an adult can make repeatable noises. One might say, “After all, talking is nothing but making repeatable noises.” But the adult’s repeatable noises are called words, they form sentences, and those sentences can cause nuclear wars. There is something more in adult language than simply repeatable sounds. In the same vein, a game of tennis can be viewed in terms of physics, the movement of trillions of atoms, but in so doing one won’t see the game aspect. So we have here something analogous to two categories here: {repeated noises} and {meaningful words}. We are looking for adjoint functors to serve as the appropriate sort of dictionary.</p>
<p>To translate baby talk into adult language we would make every repeated noise a kind of word, thereby granting it meaning. We do not know what a given repeated noise should mean, but we give it a slot in our conceptual space while always pondering, “I wonder what she means by Koh….” On the other hand, to translate from meaningful words to repeatable noises is easy. We just hear the word as a repeated noise, which is how the baby probably hears it.</p>
<p>Adjoint functors often come in the form of “free” and “forgetful.” Here we freely add Koh to our conceptual space without having any idea how it adheres to the rest of the child’s noises or feelings. But it does not act like a sound to us, it acts like a word; we do not know what it means, but we figure it means something. Conversely, the translation going the other way is “forgetful,” forgetting the meaning of the words and just hearing them as sounds. The baby hears our words and accepts them as mere sounds, not knowing that there is anything extra to get.</p>
<p>Sets are like the babies in the story: they are simple objects full of unconnected dots. Monoids are like the adults, forming words and performing actions. In the monoid each element means something and combines with other elements in certain ways. There are many different sets and many different monoids, just as there are many babies and many adults, but there are differences in how they interact, so we put them in different categories.</p>
<p>Applying free functor <em>L</em>: <strong>Set</strong> → <strong>Mon</strong> to a set <em>X</em> makes every element <em>x</em> ∈ <em>X</em> a word, and these words can be strung together to form more complex words. (Section <a href="chapter004.html#lev_4-1-1-12">4.1.1.12</a> discussed the free monoid functor <em>L</em>.) Since a set such as <em>X</em> carries no information about the meaning or structure of its various elements, the free monoid <em>F</em>(<em>X</em>) does not relate different words in any way. To apply the forgetful functor <em>R</em>: <strong>Mon</strong> → <strong>Set</strong> to a monoid, even a structured one, is to simply forget that its elements are anything but mere elements of a set. It sends a monoid (<em>M</em>, <em>e</em>, ⋆) to the set <em>M</em>.</p>
<p><strong>Definition 7.1.1.1</strong>. Let B and A be categories.<sup><a href="chapter007.html#endnote_1">1</a></sup> An <em>adjunction between</em> B <em>and</em> A is a pair of functors</p>
<p>L:B→AandR:A→B</p>
<p>together with a natural isomorphism<sup><a href="chapter007.html#endnote_2">2</a></sup> whose component for any objects A∈Ob(A) and B∈Ob(B)) is</p>
<p>αB,A:HOMA(L(B),A)→≅HOMB(B,R(A)).(7.1)</p>
<p>This isomorphism is called the <em>adjunction isomorphism</em> for the (<em>L</em>, <em>R</em>) adjunction, and for any morphism <em>f</em> : <em>L</em>(<em>B</em>) → <em>A</em> in A, we refer to <em>α</em><sub><em>B</em>,<em>A</em></sub>(<em>f</em>): <em>B</em> → <em>R</em>(<em>A</em>) as <em>the adjunct</em> of <em>f</em>.<sup><a href="chapter007.html#endnote_3">3</a></sup></p>
<p>The functor <em>L</em> is called the <em>left adjoint</em> and the functor <em>R</em> is called the <em>right adjoint</em>. We may say that <em>L is the left adjoint of R</em> or that <em>R is the right adjoint of L</em>.<sup><a href="chapter007.html#endnote_4">4</a></sup> We often denote this setup</p>
<p>L:B⇄A:R(7.2)</p>
<p><strong>Proposition 7.1.1.2</strong>. <em>Let L</em>: <strong>Set</strong> → <strong>Mon</strong> <em>be the functor sending X</em> ∈ Ob(<strong>Set</strong>) <em>to the free monoid L</em>(<em>X</em>) ≔ (List(<em>X</em>), [ ], ++), <em>as in Definition</em> <a href="chapter004.html#Def_4-1-1-15">4.1.1.15</a>. <em>Let R</em>: <strong>Mon</strong> → <strong>Set</strong> <em>be the functor sending each monoid</em> M ≔ (<em>M</em>, <em>e</em>, ⋆) <em>to its underlying set R</em>(M) ≔ <em>M. Then L is left adjoint to R</em>.</p>
<p><em>Proof</em>. This is precisely the content of Proposition <a href="chapter004.html#Pro_4-1-4-9">4.1.4.9</a>.</p>
<p><em>Example</em> 7.1.1.3. We need to ground the discussion in some concrete mathematics. In Proposition <a href="chapter007.html#Pro_7-1-1-2">7.1.1.2</a> we provided an adjunction between sets and monoids. A set <em>X</em> gets transformed into a monoid by considering lists in <em>X</em>; a monoid M gets transformed into a set by forgetting the multiplication law. So we have a functor for translating each way,</p>
<p>L:Set→Mon,  R:Mon→Set,</p>
<p>but an adjunction is more than that: it includes a guarantee about the relationship between these two functors. What is the relationship between <em>L</em> and <em>R</em>? Consider an arbitrary monoid M = (<em>M</em>, <em>e</em>, ⋆).</p>
<p>If we want to pick out three elements of the set <em>M</em>, that is the same thing as giving a function {<em>a</em>, <em>b</em>, <em>c</em>} → <em>M</em>. But that function exists in the category of sets; in fact it is an element of Hom<strong><sub>Set</sub></strong>({<em>a</em>, <em>b</em>, <em>c</em>}, <em>M</em>). But since <em>M</em> = <em>R</em>(M) is the underlying set of the monoid, we can view the current paragraph in the light of adjunction (<a href="chapter007.html#eq_7-1">7.1</a>) by saying the set</p>
<p>HomSet({a,b,c},R(M)).</p>
<p>classifies all the ways to choose three elements out of the underlying set of monoid M. It was constructed completely from within the context of sets and functions.</p>
<p>Now, what does (<a href="chapter007.html#eq_7-1">7.1</a>) mean? The equation</p>
<p>HomMon(L({a,b,c}),M)≅HomSet({a,b,c},R(M))</p>
<p>tells us that somehow we can classify all the ways to choose three elements from <em>M</em>, while staying in the context of monoids and monoid homomorphisms. In fact, it tells us how to do so, namely, as Hom<strong><sub>Mon</sub></strong>(List({1, 2, 3}), M). Exercise <a href="chapter007.html#Exe_7-1-1-4">7.1.1.4</a> looks at that. The answer can be extracted from the proof of Proposition <a href="chapter004.html#Pro_4-1-4-9">4.1.4.9</a>.</p>
<p><em>Exercise</em> 7.1.1.4.</p>
<p>Let <em>X</em> = {<em>a</em>, <em>b</em>, <em>c</em>}, and let M = (ℕ, 1, *) be the multiplicative monoid of natural numbers (see Example <a href="chapter004.html#Exa_4-1-3-2">4.1.3.2</a>). Let <em>g</em> : <em>X</em> → ℕ be the function given by <em>g</em>(<em>a</em>) = 7, <em>g</em>(<em>b</em>) = 2, <em>g</em>(<em>c</em>) = 2, and let <em>β</em><sub><em>X</em>,M</sub> : Hom<strong><sub>Set</sub></strong>(<em>X</em>, <em>R</em>(M)) → Hom<strong><sub>Mon</sub></strong>(<em>L</em>(<em>X</em>), M) be as in the proof of Proposition <a href="chapter004.html#Pro_4-1-4-9">4.1.4.9</a>.</p>
<p>Consider the list [<em>b</em>, <em>b</em>, <em>a</em>, <em>c</em>] ∈ <em>L</em>(<em>X</em>). What is <em>β</em><sub><em>X</em>,M</sub>(<em>g</em>)([<em>b</em>, <em>b</em>, <em>a</em>, <em>c</em>])?</p>
<p>Let us look once more at the adjunction between adults and babies. Using the notation of Definition <a href="chapter007.html#Def_7-1-1-1">7.1.1.1</a>, A is the adult category of meaningful words, and B is the baby category of repeated noises. The left adjoint turns every repeated sound into a meaningful word (having free meaning), and the right adjoint forgets the meaning of any word and considers it merely as a sound.</p>
<p>At the risk of taking this simple analogy too far, let’s look at the heart of the issue: how to conceive of the isomorphism (<a href="chapter007.html#eq_7-1">7.1</a>) of hom-sets. Once we have freely given a slot to each of the baby’s repeated sounds, we try to find a mapping from the lexicon <em>L</em>(<em>B</em>) of these new words to the adult lexicon <em>A</em> of meaningful words; these are mappings in the adult category A of the form <em>L</em>(<em>B</em>) → <em>A</em>. And (stretching it) the baby tries to find a mapping (which we might see as emulation) from her set <em>B</em> of repeatable sounds to the set <em>R</em>(<em>A</em>) of the sounds the adult seems to repeat. If there were a global system for making these transformations, that would establish (<a href="chapter007.html#eq_7-1">7.1</a>) and hence the adjunction.</p>
<p>Note that the directionality of the adjunction makes a difference. If L:B→A is left adjoint to R:A→B, there is no reason to think that <em>L</em> is also a right adjoint. In the case of babies and adults, we see that it would make little sense to look for a mapping in the category of meaningful words from the adult lexicon to the wordifications of baby sounds HomA(A,L(B)), because there is unlikely to be a good candidate for most of the words. That is, to which of the child’s repeated noises would we assign the concept “weekday”?</p>
<p>Again, this is simply an analogy and should not be taken to seriously. The next example shows mathematically that the directionality of an adjunction is not arbitrary.</p>
<p><em>Example</em> 7.1.1.5. Let <em>L</em>: <strong>Set</strong> → <strong>Mon</strong> and <em>R</em>: <strong>Mon</strong> → <strong>Set</strong> be the free and forgetful functors from Proposition <a href="chapter007.html#Pro_7-1-1-2">7.1.1.2</a>. We know that <em>L</em> is left adjoint to <em>R</em>; however <em>L</em> is <em>not</em> right adjoint to <em>R</em>. In other words, we can show that the necessary natural isomorphism cannot exist.</p>
<p>Let <em>X</em> = {<em>a</em>, <em>b</em>}, and let M = 1 be the trivial monoid. Then the necessary natural isomorphism would need to give a bijection</p>
<p>HomMon(M,L(X))≅?HomSet({1},X).</p>
<p>But the left-hand side has one element, because M is the initial object in <strong>Mon</strong> (see Example <a href="chapter006.html#Exa_6-1-3-7">6.1.3.7</a>), whereas the right-hand side has two elements. Therefore, no isomorphism can exist.</p>
<p><em>Example</em> 7.1.1.6. Preorders have underlying sets, giving rise to a functor <em>U</em> : <strong>PrO</strong> → <strong>Set</strong>. The functor <em>U</em> has both a left adjoint and a right adjoint. The left adjoint of <em>U</em> is <em>D</em> : <strong>Set</strong> → <strong>PrO</strong>, sending a set <em>X</em> to the discrete preorder on <em>X</em> (the preorder with underlying set <em>X</em>, having the fewest possible ⩽’s). The right adjoint of <em>U</em> is <em>I</em> : <strong>Set</strong> → <strong>PrO</strong>, sending a set <em>X</em> to the indiscrete preorder on <em>X</em> (the preorder with underlying set <em>X</em>, having the most possible ⩽’s). See Example <a href="chapter004.html#Exa_4-4-4-5">4.4.4.5</a>.</p>
<p><em>Exercise</em> 7.1.1.7.</p>
<p>Let <em>U</em> : <strong>Grph</strong> → <strong>Set</strong> denote the functor sending a graph to its underlying set of vertices. This functor has both a left and a right adjoint.</p>
<p>a. What functor <strong>Set</strong> → <strong>Grph</strong> is the left adjoint of <em>U</em>?</p>
<p>b. What functor <strong>Set</strong> → <strong>Grph</strong> is the right adjoint of <em>U</em>?</p>
<p><em>Example</em> 7.1.1.8. Here are some other adjunctions:</p>
<ul>
<li>Ob: <strong>Cat</strong> → <strong>Set</strong> has a left adjoint <em>Disc</em>: <strong>Set</strong> → <strong>Cat</strong> given by the discrete category.</li>
<li>Ob: <strong>Cat</strong> → <strong>Set</strong> has a right adjoint <em>Ind</em>: <strong>Set</strong> → <strong>Cat</strong> given by the indiscrete category.</li>
<li>The underlying graph functor <strong>Cat</strong> → <strong>Grph</strong> has a left adjoint <strong>Grph</strong> → <strong>Cat</strong> given by the free category.</li>
<li>The inclusion <strong>Grp</strong> → <strong>Mon</strong> has a right adjoint Mon→CoreGrp, called the <em>core</em>, that sends a monoid to its subgroup of invertible elements.</li>
<li>The functor <strong>PrO</strong> → <strong>Grph</strong>, given by drawing edges for ⩽’s, has a left adjoint given by existence of paths.</li>
<li>The forgetful functor from partial orders to preorders has a left adjoint given by quotienting out the cliques (see Exercise <a href="chapter004.html#Exe_4-4-1-15">4.4.1.15</a>).</li>
<li>Given a set <em>A</em>, the functor (− × <em>A</em>): <strong>Set</strong> → <strong>Set</strong> has a right adjoint Hom(<em>A</em>, −) (this was called currying in Section <a href="chapter003.html#lev_3-4-2">3.4.2</a>).</li>
</ul>
<p><em>Exercise</em> 7.1.1.9.</p>
<p>Let 1 denote the terminal category. There is a unique functor !: <strong>Set</strong> → 1.</p>
<p>a. Does ! have a left adjoint? If so, what is it; if not, why not?</p>
<p>b. Does ! have a right adjoint? If so, what is it; if not, why not?</p>
<p><em>Exercise</em> 7.1.1.10.</p>
<p>The discrete category functor <em>Disc</em>: <strong>Set</strong> → <strong>Cat</strong> has a left adjoint <em>p</em>: <strong>Cat</strong> → <strong>Set</strong>. In this exercise you will work out how to unpack this idea and begin to deduce how <em>p</em> must behave.</p>
<p>a. For an arbitrary object <em>X</em> ∈ Ob(<strong>Set</strong>) and an arbitrary object C∈Ob(Cat), write the adjunction in the style of (<a href="chapter007.html#eq_7-2">7.2</a>), appropriately filling in all the variables (e.g., decide whether B = <strong>Cat</strong> or B = <strong>Set</strong>, etc.).</p>
<p>b. For <em>X</em> and C as in part (a), write the adjunction isomorphism in the style of (<a href="chapter007.html#eq_7-1">7.1</a>), appropriately filling in all the variables.</p>
<p>c. Let C be the free category on the graph <em>G</em></p>
<p><img src="images/Art_P278.jpg" alt="art" /></p>
<p>and let <em>X</em> = {1, 2, 3}. How many elements does the set HomCat(C,Disc(X)) have?</p>
<p>d. What can you do to an arbitrary category C∈Ob(Cat) to make a set p(C) such that the adjunction isomorphism holds? That is, how does the functor <em>p</em>: <strong>Cat</strong> → <strong>Set</strong> behave on objects?</p>
<p>The following proposition says that all adjoints to a given functor are isomorphic to each other.</p>
<p><strong>Proposition 7.1.1.11</strong>. <em>Let</em> C <em>and</em> D <em>be categories, let</em> F:C→D <em>be a functor, and let</em> G,G′:D→C <em>also be functors. If both G and G′ are right adjoint (resp. if both are left adjoint) to F, then there is a natural isomorphism</em> ϕ:G→≅G′.</p>
<p><em>Proof</em>. Suppose that both <em>G</em> and <em>G</em>′ are right adjoint to <em>F</em> (the case of <em>G</em> and <em>G</em>′ being left adjoint is similarly proved). We first give a formula for the components of <em>ϕ</em>: <em>G</em> → <em>G</em>′ and its inverse <em>ψ</em> : <em>G</em>′ → <em>G</em>. Given an object d∈Ob(D), we use <em>c</em> = <em>G</em>(<em>d</em>) to obtain two natural isomorphisms, one from each adjunction:</p>
<p>HomC(G(d),G(d))≅HomD(F(G(d)),d)≅HomC(G(d),G′(d)).</p>
<p>The identity morphism id<sub><em>G</em>(<em>d</em>)</sub> is then sent to some morphism <em>G</em>(<em>d</em>) → <em>G</em>′(<em>d</em>), which we take to be the component <em>ϕ<sub>d</sub></em>. Similarly, we use <em>c</em>′ = <em>G</em>′(<em>d</em>) to obtain two natural isomorphisms, one from each adjunction:</p>
<p>HomC(G′(d),G′(d))≅HomD(F(G′(d)),d)≅HomC(G′(d),G(d)).</p>
<p>Again, the identity element id<sub><em>G</em>′(<em>d</em>)</sub> is sent to some morphism <em>G</em>′(<em>d</em>) → <em>G</em>(<em>d</em>), which we take to be the <em>d</em>-component <em>ψ<sub>d</sub></em>. The naturality of the adjunction isomorphisms implies that <em>ϕ</em> and <em>ψ</em> are natural transformations, and it is straightforward to check that they are mutually inverse.</p>
<h3 id="lev_7-1-1-12" class="level3"><strong>7.1.1.12   Quantifiers as adjoints</strong></h3>
<p>One of the simplest places where adjoints show up is between preimages and the logical quantifiers ∃ and ∀, ideas first discussed in Notation <a href="chapter002.html#Not_2-1-1-1">2.1.1.1</a>. The setting in which to discuss this is that of sets and their power preorders. That is, if <em>X</em> is a set, then recall from Section <a href="chapter004.html#lev_4-4-2">4.4.2</a> that the power-set ℙ(<em>X</em>) has a natural ordering by inclusion of subsets.</p>
<p>Given a function <em>f</em> : <em>X</em> → <em>Y</em> and a subset <em>V</em> ⊆ <em>Y</em> the preimage is <em>f</em><sup>−1</sup>(<em>V</em>) ≔ {<em>x</em> ∈ <em>X</em> | <em>f</em>(<em>x</em>) ∈ <em>V</em>}. If <em>V</em>′ ⊆ <em>V</em>, then <em>f</em><sup>−1</sup>(<em>V</em>′) ⊆ <em>f</em><sup>−1</sup>(<em>V</em>), so in fact <em>f</em><sup>−1</sup> : ℙ(<em>Y</em>) → ℙ(<em>X</em>) can be considered a functor (where of course we are thinking of preorders as categories). The quantifiers ∃ and ∀ appear as adjoints of <em>f</em><sup>−1</sup>.</p>
<p>Let’s begin with the left adjoint of <em>f</em><sup>−1</sup> : ℙ(<em>Y</em>) → ℙ(<em>X</em>). It is a functor <em>L<sub>f</sub></em> : ℙ(<em>X</em>) → ℙ(<em>Y</em>). Choose an object <em>U</em> ⊆ <em>X</em> in ℙ(<em>X</em>). It turns out that</p>
<p>Lf(U)={y∈Y|∃x∈f−1(y) such that x∈U}.</p>
<p>And the right adjoint <em>R<sub>f</sub></em> : ℙ(<em>X</em>) → ℙ(<em>Y</em>), when applied to <em>U</em>, is</p>
<p>Rf(U)={y∈Y|∀x∈f−1(y),x∈U}.</p>
<p>In fact, the functor <em>L<sub>f</sub></em> is generally denoted ∃<em><sub>f</sub></em> : ℙ(<em>X</em>) → ℙ(<em>Y</em>), and <em>R<sub>f</sub></em> is generally denoted ∀<em><sub>f</sub></em> : ℙ(<em>X</em>) → ℙ(<em>Y</em>).</p>
<p><img src="images/Art_P279.jpg" alt="art" /></p>
<p>The next example shows why this notation is apt.</p>
<p><em>Example</em> 7.1.1.13. In logic or computer science the quantifiers ∃ and ∀ are used to ask whether any or all elements of a set have a certain property. For example, one may have a set <em>U</em> of natural numbers and want to know whether any or all are even or odd. Let <em>Y</em> = {even, odd}, and let</p>
<p>p:ℕ→Y</p>
<p>be the function that assigns to each natural number its parity (even or odd). Because the elements of ℙ(ℕ) and ℙ(<em>Y</em>) are ordered by inclusion of subsets, we can construe these orders as categories (by Proposition <a href="chapter005.html#Pro_5-2-1-13">5.2.1.13</a>). What is new is that we have adjunctions between these categories:</p>
<p><img src="images/Art_P280.jpg" alt="art" /></p>
<p>Given a subset <em>U</em> ⊆ ℕ, i.e., an object <em>U</em> ∈ Ob(ℙ(ℕ)), we investigate the objects ∃<em><sub>p</sub></em>(<em>U</em>), ∀<em><sub>p</sub></em>(<em>U</em>). These are both subsets of {even, odd}. The set ∃<em><sub>p</sub></em>(<em>U</em>) includes the element even if there exists an even number in <em>U</em>; it includes the element odd if there exists an odd number in <em>U</em>. Similarly, the set ∀<em><sub>p</sub></em>(<em>U</em>) includes the element even if every even number is in <em>U</em>, and it includes odd if every odd number is in <em>U</em>.</p>
<p>Let’s use the definition of adjunction to ask whether every element of <em>U</em> ⊆ ℕ is even. Let <em>V</em> = {even} ⊆ <em>Y</em>. Then <em>f</em><sup>−1</sup>(<em>V</em>) ⊆ ℕ is the set of even numbers, and there is a morphism <em>U</em> → <em>f</em><sup>−1</sup>(<em>V</em>) in the preorder ℙ(ℕ) if and only if every element of <em>U</em> is even. Therefore, the adjunction isomorphism Hom<sub>ℙ(ℕ)</sub>(<em>U</em>, <em>f</em><sup>−1</sup>(<em>V</em>)) ≅ Hom<sub>ℙ(<em>Y</em>)</sub>(∃<em><sub>p</sub>U</em>, <em>V</em>) says that ∃<em><sub>p</sub>U</em> ⊆ {even} if and only if every element of <em>U</em> is even.</p>
<p><em>Exercise</em> 7.1.1.14.</p>
<p>The national scout jamboree is a gathering of Boy Scouts from troops across the United States. Let <em>S</em> be the set of Boy Scouts in the U.S., and let <em>T</em> be the set of Boy Scout troops in the U.S. Let <em>t</em>: <em>S</em> → <em>T</em> be the function that assigns to each Boy Scout his troop. Let <em>U</em> ⊆ <em>S</em> be the set of Boy Scouts in attendance at this year’s jamboree.</p>
<p>a. What is the meaning of the object ∃<em><sub>t</sub>U</em></p>
<p>b. What is the meaning of the object ∀<em><sub>t</sub>U</em>?</p>
<p><em>Exercise</em> 7.1.1.15.</p>
<p>Let <em>X</em> be an arbitrary set and <em>U</em> ⊆ <em>X</em> a subset.</p>
<p>a. Find a set <em>Y</em> and a function <em>f</em> : <em>X</em> → <em>Y</em> such that ∃<em><sub>f</sub>U</em> tells you whether <em>U</em> is nonempty.</p>
<p>b. What is the meaning of ∀<em><sub>f</sub>U</em> for your choice of <em>Y</em> and <em>f</em>?</p>
<p>In fact, the idea of quantifiers as adjoints is part of a larger story. Suppose we think of elements of a set <em>X</em> as bins, or storage areas. An element of ℙ(<em>X</em>) can be construed as an injection <em>U</em> ↪ <em>X</em>, i.e., an assignment of a bin to each element of <em>U</em>, with at most one element of <em>U</em> in each bin. Relaxing the injectivity restriction, we may consider arbitrary sets <em>U</em> and assignments <em>U</em> → <em>X</em> of a bin to each element <em>u</em> ∈ <em>U</em>. Given a function <em>f</em> : <em>X</em> → <em>Y</em> , we can generalize ∃<em><sub>f</sub></em> and ∀<em><sub>f</sub></em> to functors denoted Σ<em><sub>f</sub></em> and Π<em><sub>f</sub></em>, which will parameterize disjoint unions and products (respectively) over <em>y</em> ∈ <em>Y</em> . This is discussed in Section <a href="chapter007.html#lev_7-1-4">7.1.4</a>.</p>
<h2 id="lev_7-1-2" class="level2"><strong>7.1.2   Universal concepts in terms of adjoints</strong></h2>
<p>This section explores how universal concepts, i.e., initial objects and terminal objects, colimits and limits, are easily phrased in the language of adjoint functors. We say that a functor F:C→D <em>is a left adjoint</em> or <em>has a right adjoint</em> if there exists a functor G:D→C such that <em>F</em> is a left adjoint of <em>G</em>. Proposition <a href="chapter007.html#Pro_7-1-1-11">7.1.1.11</a> showed that if <em>F</em> is a left adjoint of some functor <em>G</em>, then it is isomorphic to every other left adjoint of <em>G</em>, and <em>G</em> is isomorphic to every other right adjoint of <em>F</em>.</p>
<p><em>Example</em> 7.1.2.1. Let C be a category and t:C→1¯ the unique functor to the terminal category. Then <em>t</em> has a right adjoint if and only if C has a terminal object, and <em>t</em> has a left adjoint if and only if C has an initial object. The proofs are dual, so let’s focus on the first.</p>
<p>The functor <em>t</em> has a right adjoint R:1¯→C if and only if for every object c∈Ob(C) there is an isomorphism</p>
<p>HomC(c,r)≅Hom1¯(t(c),1),</p>
<p>where <em>r</em> = <em>R</em>(1). But Hom<sub>1</sub>(<em>t</em>(<em>c</em>), 1) has one element. Thus <em>t</em> has a right adjoint iff HomC(c,r) has one element for each c∈Ob(C). This is the definition of <em>r</em> being a terminal object.</p>
<p>When colimits and limits were defined in Definitions <a href="chapter006.html#Def_6-1-3-31">6.1.3.31</a> and <a href="chapter006.html#Def_6-1-3-20">6.1.3.20</a>, it was for individual <em>I</em>-shaped diagrams X:I→C. Using adjoints we can define the limit of every <em>I</em>-shaped diagram in C at once.</p>
<p>Let <em>t</em>: <em>I</em> → 1 denote the unique functor to the terminal category. Suppose given an object c∈Ob(C), represented by the functor c:1¯→C. Then c○t:I→C is the <em>constant functor at c</em>, sending each object in <em>I</em> to the same C-object, <em>c</em>, and every morphism in <em>I</em> to id<em><sub>c</sub></em>. Thus composing with <em>t</em> induces a functor C≅Fun(1¯,C)→Fun(I,C), denoted Δt:C→Fun(I,C). It sends each object <em>c</em> to the associated constant functor <em>c</em> ○ <em>t</em>.</p>
<p>Suppose we want to take the colimit or limit of <em>X</em>. We are given an object <em>X</em> of Fun(I,C), and we want back an object of C. We could hope, and it turns out to be true, that the adjoints of Δ<em><sub>t</sub></em> are the limit and colimit. Indeed, let Σt:Fun(I,C)→C denote the left adjoint of Δ<em><sub>t</sub></em>, and let Πt:Fun(I,C)→C denote the right adjoint of Δ<em><sub>t</sub></em>. Then Σ<em><sub>t</sub></em> is the functor that takes colimits, and Π<em><sub>t</sub></em> is the functor that takes limits.</p>
<p>A generalization of colimits and limits is given in Section <a href="chapter007.html#lev_7-1-4">7.1.4</a>. But for now, let’s consider a concrete example.</p>
<p><em>Example</em> 7.1.2.2. Let C=Set, and let <em>I</em> = 3. The category Fun(3, <strong>Set</strong>) is the category of {1, 2, 3}-indexed sets, e.g., (ℤ, ℕ, ℤ) ∈ Ob(Fun(3, <strong>Set</strong>)) is an object of it. We will obtain the limit, i.e., the product of these three sets 3 → <strong>Set</strong> using adjoints.</p>
<p>In fact, the limit will be right adjoint to a functor Δ<em><sub>t</sub></em>: <strong>Set</strong> → Fun(3, <strong>Set</strong>), defined as follows. Given a set <em>c</em> ∈ Ob(<strong>Set</strong>), represented by a functor <em>c</em>: 1 → <strong>Set</strong>, and define Δ<em><sub>t</sub></em>(<em>c</em>) to be the composite <em>c</em> ○ <em>t</em>: 3 → <strong>Set</strong>; it is the constant functor. That is, Δ<em><sub>t</sub></em>(<em>c</em>): 3 → <strong>Set</strong> is the {1, 2, 3}-indexed set (<em>c</em>, <em>c</em>, <em>c</em>).</p>
<p>To say that Δ<em><sub>t</sub></em> has a right adjoint called Π<em><sub>t</sub></em> : Fun(3, <strong>Set</strong>) → <strong>Set</strong> and that Π<em><sub>t</sub></em> takes limits should mean that the definition of right adjoint provides the formula that yields the appropriate limit. Fix a functor <em>D</em> : 3 → <strong>Set</strong>, so <em>D</em>(1), <em>D</em>(2), and <em>D</em>(3) are sets. We know from Example <a href="chapter006.html#Exa_6-1-3-25">6.1.3.25</a> that the limit, lim <em>D</em>, of <em>D</em> is supposed to be the product <em>D</em>(1) × <em>D</em>(2) × <em>D</em>(3). For example, if <em>D</em> = (ℤ, ℕ, ℤ), then lim <em>D</em> = ℤ × ℕ × ℤ. How does this fact arise in the definition of adjoint?</p>
<p>The definition of Π<em><sub>t</sub></em> being the right adjoint to Δ<em><sub>t</sub></em> says that for any <em>c</em> ∈ Ob(<strong>Set</strong>) and <em>D</em> ∈ Fun(3, <strong>Set</strong>), there is a natural isomorphism of sets,</p>
<p>αc,D:HomFun( 3¯,Set)(Δt(c),D)≅HomSet(c,Πt(D)).(7.3)</p>
<p>The domain of <em>α</em><sub><em>c</em>,<em>D</em></sub> has elements <em>f</em> ∈ Hom<sub>Fun(3,<strong>Set</strong>)</sub>(Δ<sub><em>t</em></sub>(<em>c</em>), <em>D</em>) that look like the left-hand drawing, but having these three maps is equivalent to having the right-hand diagram:</p>
<p><img src="images/Art_P281.jpg" alt="art" /></p>
<p>The isomorphism <em>α</em><sub><em>c</em>,<em>D</em></sub> in (<a href="chapter007.html#eq_7-3">7.3</a>) says that choosing the three functions <em>f</em>(1), <em>f</em>(2), <em>f</em>(3) is the same thing as choosing a function <em>c</em> → Π<em><sub>t</sub></em>(<em>D</em>). This is basically the universal property for limits: there is a unique function <em>ℓ</em>: <em>c</em> → <em>D</em>(1) × <em>D</em>(2) × <em>D</em>(3), so this product is isomorphic to Π<em><sub>t</sub></em>. I have not given a formal proof here but hopefully enough for the interested reader to work it out.</p>
<h2 id="lev_7-1-3" class="level2"><strong>7.1.3   Preservation of colimits or limits</strong></h2>
<p>One useful fact about adjunctions is that left adjoints preserve all colimits, and right adjoints preserve all limits.</p>
<p><strong>Proposition 7.1.3.1</strong>. <em>Let</em> L:B⇄A :R <em>be an adjunction. For any indexing category I and functor D</em> : <em>I</em> → B, <em>if D has a colimit in</em> B, <em>then there is a unique isomorphism</em></p>
<p>L(colim D)≅colim(L○D).</p>
<p><em>Similarly, for any I</em> ∈ Ob(<strong>Cat</strong>) <em>and functor</em> D:I→A, <em>if D has a limit in</em> A<em>, then there is a unique isomorphism</em></p>
<p>R(lim⁡D)≅lim⁡(R○D).</p>
<p><em>Proof</em>. The proof is simple if one knows the Yoneda lemma (Section <a href="chapter007.html#lev_7-2-1-14">7.2.1.14</a>). See Mac Lane [29] for details.</p>
<p><em>Example</em> 7.1.3.2. Since Ob: <strong>Cat</strong> → <strong>Set</strong> is both a left adjoint and a right adjoint, it must preserve both limits and colimits. This means that if one wants to know the set of objects in the fiber product of some categories, one can simply take the fiber product of the set of objects in those categories,</p>
<p>Ob(A×CB)≅Ob(A)×Ob(C)Ob(B).</p>
<p>While the right-hand side might look daunting, it is just a fiber product in <strong>Set</strong>, which is quite understandable (see Definition <a href="chapter003.html#Def_3-2-1-1">3.2.1.1</a>).</p>
<p>This is greatly simplifying. If one thinks through what defines a limit in <strong>Cat</strong>, one encounters notions of slice categories and terminal objects in them. These slice categories are in <strong>Cat</strong> so they involve several categories and functors, and it is difficult for a beginner. Knowing that the objects are given by a simple fiber product makes the search for limits in <strong>Cat</strong> much simpler.</p>
<p>For example, if [<em>n</em>] is the linear order category of length <em>n</em>, then [<em>n</em>] × [<em>m</em>] has (<em>n</em> + 1)(<em>m</em> + 1) objects because [<em>n</em>] has <em>n</em> + 1 objects and [<em>m</em>] has <em>m</em> + 1 objects.</p>
<p><em>Example</em> 7.1.3.3. The path preorder functor <em>L</em>: <strong>Grph</strong> → <strong>PrO</strong> given by existence of paths (see Exercise <a href="chapter005.html#Exe_5-1-2-13">5.1.2.13</a>) is left adjoint to the functor <em>R</em>: <strong>PrO</strong> → <strong>Grph</strong> given by replacing ⩽’s by arrows. This means that <em>L</em> preserves colimits. So taking the union of graphs <em>G</em> and <em>H</em> results in a graph whose path poset <em>L</em>(<em>G</em> ⊔ <em>H</em>) is the union of the path posets of <em>G</em> and <em>H</em>. But this is not so for products, i.e., we do not expect to have an isomorphism <em>L</em>(<em>G</em> × <em>H</em>) ≅<sup>?</sup> <em>L</em>(<em>G</em>) × <em>L</em>(<em>H</em>).</p>
<p>As an example, let <img src="images/Art_P282.jpg" alt="art" />. Then <em>L</em>(<em>G</em>) = <em>L</em>(<em>H</em>) = [1], the linear order of length 1. But the product <em>G</em> × <em>H</em> in <strong>Grph</strong> looks like the graph</p>
<p><img src="images/Art_P283.jpg" alt="art" /></p>
<p>Its preorder <em>L</em>(<em>G</em> × <em>H</em>) does not have (<em>a</em>, <em>a</em>) ⩽ (<em>a</em>, <em>b</em>), whereas this is the case in the preorder <em>L</em>(<em>G</em>) × <em>L</em>(<em>H</em>). So <em>L</em>(<em>G</em> × <em>H</em>) ≇ <em>L</em>(<em>G</em>) × <em>L</em>(<em>H</em>). The left adjoint preservers all colimits, but not necessarily limits.</p>
<h2 id="lev_7-1-4" class="level2"><strong>7.1.4   Data migration</strong></h2>
<p>As we saw in Sections <a href="chapter005.html#lev_5-2-2">5.2.2</a> and <a href="chapter005.html#lev_5-2-2-6">5.2.2.6</a>, a database schema is a category C, and an instance is a functor I:C→Set.</p>
<p><em>Notation</em> 7.1.4.1. Let C be a category. The category Fun(C,Set) of functors from C to <strong>Set</strong>, i.e., the category of instances on C, is denoted C–Set.</p>
<p>This section discusses what happens to the resulting instances when different schemas are connected by a functor, say, F:C→D. It turns out that three adjoint functors emerge: ΔF:D−Set→C−Set, ΣF:C−Set→D−Set, and ΠF:C−Set→D−Set, where Δ<em><sub>F</sub></em> is adjoint to both of them:</p>
<p>ΣF:C−Set⇄D−Set :ΔFΔF:D−Set⇄C−Set :ΠF.</p>
<p>Interestingly, many of the basic database operations are captured by these three functors. For example, Δ<em><sub>F</sub></em> handles the job of duplicating or deleting tables as well as duplicating or deleting columns in a single table. The functor Σ<em><sub>F</sub></em> handles taking unions, and the functor Π<em><sub>F</sub></em> handles joining tables together, matching columns, or selecting the rows with certain properties (e.g., everyone whose first name is Mary).</p>
<p>This section is challenging, and it can be safely skipped, resuming at Section <a href="chapter007.html#lev_7-2">7.2</a>. For those who want to pursue it, there is an open source implementation of these ideas and more, called FQL,<sup><a href="chapter007.html#endnote_5">5</a></sup> which stands for <em>functorial query language</em> (not to be confused with Facebook query language).</p>
<h3 id="lev_7-1-4-2" class="level3"><strong>7.1.4.2   Pullback:</strong> Δ</h3>
<p>Given a functor F:C→D and a functor I:D→Set, we can compose them to get a functor I○F:C→Set. In other words, the presence of <em>F</em> provides a way to convert D-instances into C-instances. In fact, this conversion is functorial, meaning that a morphism of D-instances <em>α</em>: <em>I</em> → <em>I</em>′ is sent to a morphism of C-instances. This can be seen by whiskering (see Definition <a href="chapter005.html#Def_5-3-2-16">5.3.2.16</a>):</p>
<p><img src="images/Art_P284.jpg" alt="art" /></p>
<p>We denote the resulting functor ΔF:D−Set→C−Set and call it <em>pullback along F</em> .</p>
<p>An example of this was given in Example <a href="chapter005.html#Exa_5-3-2-15">5.3.2.15</a>, which showed how a monoid homomorphism F:M′→M could add functionality to a finite state machine. More generally, we can use pullbacks to reorganize data, copying and deleting tables and columns.</p>
<p><em>Remark</em> 7.1.4.3. Given a functor F:C→D, which we think of as a schema translation, the functor ΔF:D−Set→C−Set goes the opposite way. The reasoning is simple to explain (we are composing functors) but something about it often seems strange at first. The rough idea of this contravariance is captured by the role-reversal in the following slogan:</p>
<p><em>Slogan</em> 7.1.4.4.</p>
<p><em>If I get my information from you, then your information becomes my information</em>.</p>
<p>Consider the following functor F:C→D:<sup><a href="chapter007.html#endnote_6">6</a></sup></p>
<p><img src="images/Art_P285.jpg" alt="art" /></p>
<p>Recall how to read schemas. In schema C there are leaf tables SSN, First, Last, Salary, which represent different kinds of basic data. More interestingly, there are two <em>fact tables</em>. The first is called T1, and it relates SSN, First, and Last. The second is called T2, and it relates First, Last, and Salary.</p>
<p>The functor F:C→D relates C to a schema D which has a single fact table relating all four attributes: SSN, First, Last, and Salary. We are interested in ΔF:D−Set→C−Set. Suppose given the following database instance I:D→Set on D:</p>
<p><img src="images/Art_P286.jpg" alt="art" /></p>
<p><img src="images/Art_P286a.jpg" alt="art" /></p>
<p>How does one get the instance ΔF(I):C→Set? The formula was given: compose <em>I</em> with <em>F</em> . In terms of tables, it is like duplicating table T as T1 and T2 but deleting a column from each in accordance with the definition of C in (<a href="chapter007.html#eq_7-4">7.4</a>). Here is the result, Δ<em><sub>F</sub></em> (<em>I</em>), in table form:</p>
<p><img src="images/Art_P287.jpg" alt="art" /></p>
<p><em>Exercise</em> 7.1.4.5.</p>
<p>Consider the schemas</p>
<p><img src="images/Art_P288.jpg" alt="art" /></p>
<p>and the functor <em>F</em> : [1] → [2] given by sending 0 ↦ 0 and 1 ↦ 2.</p>
<p>a. How many possibilities are there for <em>F</em>(<em>f</em>)?</p>
<p>b. Suppose <em>I</em> : [2] → <strong>Set</strong> is given by the following tables:</p>
<p><img src="images/Art_P289.jpg" alt="art" /></p>
<p>Write the two tables associated to the [1]-instance Δ<em><sub>F</sub></em>(<em>I</em>): [1] → <strong>Set</strong>.</p>
<h3 id="lev_7-1-4-6" class="level3"><strong>7.1.4.6   Left pushforward:</strong> Σ</h3>
<p>Let F:C→D be a functor. The functor ΔF:D−Set→C−Set has a left adjoint, ΣF:C−Set→D−Set. The rough idea is that Σ<em><sub>F</sub></em> performs parameterized colimits. Given an instance I:C→Set, we get an instance on D that acts as follows. For each object d∈Ob(D), the set Σ<em><sub>F</sub></em>(<em>I</em>)(<em>d</em>) is the colimit (think of union) of some diagram in C.</p>
<p>Left pushforwards (also known as left Kan extensions) are discussed at length in Spivak [38]; here we examine some examples from that paper.</p>
<p><em>Example</em> 7.1.4.7. We again use the functor F:C→D from (<a href="chapter007.html#eq_7-4">7.4</a>):</p>
<p><img src="images/Art_P290.jpg" alt="art" /></p>
<p>We apply the left pushforward ΣF:C−Set→D−Set to the following instance I:C→Set:</p>
<p><img src="images/Art_P291.jpg" alt="art" /></p>
<p>The functor F:C→D sends both tables T1 and T2 to table T. Applying Σ<em><sub>F</sub></em> takes what was in T1 and T2 and puts the union in T. The result, ΣFI:D→Set, is as follows:</p>
<p><img src="images/Art_P292.jpg" alt="art" /></p>
<p><img src="images/Art_P292a.jpg" alt="art" /></p>
<p>As one can see, no set salary information for any data comes from table T1, nor does any set SSN information come form table T2. But the definition of adjoint, given in Definition <a href="chapter007.html#Def_7-1-1-1">7.1.1.1</a>, yields the universal response: freely add new variables that take the place of missing information. It turns out that this idea already has a name in logic, <em>Skolem variables</em>, and a name in database theory, <em>labeled nulls</em>.</p>
<p><em>Exercise</em> 7.1.4.8.</p>
<p>Consider the functor <em>F</em> : 3 → 2 given by the sequence (1, 2, 2).</p>
<p>a. Write an instance <em>I</em> : 3 → <strong>Set</strong>.</p>
<p>b. Given the description “Σ<em><sub>F</sub></em> performs a parameterized colimit,” make an educated guess about what Σ<em><sub>F</sub></em>(<em>I</em>): 2 → <strong>Set</strong> is. Give your answer in the form of two sets that are made up from the three sets you already wrote.</p>
<p>Here is the actual formula for computing left pushforwards. Suppose that F:C→D is a functor, and let I:C→Set be a set-valued functor on C. Then ΣF(I):D→Set is defined as follows. Given an object d∈Ob(D), we first form the comma category (see Definition <a href="chapter006.html#Def_6-2-4-1">6.2.4.1</a>) for the cospan</p>
<p>C→FD←d1¯</p>
<p>and denote it (<em>F</em> ↓ <em>d</em>). There is a canonical projection functor π:(F↓d)→C, which we can compose with I:C→Set to obtain a functor (<em>F</em> ↓ <em>d</em>) → <strong>Set</strong>. We are ready to define Σ<em><sub>F</sub></em>(<em>I</em>)(<em>d</em>) to be its colimit,</p>
<p>ΣF(I)(d)≔colim(F↓d) I○π.</p>
<p>ΣF(I):D→Set has been defined on objects d∈Ob(D). Morphisms are treated here only briefly; see Spivak [38] for details. Given a morphism <em>g</em> : <em>d</em> → <em>d</em>′, there is an induced functor (<em>F</em> ↓ <em>g</em>): (<em>F</em> ↓ <em>d</em>) → (<em>F</em> ↓ <em>d</em>′) and a commutative diagram of categories:</p>
<p><img src="images/Art_P293.jpg" alt="art" /></p>
<p>By the universal property for colimits, this induces the required function</p>
<p>colim(F↓d) I○π→ΣF(I)(g)colim(F↓d′) I○π′.</p>
<h3 id="lev_7-1-4-9" class="level3"><strong>7.1.4.9   Right pushforward:</strong> Π</h3>
<p>Let F:C→D be a functor. Section <a href="chapter007.html#lev_7-1-4-6">7.1.4.6</a> explained that the functor ΔF:D−Set→C−Set has a left adjoint. The present section explains that Δ<em><sub>F</sub></em> has a right adjoint, ΠF:C−Set→D−Set as well. The rough idea is that Π<em><sub>F</sub></em> performs parameterized limits. Given an instance I:C→Set, we get an instance on D that acts as follows. For each object d∈Ob(D), the set Π<em><sub>F</sub></em>(<em>I</em>)(<em>d</em>) is the limit (think of fiber product) of some diagram in C.</p>
<p>Right pushforwards (also known as right Kan extensions) are discussed at length in Spivak [38]; here we look at some examples from that paper.</p>
<p><em>Example</em> 7.1.4.10. We again use the functor F:C→D from (<a href="chapter007.html#eq_7-4">7.4</a>) and Example <a href="chapter007.html#Exa_7-1-4-7">7.1.4.7</a>. We apply the right pushforward Π<em><sub>F</sub></em> to instance I:C→Set from that example.<sup><a href="chapter007.html#endnote_7">7</a></sup></p>
<p>The instance Π<em><sub>F</sub></em>(<em>I</em>) puts data in all five tables in D. In T it puts pairs (<em>t</em><sub>1</sub>, <em>t</em><sub>2</sub>), where <em>t</em><sub>1</sub> is a row in T1, and <em>t</em><sub>2</sub> is a row in T2, for which the first and last names agree. It copies the leaf tables exactly, so they are not displayed here; the following is the table T for Π<em><sub>F</sub></em>(<em>I</em>):</p>
<p>T</p>
<p><strong>ID</strong></p>
<p><strong>SSN</strong></p>
<p><strong>First</strong></p>
<p><strong>Last</strong></p>
<p><strong>Salary</strong></p>
<p>T1-002T2-A104</p>
<p>122-988</p>
<p>Sue</p>
<p>Smith</p>
<p>$300</p>
<p>T1-003T2-A101</p>
<p>198-877</p>
<p>Alice</p>
<p>Jones</p>
<p>$100</p>
<p>From T1 and T2 there are only two ways to match first and last names.</p>
<p><em>Exercise</em> 7.1.4.11.</p>
<p>Consider the functor <em>F</em> : 3 → 2 given by the sequence (1, 2, 2).</p>
<p>a. Write an instance <em>I</em> : 3 → <strong>Set</strong>.</p>
<p>b. Given the description “Π<em><sub>F</sub></em> performs a parameterized limit,” make an educated guess about what Π<em><sub>F</sub></em>(<em>I</em>): 2 → <strong>Set</strong> is. Give your answer in the form of two sets that are made up from the three sets you already wrote down.</p>
<p>Here is the actual formula for computing right pushforwards. Suppose that F:C→D is a functor, and let I:C→Set be a set-valued functor on C. Then ΠF(I):D→Set is defined as follows. Given an object d∈Ob(D), we first form the comma category (see Definition <a href="chapter006.html#Def_6-2-4-1">6.2.4.1</a>) for the cospan</p>
<p>1¯→dD←FC</p>
<p>and denote it (<em>d</em> ↓ <em>F</em>). There is a canonical projection functor π:(d↓F)→C, which we can compose with I:C→Set to obtain a functor (<em>d</em> ↓ <em>F</em>) → <strong>Set</strong>. We are ready to define Π<em><sub>F</sub></em>(<em>I</em>)(<em>d</em>) to be its limit,</p>
<p>ΠF(I)(d)≔lim⁡(d↓F)I○π.</p>
<p>ΠF(I):D→Set has been defined on objects d∈Ob(D), and morphisms are treated only briefly; see Spivak [38] for details. Given a morphism <em>g</em> : <em>d</em> → <em>d</em>′, there is an induced functor (<em>g</em> ↓ <em>F</em>) : (<em>d</em>′ ↓ <em>F</em>) → (<em>d</em> ↓ <em>F</em>) and a commutative diagram of categories:</p>
<p><img src="images/Art_P294.jpg" alt="art" /></p>
<p>By the universal property for limits, this induces the required function</p>
<p>lim⁡(d↓F)I○π→ΠF(I)(g)lim⁡(d′↓F)I○π′.</p>
<p><strong>Proposition 7.1.4.12</strong>. <em>Left adjoints are closed under composition, as are right adjoints. That is, given adjunctions,</em></p>
<p>C⇄RLD⇄R′L′ℰ</p>
<p><em>their composite is also an adjunction:</em></p>
<p>C⇄R○R′L′○Lℰ.</p>
<p><em>Proof</em>. This is a straightforward calculation. For any objects c∈Ob(C) and <em>e</em> ∈ Ob(E) we have adjunction isomorphisms:</p>
<p>Homℰ(L′(L(c)),e)≅HomD(L(c),R′(e))≅HomC(c,R(R′(e)))</p>
<p>whose composite is the required adjunction isomorphism. It is natural in our choice of objects <em>c</em> and <em>e</em>.</p>
<p><em>Example</em> 7.1.4.13 (Currying via Δ, Σ, Π). This example shows how currying (as in Sections <a href="chapter003.html#lev_3-4-2">3.4.2</a> and <a href="chapter007.html#Exa_7-1-1-8">7.1.1.8</a>) arises out of a certain combination of data migration functors.</p>
<p>Let <em>A</em>, <em>B</em>, and <em>C</em> be sets. Consider the unique functor <em>a</em>: <em>A</em> → 1 and consider <em>B</em> and <em>C</em> as functors 1¯→BSet and 1¯→CSet respectively.</p>
<p><img src="images/Art_P295.jpg" alt="art" /></p>
<p>Note that 1–<strong>Set</strong> ≅ <strong>Set</strong>, and we elide the difference.</p>
<p>We know that Σ<em><sub>a</sub></em> is left adjoint to Δ<em><sub>a</sub></em> and that Δ<em><sub>a</sub></em> is left adjoint to Π<em><sub>a</sub></em>, so by Proposition <a href="chapter007.html#Pro_7-1-4-12">7.1.4.12</a>, the composite Σ<em><sub>a</sub></em> ○ Δ<em><sub>a</sub></em> is left adjoint to Π<em><sub>a</sub></em>Δ<em><sub>a</sub></em>. The goal is to see currying arise out of the adjunction isomorphism</p>
<p>HomSet(ΣaΔa(B),C)≅HomSet(B,ΠaΔa(C)).(7.5)</p>
<p>By definition, Δ<em><sub>a</sub></em>(<em>B</em>): <em>A</em> → <strong>Set</strong> assigns to each element <em>a</em> ∈ <em>A</em> the set <em>B</em>. Since Σ<em><sub>A</sub></em> takes disjoint unions, we have a bijection</p>
<p>Σa(Δa(B))=(∐a∈AB)≅A×B.</p>
<p>Similarly, Δ<em><sub>a</sub></em>(<em>C</em>): <em>A</em> → <strong>Set</strong> assigns to each element <em>a</em> ∈ <em>A</em> the set <em>C</em>. Since Π<em><sub>A</sub></em> takes products, we have a bijection</p>
<p>Πa(Δa(C))=(∐a∈AC)≅CA.</p>
<p>The currying isomorphism Hom<strong><sub>Set</sub></strong>(<em>A</em> × <em>B</em>, <em>C</em>) ≅ Hom<strong><sub>Set</sub></strong>(<em>B</em>, <em>C<sup>A</sup></em>) falls out of (<a href="chapter007.html#eq_7-5">7.5</a>).</p>
<h1 id="lev_7-2" class="level1"><a href="toc.html#Rlev_7-2"><strong>7.2   Categories of functors</strong></a></h1>
<p>For any two categories C and D,<sup><a href="chapter007.html#endnote_8">8</a></sup> Section <a href="chapter005.html#lev_5-3-2">5.3.2</a>.1 discussed the category Fun(C,D) of functors and natural transformations between them. This section discusses functor categories a bit more and gives some important applications in mathematics (sheaves) that extend to the real world.</p>
<h2 id="lev_7-2-1" class="level2"><strong>7.2.1   Set-valued functors</strong></h2>
<p>Let C be a category. We have been denoted by C−Set the functor category Fun(C,Set). Here is a nice result about these categories.</p>
<p><strong>Proposition 7.2.1.1</strong>. <em>Let</em> C <em>be a category. The category</em> C−Set <em>is closed under colimits and limits. That is, for any category I and functor</em> D:I→C−Set, <em>both the limit and the colimit of D exist in</em> C−Set.</p>
<p><em>Sketch of proof</em>. We rely on the fact that the category <strong>Set</strong> is complete and cocomplete (see Remark <a href="chapter006.html#Rem_6-1-3-37">6.1.3.37</a>), i.e., that it has all limits and colimits (see Theorems <a href="chapter006.html#The_6-1-3-28">6.1.3.28</a> and <a href="chapter006.html#The_6-1-3-35">6.1.3.35</a> for constructions). Let <em>J</em> be an indexing category and D:J→C−Set a functor. For each object c∈Ob(C), we have a functor Dc:J→Set defined by <em>D<sub>c</sub></em>(<em>j</em>) = <em>D</em>(<em>j</em>)(<em>c</em>). Define a functor L:C→Set by <em>L</em>(<em>c</em>) = lim<em><sub>J</sub> D<sub>c</sub></em>, and note that for each <em>f</em> : <em>c</em> → <em>c</em>′ in C there is an induced function <em>L</em>(<em>f</em>): <em>L</em>(<em>c</em>) → <em>L</em>(<em>c</em>′). One can check that <em>L</em> is a limit of <em>J</em>, because it satisfies the relevant universal property.</p>
<p>The dual proof holds for colimits.</p>
<p><em>Application</em> 7.2.1.2. When taking in data about a scientific subject, one often finds that how one thinks about the problem changes over time. We understand this phenomenon in the language of databases in terms of a series of schemas C1,C2,…,Cn+1, perhaps indexed chronologically. The problem is that previously-collected data is held in what may be outdated schemas, and we want to work with it in our current understanding. By finding appropriate functors between these schemas, or possibly with the help of auxiliary schemas, we can make a chain of categories and functors</p>
<p>C1←F1D1→G1ℰ1→H1C2←F2D2→G2ℰ2→H2…→Gnℰn→HnCn+1.</p>
<p>We can then use the data migration functors Δ<em><sub>F</sub></em>, Π<em><sub>G</sub></em>, and Σ<em><sub>H</sub></em> to move data from category C1 to category Cn+1 using projections, joins, and unions in any combination. Theorems about sequences of Δ’s, Π’s, and Σ’s can help us understand how such a transformation will behave, before we spend the resources to enact it.</p>
<p><em>Exercise</em> 7.2.1.3.</p>
<p>By Proposition <a href="chapter007.html#Pro_7-2-1-1">7.2.1.1</a>, the category C–Set is closed under taking colimits and limits. By Exercises <a href="chapter006.html#Exe_6-1-3-24">6.1.3.24</a> and <a href="chapter006.html#Exe_6-1-3-34">6.1.3.34</a>, this means in particular, that C–Set has an initial object and a terminal object.</p>
<p>a. Let A∈Ob(C−Set) be the initial object, considered as a functor A:C→Set. For any c∈Ob(C), what is the set <em>A</em>(<em>c</em>)?</p>
<p>b. Let Z∈Ob(C−Set) be the terminal object, considered as a functor Z:C→Set. For any c∈Ob(C), what is the set <em>Z</em>(<em>c</em>)?</p>
<p>Proposition <a href="chapter007.html#Pro_7-2-1-1">7.2.1.1</a> says that we can add or multiply database instances together. In fact, database instances on C form a <em>topos</em>, which means that just about every consideration we made for sets holds for instances on any schema. Perhaps the simplest schema is <img src="images/Art_P296.jpg" alt="art" />, on which the relevant topos <img src="images/Art_P297.jpg" alt="art" /> is indeed equivalent to <strong>Set</strong>. But schemas can be arbitrarily complex categories, and it is impressive that all these set-theoretic notions make sense in such generality. Here is a table that compares these domains:</p>
<p>Dictionary between <strong>Set</strong> and C→Set</p>
<p><strong>Concept in Set</strong></p>
<p><strong>Concept in</strong> C–Set</p>
<p>Set</p>
<p>Object in C–Set</p>
<p>Function</p>
<p>Morphism in C–Set</p>
<p>Element</p>
<p>Representable functor</p>
<p>Empty set</p>
<p>Initial object</p>
<p>Natural numbers</p>
<p>Natural numbers object</p>
<p>Image</p>
<p>Image</p>
<p>(Co)limits</p>
<p>(Co)limits</p>
<p>Exponential objects</p>
<p>Exponential objects</p>
<p>“Familiar” arithmetic</p>
<p>“Familiar” arithmetic</p>
<p>Power-sets 2<em><sup>X</sup></em></p>
<p>Power objects Ω<em><sup>X</sup></em></p>
<p>Characteristic functions</p>
<p>Characteristic morphisms</p>
<p>Surjections, injections</p>
<p>Epimorphisms, monomorphisms</p>
<p>Thus elements of a set are akin to representable functors in C–Set, which are defined in Section <a href="chapter007.html#lev_7-2-1-6">7.2.1.6</a>. We briefly discuss monomorphisms and epimorphisms first in general (Definition <a href="chapter007.html#Def_7-2-1-4">7.2.1.4</a>) and then in C–Set (Proposition <a href="chapter007.html#Pro_7-2-1-5">7.2.1.5</a>).</p>
<p><strong>Definition 7.2.1.4</strong> (Monomorphism, epimorphism). Let S be a category, and let <em>f</em> : <em>X</em> → <em>Y</em> be a morphism. We say that <em>f</em> is a <em>monomorphism</em> if it has the following property. For all objects A∈Ob(S) and morphisms <em>g</em>, <em>g</em>′ : <em>A</em> → <em>X</em> in S,</p>
<p><img src="images/Art_P298.jpg" alt="art" /></p>
<p>if <em>f</em> ○ <em>g</em> = <em>f</em> ○ <em>g</em>′, then <em>g</em> = <em>g</em>′.</p>
<p>We say that <em>f</em> : <em>X</em> → <em>Y</em> is an <em>epimorphism</em> if it has the following property. For all objects B∈Ob(S) and morphisms <em>h</em>, <em>h</em>′ : <em>Y</em> → <em>B</em> in S,</p>
<p><img src="images/Art_P299.jpg" alt="art" /></p>
<p>if <em>h</em> ○ <em>f</em> = <em>h</em>′ ○ <em>f</em>, then <em>h</em> = <em>h</em>′.</p>
<p>In the category of sets, monomorphisms are the same as injections, and epimorphisms are the same as surjections (see Proposition <a href="chapter003.html#Pro_3-4-5-8">3.4.5.8</a>). The same is true in C–Set: one can check table by table that a morphism of instances is mono or epi.</p>
<p><strong>Proposition 7.2.1.5</strong>. <em>Let</em> C <em>be a category, let</em> X,Y:C→Set <em>be objects in</em> C−Set, <em>and let f</em> : <em>X</em> → <em>Y be a morphism in</em> C−Set. <em>Then f is a monomorphism (resp. an epimorphism) if and only if for every object</em> c∈Ob(C), <em>the function f</em>(<em>c</em>): <em>X</em>(<em>c</em>) → <em>Y</em>(<em>c</em>) <em>is injective (resp. surjective)</em>.</p>
<p><em>Sketch of proof</em>. We first show that if <em>f</em> is mono (resp. epi), then so is <em>f</em>(<em>c</em>), for all c∈Ob(C). Considering <em>c</em> as a functor c:1¯→C, this result follows from the fact that Δ<em><sub>c</sub></em> preserves limits and colimits, hence monos and epis.</p>
<p>We now check that if <em>f</em>(<em>c</em>) is mono for all c∈Ob(C), then <em>f</em> is mono. Suppose that <em>g</em>, <em>g</em>′ : <em>A</em> → <em>X</em> are morphisms in C–Set such that <em>f</em> ○ <em>g</em> = <em>f</em> ○ <em>g</em>′. Then for every <em>c</em>, we have <em>f</em> ○ <em>g</em>(<em>c</em>) = <em>f</em> ○ <em>g</em>′(<em>c</em>), which implies by hypothesis that <em>g</em>(<em>c</em>) = <em>g</em>′(<em>c</em>). But the morphisms in C–Set are natural transformations, and if two natural transformations <em>g</em>, <em>g</em>′ have the same components, then they are the same.</p>
<p>A similar argument works to show the analogous result for epimorphisms.</p>
<h3 id="lev_7-2-1-6" class="level3"><strong>7.2.1.6   Representable functors</strong></h3>
<p>Given a category C, there are certain functors C→Set that come with the package, i.e., that are not arbitrary from a mathematical perspective as database instances usually are. In fact, there is a certain instance corresponding to each object in C. So if C is a database schema, then for every table c∈Ob(C) there is a certain database instance associated to it. These instances, i.e., set-valued functors, are called representable functors (see Definition <a href="chapter007.html#Def_7-2-1-7">7.2.1.7</a>). The idea is that if a database schema is a conceptual layout of types (e.g., as an olog), then each type <em>c</em> has an instance associated to it, standing for “the generic thing of type <em>c</em> with all its generic attributes.”</p>
<p><strong>Definition 7.2.1.7</strong>. Let C be a category, and let c∈Ob(C) be an object. The functor HomC(c,−):C→Set, sending d∈Ob(C) to the set HomC(c,d) and acting similarly on morphisms <em>d</em> → <em>d</em>′, is said to be <em>represented by c</em>. If a functor F:C→Set is isomorphic to HomC(c,−), we say that <em>F</em> is <em>a representable functor</em>. To shorten notation we sometimes write</p>
<p>Yc≔HomC(c,−).</p>
<p><em>Example</em> 7.2.1.8. Given a category C and an object c∈Ob(C), we get a representable functor <em>Y<sub>c</sub></em>. If we think of C as a database schema and <em>c</em> as a table, then what does the representable functor Yc:C→Set look like in terms of databases? It turns out that the following procedure will generate it.</p>
<p>Begin by writing a new row, say, “☺,” in the ID column of table <em>c</em>. For each foreign key column <em>f</em> : <em>c</em> → <em>c</em>′, add a row in the ID column of table <em>c</em>′ called “<em>f</em>(☺)” and record that result, “<em>f</em>(☺),” in the <em>f</em> column of table <em>c</em>. Repeat as follows: for each table <em>d</em>, identify all rows <em>r</em> that have a blank cell in column <em>g</em> : <em>d</em> → <em>e</em>. Add a new row called “<em>g</em>(<em>r</em>)” to table <em>e</em> and record that result, “<em>g</em>(<em>r</em>),” in the (<em>r</em>, <em>g</em>) cell of table <em>d</em>.</p>
<p>Here is a concrete example. Let C be the following schema:</p>
<p><img src="images/Art_P300.jpg" alt="art" /></p>
<p>Then YB:C→Set is given by “morphisms from <em>B</em> to −,” i.e., it is the following instance:</p>
<p><img src="images/Art_P301.jpg" alt="art" /></p>
<p>To create <em>Y<sub>B</sub></em> we began with a single element in table <em>B</em> and followed the arrows, putting new entries wherever they were required. One might call this the <em>schematically implied reference spread</em> or SIRS of the element ☺ in table <em>B</em>. Notice that the table at <em>A</em> is empty, because there are no morphisms <em>B</em> → <em>A</em> in C.</p>
<p>Representable functors <em>Y<sub>c</sub></em> yield database instances that are as free as possible, subject to having the initial row ☺ in table <em>c</em>. We saw this before (as Skolem variables) when studying the left pushforward Σ. Indeed, suppose c∈Ob(C) is an object represented by the functor c:1¯→C. A database instance on 1 is the same thing as a set <em>X</em>. The left pushforward Σ<em><sub>c</sub></em>(<em>X</em>) has the same kinds of Skolem variables as <em>Y<sub>c</sub></em> does. In fact, if <em>X</em> = {☺} is a one-element set, then we get the representable functor</p>
<p>Yc≅Σc{☺}.</p>
<p><em>Exercise</em> 7.2.1.9.</p>
<p>Consider the schema for graphs,</p>
<p><img src="images/Art_P302.jpg" alt="art" /></p>
<p>a. Write the representable functor <em>Y<sub>Ar</sub></em> : <strong>GrIn</strong> → <strong>Set</strong> as two tables.</p>
<p>b. Write the representable functor <em>Y<sub>Ve</sub></em> as two tables.</p>
<p><em>Solution</em> 7.2.1.9.</p>
<p>a. This was done in Exercise <a href="chapter005.html#Exe_5-3-3-7">5.3.3.7</a>, although not with the most natural names. Here we rewrite <em>Y<sub>Ar</sub></em> = Hom<strong><sub>GrIn</sub></strong>(<em>Ar</em>, −) as</p>
<p><img src="images/Art_P303.jpg" alt="art" /></p>
<p>b. Here is <em>Y<sub>Ve</sub></em> = Hom<strong><sub>GrIn</sub></strong>(<em>Ve</em>, −) with “natural names”:</p>
<p><img src="images/Art_P304.jpg" alt="art" /></p>
<p>(The left-hand table is empty because there are no morphisms <em>Ve</em> → <em>Ar</em> in <strong>GrIn</strong>.)</p>
<p><em>Exercise</em> 7.2.1.10.</p>
<p>Consider the loop schema</p>
<p><img src="images/Art_P305.jpg" alt="art" /></p>
<p>Express the representable functor Ys:Loop→Set in table form.</p>
<p><em>Solution</em> 7.2.1.10.</p>
<p>We have Ys=HomLoop(s,−):Loop→Set. On objects, of which there is only Ob(Loop)={s}, we have <em>Y<sub>s</sub></em>(<em>s</em>) = {<em>f<sup>n</sup></em> | <em>n</em> ∈ ℕ}. The morphism <em>f</em> : <em>s</em> → <em>s</em> acts on <em>Y<sub>s</sub></em>(<em>s</em>) by composing. Here is <em>Y<sub>s</sub></em> in table form:</p>
<p><em><strong>s</strong></em></p>
<p><strong>ID</strong></p>
<p><strong>f</strong></p>
<p>☺</p>
<p><em>f</em>(☺)</p>
<p><em>f</em>(☺)</p>
<p><em>f</em><sup>2</sup>(☺)</p>
<p><em>f</em><sup>2</sup>(☺)</p>
<p><em>f</em><sup>3</sup>(☺)</p>
<p><em>f</em><sup>3</sup>(☺)</p>
<p><em>f</em><sup>4</sup>(☺)</p>
<p><em>f</em><sup>4</sup>(☺)</p>
<p><em>f</em><sup>5</sup>(☺)</p>
<p>⋮</p>
<p>⋮</p>
<p>Let <em>B</em> be a box in an olog, say, ⌜a person⌝, and recall that an aspect of <em>B</em> is an outgoing arrow, such as ⌜a person⌝→has as height in inches⌜an integer⌝. The following slogan explains representable functors in those terms.</p>
<p><em>Slogan</em> 7.2.1.11.</p>
<p><em>The functor represented by</em> ⌜a person⌝ <em>simply leaves a placeholder, like</em> 〈<em>person’s name here</em>〉 <em>or</em> 〈<em>person’s height here</em>〉, <em>for every aspect of</em> ⌜a person⌝<em>. In general, there is a representable functor for every type in an olog. The representable functor for type T simply encapsulates the most generic or abstract example of type T, by leaving a placeholder for each of its attributes.</em></p>
<p><em>Exercise</em> 7.2.1.12.</p>
<p>Recall from Definition <a href="chapter007.html#Def_7-2-1-7">7.2.1.7</a> that a functor F:C→Set is said to be represented by <em>c</em> if there is a natural isomorphism F≅HomC(c,−).</p>
<p>a. There is a functor Ob: <strong>Cat</strong> → <strong>Set</strong> (see Exercise <a href="chapter005.html#Exe_5-1-2-41">5.1.2.41</a>) sending a category C to its set Ob(C) of objects, and sending a functor to its on-objects part. This functor is representable by some category. Name a category <em>A</em> that represents Ob.</p>
<p>b. There is a functor Hom: <strong>Cat</strong> → <strong>Set</strong> (see Exercise <a href="chapter005.html#Exe_5-1-2-42">5.1.2.42</a>) sending a category C to the set HomC of all morphisms in C and sending a functor to its on-morphisms part. This functor is representable by a category. Name a category <em>B</em> that represents Hom.</p>
<p><em>Exercise</em> 7.2.1.13.</p>
<p>Let C be a category, let c,c′∈Ob(C) be objects, and let Yc,Yc′:C→Set be the associated representable functors. Given <em>f</em> : <em>c</em> → <em>c</em>′, we want to construct a morphism <em>Y<sub>f</sub></em> : <em>Y</em><sub><em>c</em>′</sub> → <em>Y<sub>c</sub></em> in Fun(C−Set). Of course, <em>Y<sub>f</sub></em> is supposed to be a natural transformation, so we need to provide a component (<em>Y<sub>f</sub></em>)<em><sub>d</sub></em> for every object d∈Ob(C).</p>
<p>a. What must the domain and codomain of (<em>Y<sub>f</sub></em>)<em><sub>d</sub></em> be? (Simplify your answer using Definition <a href="chapter007.html#Def_7-2-1-7">7.2.1.7</a>.)</p>
<p>b. Can you make sense of the statement, “Define (<em>Y<sub>f</sub></em>)<em><sub>d</sub></em> by precomposition”?</p>
<p>c. If <em>h</em>: <em>d</em> → <em>e</em> is a morphism in C, draw the naturality square for <em>Y<sub>f</sub></em>. Does it commute?</p>
<p><em>Solution</em> 7.2.1.13.</p>
<p>a. We have (<em>Y<sub>f</sub></em>)<em><sub>d</sub></em> : <em>Y</em><sub><em>c</em>′</sub>(<em>d</em>) → <em>Y<sub>c</sub></em>(<em>d</em>). But by definition, this is (Yf)d:HomC(c′,d)→HomC(c,d).</p>
<p>b. Given an element g∈HomC(c′,d), we can precompose with <em>f</em> to get a morphism c→fc′→gd, so let’s define (<em>Y<sub>f</sub></em>)<em><sub>d</sub></em>(<em>g</em>) = <em>g</em> ○ <em>f</em>.</p>
<p>c. The naturality square is as follows</p>
<p><img src="images/Art_P306.jpg" alt="art" /></p>
<p>and it commutes because, for any element <em>g</em> ∈ <em>Y</em><sub><em>c</em>′</sub>(<em>d</em>), the composition c→fc′→gd→he is associative. More explicitly, going down then right we have (<em>Y<sub>f</sub></em>)<em><sub>d</sub></em>(<em>g</em>) = <em>g</em> ○ <em>f</em> and <em>Y<sub>c</sub></em>(<em>h</em>)(<em>g</em> ○ <em>f</em>) = <em>h</em> ○ (<em>g</em> ○ <em>f</em>). Going right then down we have <em>Y</em><sub><em>c</em>′</sub>(<em>h</em>)(<em>g</em>) = <em>h</em> ○ <em>g</em> and (<em>Y<sub>f</sub></em>)<em><sub>e</sub></em>(<em>h</em> ○ <em>g</em>) = (<em>h</em> ○ <em>g</em>) ○ <em>f</em>. To reiterate, the associativity of composition in C insures that this square commutes.</p>
<h3 id="lev_7-2-1-14" class="level3"><strong>7.2.1.14   Yoneda’s lemma</strong></h3>
<p>One of the most powerful tools in category theory is Yoneda’s lemma. It is often considered by students to be quite abstract, but grounding it in databases may help.</p>
<p>Suppose that I:C→Set is an arbitrary database instance, let c∈Ob(C) be an object, and let <em>f</em> : <em>c</em> → <em>c</em>′ be any outgoing arrow. Because <em>I</em> is a functor, we know that for every row <em>r</em> ∈ <em>I</em>(<em>c</em>) in table <em>c</em>, a value has been recorded in the <em>f</em> column. The value in the (<em>r</em>, <em>f</em>) cell refers to some row in table <em>c</em>′. That is, each row in table <em>c</em> induces SIRS throughout the database as freely as possible (see Example <a href="chapter007.html#Exa_7-2-1-8">7.2.1.8</a>). The instance <em>Y<sub>c</sub></em> consists entirely of a single row ☺ in table <em>c</em> and its SIRS. The idea is that for any row <em>r</em> ∈ <em>I</em>(<em>c</em>) in arbitrary instance <em>I</em>, there exists a unique map <em>Y<sub>c</sub></em> → <em>I</em> sending ☺ to <em>r</em>.</p>
<p><strong>Proposition 7.2.1.15</strong> (Yoneda’s lemma, part 1). <em>Let</em> C <em>be a category,</em> c∈Ob(C) <em>an object, and</em> I:C→Set <em>a set-valued functor. There is a natural bijection</em></p>
<p>HomC−Set(Yc,I)→≅I(c).</p>
<p><em>Proof</em>. See Mac Lane [29].</p>
<p><em>Example</em> 7.2.1.16. Consider the category C drawn as follows:</p>
<p><img src="images/Art_P307.jpg" alt="art" /></p>
<p>There are two representable functors, <em>Y</em><sub>Child</sub> and <em>Y</em><sub>Mother</sub>. The former, YChild:C→Set, is shown here:</p>
<p><img src="images/Art_P308.jpg" alt="art" /></p>
<p>The representable functor <em>Y</em><sub>Child</sub> is the freest instance possible, starting with one element in the Child table and satisfying the constraints. The latter, <em>Y</em><sub>Mother</sub> is the freest instance possible, starting with one element in the Mother table and satisfying the constraints. Since mother○firstChild=id<sub>Mother</sub>, this instance has just one row in each table:</p>
<p><img src="images/Art_P309.jpg" alt="art" /></p>
<p>Here is an arbitrary instance I:C→Set:</p>
<p><img src="images/Art_P310.jpg" alt="art" /></p>
<p>Yoneda’s lemma (<a href="chapter007.html#Pro_7-2-1-15">7.2.1.15</a>) is about the set of natural transformations <em>Y</em><sub>Child</sub> → <em>I</em>. Recall from Definition <a href="chapter005.html#Def_5-3-1-2">5.3.1.2</a> that a search for natural transformations can get tedious. Yoneda’s lemma makes the calculation quite trivial. In this case there are exactly four such natural transformations, HomC−Set(YChild,I)≅I(Child)≅4¯, and they are completely determined by where ☺ goes. In some sense the symbol ☺ in <em>Y</em><sub>Child</sub> <em>represents</em> childness in this database.</p>
<p><em>Exercise</em> 7.2.1.17.</p>
<p>Consider the schema C and instance I:C→Set from Example <a href="chapter007.html#Exa_7-2-1-16">7.2.1.16</a>. Let <em>Y</em><sub>Child</sub> be the representable functor, and write (☺ ↦ Amy) for the unique natural transformation <em>Y</em><sub>Child</sub> → <em>I</em> sending ☺ to Amy, and so on.</p>
<p>a. What is (☺ ↦ Amy)<sub>Child</sub>(firstChild(mother(☺)))?<sup><a href="chapter007.html#endnote_9">9</a></sup></p>
<p>b. What is (☺ ↦ Bob)<sub>Child</sub>(firstChild(mother(☺)))?</p>
<p>c. What is (☺ ↦ Carl)<sub>Child</sub>(firstChild(mother(☺)))?</p>
<p>d. What is (☺ ↦ Amy)<sub>Mother</sub>(mother(☺))?</p>
<p>e. In parts (a)–(d), what information does the first subscript (Child, Child, Child, Mother) give you about the answer?</p>
<p>Section <a href="chapter007.html#lev_7-2-1-6">7.2.1.6</a> showed that a representable functor C→Set is a mathematically generated database instance for an abstract thing of type T∈Ob(C). It creates placeholders for every attribute that things of type <em>T</em> are supposed to have.</p>
<p><em>Slogan</em> 7.2.1.18.</p>
<p><em>Yoneda’s lemma says the following. Specifying an actual thing of type T is the same as filling in all placeholders found in the generic thing of type T</em>.</p>
<p>Yoneda’s lemma is considered by many category theorists to be the most important tool in the subject. While its power is probably unclear to students whose sole background in category theory comes from this book, Yoneda’s lemma is indeed extremely useful for reasoning. It allows us to move the notion of functor application into the realm of morphisms between functors (i.e., morphisms in C–Set, which are natural transformations). This keeps everything in one place—it is all in the morphisms—and thus more interoperable.</p>
<p><em>Example</em> 7.2.1.19. Example <a href="chapter004.html#Exa_4-1-1-27">4.1.1.27</a> discussed the cyclic monoid M generated by the symbol <em>Q</em> and subject to the relation <em>Q</em><sup>7</sup> = <em>Q</em><sup>4</sup>, depicted as</p>
<p><img src="images/Art_P311.jpg" alt="art" /></p>
<p>Here is the mathematical foundation for this picture. Since M is a category with one object, ▲, there is a unique representable functor (up to isomorphism) Y≔Y▲:M→Set. Any functor M→Set can be thought of as a set with an M action (see Section <a href="chapter005.html#lev_5-2-1-1">5.2.1.1</a>). In the case of <em>Y</em> , the required set is</p>
<p>Y(▲)=HomM(▲,▲)≅{Q0,Q1,Q2,Q3,Q4,Q5,Q6},</p>
<p>and the action is pretty straightforward (it is called the <em>principal action</em>). For example, <img src="images/Art_IP.jpg" alt="art" />. We might say that (<a href="chapter007.html#eq_7-6">7.6</a>) is a picture of this principal action of M.</p>
<p>However, we can go one step further. Given the functor Y:M→Set, we can take its category of elements, ∫MY (see Section <a href="chapter006.html#lev_6-2-2">6.2.2</a>). The category ∫MY has objects <em>Y</em>(▲) ∈ Ob(<strong>Set</strong>), i.e., the set of dots in (<a href="chapter007.html#eq_7-6">7.6</a>), and it has a unique morphism <em>Q<sup>i</sup></em> → <em>Q<sup>j</sup></em> for every path of length ⩽ 6 from <em>Q<sup>i</sup></em> to <em>Q<sup>j</sup></em> in that picture. So the drawing of M in (<a href="chapter007.html#eq_7-6">7.6</a>) is actually the category of elements of M’s unique representable functor.</p>
<p><em>Exercise</em> 7.2.1.20.</p>
<p>Let C be a category, let c∈Ob(C) be an object, and let I∈Ob(C−Set) be in instance of C. Consider <em>c</em> also as a functor c:1¯→C and recall the pullback functor Δc:C−Set→Set and its left adjoint Σc:Set→C−Set (see Section <a href="chapter007.html#lev_7-1-4">7.1.4</a>).</p>
<p>a. What is the set Δ<em><sub>c</sub></em>(<em>I</em>)?</p>
<p>b. What is Hom<strong><sub>Set</sub></strong>({☺}, Δ<em><sub>c</sub></em>(<em>I</em>))?</p>
<p>c. What is HomC−Set(Σc({☺}),I)?</p>
<p>d. How does Σ<em><sub>c</sub></em>({☺}) compare to <em>Y<sub>c</sub></em>, the functor represented by <em>c</em>, as objects in C–Set?</p>
<p><strong>Proposition 7.2.1.21</strong> (Yoneda’s lemma, part 2). <em>Let</em> C <em>be a category. The assignment c</em> ↦ <em>Y<sub>c</sub> from Proposition</em> <a href="chapter007.html#Pro_7-2-1-15">7.2.1.15</a> <em>extends to a functor</em> Y:Cop→C−Set, <em>and this functor is fully faithful</em>.</p>
<p><em>In particular, if</em> c,c′∈Ob(C) <em>are objects and there is an isomorphism Y<sub>c</sub></em> ≅ <em>Y</em><sub><em>c</em>′</sub> <em>in</em> C−Set, <em>then there is an isomorphism c</em> ≅ <em>c</em>′ <em>in</em> C.</p>
<p><em>Proof</em>. See Mac Lane [29].</p>
<p><em>Exercise</em> 7.2.1.22.</p>
<p>The distributive law for addition of natural numbers says <em>c</em> × (<em>a</em> + <em>b</em>) = <em>c</em> × <em>a</em> + <em>c</em> × <em>b</em>. Following is a proof of the distributive law using category-theoretic reasoning. Annotate anything shown in red with a justification for why it is true.</p>
<p><em>Proposition</em> (Distributive law). <em>For any natural numbers a, b, c</em> ∈ ℕ, <em>the distributive law holds:</em></p>
<p>c(a+b)=ca+cb.</p>
<p><em>Sketch of proof. To finish, justify things shown in red</em>.</p>
<p>Let <em>A</em>, <em>B</em>, <em>C</em> be finite sets, and let <em>X</em> be another finite set.</p>
<p>Hom<strong><sub>Set</sub></strong>(<em>C</em> × (<em>A</em> + <em>B</em>), <em>X</em>)</p>
<p>≅Hom<strong><sub>Set</sub></strong>(<em>A</em> + <em>B</em>, <em>X<sup>C</sup></em>)</p>
<p>≅Hom<strong><sub>Set</sub></strong>(<em>A</em>, <em>X<sup>C</sup></em>) × Hom<strong><sub>Set</sub></strong>(<em>B</em>, <em>X<sup>C</sup></em>)</p>
<p>≅Hom<strong><sub>Set</sub></strong>(<em>C</em> × <em>A</em>, <em>X</em>) × Hom<strong><sub>Set</sub></strong>(<em>C</em> × <em>B</em>, <em>X</em>)</p>
<p>≅ Hom<strong><sub>Set</sub></strong>((<em>C</em> × <em>A</em>) + (<em>C</em> × <em>B</em>), <em>X</em>).</p>
<p>By the appropriate application of Yoneda’s lemma, we see that there is an isomorphism</p>
<p>C×(A+B)≅(C×A)+(C×B)</p>
<p>in <strong>Fin</strong>. The result about natural numbers follows.</p>
<h3 id="lev_7-2-1-23" class="level3"><strong>7.2.1.23   The subobject classifier</strong> Ω∈Ob(C−Set)</h3>
<p>If C is a category, then the functor category C–Set is a special kind of category, called a <em>topos</em>. Note that when C=1¯ is the terminal category, then we have an isomorphism 1–<strong>Set</strong> ≅ <strong>Set</strong>, so the category of sets is a special case of a topos. What is interesting about toposes (or topoi) is that they generalize many properties of <strong>Set</strong>. This short section investigates only one such property, namely, that C–Set has a subobject classifier, denoted Ω∈Ob(C−Set). In the case C=1¯ the subobject classifier is {<em>True</em>, <em>False</em>} ∈ Ob(<strong>Set</strong>) (see Definition <a href="chapter003.html#Def_3-4-4-9">3.4.4.9</a>).</p>
<p>As usual, we consider the matter of subobject classifiers by grounding the discussion in terms of databases. The analogue of {<em>True</em>, <em>False</em>} for an arbitrary database can be quite complex—it encodes the whole story of relational database instances for that schema.</p>
<p><strong>Definition 7.2.1.24</strong>. Let C be a category, let C–Set denote its category of instances, and let 1C∈Ob(C−Set) denote the terminal object. A <em>subobject classifier for</em> C−Set is an object ΩC∈Ob(C−Set) and a morphism t:1C→ΩC with the following property. For any monomorphism <em>f</em> : <em>I</em> → <em>J</em> in C–Set, there exists a unique morphism char(f):J→ΩC such that the following diagram is a pullback in C–Set:</p>
<p><img src="images/Art_P312.jpg" alt="art" /></p>
<p>That is, for any instance <em>J</em> there is a bijection</p>
<p>HomC−Set(J,Ω)≅{I∈Ob(C−Set)|I⊆J}.</p>
<p>In terms of databases, what this means is that for every schema C, there is some special instance ΩC∈Ob(C−Set) that somehow classifies subinstances of anything. When the schema is the terminal category, C=1¯, instances are sets and according to Definition <a href="chapter003.html#Def_3-4-4-9">3.4.4.9</a> the subobject classifier is Ω<sub>1</sub> = {<em>True</em>, <em>False</em>}. One might think that the subobject classifier for C–Set should just consist of a two-element set table by table, i.e., that for every c∈Ob(C), we should have ΩC=?{True,False}, but this is not correct.</p>
<p>In fact, for any object c∈Ob(C), there is a way to figure out what ΩC(c) has to be. We know by Yoneda’s lemma (Proposition <a href="chapter007.html#Pro_7-2-1-15">7.2.1.15</a>) that ΩC(c)=HomC−Set(Yc,ΩC), where <em>Y<sub>c</sub></em> is the functor represented by <em>c</em>. There is a bijection between HomC−Set(Yc,ΩC) and the set of subinstances of <em>Y<sub>c</sub></em>. Thus we have</p>
<p>ΩC(c)={I∈Ob(C−Set)|I⊆Yc}.(7.7)</p>
<p>How should ΩC:C→Set behave on morphisms? By Exercise <a href="chapter007.html#Exe_7-2-1-13">7.2.1.13</a>, each morphism <em>f</em> : <em>c</em> → <em>d</em> in C induces a morphism <em>Y<sub>f</sub></em> : <em>Y<sub>d</sub></em> → <em>Y<sub>c</sub></em>, and the map ΩC(f):ΩC(c)→ΩC(d) sends a subinstance <em>A</em> ⊆ <em>Y<sub>c</sub></em> to the pullback</p>
<p><img src="images/Art_P313.jpg" alt="art" /></p>
<p>That is, ΩC(f)(A)=Yf−1(A).</p>
<p>We have now fully described ΩC as a functor, but the description is very abstract. Here is an example of a subobject classifier.</p>
<p><em>Example</em> 7.2.1.25. Consider the following category C≅[3]:</p>
<p><img src="images/Art_P314.jpg" alt="art" /></p>
<p>To write ΩC, we need to understand the representable functors Yc∈Ob(C−Set), for <em>c</em> = 0, 1, 2, 3, as well as their subobjects. Here is <em>Y</em><sub>0</sub> as an instance:</p>
<p><img src="images/Art_P315.jpg" alt="art" /></p>
<p>What are the subinstances of this? There is the empty subinstance ∅ ⊆ <em>Y</em><sub>0</sub> and the identity subinstance <em>Y</em><sub>0</sub> ⊆ <em>Y</em><sub>0</sub>. But there are three more as well. Note that if we want to keep the ☺ row of table 0, then we have to keep everything. But if we throw away the ☺ row of table 0, we can still keep the rest and get a subinstance. If we want to keep the after_1(☺) row of table 1, then we have to keep its images in tables 2 and 3. But we could throw away both the ☺ row of table 0 and the after_1(☺) row of table 1 and still keep the rest. And so on. In other words, there are five subobjects of <em>Y</em><sub>0</sub>, i.e., elements of ΩC(0), but they are hard to name. We arbitrarily name them by ΩC(0)≔{yes, wait 1, wait 2, wait 3, never}.</p>
<p>The same analysis holds for the other tables of ΩC. For example, we denote the three subinstances of <em>Y</em><sub>2</sub> by ΩC(2)={yes, wait 1, never}. In sum, the database instance ΩC is:</p>
<p><img src="images/Art_P316.jpg" alt="art" /></p>
<p>The morphism 1→ΩC picks out the <em>yes</em> row of every table.</p>
<p>Now that we have constructed ΩC∈Ob(C−Set), we are ready to use it. What makes ΩC special is that for any instance X:C→Set, the subinstances if <em>X</em> are in one-to-one correspondence with the instance morphisms X→ΩC. Consider the following arbitrary instance <em>X</em>, where the blue rows denote a subinstance <em>A</em> ⊆ <em>X</em>.</p>
<p><img src="images/Art_P317.jpg" alt="art" /></p>
<p>This blue subinstance <em>A</em> ⊆ <em>X</em> corresponds to a natural transformation char(A):X→ΩC. That is, for each c∈Ob(C), all the rows in the <em>c</em> table of <em>X</em> are sent to the rows in the <em>c</em> table of ΩC, as they would be for any natural transformation. The way <em>char</em>(<em>A</em>) works is as follows. For each table <em>i</em> and row <em>x</em> ∈ <em>X</em>(<em>i</em>), find the first column <em>f</em> in which the entry is blue (i.e., <em>f</em>(<em>x</em>) ∈ <em>A</em>), and send <em>x</em> to the corresponding element of ΩC(i). For example, <em>char</em>(<em>A</em>)(0) sends <em>a</em><sub>1</sub> to <em>wait 2</em> and sends <em>a</em><sub>4</sub> to <em>never</em>, and <em>char</em>(<em>A</em>)(2) sends <em>c</em><sub>1</sub> to <em>yes</em> and sends <em>c</em><sub>2</sub> to <em>never</em>.</p>
<p><em>Exercise</em> 7.2.1.26.</p>
<p>a. Write the blue subinstance <em>A</em> ⊆ <em>X</em> shown in (<a href="chapter007.html#eq_7-9">7.9</a>) as an instance of C, i.e., as four tables.</p>
<p>b. This subinstance <em>A</em> ⊆ <em>X</em> corresponds to a map ℓ≔char(A):X→ΩC. For all c∈Ob(C), we have a function ℓ(c):X(c)→ΩC(c). With <em>c</em> = 1, write out ℓ(1):X(1)→ΩC(1).</p>
<p><em>Exercise</em> 7.2.1.27.</p>
<p>Let Loop be the loop schema</p>
<p><img src="images/Art_P318.jpg" alt="art" /></p>
<p>a. What is the subobject classifier ΩLoop∈Ob(Loop−Set)? (Write it out in table form.)</p>
<p>b. In Exercise <a href="chapter007.html#Exe_7-2-1-10">7.2.1.10</a> you computed the representable functor <em>Y<sub>s</sub></em>. How does ΩLoop compare to <em>Y<sub>s</sub></em>?</p>
<p>c. Consider the discrete dynamical system <em>X</em> and its subset <em>W</em> ⊆ <em>X</em>:</p>
<p><img src="images/Art_P319.jpg" alt="art" /></p>
<p>What is the morphism char(W):X→ΩLoop that corresponds to this subobject?</p>
<p><em>Exercise</em> 7.2.1.28.</p>
<p>Let <img src="images/Art_P320.jpg" alt="art" /> be the indexing category for graphs.</p>
<p>a. Write the subobject classifier Ω<strong><sub>GrIn</sub></strong> ∈ Ob(<strong>GrIn</strong>–<strong>Set</strong>) in tabular form, i.e., as two tables.</p>
<p>b. Draw Ω<strong><sub>GrIn</sub></strong> as a graph.</p>
<p>c. Let <em>G</em> be the following graph and <em>G</em>′ ⊆ <em>G</em> the blue part.</p>
<p><img src="images/Art_P321.jpg" alt="art" /></p>
<p>Write <em>G</em> ∈ Ob(<strong>GrIn</strong>–<strong>Set</strong>) in tabular form.</p>
<p>d. Write the components of the natural transformation <em>char</em>(<em>G</em>′): <em>G</em> → Ω<strong><sub>GrIn</sub></strong>.</p>
<h2 id="lev_7-2-2" class="level2"><strong>7.2.2   Database instances in other categories</strong></h2>
<p>So far we have focused on the category C−Set=Fun(C,Set) of set-valued functors C→Set for arbitrary categories, or database schemas, C. What if we allow the target category <strong>Set</strong> to change?</p>
<h3 id="lev_7-2-2-1" class="level3"><strong>7.2.2.1   Representations of groups</strong></h3>
<p>The classical mathematical subject of <em>representation theory</em> is the study of Fun(<em>G</em>, <strong>Vect</strong>), where <em>G</em> is a group and <strong>Vect</strong> is the category of vector spaces (over, say, ℝ). Every such functor <em>F</em> : <em>G</em> → <strong>Vect</strong> is called a <em>representation of G</em>. Since <em>G</em> is a category with one object ▲, the functor <em>F</em> provides a single vector space <em>V</em> = <em>F</em> (▲) together with an action of <em>G</em> on it.</p>
<p>We can think of this in terms of databases if we have a presentation of <em>G</em> in terms of generators and relations. The schema corresponding to <em>G</em> has one table, and this table has a column for each generator (see Section <a href="chapter004.html#lev_4-1-3">4.1.3</a>). Giving a representation <em>F</em> is the same as giving an instance on the schema, with some properties that stem from the fact that the target category is <strong>Vect</strong> rather than <strong>Set</strong>. There are many possibilities for expressing such data.</p>
<p>One possibility is if we could draw <em>V</em> , say, if <em>V</em> were one-, two-, or three-dimensional. If so, let <em>P</em> be the chosen picture of <em>V</em> , e.g., <em>P</em> is the standard drawing of a Cartesian coordinate plane <em>V</em> = ℝ<sup>2</sup>. Then every column of the table would consist entirely of the picture <em>P</em> instead of a set of rows. Touching a point in the ID column ℝ<sup>2</sup> would result in a point being drawn in the ℝ<sup>2</sup> corresponding to the other column, in accordance with the <em>G</em> action. Each column would, of course, respect addition and scalar multiplication.</p>
<p>Another possibility is to use the fact that there is a functor <em>U</em> : <strong>Vect</strong> → <strong>Set</strong>, so the instance <em>F</em> : <em>G</em> → <strong>Vect</strong> could be converted to an ordinary instance <em>U</em> ○ <em>F</em> : <em>G</em> → <strong>Set</strong>. We would have an ordinary set of rows. This set would generally be infinite, but it would be structured by addition and scalar multiplication. For example, assuming <em>V</em> is finite-dimensional, one could find a few rows that generated the rest.</p>
<p>A third possibility is to use monads, which would allow the table to have only as many rows as <em>V</em> has dimensions. This yields a considerable saving of space. See Section <a href="chapter007.html#lev_7-3">7.3</a>. In all these possibilities, the usual tabulated format of databases has been slightly altered to accommodate the extra information in a vector space.</p>
<h3 id="lev_7-2-2-2" class="level3"><strong>7.2.2.2   Representations of quivers</strong></h3>
<p>Representation theory also studies representations of quivers. A <em>quiver</em> is just the free category (see Example <a href="chapter005.html#Exa_5-1-2-33">5.1.2.33</a>) on a graph. If <em>P</em> is a graph with free category P, then a representation of the quiver P is a functor F:P→Vect. Such a representation consists of a vector space at each vertex of <em>P</em> and a linear transformation for each arrow. All the discussion in Section <a href="chapter007.html#lev_7-2-2-1">7.2.2.1</a> works in this setting, except that there is more than one table.</p>
<h3 id="lev_7-2-2-3" class="level3"><strong>7.2.2.3   Other target categories</strong></h3>
<p>One can imagine the value of using target categories other than <strong>Set</strong> or <strong>Vect</strong> for databases.</p>
<p><em>Application</em> 7.2.2.4. Geographic data consists of maps of the earth together with various functions on it. For example, for any point on the earth one may want to know the average of temperatures recorded in the past ten years or the precise temperature at this moment. Earth can be considered as a topological space, <em>E</em>. Similarly, temperatures on earth reside on a continuum, say, the space <em>T</em> of real numbers [−100, 200]. Thus the temperature record is a continuous function <em>E</em> → <em>T</em> .</p>
<p>Other records such as precipitation, population density, elevation, and so on, can all be considered as continuous functions from <em>E</em> to some space. Agencies like the U.S. Geological Survey hold databases of such information. By modeling them on functors C→Top, they may be able to employ mathematical tools such as persistent homology (see Weinberger [44]) to find interesting invariants of the data.</p>
<p><em>Application</em> 7.2.2.5. Application <a href="chapter007.html#App_7-2-2-4">7.2.2.4</a> discussed using topological database instances to model geographical data. Other scientific disciplines could use the same kind of tool. For example, in studying the mechanics of materials, one may want to consider the material as a topological space <em>M</em> and measure values such as energy as a continuous map <em>M</em> → <em>E</em>. Such observations could be modeled by databases with target category <strong>Top</strong> or <strong>Vect</strong> rather than <strong>Set</strong>.</p>
<h2 id="lev_7-2-3" class="level2"><strong>7.2.3   Sheaves</strong></h2>
<p>Let <em>X</em> be a topological space (see Example <a href="chapter005.html#Exa_5-2-3-1">5.2.3.1</a>), such as a sphere. Section <a href="chapter007.html#lev_7-2-2-3">7.2.2.3</a> discussed continuous functions out of <em>X</em> and their use in science (e.g., recording temperatures on the earth as a continuous map <em>X</em> → [−100, 200]). Sheaves allow us to consider the local-global nature of such maps, taking into account reparable discrepancies in data-gathering tools.</p>
<p><em>Application</em> 7.2.3.1. Suppose that <em>X</em> is the topological space corresponding to the earth, and let <em>region</em> mean an open subset <em>U</em> ⊆ <em>X</em>. Suppose that we cover <em>X</em> with 10,000 regions <em>U</em><sub>1</sub>, <em>U</em><sub>2</sub>, …, <em>U</em><sub>10000</sub>, such that some of the regions overlap in a nonempty subregion (e.g., <em>U</em><sub>5</sub> ∩ <em>U</em><sub>9</sub> ≠ ∅). For each <em>i</em>, <em>j</em>, let <em>U</em><sub><em>i</em>,<em>j</em></sub> = <em>U<sub>i</sub></em> ∩ <em>U<sub>j</sub></em>.</p>
<p>For each region <em>U<sub>i</sub></em> ⊆ <em>X</em>, we have a temperature-recording device, which gives a function <em>T<sub>i</sub></em> : <em>U<sub>i</sub></em> → [−100, 200]. If <em>U<sub>i</sub></em> ∩ <em>U<sub>j</sub></em> ≠ ∅, then two different recording devices give us temperature data for the intersection <em>U</em><sub><em>i</em>,<em>j</em></sub>. Suppose we find that they do not give precisely the same data but that there is a translation formula between their results. For example, <em>T<sub>i</sub></em> might register 3<sup>○</sup> warmer than <em>T<sub>j</sub></em> registers, throughout the region <em>U<sub>i</sub></em> ∩ <em>U<sub>j</sub></em>.</p>
<p>Roughly speaking, a consistent system of translation formulas is called a <em>sheaf</em>. It does not demand a universal true temperature function but only a consistent translation system between them.</p>
<p>Definitions <a href="chapter007.html#Def_7-2-3-2">7.2.3.2</a> and <a href="chapter007.html#Def_7-2-3-5">7.2.3.5</a> make the notion of sheaf precise, but it is developed slowly at first.</p>
<p>For every region <em>U</em>, we can record the value of some function (say, temperature) throughout <em>U</em>. Although this record might consist of a mountain of data (a temperature for each point in <em>U</em>), it can be thought of as one thing. That is, it is one element in the set of “value assignments throughout <em>U</em>”. A sheaf holds the set of “value assignments throughout <em>U</em>” for each region <em>U</em> as well as how a “value assignment throughout <em>U</em>” restricts to a “value assignment throughout <em>V</em> ” for any subset <em>V</em> ⊆ <em>U</em>.</p>
<p><strong>Definition 7.2.3.2</strong>. Let <em>X</em> be a topological space, let Open(<em>X</em>) denote its partial order of open sets, and let Open(<em>X</em>)<sup>op</sup> be the opposite category. A <em>presheaf on X</em> is a functor O:Open(X)op→Set. For every open set <em>U</em> ⊆ <em>X</em>, we refer to the set O(U) as the <em>set of value assignments throughout U of</em> O. If <em>V</em> ⊆ <em>U</em> is an open subset, it corresponds to an arrow in Open(<em>X</em>), and applying the functor O yields a function called the <em>restriction map from U to V</em> and denoted ρV,U:O(U)→O(V). Given a∈O(U), we may denote <em>ρ</em><sub><em>V</em>,<em>U</em></sub>(<em>a</em>) by <em>a</em>|<em><sub>V</sub></em>; it is called <em>the restriction of a to V</em>.</p>
<p>The <em>category of presheaves on X</em> is simply Open(<em>X</em>)<sup>op</sup>–<strong>Set</strong> (see Definition <a href="chapter005.html#Def_5-3-3-1">5.3.3.1</a>).</p>
<p><em>Exercise</em> 7.2.3.3.</p>
<p>a. Find four overlapping open subsets that cover the square <em>X</em> ≔ [0, 3] × [0, 3] ⊆ ℝ<sup>2</sup>. Write a label for each open set as well as a label for each overlap (two-fold, three-fold, etc.). You now have labeled <em>n</em> open sets. What is your <em>n</em>?</p>
<p>b. Draw the preorder Open(<em>X</em>). For each of the <em>n</em> open sets, draw a dot with the appropriate label. Then draw an arrow from one dot to another when the first refers to an open subset of the second. This is Open(<em>X</em>).</p>
<p>c. Make up and write formulas <em>R</em><sub>1</sub> : <em>X</em> → ℝ and <em>R</em><sub>2</sub> : <em>X</em> → ℝ with <em>R</em><sub>1</sub>(<em>x</em>) ⩽ <em>R</em><sub>2</sub>(<em>x</em>) for all <em>x</em> ∈ <em>X</em>, expressing a range of temperatures <em>R</em><sub>1</sub>(<em>p</em>) ⩽ <em>Temp</em>(<em>p</em>) ⩽ <em>R</em><sub>2</sub>(<em>p</em>) that an imaginary experiment shows can exist at each point <em>p</em> in the square. What is the temperature range at <em>p</em> = (2, 1) ∈ <em>X</em>?</p>
<p>d. Make a presheaf O:Open(X)op→Set as follows. For each of your open sets, say, <em>A</em> ∈ Open(<em>X</em>), put</p>
<p>O(A)≔{Temp:A→ℝ|∀a∈A, R1(a)⩽Temp(a)⩽R2(a)}.</p>
<p>Call one of your <em>n</em> open sets <em>A</em>. What is O(A)? Then choose some <em>A</em>′ ⊆ <em>A</em>; what is O(A′), and what is the restriction map ρA′,A:O(A)→O(A′) in this case? Do you like the name “value assignment throughout <em>A</em>” for an element of O(A)?</p>
<p>Before moving to a definition of sheaves, we need to clarify the notion of covering. Suppose that <em>U</em> is a region and <em>V</em><sub>1</sub>, …, <em>V<sub>n</sub></em> are subregions (i.e., for each 1 ⩽ <em>i</em> ⩽ <em>n</em>, we have <em>V<sub>i</sub></em> ⊆ <em>U</em>). Then we say that the <em>V<sub>i</sub> collectively cover U</em> if every point in <em>U</em> is in <em>V<sub>i</sub></em> for some <em>i</em>. Another way to say this is that the natural function ⊔<sub><em>i</em></sub><em>V<sub>i</sub></em> → <em>U</em> is surjective.</p>
<p><em>Example</em> 7.2.3.4. Let <em>X</em> = ℝ be the space of real numbers, and define the following open subsets: <em>U</em> = (5, 10), <em>V</em><sub>1</sub> = (5, 7), <em>V</em><sub>2</sub> = (6, 9), <em>V</em><sub>3</sub> = (8, 10).<sup><a href="chapter007.html#endnote_10">10</a></sup> Then <em>V</em><sub>1</sub>, <em>V</em><sub>2</sub>, <em>V</em><sub>3</sub> collectively cover of <em>U</em>. It has overlaps <em>V</em><sub>12</sub> = <em>V</em><sub>1</sub> ∩ <em>V</em><sub>2</sub> = (6, 7), <em>V</em><sub>13</sub> = <em>V</em><sub>1</sub> ∩ <em>V</em><sub>3</sub> = Ø, <em>V</em><sub>23</sub> = <em>V</em><sub>2</sub> ∩ <em>V</em><sub>3</sub> = (8, 9).</p>
<p>Given a presheaf O:Open(X)op→Set, we have sets and functions as in the following diagram</p>
<p><img src="images/Art_P322.jpg" alt="art" /></p>
<p>A presheaf O on <em>X</em> tells us what value assignments throughout <em>U</em> can exist for each <em>U</em>. Suppose we have a value assignment a1∈O(V1) throughout <em>V</em><sub>1</sub> and another value assignment a2∈O(V2) throughout <em>V</em><sub>2</sub>, and suppose they agree as value assignments throughout <em>V</em><sub>1</sub> ∩ <em>V</em><sub>2</sub>, i.e., a1|V1∩V2=a2|V1∩V2. In this case we should have a unique value assignment b∈O(V1∪V2) throughout <em>V</em><sub>1</sub> ∪ <em>V</em><sub>2</sub> that agrees on the <em>V</em><sub>1</sub> part with <em>a</em><sub>1</sub> and agrees on the <em>V</em><sub>2</sub> part with <em>a</em><sub>2</sub>; i.e., b|V1=a1 and b|U2=a2. The condition that such equations hold for every covering is the sheaf condition.</p>
<p>For example, the elements of O(U) might be functions <em>h</em> : <em>U</em> → ℝ, each of which we imagine as a curve defined on the interval <em>U</em> = (5, 10). The sheaf condition says that if one is given a curve-snippet over (5, 7), a curve-snippet over (6, 9), and a curve snippet over (8, 10), and these all agree on overlap intervals (6, 7) and (8, 9), then they can be put together to form a curve over all of <em>U</em>.</p>
<p><strong>Definition 7.2.3.5</strong>. Let <em>X</em> be a topological space, let Open(<em>X</em>) be its partial order of open sets, and let O:Open(X)op→Set be a presheaf. Given an open set <em>U</em> ⊆ <em>X</em> and a cover <em>V</em><sub>1</sub>, …, <em>V<sub>n</sub></em> of <em>U</em>, the following condition is called the <em>sheaf condition</em> for that cover.</p>
<p><strong>Sheaf condition</strong> Given a sequence <em>a</em><sub>1</sub>, …, <em>a<sub>n</sub></em>, where each ai∈O(Vi) is a value assignment throughout <em>V<sub>i</sub></em>, suppose that for all <em>i</em>, <em>j</em>, we have ai|Vi∩Vj=aj|Vi∩Vj; then there is a unique value assignment b∈O(U) such that b|Vi=ai.</p>
<p>The presheaf O is called a <em>sheaf</em> if it satisfies the sheaf condition for every cover.</p>
<p><em>Remark</em> 7.2.3.6. Application <a href="chapter007.html#App_7-2-3-1">7.2.3.1</a> said that sheaves help us patch together information from different sources. Even if different temperature-recording devices <em>T<sub>i</sub></em> and <em>T<sub>j</sub></em> registered different temperatures on an overlapping region <em>U<sub>i</sub></em> ∩ <em>U<sub>j</sub></em>, they could be patched together if given a consistent translation system between their results. What is actually needed is a set of isomorphisms</p>
<p>pi,j:Ti|Ui,j→≅Tj|Ui,j</p>
<p>that translate between them, and that these <em>p</em><sub><em>i</em>,<em>j</em></sub>’s act in concert with one another. This (when precisely defined) is called <em>descent data</em>. The way it interacts with the definition of sheaf given in Definitions <a href="chapter007.html#Def_7-2-3-2">7.2.3.2</a> and <a href="chapter007.html#Def_7-2-3-5">7.2.3.5</a> is buried in the restriction maps <em>ρ</em> for the overlaps as subsets <em>U</em><sub><em>i</em>,<em>j</em></sub> ⊆ <em>U<sub>i</sub></em> and <em>U</em><sub><em>i</em>,<em>j</em></sub> ⊆ <em>U<sub>j</sub></em> (see Grothendieck and Raynaud [18] for details).</p>
<p><em>Application</em> 7.2.3.7. Consider outer space as a topological space <em>X</em>. Different amateur astronomers record observations of what they see in <em>X</em> on a given night. Let <em>C</em> = [390, 700] denote the set of wavelengths in the visible light spectrum (written in nanometers). Given an open subset <em>U</em> ⊆ <em>X</em>, let O(U) denote the set of functions <em>U</em> → <em>C</em>. The presheaf O satisfies the sheaf condition; this is the taken-for-granted fact that we can patch together different observations of space.</p>
<p><a href="chapter007.html#Fig_7-1">Figure 7.1</a> (see page 377) shows three views of the night sky. Given a telescope position to obtain the first view, one moves the telescope right and a little down to obtain the second, and one moves it down and left to obtain the third. These are value assignments a1∈O(V1),a2∈O(V2), and a3∈O(V3), throughout subsets <em>V</em><sub>1</sub>, <em>V</em><sub>2</sub>, <em>V</em><sub>3</sub> ⊆ <em>X</em> (respectively). These subsets <em>V</em><sub>1</sub>, <em>V</em><sub>2</sub>, <em>V</em><sub>3</sub> cover some (strangely shaped) subset <em>U</em> ⊆ <em>X</em>. Because the restriction of <em>a</em><sub>1</sub> to <em>V</em><sub>1</sub> ∩ <em>V</em><sub>2</sub> is equal to the restriction of <em>a</em><sub>2</sub> to <em>V</em><sub>1</sub> ∩ <em>V</em><sub>2</sub>, and so on, the sheaf condition says that these three value assignments glue together to form a single value assignment throughout <em>U</em>, as shown in <a href="chapter007.html#Fig_7-2">Figure 7.2</a> (see page 378).</p>
<p><em>Exercise</em> 7.2.3.8.</p>
<p>Find an application of sheaves in your own domain of expertise.</p>
<p><em>Application</em> 7.2.3.9. Suppose we have a sheaf for temperatures on earth. For every region <em>U</em>, we have a set of theoretically possible temperature assignments throughout <em>U</em>. For example, we may know that if it is warm in Texas, warm in Arkansas, and warm in Kansas, then it cannot be cold in Oklahoma. With such a sheaf O in hand, one can use facts about the temperature in one region <em>U</em> to predict the temperature in another region <em>V</em>.</p>
<p>The mathematics is as follows. Suppose given regions <em>U</em>, <em>V</em> ⊆ <em>X</em> and a subset A⊆O(U) corresponding to what we know about the temperature assignment throughout <em>U</em>. We take the following fiber product:</p>
<p><img src="images/Art_P323.jpg" alt="art" /></p>
<p>The image of the top composite im((ρU,X)−1(A)→O(V)) is a subset of O(V) telling us which temperature assignments are possible throughout <em>V</em>, given our knowledge <em>A</em> about the temperature throughout <em>U</em>.</p>
<p>We can imagine the same type of prediction systems for other domains as well, such as the energy of various parts of a material.</p>
<p><em>Example</em> 7.2.3.10. Exercises <a href="chapter005.html#Exe_5-2-4-3">5.2.4.3</a> and <a href="chapter005.html#Exe_5-2-4-4">5.2.4.4</a> discussed the idea of laws being dictated or respected throughout a jurisdiction. If <em>X</em> is earth, to every jurisdiction <em>U</em> ⊆ <em>X</em> we assign the set O(U) of laws that are dictated to hold throughout <em>U</em>. Given a law on <em>U</em> and a law on <em>V</em>, we can see if they amount to the same law on <em>U</em> ∩ <em>V</em>. For example, on <em>U</em> a law might say, “no hunting near rivers” and on <em>V</em> a law might say, “no hunting in public areas.” It happens that on <em>U</em> ∩ <em>V</em> all public areas are near rivers, and vice versa, so the laws agree there. These laws patch together to form a single rule about hunting that is enforced throughout the union <em>U</em> ∪ <em>V</em>, respected by all jurisdictions within it.</p>
<h3 id="lev_7-2-3-11" class="level3"><strong>7.2.3.11   Sheaf of ologged concepts</strong></h3>
<p>Definition <a href="chapter007.html#Def_7-2-3-5">7.2.3.5</a> defines what should be called a sheaf of sets. We can discuss sheaves of groups or even sheaves of categories. Here is an application of the latter.</p>
<p>Recall the notion of simplicial complexes (see Section <a href="chapter003.html#lev_3-4-4-3">3.4.4.3</a>). They look like this:</p>
<p><img src="images/Art_P324.jpg" alt="art" /></p>
<p>Given such a simplicial complex <em>X</em>, we can imagine each vertex <em>v</em> ∈ <em>X</em><sub>0</sub> as an entity with a worldview (e.g., a person) and each simplex as the common worldview shared by its vertices. To model this, we assign to each vertex <em>v</em> ∈ <em>X</em> an olog O(v), corresponding to the worldview held by that entity, and to each simplex <em>u</em> ∈ <em>X<sub>n</sub></em>, we assign an olog O(u) corresponding to a <em>common ground</em> worldview. Recall that <em>X</em> is a subset of ℙ(<em>X</em><sub>0</sub>); it is a preorder and its elements (the simplices) are ordered by inclusion. If <em>u</em>, <em>v</em> are simplices with <em>u</em> ⊆ <em>v</em>, then we want a map of ologs (i.e., a schema morphism) O(v)→O(u). In this way the model says that any idea shared among the people in <em>v</em> is shared among the people in <em>u</em>. Thus we have a functor O:X→Sch (where we forget the distinction between ologs and databases for notational convenience).</p>
<p>To every simplicial complex (indeed every ordered set) one can associate a topological space; in fact, we have a functor <em>Alx</em> : <strong>PrO</strong> → <strong>Top</strong>, called the Alexandrov functor. Applying <em>Alx</em>(<em>X</em><sup>op</sup>), we have a space denoted X. One can visualize X as <em>X</em>, but the open sets include unions of simplices. There is a unique sheaf of categories on X that behaves like O on simplices of <em>X</em>.</p>
<p><em>Example</em> 7.2.3.12. Imagine two groups of people <em>G</em><sub>1</sub> and <em>G</em><sub>2</sub> each making observations about the world. Suppose there is some overlap <em>H</em> = <em>G</em><sub>1</sub> ∩ <em>G</em><sub>2</sub>. Then it may happen that there is a conversation including <em>G</em><sub>1</sub> and <em>G</em><sub>2</sub>, and both groups are talking about something (though using different words). <em>H</em> says, “You guys are talking about the same things, you just use different words.” In this case there is an observation being made throughout <em>G</em><sub>1</sub> ∪ <em>G</em><sub>2</sub> that agrees with both those on <em>G</em><sub>1</sub> and those on <em>G</em><sub>2</sub>.</p>
<h3 id="lev_7-2-3-13" class="level3"><strong>7.2.3.13   Time</strong></h3>
<p>One can use sheaves to model objects in time; Goguen [17] gave an approach to this. For an approach that more closely fits the flow of this book, let C be a database schema. The lifespan of information about the world is generally finite; that is, what was true yesterday is not always the case today. Thus we can associate to each interval <em>U</em> of time the information that we deem to hold throughout <em>U</em>. This is sometimes called the <em>valid time</em> of the data.</p>
<p>If data is valid throughout <em>U</em> and we have a subset <em>V</em> ⊆ <em>U</em>, then of course it is valid throughout <em>V</em>. And the sheaf condition holds too. If some information is valid throughout <em>U</em>, and some other information is valid throughout <em>U</em>′, and if these two things restrict to the same information on the overlap <em>U</em> ∩ <em>V</em>, then they can be glued together to form information that is valid throughout the union <em>U</em> ∪ <em>V</em>.</p>
<p>So we can model information change over time by using a sheaf of C-sets on the topological space ℝ. In other words, for every time interval, we give an C-instance whose information is valid throughout that time interval. Definition <a href="chapter007.html#Def_7-2-3-5">7.2.3.5</a> only defined sheaves with values in <strong>Set</strong>; we are now generalizing to sheaves in C−Set. Namely we consider functors Open(ℝ) → C−Set satisfying the same sheaf condition.</p>
<p><em>Example</em> 7.2.3.14. Consider a hospital in which babies are born. In our scenario, mothers enter the hospital, babies are born, mothers and babies leave the hospital. Let C be the schema</p>
<p><img src="images/Art_P325.jpg" alt="art" /></p>
<p>Consider the eight-hour intervals</p>
<p>Shift1≔(Jan 1, 00:00−08:00),Shift2≔(Jan 1, 04:00−12:00),Shift3≔(Jan 1, 08:00−16:00).</p>
<p>The nurses take shifts of eight hours, overlapping with their predecessors by four hours, and they record in the database only patients that were there <em>throughout</em> their shift or throughout any overlapping shift. Here is the schema:</p>
<p><img src="images/Art_P326.jpg" alt="art" /></p>
<p>Whether or not this implementation of the sheaf semantics is most useful in practice is certainly debatable. But something like this could easily be useful as a semantics, i.e., a way of thinking about, the temporal nature of data.</p>
<h1 id="lev_7-3" class="level1"><a href="toc.html#Rlev_7-3"><strong>7.3   Monads</strong></a></h1>
<p>Monads would probably not have been invented without category theory, but they have been useful in understanding algebraic theories, calculating invariants of topological spaces, and embedding nonfunctional operations into functional programming languages. We mainly discuss monads in terms of how they can help one make explicit a given modeling context and in so doing allow one to simplify the language used in such models. We use databases to give concrete examples.</p>
<p>Much of the following material on monads is taken from Spivak [40].</p>
<h2 id="lev_7-3-1" class="level2"><strong>7.3.1   Monads formalize context</strong></h2>
<p>Monads can formalize assumptions about the way one does business throughout a domain. For example, suppose we want to consider functions that are not required to return a value for all inputs. These are not valid functions as defined in Section <a href="chapter002.html#lev_2-1-2">2.1.2</a> (because they are not <em>total</em>), but in math classes one wants to speak of f(x)=1x and <em>g</em>(<em>x</em>) = tan(<em>x</em>) <em>as though</em> they were functions ℝ → ℝ, so that they can be composed without constantly paying attention to domains.</p>
<p>Functions that are not required to be defined throughout their domain are called <em>partial functions</em>. We all know how they should work, so we need a way to make it mathematically legal. Monads, and the <em>Kleisli</em> categories to which they give rise, provide us with a way to do so. In particular, we will be able to formally discuss the composition ℝ→1xℝ→tan⁡(x)ℝ.</p>
<p>Here we are drawing arrows between sets as though we were talking about total functions, but there is an implicit context in which we are actually talking about partial functions. Monads allow us to write maps between sets in the functional way while holding the underlying context. What makes them useful is that the notion of <em>context</em> we are using here is made formal.</p>
<p><em>Example</em> 7.3.1.1 (Partial functions). Partial functions can be modeled by ordinary functions if we add a special “no answer” element to the codomain. That is, the set of partial functions <em>A</em> → <em>B</em> is in one-to-one correspondence with the set of ordinary functions <em>A</em> → <em>B</em> ⊔ {☺}. For example, suppose we want to model the partial function fp(x)≔1x2−1:ℝ→ℝ in this way; we would use the total function <em>f<sub>t</sub></em> : ℝ → ℝ ⊔ {☺} defined as:</p>
<p>f(x)≔{1x2−1if x≠−1 and x≠1,☺if x=−1,☺if x=1.</p>
<p>An ordinary function <em>g</em> : <em>A</em> → <em>B</em> can be considered a partial function because we can compose it with the inclusion</p>
<p>B→B⊔{☺}.(7.11)</p>
<p>to get <em>A</em> → <em>B</em> ⊔ {☺}.</p>
<p>But how do we compose two partial functions written in this way? Suppose <em>f</em> : <em>A</em> → <em>B</em> ⊔ {☺} and <em>g</em> : <em>B</em> → <em>C</em> ⊔ {☺} are functions. First form a new function</p>
<p>g′≔g⊔{☺}:B⊔{☺}→C⊔{☺}⊔{☺},</p>
<p>then compose to get (<em>g</em>′ ○ <em>f</em>) : <em>A</em> → <em>C</em> ⊔ {☺} ⊔ {☺}, and finally send both ☺’s to the same element by composing with</p>
<p>C⊔{☺}⊔{☺}→C⊔{☺}.(7.12)</p>
<p>How should one think about composing partial functions <em>g</em> ○ <em>f</em>? Every element <em>a</em> ∈ <em>A</em> is sent by <em>f</em> either to an element <em>b</em> ∈ <em>B</em> or to “no answer.” If it has an answer <em>f</em>(<em>a</em>) ∈ <em>B</em>, then this again is sent by <em>g</em> either to an element <em>g</em>(<em>f</em>(<em>a</em>)) ∈ <em>C</em> or to “no answer.” We get a partial function <em>A</em> → <em>C</em> by sending <em>a</em> to <em>g</em>(<em>f</em>(<em>a</em>)) if possible or to “no answer” if it gets stopped along the way.</p>
<p>This monad is sometimes called the <em>maybe monad</em> in computer science, because a partial function <em>f</em> : <em>A</em> → <em>B</em> takes every element of <em>A</em> and may output just an element of <em>B</em> or may output nothing; more succinctly, it outputs a “maybe <em>B</em>.”</p>
<p><em>Exercise</em> 7.3.1.2.</p>
<p>a. Let <em>f</em> : ℤ → ℤ ⊔ {☺} be the partial function given by f(n)=1n2−n. Calculate the following: <em>f</em>(−3), <em>f</em>(−2), <em>f</em>(−1), <em>f</em>(0), <em>f</em>(1), and <em>f</em>(2).</p>
<p>b. Let <em>g</em> : ℤ → ℤ ⊔ {☺} be the partial function given by</p>
<p>g(n)={n2−3if n⩾−1,☺if n&lt;−1</p>
<p>Write <em>f</em> ○ <em>g</em>(<em>n</em>) for −3 ⩽ <em>n</em> ⩽ 2.</p>
<p><em>Application</em> 7.3.1.3. Experiments are supposed to be performed objectively, but suppose we imagine that changing the person who performs the experiment, say, in psychology, may change the outcome. Let <em>A</em> be the set of experimenters, let <em>X</em> be the parameter space for the experimental variables (e.g., <em>X</em> = Age × Income), and let <em>Y</em> be the observation space (e.g., <em>Y</em> = propensity for violence). We want to think of such an experiment as telling us about a function <em>f</em> : <em>X</em> → <em>Y</em> (how age and income affect propensity for violence). However, we may want to make some of the context explicit by including information about who performed the experiment. That is, we are really finding a function <em>f</em> : <em>X</em> × <em>A</em> → <em>Y</em>.</p>
<p>Given a set <em>P</em> of persons, the experimenter wants to know the age and income of each, i.e., a function <em>P</em> → <em>X</em>. However, it may be the case that even ascertaining this basic information, which is achieved merely by asking each person these questions, is subject to which experimenter in <em>A</em> is doing the asking. Then we again want to consider the experimenter as part of the equation, replacing the function <em>P</em> → <em>X</em> with a function <em>P</em> × <em>A</em> → <em>X</em>. In such a case, we can use a monad to hide the fact that everything in sight is assumed to be influenced by <em>A</em>. In other words, we want to announce, once and for all, the modeling context—that every observable is possibly influenced by the observer—so that it can recede into the background.</p>
<p>We return to this in Examples <a href="chapter007.html#Exa_7-3-2-6">7.3.2.6</a> and <a href="chapter007.html#Exa_7-3-3-4">7.3.3.4</a>.</p>
<h2 id="lev_7-3-2" class="level2"><strong>7.3.2   Definition and examples</strong></h2>
<p>What aspects of Example <a href="chapter007.html#Exa_7-3-1-1">7.3.1.1</a> are about monads, and what aspects are about partial functions in particular? Monads are structures involving a functor and a couple of natural transformations. Roughly speaking, the functor for partial functors was <em>B</em> ↦ <em>B</em> ⊔ {☺}, and the natural transformations were given in (<a href="chapter007.html#eq_7-11">7.11</a>) and (<a href="chapter007.html#eq_7-12">7.12</a>). This section gives the definition of monads and a few examples. We return to consider about how monads formalize context in Section <a href="chapter007.html#lev_7-3-3">7.3.3</a>.</p>
<p><strong>Definition 7.3.2.1</strong> (Monad). A <em>monad on</em> <strong>Set</strong> is defined as follows: One announces some constituents (A. functor, B. unit map, C. multiplication map) and shows that they conform to some laws (1. unit laws, 2. associativity law). Specifically, one announces</p>
<p>A. a functor <em>T</em> : <strong>Set</strong> → <strong>Set</strong>,</p>
<p>B. a natural transformation <em>η</em> : id<strong><sub>Set</sub></strong> → <em>T</em>,</p>
<p>C. a natural transformation <em>μ</em> : <em>T</em> ○ <em>T</em> → <em>T</em>.</p>
<p>We sometimes refer to the functor <em>T</em> as though it were the whole monad; we call <em>η</em> the <em>unit map</em> and <em>μ</em> the <em>multiplication map</em>. One must then show that the following <em>monad laws</em> hold:</p>
<ol>
<li><p>The following diagrams of functors <strong>Set</strong> → <strong>Set</strong> commute:</p>
<p><img src="images/Art_P327.jpg" alt="art" /></p></li>
<li><p>The following diagram of functors <strong>Set</strong> → <strong>Set</strong> commutes:</p>
<p><img src="images/Art_P328.jpg" alt="art" /></p></li>
</ol>
<p><em>Example</em> 7.3.2.2 (List monad). We now go through Definition <a href="chapter007.html#Def_7-3-2-1">7.3.2.1</a> using the List monad. The first step is to give a functor List: <strong>Set</strong> → <strong>Set</strong>, which was done in Example <a href="chapter005.html#Exa_5-1-2-20">5.1.2.20</a>. Recall that if <em>X</em> = {<em>p</em>, <em>q</em>, <em>r</em>}, then List(<em>X</em>) includes the empty list [ ], singleton lists such as [<em>p</em>], and any other list of elements in <em>X</em> such as [<em>p</em>, <em>p</em>, <em>r</em>, <em>q</em>, <em>p</em>]. Given a function <em>f</em> : <em>X</em> → <em>Y</em>, one obtains a function List(<em>f</em>) : List(<em>X</em>) → List(<em>Y</em>) by entrywise application of <em>f</em>, as in Exercise <a href="chapter005.html#Exe_5-1-2-22">5.1.2.22</a>.</p>
<p>As a monad, the functor List comes with two natural transformations, a unit map <em>η</em> and a multiplication map <em>μ</em>. Given a set <em>X</em>, the unit map <em>η<sub>X</sub></em> : <em>X</em> → List(<em>X</em>) returns singleton lists as follows:</p>
<p><img src="images/Art_P328a.jpg" alt="art" /></p>
<p>Given a set <em>X</em>, the multiplication map <em>μ<sub>X</sub></em> : List(List(<em>X</em>)) → List(<em>X</em>) concatenates lists of lists as follows:</p>
<p><img src="images/Art_P328b.jpg" alt="art" /></p>
<p>The naturality of <em>η</em> and <em>μ</em> means that these maps work appropriately well under entrywise application of a function <em>f</em> : <em>X</em> → <em>Y</em>. Finally, the three monad laws from Definition <a href="chapter007.html#Def_7-3-2-1">7.3.2.1</a> can be exemplified as follows:</p>
<p><img src="images/Art_P329.jpg" alt="art" /></p>
<p><img src="images/Art_P329a.jpg" alt="art" /></p>
<p><em>Exercise</em> 7.3.2.3.</p>
<p>Let ℙ : <strong>Set</strong> → <strong>Set</strong> be the power-set functor, so that given a function <em>f</em> : <em>X</em> → <em>Y</em>, the function ℙ(<em>f</em>) : ℙ(<em>X</em>) → ℙ(<em>Y</em>) is given by taking images.</p>
<p>a. Make sense of the statement, “With <em>η</em> defined by singleton subsets and with <em>μ</em> defined by union, T≔(ℙ,η,μ) is a monad.”</p>
<p>b. With <em>X</em> = {<em>a</em>, <em>b</em>}, write the function <em>η<sub>X</sub></em> as a two-row, two-column table.</p>
<p>c. With <em>X</em> = {<em>a</em>, <em>b</em>}, write the function <em>μ<sub>X</sub></em> as a sixteen-row, two-column table (you can stop after five rows if you fully understand it).</p>
<p>d. Check that you believe the monad laws from Definition <a href="chapter007.html#Def_7-3-2-1">7.3.2.1</a>.</p>
<p><em>Solution</em> 7.3.2.3.</p>
<p>a. The statement suggests that the components of <em>η</em> : id<strong><sub>Set</sub></strong> → ℙ can be defined using the concept of singleton subsets and that the components of <em>μ</em> : ℙ ○ ℙ → ℙ can be defined using the concept of union. Given a set <em>X</em> ∈ Ob(<strong>Set</strong>), we need a function <em>η<sub>X</sub></em> : <em>X</em> → ℙ(<em>X</em>), meaning that for every element <em>x</em> ∈ <em>X</em>, we need a subset of <em>X</em>. The statement suggests we send <em>x</em> to the singleton subset {<em>x</em>} ⊆ <em>X</em>. The statement also suggests that we obtain <em>μ<sub>X</sub></em> : ℙ(ℙ(<em>X</em>)) → ℙ(<em>X</em>) by sending a set of subsets to their union. For example, if <em>X</em> = {1, 2, 3, 4, 5}, then an element <em>T</em> ∈ ℙ(ℙ(<em>X</em>)) might look like {{1, 2}, Ø, {1, 3, 5}}; the union of these subsets is <em>μ<sub>X</sub></em>(<em>T</em>) = {1, 2, 3, 5}, a subset of <em>X</em>. It is not hard to check that the given <em>η</em> and <em>μ</em> are natural transformations. The statement now asserts that the power-set functor ℙ, together with these natural transformations, forms a monad.</p>
<p>b.)</p>
<p><em>η</em><sub><em>X</em></sub></p>
<p><em>X</em></p>
<p>ℙ(<em>X</em>)</p>
<p><em>a</em></p>
<p>{<em>a</em>}</p>
<p><em>b</em></p>
<p>{<em>b</em>}</p>
<p>c.)</p>
<p><em>μ<sub>X</sub></em></p>
<p>ℙ(ℙ(<em>X</em>))</p>
<p>ℙ(<em>X</em>)</p>
<p>Ø</p>
<p>Ø</p>
<p>{Ø}</p>
<p>Ø</p>
<p>{{<em>a</em>}}</p>
<p>{<em>a</em>}</p>
<p>{{<em>b</em>}}</p>
<p>{<em>b</em>}</p>
<p>{{<em>a</em>, <em>b</em>}}</p>
<p>{<em>a</em>, <em>b</em>}</p>
<p>{Ø, {<em>a</em>}}</p>
<p>{<em>a</em>}</p>
<p>{Ø, {<em>b</em>}}</p>
<p>{<em>b</em>}</p>
<p>{Ø, {<em>a</em>, <em>b</em>}}</p>
<p>{<em>a</em>, <em>b</em>}</p>
<p>{{<em>a</em>}, {<em>b</em>}}</p>
<p>{<em>a</em>, <em>b</em>}</p>
<p>{{<em>a,</em> {<em>a</em>, <em>b</em>}}}</p>
<p>{<em>a</em>, <em>b</em>}</p>
<p>{{<em>b</em>}, {<em>a</em>, <em>b</em>}}</p>
<p>{<em>a</em>, <em>b</em>}</p>
<p>{Ø, {<em>a</em>}, {<em>b</em>}}</p>
<p>{<em>a</em>, <em>b</em>}</p>
<p>{Ø, {<em>a</em>}, {<em>a</em>, <em>b</em>}}</p>
<p>{<em>a</em>, <em>b</em>}</p>
<p>{Ø, {<em>b</em>}, {<em>a</em>, <em>b</em>}}</p>
<p>{<em>a</em>, <em>b</em>}</p>
<p>{{<em>a</em>}, {<em>b</em>}, {<em>a</em>, <em>b</em>}}</p>
<p>{<em>a</em>, <em>b</em>}</p>
<p>{Ø, {<em>a</em>}, {<em>b</em>}, {<em>a</em>, <em>b</em>}}</p>
<p>{<em>a</em>, <em>b</em>}</p>
<p>d. The monad laws hold. One says that if we take all the singleton subsets of <em>X</em> and union them, we get <em>X</em>. Another says that if we take the singleton set consisting of the whole set <em>X</em> and union it, we get <em>X</em>. The last says that the union of unions is a union.</p>
<p><em>Example</em> 7.3.2.4 (Partial functions as a monad). Here is the monad for partial functions, as discussed in Example <a href="chapter007.html#Exa_7-3-1-1">7.3.1.1</a>. The functor <em>T</em> : <strong>Set</strong> → <strong>Set</strong> sends a set <em>X</em> to the set <em>X</em> ⊔ {☺}. Clearly, given a function <em>f</em> : <em>X</em> → <em>Y</em>, there is an induced function (<em>f</em> ⊔ {☺}) : (<em>X</em> ⊔ {☺}) → (<em>Y</em> ⊔ {☺}), so this is a functor. The natural transformation <em>η</em> : id → <em>T</em> is given on a set <em>X</em> by the component function</p>
<p>ηX:X→X⊔{☺}</p>
<p>that includes <em>X</em> ↪ <em>X</em> ⊔ {☺}. Finally, the natural transformation <em>μ</em> : <em>T</em> ○ <em>T</em> → <em>T</em> is given on a set <em>X</em> by the component function</p>
<p>μX:X⊔{☺}⊔{☺}→X⊔{☺}</p>
<p>that collapses both copies of ☺.</p>
<p><em>Exercise</em> 7.3.2.5.</p>
<p>Let <em>E</em> be a set with elements refered to as <em>exceptions</em>. We imagine exceptions as warnings like “overflow!” or “division by zero!” and we imagine that a function <em>f</em> : <em>X</em> → <em>Y</em> outputs either a value or one of these exceptions. Let <em>T</em> : <strong>Set</strong> → <strong>Set</strong> be the functor <em>X</em> ↦ <em>X</em> ⊔ <em>E</em>. Follow Example <a href="chapter007.html#Exa_7-3-2-4">7.3.2.4</a> and find a unit map <em>η</em> and a multiplication map <em>μ</em> for which (<em>T</em>, <em>η</em>, <em>μ</em>) is a monad.</p>
<p><em>Example</em> 7.3.2.6. Fix a set <em>A</em>. Let <em>T</em> : <strong>Set</strong> → <strong>Set</strong> be the functor given by <em>T</em>(<em>X</em>) = <em>X<sup>A</sup></em> = Hom<strong><sub>Set</sub></strong>(<em>A</em>, <em>X</em>); this is a functor. For a set <em>X</em> and an element <em>x</em> ∈ <em>X</em>, let <em>c<sub>x</sub></em> : <em>A</em> → <em>X</em> be the constant-<em>x</em> function, <em>c<sub>x</sub></em>(<em>a</em>) = <em>x</em> for all <em>a</em> ∈ <em>A</em>. Define <em>η<sub>X</sub></em> : <em>X</em> → <em>T</em>(<em>X</em>) to be given by the constant-<em>x</em> function, <em>x</em> ↦ <em>c<sub>x</sub></em>.</p>
<p>Now we have to specify a natural transformation <em>μ</em> : <em>T</em> ○ <em>T</em> → <em>T</em>, i.e., for each <em>X</em> ∈ Ob(<strong>Set</strong>), we need to provide an <em>X</em>-component function</p>
<p>μX:(XA)A→XA.</p>
<p>By currying (see Example <a href="chapter007.html#Exa_7-1-1-8">7.1.1.8</a>), this is equivalent to providing a function (<em>X<sup>A</sup></em>)<em><sup>A</sup></em> × <em>A</em> → <em>X</em>. For any <em>Y</em> ∈ Ob(<strong>Set</strong>), we have an evaluation function (see Exercise <a href="chapter003.html#Exe_3-4-2-5">3.4.2.5</a>) <em>ev</em> : <em>Y<sup>A</sup></em> × <em>A</em> → <em>Y</em>. We use it twice and find the desired function:</p>
<p>(XA)A×A→   ev×idA   XA×A→  ev   X.</p>
<p><em>Remark</em> 7.3.2.7. Monads can be defined on categories other than <strong>Set</strong>. In fact, for any category C, one can take Definition <a href="chapter007.html#Def_7-3-2-1">7.3.2.1</a> and replace every occurrence of <strong>Set</strong> with C and obtain the definition for monads on C. We have actually seen a monad (Paths, <em>η</em>, <em>μ</em>) on the category <strong>Grph</strong> of graphs before, namely, in Examples <a href="chapter005.html#Exa_5-3-1-15">5.3.1.15</a> and <a href="chapter005.html#Exa_5-3-1-16">5.3.1.16</a>. That is, Paths: <strong>Grph</strong> → <strong>Grph</strong>, which sends a graph to its paths-graph is the functor part. The unit map <em>η</em> includes a graph into its paths-graph using the observation that every arrow is a path of length 1. And the multiplication map <em>μ</em> concatenates paths of paths. The Kleisli category of this monad (see Definition <a href="chapter007.html#Def_7-3-3-1">7.3.3.1</a>) is used, e.g., in (5.17), to define morphisms of database schemas.</p>
<h2 id="lev_7-3-3" class="level2"><strong>7.3.3   Kleisli category of a monad</strong></h2>
<p>We are on our way to understanding how monads are used in computer science and how they may be useful for formalizing methodological context. There is only one more stop along the way, called the Kleisli category of a monad. For example, when we apply this Kleisli construction to the partial functions monad (Example <a href="chapter007.html#Exa_7-3-2-4">7.3.2.4</a>), we obtain the category of partial functions (see Example <a href="chapter007.html#Exa_7-3-3-2">7.3.3.2</a>). When we apply the Kleisli construction to the monad <em>X</em> ↦ <em>X<sup>A</sup></em> of Example <a href="chapter007.html#Exa_7-3-2-6">7.3.2.6</a> we get the psychological experiment example (Application <a href="chapter007.html#App_7-3-1-3">7.3.1.3</a>) completed in Example <a href="chapter007.html#Exa_7-3-3-4">7.3.3.4</a>.</p>
<p><strong>Definition 7.3.3.1</strong>. Let T=(T,η,μ) be a monad on <strong>Set</strong>. Form a new category, called the <em>Kleisli category for</em> T, denoted Kls(T), with sets as objects, Ob(Kls(T))≔Ob(Set), and with</p>
<p>HomKls(T)(X,Y)≔HomSet(X,T(Y))</p>
<p>for sets <em>X</em>, <em>Y</em>. The identity morphism id<em><sub>X</sub></em> : <em>X</em> → <em>X</em> in Kls(T) is given by <em>η</em> : <em>X</em> → <em>T</em>(<em>X</em>) in <strong>Set</strong>. The composition of morphisms <em>f</em> : <em>X</em> → <em>Y</em> and <em>g</em> : <em>Y</em> → <em>Z</em> in Kls(T) is given as follows. Writing them as functions, we have <em>f</em> : <em>X</em> → <em>T</em>(<em>Y</em>) and <em>g</em> : <em>Y</em> → <em>T</em>(<em>Z</em>). The first step is to apply the functor <em>T</em> to <em>g</em>, giving <em>T</em>(<em>g</em>) : <em>T</em>(<em>Y</em>) → <em>T</em>(<em>T</em>(<em>Z</em>)). Then compose with <em>f</em> to get <em>T</em>(<em>g</em>) ○ <em>f</em> : <em>X</em> → <em>T</em>(<em>T</em>(<em>Z</em>)). Finally, compose with <em>μ<sub>Z</sub></em> : <em>T</em>(<em>T</em>(<em>Z</em>)) → <em>T</em>(<em>Z</em>) to get the required function <em>X</em> → <em>T</em>(<em>Z</em>):</p>
<p><img src="images/Art_P329b.jpg" alt="art" /></p>
<p>The associativity of this composition formula follows from the associativity law for monads.</p>
<p><em>Example</em> 7.3.3.2. Recall the monad T for partial functions, <em>T</em>(<em>X</em>) = <em>X</em> ⊔ {☺}, from Example <a href="chapter007.html#Exa_7-3-2-4">7.3.2.4</a>. The Kleisli category Kls(T) has sets as objects, but a morphism <em>f</em> : <em>X</em> → <em>Y</em> means a function <em>X</em> → <em>Y</em> ⊔ {☺}, i.e., a partial function. Given another morphism <em>g</em> : <em>Y</em> → <em>Z</em>, the composition formula in Kls(T) ensures that <em>g</em> ○ <em>f</em> : <em>X</em> → <em>Z</em> has the appropriate behavior.</p>
<p>Note how this monad allows us to make explicit a context in which all functions are assumed partial and then hide this context from our notation.</p>
<p><em>Remark</em> 7.3.3.3. For any monad T=(T,η,μ) on <strong>Set</strong>, there is a functor i:Set→Kls(T), given as follows. On objects we have Ob(Kls(T))=Ob(Set), so take <em>i</em> = id<sub>Ob(<strong>Set</strong>)</sub>. Given a morphism <em>f</em> : <em>X</em> → <em>Y</em> in <strong>Set</strong>, we need a morphism <em>i</em>(<em>f</em>) : <em>X</em> → <em>Y</em> in Kls(T), i.e., a function <em>i</em>(<em>f</em>) : <em>X</em> → <em>T</em>(<em>Y</em>). We assign <em>i</em>(<em>f</em>) to be the composite X→fY→ηT(Y). The functoriality of this mapping follows from the unit law for monads.</p>
<p><em>Example</em> 7.3.3.4. In this example we return to the setting laid out in Application <a href="chapter007.html#App_7-3-1-3">7.3.1.3</a>, where we had a set <em>A</em> of experimenters and assumed that the person doing the experiment might affect the outcome. We use the monad T=(T,η,μ) from Example <a href="chapter007.html#Exa_7-3-2-6">7.3.2.6</a> and hope that Kls(T) will conform to the understanding of how to manage the effect of the experimenter on data.</p>
<p>The objects of Kls(T) are ordinary sets, but a map <em>f</em> : <em>X</em> → <em>Y</em> in Kls(T) is a function <em>X</em> → <em>Y<sup>A</sup></em>. By currying, this is the same as a function <em>X</em> × <em>A</em> → <em>Y</em>, as desired. To compose <em>f</em> with <em>g</em> : <em>Y</em> → <em>Z</em> in Kls(T), we follow the formula from (<a href="chapter007.html#eq_7-13">7.13</a>). It turns out to be equivalent to the following. We have a function <em>X</em> × <em>A</em> → <em>Y</em> and a function <em>Y</em> × <em>A</em> → <em>Z</em>. Multiplying by id<em><sub>A</sub></em>, we have a function <em>X</em> × <em>A</em> → <em>Y</em> × <em>A</em>, and we can now compose to get <em>X</em> × <em>A</em> → <em>Z</em>.</p>
<p>What does this say in terms of experimenters affecting data gathering? It says that if we work within Kls(T), then we may assume that the experimenter is being taken into account; all proposed functions <em>X</em> → <em>Y</em> are actually functions <em>A</em> × <em>X</em> → <em>Y</em>. The natural way to compose these experiments is that we only consider the data from one experiment to feed into another if the experimenter is the same in both experiments.<sup><a href="chapter007.html#endnote_11">11</a></sup></p>
<p><em>Exercise</em> 7.3.3.5.</p>
<p>Exercise <a href="chapter007.html#Exe_7-3-2-3">7.3.2.3</a> discussed the power-set monad T=(ℙ,η,μ).</p>
<p>a. Can you find a way to relate the morphisms in Kls(T) to relations? That is, given a morphism <em>f</em> : <em>A</em> → <em>B</em> in Kls(T), is there a natural way to associate to it a relation <em>R</em> ⊆ <em>A</em> × <em>B</em>?</p>
<p>b. How does the composition formula in Kls(T) relate to the composition of relations given in Definition <a href="chapter003.html#Def_3-2-2-3">3.2.2.3</a>?<sup><a href="chapter007.html#endnote_12">12</a></sup></p>
<p><em>Solution</em> 7.3.3.5.</p>
<p>a. A morphism <em>A</em> → <em>B</em> in Kls(T) is a function <em>f</em> : <em>A</em> → ℙ(<em>B</em>) in <strong>Set</strong>. From such a function we need to obtain a binary relation, i.e., a subset <em>R</em> ⊆ <em>A</em> × <em>B</em>. Recall that for any set <em>X</em> (e.g., <em>X</em> = <em>B</em> or <em>X</em> = <em>A</em> × <em>B</em>), we can identify the subsets of <em>X</em> with the functions <em>X</em> → Ω = {<em>True</em>, <em>False</em>}, using the characteristic function as in Definition <a href="chapter003.html#Def_3-4-4-12">3.4.4.12</a>. In other words, we have a bijection</p>
<p>ℙ(X)≅HomSet(X,Ω).</p>
<p>By currying, we get an isomorphism</p>
<p>HomSet(A,ℙ(B))≅HomSet(A,HomSet(B,Ω))≅HomSet(A×B,Ω)≅ℙ(A×B).</p>
<p>In other words, we can identify the function <em>f</em> : <em>A</em> → ℙ(<em>B</em>) with an element of ℙ(<em>A</em> × <em>B</em>), i.e., with a subset <em>R</em> ⊆ <em>A</em> × <em>B</em>, i.e., with a relation.</p>
<p>A more down-to-earth way to specify how <em>f</em> : <em>A</em> → ℙ(<em>B</em>) gives rise to a binary relation <em>R</em> ⊆ <em>A</em> × <em>B</em> is as follows. We ask, given (<em>a</em>, <em>b</em>) ∈ <em>A</em> × <em>B</em>, when is it in <em>R</em>? We see that <em>f</em>(<em>a</em>) ∈ ℙ(<em>B</em>) is a subset, so the answer is that we put (<em>a</em>, <em>b</em>) ∈ <em>R</em> if <em>b</em> ∈ <em>f</em>(<em>a</em>). This gives the desired relation.</p>
<p>b. It is the same.</p>
<p><em>Exercise</em> 7.3.3.6.</p>
<p>(Challenge) Let T=(ℙ,η,μ) be the power-set monad. The category Kls(T) is closed under binary products, i.e., every pair of objects A,B∈Ob(Kls(T)) has a product in Kls(T). What is the product of <em>A</em> = {1, 2, 3} and <em>B</em> = {<em>a</em>, <em>b</em>}, and what are the projections?</p>
<p><em>Solution</em> 7.3.3.6.</p>
<p>The product of <em>A</em> and <em>B</em> in Kls(T) is <em>A</em> × <em>B</em> = {1, 2, 3, <em>a</em>, <em>b</em>}, which coincidentally would be their coproduct in <strong>Set</strong>. The projection maps are functions ℙ(A)←π1{1,2,3,a,b}→π2ℙ(B); we use the obvious maps, e.g., <em>π</em><sub>1</sub>(3) = {3} and <em>π</em><sub>1</sub>(<em>a</em>) = Ø. The question did not ask for the universal property, but we specify it anyway. Given <em>f</em> : <em>X</em> → ℙ(<em>A</em>) and <em>g</em> : <em>X</em> → ℙ(<em>B</em>), we take 〈<em>f</em>, <em>g</em>〉: <em>X</em> → ℙ(<em>A</em> ⊔ <em>B</em>} to be given by union.</p>
<p><em>Exercise</em> 7.3.3.7.</p>
<p>(Challenge.) Let T=(ℙ,η,μ) be the power-set monad. The category Kls(T) is closed under binary coproducts, i.e., every pair of objects A,B∈Ob(Kls(T)) has a coproduct in Kls(T). What is the coproduct of <em>A</em> = {1, 2, 3} and <em>B</em> = {<em>a</em>, <em>b</em>}?</p>
<p><em>Example</em> 7.3.3.8. Let <em>A</em> be any preorder. We speak of <em>A</em> throughout this example as though it were the linear order given by time; however, the mathematics works for any <em>A</em> ∈ Ob(<strong>PrO</strong>).</p>
<p>There is a monad T=(T,η,μ) that captures the idea that a function <em>f</em> : <em>X</em> → <em>Y</em> occurs in the context of time in the following sense: The output of <em>f</em> is determined not only by the element <em>x</em> ∈ <em>X</em> on which it is applied but also by the time at which it was applied to <em>x</em>; and the output of <em>f</em> occurs at another time, which is not before the time of input.</p>
<p>The functor part of the monad is given on <em>Y</em> ∈ Ob(<strong>Set</strong>) by</p>
<p>T(Y)={p:A→A×Y| if p(a)=(a′,y) then a⩽a′}.</p>
<p>The unit <em>η<sub>Y</sub></em> : <em>Y</em> → <em>T</em>(<em>Y</em>) sends <em>y</em> to the function <em>a</em> ↦ (<em>a</em>, <em>y</em>). The multiplication map <em>μ<sub>Y</sub></em> : <em>T</em>(<em>T</em>(<em>Y</em>)) → <em>T</em>(<em>Y</em>) is as follows. Suppose given <em>p</em> : <em>A</em> → <em>A</em> × <em>T</em>(<em>Y</em>) in <em>T</em>(<em>T</em>(<em>Y</em>)). Then <em>μ<sub>Y</sub></em> (<em>p</em>) : <em>A</em> → <em>A</em> × <em>Y</em> is given on <em>a</em> ∈ <em>A</em> as follows. Suppose <em>p</em>(<em>a</em>) = (<em>a</em>′, <em>p</em>′), where <em>p</em>′ : <em>A</em> → <em>A</em> × <em>Y</em>. Then we assign <em>μ<sub>Y</sub></em> (<em>p</em>)(<em>a</em>) = <em>p</em>′(<em>a</em>′) ∈ <em>A</em> × <em>Y</em>.</p>
<p>Given two sets <em>X</em>, <em>Y</em>, what is the meaning of a morphism <em>X</em> → <em>Y</em> in the Kleisli category Kls(T), i.e., a function <em>f</em> : <em>X</em> → <em>T</em>(<em>Y</em>)? Note that <em>T</em>(<em>Y</em>) ⊆ Hom<strong><sub>Set</sub></strong>(<em>A</em>, <em>A</em> × <em>Y</em>), and composing with <em>f</em>, we have a function <em>X</em> → Hom<strong><sub>Set</sub></strong>(<em>A</em>, <em>A</em> × <em>Y</em>), which can be curried to a function <em>f</em> : <em>A</em> × <em>X</em> → <em>A</em> × <em>Y</em>. So we have an isomorphism</p>
<p>HomKls(T)(X,Y)≅{f∈HomSet(A×X,A×Y)| if f(a,x)=(a′,y) then a⩽a′}.</p>
<p>The right-hand set could be characterized as time-sensitive functions <em>f</em> : <em>X</em> → <em>Y</em> for which the output arrives after the input.</p>
<p><em>Remark</em> 7.3.3.9. One of the most important monads in computer science is the <em>state monad</em>. It is used when one wants to allow a program to mutate state variables (e.g., in the program</p>
<p>if <em>x</em> ⩽ 4, then <em>x</em> ≔ <em>x</em> + 1 else Print “done”</p>
<p><em>x</em> is a state variable). The state monad is a special case of the monad discussed in Example <a href="chapter007.html#Exa_7-3-3-8">7.3.3.8</a>. Given any set <em>A</em>, the usual <em>state monad of type A</em> is obtained by giving <em>A</em> the indiscrete preorder (see Example <a href="chapter004.html#Exa_4-4-4-5">4.4.4.5</a>). More explicitly, it is a monad with functor part</p>
<p>X↦(A×X)A</p>
<p>(see Example <a href="chapter007.html#Exa_7-3-5-3">7.3.5.3</a>).</p>
<p><em>Example</em> 7.3.3.10. We reconsider <a href="chapter001.html#Fig_1-1">Figure 1.1</a> reproduced as <a href="chapter007.html#Fig_7-3">Figure 7.3</a>.</p>
<p><img src="images/Art_P330.jpg" alt="art" /></p>
<p><strong>Figure 7.3</strong> An olog whose arrows do not denote functions. It should be interpreted using a monad.</p>
<p>It looks like an olog, and all ologs are database schemas (see Section <a href="chapter004.html#lev_4-5-2-15">4.5.2.15</a>). But how is “analyzed by a person yields” a function? For it to be a function, there must be only one hypothesis corresponding to a given observation. The very name of this arrow belies the fact that it is an invalid aspect in the sense of Section <a href="chapter002.html#lev_2-3-2-1">2.3.2.1</a>, because given an observation, there may be more than one hypothesis yielded, corresponding to which person is doing the observing. In fact, all the arrows in this figure correspond to some hidden context involving people: the prediction is dependent on who analyzes the hypothesis, the specification of an experiment is dependent on who is motivated to specify it, and experiments may result in different observations by different observers.</p>
<p>Without monads, the model of science proposed by this olog would be difficult to believe in. But by choosing a monad we can make explicit (and then hide from discourse) the implicit assumption that “this is all dependent on which human is doing the science.” The choice of monad is an additional modeling choice. Do we want to incorporate the partial order of time? Do we want the scientist to be modified by each function (i.e., the person is changed when analyzing an observation to yield a hypothesis)? These are all interesting possibilities.</p>
<p>One reasonable choice would be to use the state monad of type <em>A</em>, where <em>A</em> is the set of scientific models. This implies the following context. Every morphism <em>f</em> : <em>X</em> → <em>Y</em> in the Kleisli category of this monad is really a morphism <em>f</em> : <em>X</em> × <em>A</em> → <em>Y</em> × <em>A</em>; while ostensibly giving a map from <em>X</em> to <em>Y</em>, it is influenced by the scientific model under which it is performed, and its outcome yields a new scientific model.</p>
<p>Reading the olog in this context might look like this:</p>
<p>A hypothesis (in the presence of a scientific model) analyzed by a person produces a prediction (in the presence of a scientific model), which motivates the specification of an experiment (in the presence of a scientific model), which when executed results in an observation (in the presence of a scientific model), which analyzed by a person yields a hypothesis (in the presence of a scientific model).</p>
<p>The parenthetical statements can be removed if we assume them to be always there, which can be done using the preceding monad.</p>
<h3 id="lev_7-3-3-11" class="level3"><strong>7.3.3.11   Relaxing functionality constraint for ologs</strong></h3>
<p>Section <a href="chapter002.html#lev_2-3-2">2.3.2</a> said that every arrow in an olog has to be English-readable as a sentence, and it has to correspond to a function. For example, the arrow</p>
<p><img src="images/Art_P331.jpg" alt="art" /></p>
<p>makes for a readable sentence, but it does not correspond to a function because a person may have no children or more than one child. We call an olog in which every arrow corresponds to a function (the only option proposed so far in this book) a <em>functional olog</em>. Requiring that ologs be functional comes with advantages and disadvantages. The main advantage is that creating a functional olog requires more conceptual clarity, and this has benefits for the olog creator as well as for anyone to whom he tries to explain the situation. The main disadvantage is that creating a functional olog takes more time, and the olog takes up more space on the page.</p>
<p>In the context of the power-set monad (see Exercise <a href="chapter007.html#Exe_7-3-2-3">7.3.2.3</a>), a morphism <em>f</em> : <em>X</em> → <em>Y</em> between sets <em>X</em> and <em>Y</em>, as objects in <strong>Kls</strong>(ℙ), becomes a binary relation on <em>X</em> and <em>Y</em> rather than a function (see Exercise <a href="chapter007.html#Exe_7-3-3-5">7.3.3.5</a>). So in that context, the arrow in (<a href="chapter007.html#eq_7-14">7.14</a>) becomes valid. An olog in which arrows correspond to mere binary relations rather than functions might be called a <em>relational olog</em>.</p>
<h2 id="lev_7-3-4" class="level2"><strong>7.3.4   Monads in databases</strong></h2>
<p>This section discusses how to record data in the presence of a monad. The idea is quite simple. Given a schema (category) C, an ordinary instance is a functor I:C→Set. But if T=(T,η,μ) is a monad, then a <em>Kleisli</em> T-<em>instance on</em> C is a functor J:C→Kls(T). Such a functor associates to every object c∈Ob(C) a set <em>J</em>(<em>c</em>), and to every arrow <em>f</em> : <em>c</em> → <em>c</em>′ in C a morphism <em>J</em>(<em>f</em>) : <em>J</em>(<em>c</em>) → <em>J</em>(<em>c</em>′) in Kls(T). How does this look in terms of tables?</p>
<p>Recall that to represent an ordinary database instance I:C→Set, we use a tabular format in which every object c∈Ob(C) is displayed as a table including one ID column and one additional column for each arrow <em>f</em> : <em>c</em> → <em>c</em>′ emanating from <em>c</em>. The cells in the ID column of table <em>c</em> contain the elements of the set <em>I</em>(<em>c</em>), and the cells in the <em>f</em> column contain elements of the set <em>I</em>(<em>c</em>′).</p>
<p>To represent a <em>Kleisli</em> database instance J:C→Kls(T) is similar; we again use a tabular format in which every object c∈Ob(C) is displayed as a table including one ID column and one additional column for each arrow <em>f</em> : <em>c</em> → <em>c</em>′ emanating from <em>c</em>. The cells in the ID column of table <em>c</em> again contain the elements of the set <em>J</em>(<em>c</em>); however the cells in the <em>f</em> column do not contain elements of <em>J</em>(<em>c</em>′), but <em>T</em>-values in <em>J</em>(<em>c</em>′), i.e., elements of <em>T</em>(<em>J</em>(<em>c</em>′)).</p>
<p><em>Example</em> 7.3.4.1. Let T=(T,η,μ) be the monad for partial functions (see Example <a href="chapter007.html#Exa_7-3-1-1">7.3.1.1</a>). Given any schema C, we can represent a Kleisli T-instance I:C→Kls(T) in tabular format. For every object c∈Ob(C) we have a set <em>I</em>(<em>c</em>) of rows, and given a column <em>f</em> : <em>c</em> → <em>c</em>′, applying <em>f</em> to a row either produces a value in <em>I</em>(<em>c</em>′) or fails to produce a value; this is the essence of partial functions. We might denote the absence of a value using ☺.</p>
<p>Consider the schema indexing graphs</p>
<p><img src="images/Art_P332.jpg" alt="art" /></p>
<p>As discussed in Section <a href="chapter005.html#lev_5-2-1-21">5.2.1.21</a>, an ordinary instance on C represents a graph:</p>
<p><img src="images/Art_P333.jpg" alt="art" /></p>
<p>A Kleisli T-instance on C represents graphs in which edges can fail to have a source vertex, fail to have a target vertex, or both:</p>
<p><img src="images/Art_P334.jpg" alt="art" /></p>
<p>The context of these tables is that of partial functions, so we do not need a reference for ☺ in the vertex table. Mathematically, the morphism <em>J</em>(<em>src</em>) : <em>J</em>(Arrow) → <em>J</em>(Vertex) in Kls(T) needs to be a function <em>J</em>(Arrow) → <em>J</em>(Vertex) ⊔ {☺}, and it is.</p>
<h3 id="lev_7-3-4-2" class="level3"><strong>7.3.4.2   Probability distributions</strong></h3>
<p>Let [0, 1] ⊆ ℝ denote the set of real numbers between 0 and 1. Let <em>X</em> be a set and <em>p</em> : <em>X</em> → [0, 1] a function. We say that <em>p</em> is a <em>finitary probability distribution on X</em> if there exists a finite subset <em>W</em> ⊆ <em>X</em> such that</p>
<p>∑w∈Wp(w)=1,(7.15)</p>
<p>and such that <em>p</em>(<em>x</em>) &gt; 0 if and only if <em>x</em> ∈ <em>W</em>. Note that the subset <em>W</em> is unique if it exists; we call it <em>the support of p</em> and denote it <strong>Supp</strong>(<em>p</em>).</p>
<p>For any set <em>X</em>, let <strong>Dist</strong>(<em>X</em>) denote the set of finitary probability distributions on <em>X</em>. It is easy to check that given a function <em>f</em> : <em>X</em> → <em>Y</em>, one obtains a function <strong>Dist</strong>(<em>f</em>) : <strong>Dist</strong>(<em>X</em>) → <strong>Dist</strong>(<em>Y</em>) by <strong>Dist</strong>(<em>f</em>)(<em>y</em>) = Σ<sub><em>f</em>(<em>x</em>)=<em>y</em></sub><em>p</em>(<em>x</em>). Thus we can consider <strong>Dist</strong> : <strong>Set</strong> → <strong>Set</strong> as a functor, and in fact the functor part of a monad. Its unit <em>η</em> : <em>X</em> → <strong>Dist</strong>(<em>X</em>) is given by the Kronecker delta function <em>x</em> ↦ <em>δ<sub>x</sub></em>, where <em>δ<sub>x</sub></em>(<em>x</em>) = 1 and <em>δ<sub>x</sub></em>(<em>x</em>′) = 0 for <em>x</em>′ ≠ <em>x</em>. Its multiplication <em>μ</em> : <strong>Dist</strong>(<strong>Dist</strong>(<em>X</em>)) → <strong>Dist</strong>(<em>X</em>) is given by weighted sum: given a finitary probability distribution <em>w</em> : <strong>Dist</strong>(<em>X</em>) → [0, 1] and <em>x</em> ∈ <em>X</em>, put <em>μ</em>(<em>w</em>)(<em>x</em>) = Σ<sub><em>p</em>∈<strong>Supp</strong>(<em>w</em>)</sub> <em>w</em>(<em>p</em>)<em>p</em>(<em>x</em>).</p>
<p><em>Example</em> 7.3.4.3 (Markov chains). Let Loop be the loop schema</p>
<p><img src="images/Art_P335.jpg" alt="art" /></p>
<p>as in Example <a href="chapter004.html#Exa_4-5-2-10">4.5.2.10</a>. A <strong>Dist</strong>-instance on Loop is equivalent to a time-homogeneous Markov chain. To be explicit, a functor <em>δ</em> : Loop → <strong>Kls</strong>(<strong>Dist</strong>) assigns to the unique object <em>s</em> ∈ Ob(Loop) a set <em>S</em> = <em>δ</em>(<em>s</em>), called the state space, and to <em>f</em> : <em>s</em> → <em>s</em> a function <em>δ</em>(<em>f</em>) : <em>S</em> → <strong>Dist</strong>(<em>S</em>), which sends each element <em>x</em> ∈ <em>S</em> to some probability distribution on elements of <em>S</em>. For example, the left-hand table <em>δ</em> (having states <em>δ</em>(<em>s</em>) = {<em>a</em>, <em>b</em>, <em>c</em>, <em>d</em>}) corresponds to the right-hand Markov matrix <em>M</em>:</p>
<p><img src="images/Art_P336.jpg" alt="art" /></p>
<p>As one might hope, for any natural number <em>n</em> ∈ ℕ, the map <em>f<sup>n</sup></em> : <em>S</em> → <em>S</em> in <strong>Kls</strong>(<strong>Dist</strong>) corresponds to the matrix <em>M<sup>n</sup></em>, which sends an element <em>s</em> ∈ <em>S</em> to its probable location after <em>n</em> iterations of the transition map, <em>f<sup>n</sup></em>(<em>s</em>) ∈ <strong>Dist</strong>(<em>S</em>).</p>
<p><em>Application</em> 7.3.4.4. Every star emits a spectrum of light, which can be understood as a distribution on the electromagnetic spectrum. Given an object <em>B</em> on earth, different parts of <em>B</em> will absorb radiation at different rates. Thus <em>B</em> produces a function from the electromagnetic spectrum to distributions of energy absorption. In the context of the probability distributions monad, we can record data on the schema</p>
<p>•star→    emits    •wavelengths→  absorbed by B  •energies</p>
<p>The composition formula for Kleisli categories is the desired one: to each star we associate the weighted sum of energy absorption rates over the set of wavelengths emitted by the star.</p>
<h2 id="lev_7-3-5" class="level2"><strong>7.3.5   Monads and adjunctions</strong></h2>
<p>There is a strong connection between monads and adjunctions: every adjunction creates a monad, and every monad comes from an adjunction. For example, the List monad (Example <a href="chapter007.html#Exa_7-3-2-2">7.3.2.2</a>) comes from the free forgetful adjunction between sets and monoids</p>
<p>Set⇄UFMon</p>
<p>(see Proposition <a href="chapter007.html#Pro_7-1-1-2">7.1.1.2</a>). That is, for any set <em>X</em>, the free monoid on <em>X</em> is</p>
<p>F(X)=(List(X),[],++),</p>
<p>and the underlying set of that monoid is <em>U</em>(<em>F</em>(<em>X</em>)) = List(<em>X</em>). So the List functor is given by <em>U</em> ○ <em>F</em> : <strong>Set</strong> → <strong>Set</strong>. But a monad is more than a functor; it includes a unit map <em>η</em> and a multiplication map <em>μ</em> (see Definition <a href="chapter007.html#Def_7-3-2-1">7.3.2.1</a>). Luckily, the unit <em>η</em> and multiplication <em>μ</em> drop out of the adjunction too. First, we discuss the unit and counit of an adjunction.</p>
<p><strong>Definition 7.3.5.1</strong>. Let C and D be categories, and let L:C→D and R:D→C be functors with adjunction isomorphism</p>
<p>αc,d:HomD(L(c),d)→  ≅  HomC(c,R(d))</p>
<p>for any objects c∈Ob(C) and d∈Ob(D) (see Definition <a href="chapter007.html#Def_7-1-1-1">7.1.1.1</a>). The <em>unit</em> η:idC→R○L (resp. the <em>counit</em> ϵ:L○R→idD) of the adjunction is a natural transformation defined as follows.</p>
<p>Given an object c∈Ob(C), we apply <em>α</em> to id<sub><em>L</em>(<em>c</em>)</sub> : <em>L</em>(<em>c</em>) → <em>L</em>(<em>c</em>) to get the <em>c</em> component</p>
<p>ηc:c→R○L(c)</p>
<p>of <em>η</em>. Similarly given an object d∈Ob(D) we apply <em>α</em><sup>−1</sup> to id<sub><em>R</em>(<em>d</em>)</sub> : <em>R</em>(<em>d</em>) → <em>R</em>(<em>d</em>) to get the <em>d</em> component</p>
<p>ϵd:L○R(d)→d.</p>
<p>One checks that these components are natural.</p>
<p>Later we see how to use the unit and counit of any adjunction to make a monad. We first walk through the process in Example <a href="chapter007.html#Exa_7-3-5-2">7.3.5.2</a>.</p>
<p><em>Example</em> 7.3.5.2. Consider the adjunction Set⇄UFMon between sets and monoids. Let <em>T</em> = <em>U</em> ○ <em>F</em> : <strong>Set</strong> → <strong>Set</strong>; this will be the functor part of the monad, and we have seen that <em>T</em> = List. The unit of the adjunction, <em>η</em> : id<strong><sub>Set</sub></strong> → <em>U</em> ○ <em>F</em> is precisely the unit of the monad: for any set <em>X</em> ∈ Ob(<strong>Set</strong>) the component <em>η<sub>X</sub></em> : <em>X</em> → List(<em>X</em>) is the function that takes <em>x</em> ∈ <em>X</em> to the singleton list [<em>x</em>] ∈ List(<em>X</em>). The monad also has a multiplication map <em>μ<sub>X</sub></em> : <em>T</em>(<em>T</em>(<em>X</em>)) → <em>T</em>(<em>X</em>), which amounts to concatenating a list of lists. This function comes about using the counit <em>ϵ</em>, as follows</p>
<p>T○T=U○F○U○F→  idU⋄ϵ⋄idF  U○F=T.</p>
<p>The general procedure for extracting a monad from an adjunction is analogous to the process shown in Example <a href="chapter007.html#Exa_7-3-5-2">7.3.5.2</a>. Given any adjunction</p>
<p>C⇄RLD,</p>
<p>we define T=R○L:C→C, we define η:idC→T to be the unit of the adjunction (as in Definition <a href="chapter007.html#Def_7-3-5-1">7.3.5.1</a>), and we define μ:T○T→T to be the natural transformation id<em><sub>R</sub></em> ⋄ <em>ϵ</em> ⋄ id<em><sub>L</sub></em> : <em>RLRL</em> → <em>RL</em>, obtained by applying the counit ϵ:LR→idD.</p>
<p>This procedure produces monads on arbitrary categories C, whereas the definition of monad (Definition <a href="chapter007.html#Def_7-3-2-1">7.3.2.1</a>) considers only the case C=Set. However, Definition <a href="chapter007.html#Def_7-3-2-1">7.3.2.1</a> can be generalized to arbitrary categories C by simply replacing every occurrence of the string <strong>Set</strong> with the string C. Similarly, the definition of Kleisli categories (Definition <a href="chapter007.html#Def_7-3-3-1">7.3.3.1</a>) considers only the case C=Set, but again the generalization to arbitrary categories C is straightforward.</p>
<p><em>Example</em> 7.3.5.3. Let <em>A</em> ∈ Ob(<strong>Set</strong>) be a set, and recall the currying adjunction</p>
<p>Set⇄  Y↦YA    X↦X×A  Set,</p>
<p>discussed briefly in Example <a href="chapter007.html#Exa_7-1-1-8">7.1.1.8</a>. The corresponding monad <em>St<sub>A</sub></em> is typically called the <em>state monad of type A</em> in programming language theory. Given a set <em>X</em>, we have</p>
<p>StA(X)=(A×X)A.</p>
<p>In the Kleisli category <strong>Kls</strong>(<em>St<sub>A</sub></em>) a morphism from <em>X</em> to <em>Y</em> is a function of the form <em>X</em> → (<em>A</em> × <em>Y</em>)<em><sup>A</sup></em>, but this can be curried to a function <em>A</em> × <em>X</em> → <em>A</em> × <em>Y</em>.</p>
<p>As discussed in Remark <a href="chapter007.html#Rem_7-3-3-9">7.3.3.9</a>, this monad is related to holding onto an internal state variable of type <em>A</em>. Under the state monad <em>St<sub>A</sub></em>, every morphism written <em>X</em> → <em>Y</em>, when viewed as a function, takes as input not only an element of <em>X</em>, but also the current state <em>a</em> ∈ <em>A</em>, and it produces as output not only an element of <em>Y</em>, but also an updated state.</p>
<p>Computer scientists in programming language theory have found monads very useful (Moggi [33]). In much the same way, monads on <strong>Set</strong> might be useful in databases (see Section <a href="chapter007.html#lev_7-3-4">7.3.4</a>). Another, totally different way to use monads in databases is by using a mapping between schemas to produce in each one an internal model of the other. That is, for any functor F:C→D, i.e., mapping of database schemas, the adjunction (Σ<em><sub>F</sub></em>, Δ<em><sub>F</sub></em>) produces a monad on C−Set, and the adjunction (Δ<em><sub>F</sub></em>, Π<em><sub>F</sub></em>) produces a monad on D−Set. If one interprets the List monad as producing in <strong>Set</strong> an internal model of the category <strong>Mon</strong> of monoids, one can similarly interpret these monads on C−Set and D−Set as producing internal models of each within the other.</p>
<h1 id="lev_7-4" class="level1"><a href="toc.html#Rlev_7-4"><strong>7.4   Operads</strong></a></h1>
<p>This section briefly introduces operads, which are generalizations of categories. They often are useful for speaking about self-similarity of structure. For example, we use operads to model agents made up of smaller agents, or materials made up of smaller materials. This association with self-similarity is not really inherent in the definition, but it tends to emerge in thinking about many operads used in practice.</p>
<p>Let me begin with a warning.</p>
<p><em>Warning</em> 7.4.0.4. My use of the term <em>operad</em> is not entirely standard and conflicts with widespread usage. The more common term for what I am calling an operad is <em>colored operad</em> or <em>symmetric multicategory</em>. An operad classically is a multicategory with one object, and a colored operad is a multicategory with possibly many objects (one for each “color”). The term <em>multicategory</em> stems from the fact that the morphisms in a multicategory have many, rather than one, domain object. One reason I prefer not to use the term <em>multicategory</em> is that there is nothing really “multi” about the multicategory itself, only its morphisms. Further, I do not see enough reason to differentiate, given that the term <em>multicategory</em> seems rather clunky and the term <em>operad</em> seems rather sleek. I hope my break with standard terminology does not cause confusion.</p>
<p>This introduction to operads is quite short; see Leinster [25] for an excellent treatment. Operads are also related to monoidal categories, a subject that is not elaborated in this book to discuss, but which was briefly mentioned when discussing topological enrichment in Example <a href="chapter005.html#Exa_5-2-3-3">5.2.3.3</a>. Many of the following operads are actually monoidal categories in disguise.</p>
<h2 id="lev_7-4-1" class="level2"><strong>7.4.1   Definition and classical examples</strong></h2>
<p>An operad is like a category in that it has objects, morphisms, and a composition formula, and it obeys an identity law and an associativity law. The difference is that each morphism <em>f</em> in an operad can have many inputs (and one output):</p>
<p><img src="images/Art_P337.jpg" alt="art" /></p>
<p>The description of composition in an operad is a bit more complicated than for a category, because it involves much more variable indexing; however, the idea is straightforward. Figure <strong>??</strong> shows morphisms being composed. Note that <em>S</em> and <em>T</em> disappear from the composition, but this is analogous to the way the middle object disappears from the composition of morphisms in a category</p>
<p><img src="images/Art_P338.jpg" alt="art" /></p>
<p>Here is the definition, taken from Spivak [41]. Skip to Example <a href="chapter007.html#Exa_7-4-1-3">7.4.1.3</a> if the definition gets too difficult.</p>
<p><strong>Definition 7.4.1.1</strong>. An <em>operad</em> O is defined as follows: One announces some constituents (A. objects, B. morphisms, C. identities, D. compositions) and shows that they conform to some laws (1. identity law, 2. associativity law). Specifically, one announces</p>
<p>A. a collection Ob(O), each element of which is called an <em>object</em> of O;</p>
<p>B. for each object y∈Ob(O), finite set <em>n</em> ∈ Ob(<strong>Fin</strong>), and <em>n</em>-indexed set of objects x:n→Ob(O), a set On(x;y)∈Ob(Set); its elements are called <em>morphisms from x to y</em> in O;</p>
<p>C. for every object x∈Ob(O), a specified morphism, denoted idx∈O1(x;x) and called <em>the identity morphism on x</em>.</p>
<p>D. Let <em>s</em> : <em>m</em> → <em>n</em> be a morphism in <strong>Fin</strong>. Let z∈Ob(O) be an object, let y:n→Ob(O) be an <em>n</em>-indexed set of objects, and let x:m→Ob(O) be an <em>m</em>-indexed set of objects. For each element <em>i</em> ∈ <em>n</em>, write <em>m<sub>i</sub></em> ≔ <em>s</em><sup>−1</sup>(<em>i</em>) for the pre-image of <em>s</em> under <em>i</em>, and write xi=x|mi:mi→Ob(O) for the restriction of <em>x</em> to <em>m<sub>i</sub></em>. Then one announces a function</p>
<p>○:On(y;z)×∏i∈nOmi(xi;y(i))→Om(x;z),(7.17)</p>
<p>called <em>the composition formula</em>.</p>
<p>Given an <em>n</em>-indexed set of objects x:n→Ob(O) and an object y∈Ob(O), we sometimes abuse notation and denote the set of morphisms from <em>x</em> to <em>y</em> by O(x1,…,xn;y).<sup><a href="chapter007.html#endnote_13">13</a></sup> We may write HomO(x1,…,xn;y), in place of O(x1,…,xn;y), when convenient. We can denote a morphism ϕ∈On(x;y) by <em>ϕ</em> : <em>x</em> → <em>y</em> or by <em>ϕ</em> : (<em>x</em><sub>1</sub>, …, <em>x<sub>n</sub></em>) → <em>y</em>; we say that each <em>x<sub>i</sub></em> is a <em>domain object</em> of <em>ϕ</em> and that <em>y</em> is the <em>codomain object</em> of <em>ϕ</em>. We use infix notation for the composition formula, e.g., <em>ψ</em> ○ (<em>ϕ</em><sub>1</sub>, …, <em>ϕ<sub>n</sub></em>).</p>
<p>One must then show that the following <em>operad laws</em> hold:</p>
<ol>
<li><p>For every x1,…,xn,y∈Ob(O) and every morphism <em>ϕ</em> : (<em>x</em><sub>1</sub>, …, <em>x<sub>n</sub></em>) → <em>y</em>, we have</p>
<p>ϕ○(idx1,…,idxn)=ϕ and idy○ϕ=ϕ.</p></li>
<li><p>Let m→sn→tp be composable morphisms in <strong>Fin</strong>. Let z∈Ob(O) be an object, let y:p→Ob(O), x:n→Ob(O), and w:m→Ob(O) respectively be a <em>p</em>-indexed, <em>n</em>-indexed, and <em>m</em>-indexed set of objects. For each <em>i</em> ∈ <em>p</em>, write <em>n<sub>i</sub></em> = <em>t</em><sup>−1</sup>(<em>i</em>) for the pre-image and xi:ni→Ob(O) for the restriction. Similarly, for each <em>k</em> ∈ <em>n</em>, write <em>m<sub>k</sub></em> = <em>s</em><sup>−1</sup>(<em>k</em>) and wk:mk→Ob(O); for each <em>i</em> ∈ <em>p</em>, write <em>m</em><sub><em>i</em>,−</sub> = (<em>t</em> ○ <em>s</em>)<sup>−1</sup>(<em>i</em>) and wi,−:mi,−→Ob(O); for each <em>j</em> ∈ <em>n<sub>i</sub></em>, write <em>m</em><sub><em>i</em>,<em>j</em></sub> ≔ <em>s</em><sup>−1</sup>(<em>j</em>) and wi,j:mi,j→Ob(O). Then the following diagram commutes:</p>
<p><img src="images/Art_P339.jpg" alt="art" /></p></li>
</ol>
<p><em>Remark</em> 7.4.1.2. This remark considers the abuse of notation in Definition <a href="chapter007.html#Def_7-4-1-1">7.4.1.1</a> and how it relates to an action of a symmetric group on each morphism set in the definition of operad. We follow the notation of Definition <a href="chapter007.html#Def_7-4-1-1">7.4.1.1</a>, especially the use of subscripts in the composition formula.</p>
<p>Suppose that O is an operad, z∈Ob(O) is an object, y:n→Ob(O) is an <em>n</em>-indexed set of objects, and <em>ϕ</em> : <em>y</em> → <em>z</em> is a morphism. If we linearly order <em>n</em>, enabling us to write <em>ϕ</em> : (<em>y</em>(1), …, <em>y</em>(|<em>n</em>|)) → <em>z</em>, then changing the linear ordering amounts to finding an isomorphism of finite sets σ:m→≅n, where |<em>m</em>| = |<em>n</em>|. Let <em>x</em> = <em>y</em> ○ <em>σ</em>, and for each <em>i</em> ∈ <em>n</em>, note that <em>m<sub>i</sub></em> = <em>σ</em><sup>−1</sup>({<em>i</em>}) = {<em>σ</em><sup>−1</sup>(<em>i</em>)}, so xi=x|σ−1(i)=y(i). Taking idxi∈Omi(xi;y(i)) for each <em>i</em> ∈ <em>n</em>, and using the identity law, we find that the composition formula induces a bijection On(y;z)→≅Om(x;z), which we might denote</p>
<p>σ:O(y(1),y(2),…,y(n);z)≅O(y(σ(1)),y(σ(2)),…,y(σ(n));z).(7.18)</p>
<p>In other words, the permutation group Aut(<em>n</em>) acts on the set On of <em>n</em>-ary morphisms by permuting the order of the domain objects Ob(O)n.</p>
<p>Throughout this book, we allow this abuse of notation and speak of morphisms <em>ϕ</em> : (<em>y</em><sub>1</sub>, <em>y</em><sub>2</sub>, …, <em>y<sub>n</sub></em>) → <em>z</em> for a natural number <em>n</em> ∈ ℕ, without mentioning the abuse inherent in choosing an order, as long as it is clear that permuting the order of indices would not change anything up to the canonical isomorphism of (<a href="chapter007.html#eq_7-18">7.18</a>).</p>
<p><em>Example</em> 7.4.1.3 (Little squares operad). An operad commonly used in mathematics is called the <em>little n-cubes operad</em>. We will focus on <em>n</em> = 2 and talk about the little squares operad O. Here the set of objects has only one element, denoted by a square, Ob(O)={▫}. For a natural number <em>n</em> ∈ ℕ, a morphism <em>f</em> : (▫, ▫, …, ▫) → ▫ is a positioning of <em>n</em> nonoverlapping squares inside of a square. <a href="chapter007.html#Fig_7-5">Figure 7.5</a> shows a morphism (<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, <em>X</em><sub>3</sub>) → <em>Y</em>, where <em>X</em><sub>1</sub> = <em>X</em><sub>2</sub> = <em>X</em><sub>3</sub> = <em>Y</em> = ▫.</p>
<p>The composition formula says that given a positioning of small squares inside a large square, and given a positioning of tiny squares inside each of those small squares, we get a positioning of tiny squares inside a large square. See <a href="chapter007.html#Fig_7-6">Figure 7.6</a>.</p>
<p>Example <a href="chapter007.html#Exa_7-4-1-3">7.4.1.3</a> exemplifies the kind of self-similarity mentioned on page 362.</p>
<p><em>Exercise</em> 7.4.1.4.</p>
<p>Consider an operad O like the little squares operad from Example <a href="chapter007.html#Exa_7-4-1-3">7.4.1.3</a>, except with three objects: square, circle, equilateral triangle. A morphism is again a nonoverlapping positioning of shapes inside a shape.</p>
<p>a. Draw an example of a morphism <em>f</em> from two circles and a square to a triangle.</p>
<p>b. Find three other morphisms that compose into <em>f</em>, and draw the composite.</p>
<p><em>Solution</em> 7.4.1.4.</p>
<p>a.</p>
<p><img src="images/Art_P340.jpg" alt="art" /></p>
<p>b.</p>
<p><img src="images/Art_P341.jpg" alt="art" /></p>
<p><em>Example</em> 7.4.1.5. Let <strong>Sets</strong> denote the operad defined as follows. As objects we put Ob(<strong>Sets</strong>) = Ob(<strong>Set</strong>). For a natural number <em>n</em> ∈ ℕ and sets <em>X</em><sub>1</sub>, …, <em>X<sub>n</sub></em>, <em>Y</em>, put</p>
<p>HomSets(X1,…,Xn;Y)≔HomSet(X1×⋯×Xn,Y).</p>
<p>Given functions f1:(X1,1×⋯×X1,m1)→Y1 through fn:(Xn,1×⋯×Xn,mn)→Yn and a function <em>Y</em><sub>1</sub> × ⋯ × <em>Y<sub>n</sub></em> → <em>Z</em>, the universal property provides a unique function of the form (X1,1×⋯×Xn,mn)→Z, giving rise to the composition formula in <strong>Sets</strong>.</p>
<h3 id="lev_7-4-1-6" class="level3"><strong>7.4.1.6   Operads: functors and algebras</strong></h3>
<p>If operads are like categories, then we can define things like functors and call them <em>operad functors</em>.</p>
<p><em>Warning</em> 7.4.1.7. What is called an operad functor in Definition <a href="chapter007.html#Def_7-4-1-8">7.4.1.8</a> is usually called an <em>operad morphism</em>. I think the terminology clash between morphisms <em>of</em> operads and morphisms <em>in</em> an operad is confusing. It is similar to what would occur in regular category theory (see Chapter 5) if we replaced the term <em>functor</em> with the term <em>category morphism</em>.</p>
<p><strong>Definition 7.4.1.8</strong>. Let O and O′ be operads. An <em>operad functor from</em> O <em>to</em> O′, denoted F:O→O′, is defined as follows. One announces some constituents (A. on-objects part, B. on-morphisms part) and shows that they conform to some laws (1. preservation of identities, 2. preservation of composition). Specifically, one announces</p>
<p>A. a function Ob(F):Ob(O)→Ob(O′), sometimes denoted simply F:Ob(O)→Ob(O′);</p>
<p>B. for each object y∈Ob(O), finite set <em>n</em> ∈ Ob(<strong>Fin</strong>), and <em>n</em>-indexed set of objects x:n→Ob(O), a function</p>
<p>Fn:On(x;y)→On′(Fx;Fy).</p>
<p>One must then show that the following <em>operad functor laws</em> hold:</p>
<ol>
<li>For each object x∈Ob(O), the equation <em>F</em>(id<em><sub>x</sub></em>) = id<sub><em>Fx</em></sub> holds.</li>
<li><p>Let <em>s</em> : <em>m</em> → <em>n</em> be a morphism in <strong>Fin</strong>. Let z∈Ob(O) be an object, let y:n→Ob(O) be an <em>n</em>-indexed set of objects, and let x:m→Ob(O) be an <em>m</em>-indexed set of objects. Then, with notation as in Definition <a href="chapter007.html#Def_7-4-1-1">7.4.1.1</a>, the following diagram of sets commutes:</p>
<p><img src="images/Art_P342.jpg" alt="art" /></p></li>
</ol>
<p>We denote the category of operads and operad functors <strong>Oprd</strong>.</p>
<p><em>Exercise</em> 7.4.1.9.</p>
<p>Let O denote the little squares operad from Example <a href="chapter007.html#Exa_7-4-1-3">7.4.1.3</a>, and let O′ denote the little shapes operad you constructed in Exercise <a href="chapter007.html#Exe_7-4-1-4">7.4.1.4</a>.</p>
<p>a. Can you find an operad functor F:O→O′?</p>
<p>b. Is it possible to find an operad functor G:O′→O?</p>
<p><strong>Definition 7.4.1.10</strong> (Operad algebra). Let O be an operad, and let <strong>Sets</strong> be the operad from Example <a href="chapter007.html#Exa_7-4-1-5">7.4.1.5</a>. An <em>algebra on</em> O is an operad functor A:O→Sets.</p>
<p><em>Remark</em> 7.4.1.11. Every category can be construed as an operad (there is a functor <strong>Cat</strong> → <strong>Oprd</strong>), one in which every morphism is unary. That is, given a category C, one makes an operad O with Ob(O)≔Ob(C) and with</p>
<p>HomO(x1,…,xn;y)={HomC(x1,y)if n=1,∅if n≠1.</p>
<p>Throughout the book a connection is made between database schemas and categories (see Section <a href="chapter005.html#lev_5-2-2">5.2.2</a>), under which a schema C is construed as a category presentation, i.e., by generators and relations. Similarly, it is possible to discuss operad presentations O, again by generators and relations. Under this analogy, an instance C→Set of the database (see Section <a href="chapter005.html#lev_5-2-2-6">5.2.2.6</a>) corresponds to an algebra O→Sets of the operad.</p>
<h2 id="lev_7-4-2" class="level2"><strong>7.4.2   Applications of operads and their algebras</strong></h2>
<p>Hierarchical structures seem to be well modeled by operads. A hierarchical structure often has basic building blocks and instructions for how they can be put together into larger building blocks. Describing such structures using operads and their algebras allows one to make appropriate distinctions between different types of thinking, which may otherwise be blurred. For example, the abstract building instructions should be encoded in the operad, whereas the concrete building blocks should be encoded in the algebra. Morphisms of algebras are high-level understandings of how building blocks of very different types (such as materials versus numbers) can occupy the same place in the structure and be compared.</p>
<p>We get a general flavor of these ideas in the following examples.</p>
<p><em>Application</em> 7.4.2.1. Every material is composed of constituent materials, arranged in certain patterns. (In case the material is pure, we consider the material to consist of itself as the sole constituent.) Each of these constituent materials is itself an arrangement of constituent materials. Thus a kind of self-similarity can be modeled with operads.</p>
<p>For example, a tendon is made of collagen fibers that are assembled in series and then in parallel, in a specific way. Each collagen fiber is made of collagen fibrils that are again assembled in series and then in parallel, with slightly different specifications. We can continue, perhaps indefinitely. Going a bit further, each collagen fibril is made up of tropocollagen collagen molecules, which are twisted ropes of collagen molecules, and so on.<sup><a href="chapter007.html#endnote_14">14</a></sup></p>
<p>Here is how operads might be employed. We want the same operad to model all three of the following: actual materials, theoretical materials, and functional properties. That is, we want more than one algebra on the same operad.</p>
<p>The operad O should abstractly model the structure but not the substance being structured. Imagine that each of the shapes, say a triangle, in Figure (<a href="chapter007.html#eq_7-7">7.7</a>) is a placeholder that indicates “your triangular material here.” Each morphism represents a construction of a material out of parts.</p>
<p><em>Application</em> 7.4.2.2. Suppose we have chosen an operad O to model the structure of materials. Say each object of O corresponds to a certain quality of material, and each morphism corresponds to an arrangement of various qualities to form a new quality. An algebra A:O→Sets on O requires us to choose what substances will fill in for these qualities. For every object x∈Ob(O), we want a set <em>A</em>(<em>x</em>) that will be the set of materials with that quality. For every arrangement, i.e., morphism, <em>f</em> : (<em>x</em><sub>1</sub>, …, <em>x<sub>n</sub></em>) → <em>y</em>, and every choice <em>a</em><sub>1</sub> ∈ <em>A</em>(<em>x</em><sub>1</sub>), …, <em>a<sub>n</sub></em> ∈ <em>A</em>(<em>x<sub>n</sub></em>) of materials, we need to understand what material <em>a</em>′ = <em>A</em>(<em>f</em>)(<em>a</em><sub>1</sub>, …, <em>a<sub>n</sub></em>) ∈ <em>A</em>(<em>y</em>) will emerge when materials <em>a</em><sub>1</sub>, …, <em>a<sub>n</sub></em> are arranged in accordance with <em>f</em>.</p>
<p>There may be more than one interesting algebra on O. Suppose that B:O→Sets is an algebra of strengths rather than of materials. For each object x∈Ob(O), which represents some quality, we let <em>B</em>(<em>x</em>) be the set of possible strengths that something of quality <em>x</em> can have. Then for each arrangement, i.e., morphism, <em>f</em> : (<em>x</em><sub>1</sub>, …, <em>x<sub>n</sub></em>) → <em>y</em>, and every choice <em>b</em><sub>1</sub> ∈ <em>B</em>(<em>x</em><sub>1</sub>), …, <em>b<sub>n</sub></em> ∈ <em>B</em>(<em>x<sub>n</sub></em>) of strengths, we need to understand what strength <em>b</em>′ = <em>B</em>(<em>f</em>)(<em>b</em><sub>1</sub>, …, <em>b<sub>n</sub></em>) ∈ <em>B</em>(<em>y</em>) will emerge when strengths <em>b</em><sub>1</sub>, …, <em>b<sub>n</sub></em> are arranged in accordance with <em>f</em>.</p>
<p>Finally, a morphism of algebras <em>S</em> : <em>A</em> → <em>B</em> would consist of a coherent system for assigning to each material <em>a</em> ∈ <em>A</em>(<em>X</em>) of a given quality <em>x</em> a specific strength <em>S</em>(<em>a</em>) ∈ <em>B</em>(<em>X</em>), in such a way that morphisms behave appropriately. One can use the language of operads and algebras to state a very precise goal for the field of material mechanics.</p>
<p><em>Exercise</em> 7.4.2.3.</p>
<p>Consider again the little squares operad O from Example <a href="chapter007.html#Exa_7-4-1-3">7.4.1.3</a>. Suppose we want to use this operad to describe photographic mosaics.</p>
<p>a. Devise an algebra P:O→Sets that sends the square to the set <em>M</em> of all photos that can be pasted into that square. What does <em>P</em> do on morphisms in O?</p>
<p>b. Devise an algebra C:O→Sets that sends each square to the set of all colors (visible frequencies of light). In other words, <em>C</em>(▫) is the set of colors, not the set of ways to color the square. What does <em>C</em> do on morphisms in O. Hint: Use some kind of averaging scheme for the morphisms.</p>
<p>c. Guess: If someone were to appropriately define morphisms of O-algebras (something akin to natural transformations between functors O→Sets), do you think there would be some morphism of algebras <em>P</em> → <em>C</em>?</p>
<h3 id="lev_7-4-2-4" class="level3"><strong>7.4.2.4   Relations and wiring diagrams</strong></h3>
<p><em>Example</em> 7.4.2.5. Here we describe an <em>operad of relations</em>, denoted R. The objects are sets, Ob(R)=Ob(Set). A morphism <em>f</em> : (<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X<sub>n</sub></em>) → <em>Y</em> in R is a relation</p>
<p>R⊆X1×X2×⋯×Xn×Y.(7.20)</p>
<p>We use a composition formula similar to that in Definition <a href="chapter003.html#Def_3-2-2-3">3.2.2.3</a>. Namely, to compose relations <em>R</em><sub>1</sub>, …, <em>R<sub>n</sub></em> with <em>S</em>, we first form a fiber product, denoted <em>FP</em>:</p>
<p><img src="images/Art_P343.jpg" alt="art" /></p>
<p>We have an induced function FP→(∏i∈n¯∏j∈mi¯Xi,j)×Z, and its image is the subset we take to be the composite: S○(R1,…,Rn)⊆(∏i∈n¯∏j∈mi¯Xi,j)×Z. This gives a composition formula, for which the associativity and identity laws hold, so we indeed have an operad R.</p>
<p><em>Application</em> 7.4.2.6. Suppose we are trying to model life in the following way. We define an entity as a set of <em>available experiences</em>. We also want to be able to put entities together to form a superentity, so we have a notion of morphism <em>f</em> : (<em>X</em><sub>1</sub>, …, <em>X<sub>n</sub></em>) → <em>Y</em> defined as a relation, as in (<a href="chapter007.html#eq_7-20">7.20</a>).</p>
<p>The idea is that the morphism <em>f</em> is a way of translating between the experiences available to the subentities and the experiences available to the superentity. The superentity <em>Y</em> consists of some available experiences, like “hunger” ∈ <em>Y</em>. The subentities <em>X<sub>i</sub></em> each have their own set of available experiences, like “U88fh” ∈ <em>X</em><sub>2</sub>. The relation <em>R</em> ⊆ <em>X</em><sub>1</sub> × … × <em>X<sub>n</sub></em> × <em>Y</em> provides a way to translate between them. It says that when <em>X</em><sub>1</sub> is experiencing “acidic” and <em>X</em><sub>2</sub> is experiencing “U88fh,” and so on, this is the same as <em>Y</em> experiencing “hunger.”</p>
<p>The operad R from Example <a href="chapter007.html#Exa_7-4-2-5">7.4.2.5</a> becomes useful as a language for discussing issues in this domain.</p>
<p><em>Example</em> 7.4.2.7. Let R be the operad of relations from Example <a href="chapter007.html#Exa_7-4-2-5">7.4.2.5</a>, and recall that Ob(R)=Ob(Set). Consider the algebra S:R→Sets given by <em>S</em>(<em>X</em>) = ℙ(<em>X</em>) for X∈Ob(R). Given a morphism <em>R</em> ⊆ ∏<sub><em>i</em></sub> <em>X<sub>i</sub></em> × <em>Y</em> and subsets Xi′⊆Xi, we have a subset ∏iXi′⊆∏iXi. We take the fiber product</p>
<p><img src="images/Art_P344.jpg" alt="art" /></p>
<p>and the image of <em>FP</em> → <em>Y</em> is a subset of <em>Y</em>, as needed. We will continue with Application <a href="chapter007.html#App_7-4-2-8">7.4.2.8</a> using this algebra.</p>
<p><em>Application</em> 7.4.2.8. Following Application <a href="chapter007.html#App_7-4-2-6">7.4.2.6</a> we can use Example <a href="chapter007.html#Exa_7-4-2-7">7.4.2.7</a> as a model of survival. Each entity <em>Y</em> survives only for a subset of the phenomena that it can experience. Under this interpretation, the algebra from Example <a href="chapter007.html#Exa_7-4-2-7">7.4.2.7</a> defines survival of an entity as the survival of all parts.</p>
<p>Suppose that we understand how the experiences of a superentity <em>Y</em> relate to those of subentities <em>X</em><sub>1</sub>, …, <em>X<sub>n</sub></em> in the sense that we have a morphism <em>f</em> : (<em>X</em><sub>1</sub>, …, <em>X<sub>n</sub></em>) → <em>Y</em> in R. In the language of Application <a href="chapter007.html#App_7-4-2-6">7.4.2.6</a>, we have a translation between the set of experiences available across the sub-entities and the set of experiences available to the superentity. Our algebra postulates that the superentity will survive exactly those experiences for which each subentity survives.</p>
<p>Another way to phrase this, rather than in terms of survival, would be in terms of allowance. A bureaucracy consists of a set of smaller bureaucracies, each of which allows certain requests to pass; the whole bureaucracy allows a request to pass if and only if, when the request is translated into the perspective of each subbureaucracy, it is allowed to pass there.</p>
<p><em>Exercise</em> 7.4.2.9.</p>
<p>Define the following six sets, <em>A</em> = <em>B</em> = <em>M</em> = <em>C</em> = <em>N</em> = <em>Z</em> = ℤ, and consider them as objects A,B,M,C,N,Z∈Ob(R).</p>
<p>a. How would you encode the relations</p>
<p>ab=m2, c2=m3, m+n=z</p>
<p>as a 2-ary morphism <em>R</em><sub>1</sub> : (<em>A</em>, <em>B</em>) → <em>M</em>, a 1-ary morphism <em>R</em><sub>2</sub> : (<em>C</em>) → <em>N</em>, and a 2-ary morphism <em>S</em> : (<em>M</em>, <em>N</em>) → <em>Z</em> in the operad R?</p>
<p>b. What is the domain and codomain of the composite <em>S</em> ○ (<em>R</em><sub>1</sub>, <em>R</em><sub>2</sub>)?</p>
<p>c. Write the composite <em>S</em> ○ (<em>R</em><sub>1</sub>, <em>R</em><sub>2</sub>) as a relation.</p>
<p><em>Example</em> 7.4.2.10. This example discusses wiring diagrams. This operad is denoted W (see [41]). An object of W is just a finite set, Ob(W)=Ob(Fin), elements of which are called <em>wires</em>. A morphism in W is shown in <a href="chapter007.html#Fig_7-8">Figure 7.8</a> (see page 382) and is formalized as follows. Given objects <em>C</em><sub>1</sub>, …, <em>C<sub>n</sub></em>, and <em>D</em>, a morphism (<em>C</em><sub>1</sub>, …, <em>C<sub>n</sub></em>) → <em>D</em> is a commutative diagram of sets</p>
<p><img src="images/Art_P345.jpg" alt="art" /></p>
<p>such that <em>p</em> and <em>q</em> are jointly surjective.</p>
<p>Composition of morphisms is easily understood in graphic form: Given wiring diagrams inside of wiring diagrams, we can throw away the intermediary circles. In terms of sets, we first take the pushout <em>PO</em>:</p>
<p><img src="images/Art_P346.jpg" alt="art" /></p>
<p>and then take the composition to be the image of (⊔i∈n¯⊔j∈mi¯Ci,j)⊔E→PO.</p>
<p><em>Exercise</em> 7.4.2.11.</p>
<p>Let <em>C</em><sub>1</sub> = {<em>a</em>, <em>b</em>, <em>m</em>}, <em>C</em><sub>2</sub> = {<em>c</em>, <em>n</em>}, <em>C</em><sub>3</sub> = {<em>m</em>, <em>n</em>, <em>z</em>}, let <em>C</em> = <em>C</em><sub>1</sub> ⊔ <em>C</em><sub>2</sub> ⊔ <em>C</em><sub>3</sub>, and let <em>D</em> = {<em>a</em>, <em>c</em>, <em>z</em>}.</p>
<p>a. Suppose we draw <em>C</em><sub>1</sub>, <em>C</em><sub>2</sub>, and <em>C</em><sub>3</sub> as follows:</p>
<p><img src="images/Art_P347.jpg" alt="art" /></p>
<p>Follow those examples to draw <em>D</em>.</p>
<p>b. What set <em>G</em> and functions C→pG←qD in (<a href="chapter007.html#eq_7-21">7.21</a>) correspond to this picture?</p>
<p><img src="images/Art_P348.jpg" alt="art" /></p>
<p><em>Solution</em> 7.4.2.11.</p>
<p>a. We can draw <em>D</em> = {<em>a</em>, <em>c</em>, <em>z</em>} as follows:</p>
<p><img src="images/Art_P349.jpg" alt="art" /></p>
<p>b. Here <em>G</em> = {<em>a</em>, <em>b</em>, <em>m</em>, <em>c</em>, <em>n</em>, <em>z</em>}. The functions C→pG←qD are given in the following tables:</p>
<p><img src="images/Art_P350.jpg" alt="art" /></p>
<p><em>Example</em> 7.4.2.12. Let’s continue with the operad W of wiring diagrams, and try to form an algebra on it. Taking R to be the operad of relations as described in Example <a href="chapter007.html#Exa_7-4-2-5">7.4.2.5</a>, there is an operad functor Q:W→R. It assigns to each C∈Ob(W) the set ℤC∈Ob(R)=Ob(Set). To a morphism <em>G</em> : (<em>C</em><sub>1</sub>, …, <em>C<sub>n</sub></em>) → <em>D</em> as in (<a href="chapter007.html#eq_7-21">7.21</a>) it assigns the relation</p>
<p>ℤG⊆(∏i∈n¯ℤCi)×ℤD.</p>
<p>The idea is that to an entity defined as having a bunch of cables carrying integers, a phenomenon is the same thing as a choice of integer on each cable. A wiring diagram translates between phenomena experienced locally and phenomena experienced globally.</p>
<p>Now recall the algebra S:R→Set from Example <a href="chapter007.html#Exa_7-4-2-7">7.4.2.7</a>. We can compose with <em>Q</em> to get Q′≔S○Q:W→Set.</p>
<p><em>Exercise</em> 7.4.2.13.</p>
<p>Consider the wiring diagrams operad W from Example <a href="chapter007.html#Exa_7-4-2-10">7.4.2.10</a>. Let’s continue with Exercise <a href="chapter007.html#Exe_7-4-2-11">7.4.2.11</a> so that “everything,” i.e., <em>C</em><sub>1</sub>, <em>C</em><sub>2</sub>, <em>C</em><sub>3</sub>, <em>D</em>, <em>G</em>, <em>i</em>, and <em>j</em>, are as in that exercise. By Example <a href="chapter007.html#Exa_7-4-2-12">7.4.2.12</a> we have an algebra Q′:W→Set.</p>
<p>a. What might we mean by saying that the following picture represents an element <em>q</em><sub>1</sub> ∈ <em>Q</em>′(<em>C</em><sub>1</sub>)?</p>
<p><img src="images/Art_P351.jpg" alt="art" /></p>
<p>b. Suppose we have the following elements <em>q</em><sub>1</sub> ∈ <em>Q</em>′(<em>C</em><sub>1</sub>), <em>q</em><sub>2</sub> ∈ <em>Q</em>′(<em>C</em><sub>2</sub>), and <em>q</em><sub>3</sub> ∈ <em>Q</em>′(<em>C</em><sub>3</sub>):</p>
<p><img src="images/Art_P352.jpg" alt="art" /></p>
<p>Given the wiring diagram <em>G</em> : (<em>C</em><sub>1</sub>, <em>C</em><sub>2</sub>, <em>C</em><sub>3</sub>) → <em>D</em> pictured here,</p>
<p><img src="images/Art_P353.jpg" alt="art" /></p>
<p>what is <em>G</em>(<em>q</em><sub>1</sub>, <em>q</em><sub>2</sub>, <em>q</em><sub>3</sub>) ∈ <em>Q</em>′(<em>D</em>)?</p>
<p><em>Application</em> 7.4.2.14. In cognitive neuroscience or in industrial economics, it may be that we want to understand the behavior of an entity such as a mind, a society, or a business in terms of its structure. Knowing the connection pattern (connectome, supply chain) of subentities should help us understand how big changes are generated from small ones.</p>
<p><em>Application</em> 7.4.2.15. In [36], Radul and Sussman discuss propagator networks. Their implementation can presumably be understood in terms of wiring diagrams and their algebra of relations.</p>
<p><img src="images/Art_P354.jpg" alt="art" /></p>
<p><strong>Figure 7.1</strong> Three overlapping views of the night sky. Source: NASA, ESA, Digitized Sky Survey Consortium.</p>
<p><img src="images/Art_P355.jpg" alt="art" /></p>
<p><strong>Figure 7.2</strong> The three overlapping views have been glued together into one coherent view.</p>
<p><img src="images/Art_P356.jpg" alt="art" /></p>
<p><strong>Figure 7.4</strong> The composition of morphisms <em>f</em><sub>1</sub> and <em>f</em><sub>2</sub> with <em>g</em>.</p>
<p><img src="images/Art_P357.jpg" alt="art" /></p>
<p><strong>Figure 7.5</strong> A morphism (<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, <em>X</em><sub>3</sub>) → <em>Y</em> in an operad with only one object, ▫.</p>
<p><img src="images/Art_P358.jpg" alt="art" /></p>
<p><strong>Figure 7.6</strong> A morphism (<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, <em>X</em><sub>3</sub>) → <em>Y</em> and morphisms (<em>W</em><sub>1,1</sub>, <em>W</em><sub>1,2</sub>) → <em>X</em><sub>1</sub>, (<em>W</em><sub>2,1</sub>, <em>W</em><sub>2,2</sub>, <em>W</em><sub>2,3</sub>) → <em>X</em><sub>2</sub>, and (<em>W</em><sub>3,1</sub>) → <em>X</em><sub>3</sub>, each of which is a positioning of squares inside a square. The composition formula is given by scaling and positioning the squares to give (<em>W</em><sub>1,1</sub>, <em>W</em><sub>1,2</sub>, <em>W</em><sub>2,1</sub>, <em>W</em><sub>2,2</sub>, <em>W</em><sub>2,3</sub>, <em>W</em><sub>3,1</sub>) → <em>Y</em>.</p>
<p><img src="images/Art_P359.jpg" alt="art" /></p>
<p><strong>Figure 7.7</strong> A morphism expressing the construction of a material from smaller materials.</p>
<p><img src="images/Art_P360.jpg" alt="art" /></p>
<p><strong>Figure 7.8</strong> Morphisms in a wiring diagram operad W. Composition of wiring diagrams is given by substitution.</p>
<p>__________________</p>
<p><a href="chapter007.html#endnote_ref_1"><sup>1</sup></a>Throughout this definition, notice that <em>B</em>’s come before <em>A</em>’s, especially in (<a href="chapter007.html#eq_7-1">7.1</a>), which might be confusing. It was a stylistic choice to match with the <strong>B</strong>abies and <strong>A</strong>dults discussion.</p>
<p><a href="chapter007.html#endnote_ref_2"><sup>2</sup></a>The natural isomorphism <em>α</em> (see Proposition <a href="chapter005.html#Pro_5-3-2-12">5.3.2.12</a>) is between two functors Bop×A→Set, namely, the functor (B,A)↦HomA(L(B),A) and the functor (B,A)↦HomB(B,R(A)).</p>
<p><a href="chapter007.html#endnote_ref_3"><sup>3</sup></a>Conversely, for any <em>g</em> : <em>B</em> → <em>R</em>(<em>A</em>) in B, we refer to αB,A−1(g):L(B)→A as <em>the adjunct</em> of <em>g</em>.</p>
<p><a href="chapter007.html#endnote_ref_4"><sup>4</sup></a>The left adjoint does not have to be called <em>L</em>, nor does the right adjoint have to be called <em>R</em>, of course.</p>
<p><a href="chapter007.html#endnote_ref_5"><sup>5</sup></a>FQL is available on the Internet. See http://categoricaldata.net/fql.html.</p>
<p><a href="chapter007.html#endnote_ref_6"><sup>6</sup></a>This example was taken from Spivak [38].</p>
<p><a href="chapter007.html#endnote_ref_7"><sup>7</sup></a>Repeated for convenience,</p>
<p><img src="images/Art_P361.jpg" alt="art" /></p>
<p>I:C→Set is</p>
<p><img src="images/Art_P362.jpg" alt="art" /></p>
<p><a href="chapter007.html#endnote_ref_8"><sup>8</sup></a>Technically C has to be small but, as mentioned in Remark <a href="chapter005.html#Rem_5-1-1-2">5.1.1.2</a>), we do not worry about that distinction in this book.</p>
<p><a href="chapter007.html#endnote_ref_9"><sup>9</sup></a>There is a lot of clutter here. Note that “firstChild(mother(☺))” is a row in the Child table of <em>Y</em><sub>Child</sub>. Assuming that the math follows the meaning, if ☺ points to Amy, where should firstChild(mother(☺)) point?</p>
<p><a href="chapter007.html#endnote_ref_10"><sup>10</sup></a>Parentheses are used to denote open intervals of real numbers. For example, (6, 9) denotes the set {<em>x</em> ∈ ℝ | 6 &lt; <em>x</em> &lt; 9}.</p>
<p><a href="chapter007.html#endnote_ref_11"><sup>11</sup></a>This requirement is somewhat stringent, but it can be mitigated in a variety of ways. One such way would be to model the ability to hand off the experimental results to another person, who would then carry them forward. This could be done by defining a preorder structure on <em>A</em> to model who can hand off to whom (see Example <a href="chapter007.html#Exa_7-3-3-8">7.3.3.8</a>).</p>
<p><a href="chapter007.html#endnote_ref_12"><sup>12</sup></a>Actually, Definition <a href="chapter003.html#Def_3-2-2-3">3.2.2.3</a> is about composing spans, but a relation <em>R</em> ⊆ <em>A</em> × <em>B</em> is a kind of span, <em>R</em> → <em>A</em> × <em>B</em>.</p>
<p><a href="chapter007.html#endnote_ref_13"><sup>13</sup></a>There are three abuses of notation when writing O(x1,…,xn;y). First, it confuses the set <em>n</em> ∈ Ob(<strong>Fin</strong>) with its cardinality |<em>n</em>| ∈ ℕ. But rather than writing O(x1,…,x|n|;y), it would be more consistent to write O(x(1),…,x(|n|);y) because we have assigned subscripts another meaning in part D. But even this notation unfoundedly suggests that the set <em>n</em> has been endowed with a linear ordering, which it has not. This may be seen as a more serious abuse, but see Remark <a href="chapter007.html#Rem_7-4-1-2">7.4.1.2</a>.</p>
<p><a href="chapter007.html#endnote_ref_14"><sup>14</sup></a>Thanks to Professor Sandra Shefelbine for explaining the hierarchical nature of collagen to me. Any errors are my own.</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter006.html">previous</a>, <a href="reference.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter007.html">previous</a>, <a href="bookindex.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<h1 class="back-title"><a href="toc.html#bib-1"><strong>References</strong></a></h1>
<p>[1]  Abramsky, S. (2012) Relational databases and Bell’s Theorem. Available at <a href="http://arxiv.org/abs/1208.6416">http://arxiv.org/abs/1208.6416</a></p>
<p>[2]  Atiyah, M. (1989) Topological quantum field theories. <em>Publications Mathématiques de l’IHÉS</em> 68(1), 175–186.</p>
<p>[3]  Axler, S. (1997) <em>Linear Algebra Done Right</em>. 2d ed. New York: Springer.</p>
<p>[4]  Awodey, S. (2010) <em>Category Theory</em>. 2d ed. Oxford: Oxford University Press.</p>
<p>[5]  Bralow, H. (1961) Possible principles underlying the transformation of sensory messages. In <em>Sensory Communication</em>, ed. W. Rosenblaith, 217–234. Cambridge, MA: MIT Press.</p>
<p>[6]  Baez, J.C.; Dolan, J. (1995) Higher-dimensional algebra and topological quantum field theory. <em>Journal of Mathematical Physics</em> 36: 6073–6105.</p>
<p>[7]  Baez, J.C.; Fritz, T.; Leinster, T. (2011) A characterization of entropy in terms of information loss. <em>Entropy</em> 13(11): 1945–1957.</p>
<p>[8]  Baez, J.C.; Stay, M. (2011) Physics, topology, logic and computation: a Rosetta Stone. In <em>New Structures for Physics</em>, ed. B. Coecke, 95Ð172. Lecture Notes in Physics 813. Heidelberg: Springer.</p>
<p>[9]  Brown, R.; Porter, T. (2006) Category Theory: An abstract setting for analogy and comparison. In: <em>What Is Category Theory?</em> ed. G. Sica, 257–274. Advanced Studies in Mathematics and Logic. Monza Italy: Polimetrica.</p>
<p>[10]  Brown, R.; Porter, T. (2003) Category theory and higher dimensional algebra: potential descriptive tools in neuroscience. In <em>Proceedings of the International Conference on Theoretical Neurobiology</em>, vol. 1, 80–92.</p>
<p>[11]  Barr, M.; Wells, C. (1990) <em>Category Theory for Computing Science</em>. New York: Prentice Hall.</p>
<p>[12]  Biggs, N.M. (2004) <em>Discrete Mathematics</em>. New York: Oxford University Press.</p>
<p>[13]  Diaconescu, R. (2008) <em>Institution-Independent Model Theory</em> Boston: Birkhäuser.</p>
<p>[14]  Döring, A.; Isham, C. J. (2008) A topos foundation for theories of physics. I. Formal languages for physics. <em>Journal of Mathematical Physics</em> 49(5): 053515.</p>
<p>[15]  Ehresmann, A.C.; Vanbremeersch, J-P. (2007) <em>Memory Evolutive Systems: Hierarchy, Emergence, Cognition</em>. Amsterdam: Elsevier.</p>
<p>[16]  Everett III, H. (1973). The theory of the universal wave function. In <em>The Many-Worlds Interpretation of Quantum Mechanics</em>, ed. B.S. DeWitt and N. Graham, 3–140. Princeton, NJ: Princeton University Press.</p>
<p>[17]  Goguen, J. (1992) Sheaf semantics for concurrent interacting objects <em>Mathematical Structures in Computer Science</em> 2(2): 159–191.</p>
<p>[18]  Grothendieck, A.; Raynaud, M. (1971) <em>Revêtements étales et groupe fondamental</em> Séminaire de Géométrie Algébrique du Bois Marie, 1960/61 (SGA 1) Lecture Notes in Mathematics 224. In French. New York: Springer.</p>
<p>[19]  Krömer, R. (2007) <em>Tool and Object: A History and Philosophy of Category Theory</em>. Boston: Birkhäuser.</p>
<p>[20]  Lambek, J. (1980) From <em>λ</em>-calculus to Cartesian closed categories. In <em>To H. B. Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism</em>, ed. J.P. Seldin and J. Hindley, 376–402. London: Academic Press.</p>
<p>[21]  Khovanov, M. (2000) A categorificiation of the Jones polynomial. <em>Duke Mathematical Journal</em> 101(3):359–426.</p>
<p>[22]  Landry, E.; Marquis, J.-P. (2005) Categories in contexts: Historical, foundational, and philosophical. <em>Philosophia Mathematica</em> 13(1): 1–43.</p>
<p>[23]  Lawvere, F.W. (2005) An elementary theory of the category of sets (long version) with commentary. <em>Reprints in Theory and Applications of Categories</em>. no. 11, 1–35. Expanded from <em>Procedings of the National Academy of Sciences</em> 1964; 52(6):1506–1511.</p>
<p>[24]  Lawvere, F.W.; Schanuel, S.H. (2009) <em>Conceptual Mathematics. A First Introduction to Categories</em>. 2d ed. Cambridge: Cambridge University Press.</p>
<p>[25]  Leinster, T. (2004) <em>Higher Operads, Higher Categories</em>. London Mathematical Society Lecture Note Series 298. New York: Cambridge University Press.</p>
<p>[26]  Leinster, T. (2012) Rethinking set theory. Available at <a href="http://arxiv.org/abs/1212.6543">http://arxiv.org/abs/1212.6543</a>.</p>
<p>[27]  Linsker, R. (1988) Self-organization in a perceptual network. <em>Computer</em> 21(3): 105–117.</p>
<p>[28]  MacKay, D.J. (2003) <em>Information Theory, Inference and Learning Algorithms</em>. Cambridge: Cambridge University Press.</p>
<p>[29]  Mac Lane, S. (1998) <em>Categories for the Working Mathematician</em>. 2d ed. New York: Springer.</p>
<p>[30]  Marquis, J.-P. (2009) <em>From a Geometrical Point of View: A Study in the History and Philosophy of Category Theory</em>. New York: Springer.</p>
<p>[31]  Marquis, J.-P. (2013) Category theory. In <em>Stanford Encyclopedia of Philosophy</em> (summer ed.), ed. E.N. Zalta, Available at <a href="http://plato.stanford.edu/archives/spr2011/entries/category-theory">http://plato.stanford.edu/archives/spr2011/entries/category-theory</a>.</p>
<p>[32]  Minsky, M. (1985) <em>The Society of Mind</em>. New York: Simon and Schuster.</p>
<p>[33]  Moggi, E. (1991) Notions of computation and monads. <em>Information and Computation</em> 93(1): 52–92.</p>
<p>[34]  nLab. <a href="http://ncatlab.org/nlab/show/HomePage">http://ncatlab.org/nlab/show/HomePage</a>.</p>
<p>[35]  Penrose, R. (2005) <em>The Road to Reality</em>. New York: Knopf.</p>
<p>[36]  Radul, A.; Sussman, G.J. (2009). The Art of the Propagator. MIT Computer Science and Artificial Intelligence Laboratory Technical Report.</p>
<p>[37]  Simmons, H. (2011) <em>An Introduction to Category Theory</em>. New York: Cambridge University Press.</p>
<p>[38]  Spivak, D.I. (2012) Functorial data migration. <em>Information and Computation</em> 217 (August): 31–51.</p>
<p>[39]  Spivak, D.I. (2013) Database queries and constraints via lifting problems. <em>Mathematical structures in computer science</em> 1–55. Available at <a href="http://arxiv.org/abs/1202.2591">http://arxiv.org/abs/1202.2591</a>.</p>
<p>[40]  Spivak, D.I. (2012) Kleisli database instances. Available at <a href="http://arxiv.org/abs/1209.1011">http://arxiv.org/abs/1209.1011</a>.</p>
<p>[41]  Spivak, D.I. (2013) The operad of wiring diagrams: Formalizing a graphical language for databases, recursion, and plug-and-play circuits. Available at: <a href="http://arxiv.org/abs/1305.0297">http://arxiv.org/abs/1305.0297</a>.</p>
<p>[42]  Spivak, D.I.; Giesa, T.; Wood, E.; Buehler, M.J. (2011) Category-theoretic analysis of hierarchical protein materials and social networks. <em>PLoS ONE</em> 6(9): e23911.</p>
<p>[43]  Spivak, D.I.; Kent, R.E. (2012) Ologs: A categorical framework for knowledge representation. <em>PLoS ONE</em> 7(1): e24274.</p>
<p>[44]  Weinberger, S. (2011) What is … persistent homology? <em>Notices of the AMS</em> 58(1): 36–39.</p>
<p>[45]  Weinstein, A. (1996) Groupoids: Unifying internal and external symmetry. <em>Notices of the AMS</em> 43(7): 744–752.</p>
<p>[46]  Wikipedia. Accessed between December 6, 2012 and December 31, 2013.</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="chapter007.html">previous</a>, <a href="bookindex.html">next</a> page;   <a href="toc.html">contents</a>;   <a href="bookindex.html">index</a>]</p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="reference.html">previous</a>, next page;   <a href="toc.html">contents</a>;   index]</p>
<p></p>
<h1 class="back-title"><strong>Index</strong></h1>
<p>a category</p>
<p><strong>Cat</strong>, <a href="chapter005.html#p186">186</a></p>
<p><strong>FLin</strong>, <a href="chapter005.html#p167">167</a></p>
<p><strong>Fin</strong>, <a href="chapter005.html#p163">163</a>, <a href="chapter005.html#p239">239</a></p>
<p>Fun(C,D), <a href="chapter005.html#p223">223</a></p>
<p><strong>Grp</strong>, <a href="chapter005.html#p164">164</a></p>
<p><strong>Grpd</strong>, <a href="chapter005.html#p205">205</a></p>
<p><strong>Grph</strong>, <a href="chapter005.html#p168">168</a></p>
<p>Kls(T), <a href="chapter007.html#p351">351</a></p>
<p><strong>Mon</strong>, <a href="chapter005.html#p163">163</a></p>
<p><strong>Oprd</strong>, <a href="chapter007.html#p367">367</a></p>
<p><strong>PrO</strong>, <a href="chapter005.html#p164">164</a></p>
<p><strong>Prop</strong>, <a href="chapter005.html#p208">208</a></p>
<p><strong>Sch</strong>, <a href="chapter005.html#p243">243</a></p>
<p><strong>Set</strong>, <a href="chapter005.html#p163">163</a></p>
<p><strong>Star</strong><em><sub>n</sub></em>, <a href="chapter006.html#p265">265</a></p>
<p><strong>Top</strong>, <a href="chapter005.html#p203">203</a></p>
<p><strong>Vect</strong>, <a href="chapter005.html#p204">204</a>, <a href="chapter007.html#p335">335</a></p>
<p><strong>Δ</strong>, <a href="chapter005.html#p238">238</a>, <a href="chapter006.html#p286">286</a></p>
<p>C−Set, <a href="chapter005.html#p230">230</a></p>
<p><strong>GrIn</strong>, <a href="chapter005.html#p197">197</a></p>
<p>free arrow, <a href="chapter005.html#p187">187</a></p>
<p>terminal, <a href="chapter005.html#p189">189</a></p>
<p>a functor</p>
<p>Cat→CoreGrpd, <a href="chapter005.html#p205">205</a></p>
<p>Cat→HomSet, <a href="chapter005.html#p190">190</a></p>
<p>Cat→ObSet, <a href="chapter005.html#p189">189</a>, <a href="chapter005.html#p224">224</a>, <a href="chapter007.html#p301">301</a></p>
<p><strong>Cat</strong> → <strong>Grph</strong>, <a href="chapter005.html#p188">188</a>, <a href="chapter007.html#p301">301</a></p>
<p><strong>Cat</strong> → <strong>Oprd</strong>, <a href="chapter007.html#p368">368</a></p>
<p><strong>Cat</strong> → <strong>Sch</strong>, <a href="chapter005.html#p246">246</a></p>
<p><strong>FLin</strong> → <strong>PrO</strong>, <a href="chapter005.html#p176">176</a></p>
<p><strong>Grp</strong> → <strong>Cat</strong>, <a href="chapter005.html#p192">192</a></p>
<p><strong>Grp</strong> → <strong>Grpd</strong>, <a href="chapter005.html#p205">205</a></p>
<p><strong>Grp</strong> → <strong>Mon</strong>, <a href="chapter005.html#p175">175</a>, <a href="chapter007.html#p301">301</a></p>
<p><strong>Grpd</strong> → <strong>Cat</strong>, <a href="chapter005.html#p205">205</a></p>
<p>Grph→PathsGrph, <a href="chapter005.html#p183">183</a>, <a href="chapter005.html#p187">187</a>, <a href="chapter005.html#p221">221</a>, <a href="chapter005.html#p242">242</a></p>
<p><strong>Grph</strong> → <strong>Cat</strong>, <a href="chapter005.html#p187">187</a>, <a href="chapter007.html#p301">301</a></p>
<p><strong>Grph</strong> → <strong>PrO</strong>, <a href="chapter005.html#p178">178</a>, <a href="chapter005.html#p196">196</a></p>
<p><strong>Grph</strong> → <strong>Set</strong>, <a href="chapter005.html#p178">178</a>, <a href="chapter005.html#p222">222</a>, <a href="chapter007.html#p301">301</a></p>
<p>Kls(T)→Set, <a href="chapter007.html#p352">352</a></p>
<p>Mon→CoreGrp, <a href="chapter007.html#p301">301</a></p>
<p><strong>Mon</strong> → <strong>Cat</strong>, <a href="chapter005.html#p191">191</a></p>
<p><strong>Mon</strong> → <strong>Set</strong>, <a href="chapter005.html#p174">174</a>, <a href="chapter007.html#p297">297</a></p>
<p><strong>PrO</strong> → <strong>Cat</strong>, <a href="chapter005.html#p195">195</a>, <a href="chapter005.html#p196">196</a>, <a href="chapter005.html#p237">237</a>, <a href="chapter006.html#p255">255</a>, <a href="chapter006.html#p261">261</a></p>
<p><strong>PrO</strong> → <strong>Grph</strong>, <a href="chapter005.html#p176">176</a>, <a href="chapter005.html#p196">196</a>, <a href="chapter007.html#p302">302</a></p>
<p><strong>PrO</strong> → <strong>Set</strong>, <a href="chapter005.html#p178">178</a>, <a href="chapter007.html#p301">301</a></p>
<p><strong>PrO</strong> → <strong>Top</strong>, <a href="chapter007.html#p342">342</a></p>
<p><strong>Sch</strong> → <strong>Cat</strong>, <a href="chapter005.html#p245">245</a></p>
<p>Set→DiscCat, <a href="chapter005.html#p189">189</a>, <a href="chapter005.html#p224">224</a>, <a href="chapter007.html#p301">301</a></p>
<p>Set→DiscGrph, <a href="chapter005.html#p188">188</a></p>
<p>Set→IndCat, <a href="chapter006.html#p292">292</a>, <a href="chapter007.html#p301">301</a></p>
<p>Set→ListSet, <a href="chapter005.html#p212">212</a></p>
<p><strong>Set</strong> → <strong>Mon</strong>, <a href="chapter005.html#p181">181</a>, <a href="chapter007.html#p297">297</a></p>
<p><strong>Set</strong> → <strong>PrO</strong>, <a href="chapter007.html#p301">301</a></p>
<p>Top→Π1Grpd, <a href="chapter005.html#p206">206</a></p>
<p><strong>Top</strong> → <strong>PrO</strong><sup>op</sup>, <a href="chapter005.html#p203">203</a></p>
<p><strong>Top</strong> → <strong>Set</strong>, <a href="chapter005.html#p203">203</a></p>
<p><strong>Vect</strong><sub>ℝ</sub> → <strong>Grp</strong>, <a href="chapter005.html#p204">204</a></p>
<p><strong>Vect</strong><sub>ℝ</sub> → <strong>PrO</strong>, <a href="chapter005.html#p204">204</a></p>
<p><strong>Vect</strong><sub>ℝ</sub> → <strong>Set</strong>, <a href="chapter005.html#p205">205</a></p>
<p><strong>Vect</strong><sub>ℝ</sub> → <strong>Top</strong>, <a href="chapter005.html#p204">204</a></p>
<p><strong>Δ</strong> → <strong>FLin</strong>, <a href="chapter005.html#p238">238</a></p>
<p>Set→DiscCat, <a href="chapter005.html#p224">224</a></p>
<p>a group</p>
<p><em>E</em><sub>3</sub>, <a href="chapter004.html#p115">115</a></p>
<p><em>GL</em><sub>3</sub>, <a href="chapter004.html#p115">115</a></p>
<p><em>U</em>(1), <a href="chapter004.html#p117">117</a></p>
<p>dihedral, <a href="chapter004.html#p115">115</a>, <a href="chapter005.html#p194">194</a></p>
<p>a monad</p>
<p>Paths, <a href="chapter007.html#p351">351</a></p>
<p>exceptions, <a href="chapter007.html#p350">350</a></p>
<p>List, <a href="chapter007.html#p348">348</a></p>
<p>maybe, <a href="chapter007.html#p345">345</a></p>
<p>partial functions, <a href="chapter007.html#p345">345</a></p>
<p>a schema</p>
<p>Loop, <a href="chapter006.html#p253">253</a>, <a href="chapter007.html#p359">359</a></p>
<p>department store, <a href="chapter004.html#p149">149</a></p>
<p>indexing graphs, <a href="chapter005.html#p233">233</a></p>
<p>a set</p>
<p>ℝ, <a href="chapter002.html#p11">11</a></p>
<p>ℝ<sub>⩾0</sub>, <a href="chapter002.html#p11">11</a></p>
<p>{☺}, <a href="chapter002.html#p11">11</a></p>
<p><em>n</em>, <a href="chapter002.html#p20">20</a></p>
<p>ℕ, <a href="chapter002.html#p10">10</a></p>
<p>ℤ, <a href="chapter002.html#p10">10</a></p>
<p>a symbol</p>
<p>(<em>F</em> ↓ <em>G</em>), <a href="chapter006.html#p293">293</a></p>
<p>&lt;<em>f</em>, <em>g</em>&gt;, <a href="chapter003.html#p40">40</a></p>
<p><em>X</em>/∼, <a href="chapter003.html#p64">64</a></p>
<p>[<em>n</em>], <a href="chapter004.html#p134">134</a></p>
<p>{fg, <a href="chapter003.html#p46">46</a></p>
<p>Fun, <a href="chapter005.html#p223">223</a></p>
<p>Hom<strong><sub>Set</sub></strong>, <a href="chapter002.html#p15">15</a></p>
<p>HomC, <a href="chapter005.html#p162">162</a></p>
<p>ℕ, <a href="chapter002.html#p10">10</a></p>
<p>Ob, <a href="chapter005.html#p162">162</a></p>
<p>Ω, <a href="chapter003.html#p82">82</a></p>
<p>ℙ, <a href="chapter003.html#p78">78</a></p>
<p>Path, <a href="chapter004.html#p125">125</a></p>
<p>ℝ, <a href="chapter003.html#p39">39</a></p>
<p>ℤ, <a href="chapter002.html#p10">10</a></p>
<p><img src="images/rotate.jpg" alt="art" />, <a href="chapter004.html#p101">101</a></p>
<p>○, <a href="chapter002.html#p13">13</a>, <a href="chapter005.html#p162">162</a></p>
<p>colim, <a href="chapter006.html#p278">278</a></p>
<p>◊, <a href="chapter005.html#p228">228</a></p>
<p>∅, <a href="chapter002.html#p10">10</a></p>
<p>∃, <a href="chapter002.html#p10">10</a>, <a href="chapter007.html#p303">303</a></p>
<p>∃!, <a href="chapter002.html#p10">10</a></p>
<p>∀, <a href="chapter002.html#p11">11</a>, <a href="chapter007.html#p303">303</a></p>
<p>id<em><sub>X</sub></em>, <a href="chapter002.html#p16">16</a></p>
<p>∫, <a href="chapter006.html#p287">287</a></p>
<p>≌, <a href="chapter002.html#p17">17</a></p>
<p>⊲, <a href="chapter006.html#p265">265</a></p>
<p>lim, <a href="chapter006.html#p273">273</a></p>
<p>⌟, <a href="chapter003.html#p49">49</a></p>
<p>↦, <a href="chapter002.html#p12">12</a></p>
<p>Cop, <a href="chapter006.html#p285">285</a></p>
<p>C/X, <a href="chapter006.html#p273">273</a></p>
<p>CX/, <a href="chapter006.html#p278">278</a></p>
<p>++, <a href="chapter004.html#p97">97</a></p>
<p>《<em>ℓ</em>》, <a href="chapter002.html#p33">33</a></p>
<p>⊳, <a href="chapter006.html#p266">266</a></p>
<p>∼, <a href="chapter003.html#p63">63</a></p>
<p>≃, <a href="chapter002.html#p31">31</a>, <a href="chapter005.html#p236">236</a></p>
<p>⊔, <a href="chapter003.html#p43">43</a></p>
<p>×, <a href="chapter003.html#p37">37</a></p>
<p>⌜, <a href="chapter003.html#p68">68</a></p>
<p><em>f</em><sup>−1</sup>, <a href="chapter003.html#p54">54</a></p>
<p>≔, <a href="chapter002.html#p11">11</a></p>
<p>a warning</p>
<p>“set” of objects in a category, <a href="chapter005.html#p163">163</a></p>
<p>different worldviews, <a href="chapter002.html#p26">26</a></p>
<p>misuse of <em>the</em>, <a href="chapter006.html#p270">270</a></p>
<p>notation for composition, <a href="chapter002.html#p31">31</a></p>
<p>operad functors, <a href="chapter007.html#p367">367</a></p>
<p>operads vs. multicategories, <a href="chapter007.html#p362">362</a></p>
<p>oversimplified science, <a href="chapter001.html#p6">6</a></p>
<p>action</p>
<p>left, <a href="chapter004.html#p101">101</a></p>
<p>of a group, <a href="chapter004.html#p117">117</a></p>
<p>of a monoid, <a href="chapter004.html#p101">101</a></p>
<p>orbit of, <a href="chapter004.html#p118">118</a></p>
<p>right, <a href="chapter004.html#p101">101</a></p>
<p>action table, <a href="chapter004.html#p108">108</a></p>
<p>adjoint functors, <a href="chapter007.html#p297">297</a></p>
<p>adjunct, <a href="chapter007.html#p299">299</a></p>
<p>adjunction, <a href="chapter007.html#p298">298</a></p>
<p>adjunction isomorphism, <a href="chapter007.html#p299">299</a></p>
<p>analogy: babies and adults, <a href="chapter007.html#p298">298</a></p>
<p>counit, <a href="chapter007.html#p360">360</a></p>
<p>unit, <a href="chapter007.html#p360">360</a></p>
<p>algebra</p>
<p>operad, <a href="chapter007.html#p368">368</a></p>
<p>an operad</p>
<p><strong>Sets</strong>, <a href="chapter007.html#p366">366</a></p>
<p>little <em>n</em>-cubes, <a href="chapter007.html#p365">365</a></p>
<p>little squares, <a href="chapter007.html#p365">365</a></p>
<p>relations, <a href="chapter007.html#p370">370</a></p>
<p>wiring diagrams, <a href="chapter007.html#p372">372</a></p>
<p>appropriate comparison, <a href="chapter004.html#p110">110</a>, <a href="chapter004.html#p126">126</a>, <a href="chapter004.html#p142">142</a>, <a href="chapter005.html#p162">162</a>, <a href="chapter005.html#p174">174</a></p>
<p>arrow, <a href="chapter004.html#p119">119</a></p>
<p>Baez, John, <a href="chapter001.html#p5">5</a></p>
<p>biological classification, <a href="chapter004.html#p143">143</a></p>
<p>canonical, <a href="chapter002.html#p19">19</a></p>
<p>cardinality, <a href="chapter002.html#p20">20</a></p>
<p>category, <a href="chapter005.html#p162">162</a></p>
<p>arithmetic of, <a href="chapter006.html#p295">295</a></p>
<p>as equivalent to schema, <a href="chapter005.html#p241">241</a></p>
<p>cartesian closed, <a href="chapter005.html#p210">210</a></p>
<p>cocomplete, <a href="chapter006.html#p281">281</a></p>
<p>comma, <a href="chapter006.html#p292">292</a></p>
<p>complete, <a href="chapter006.html#p281">281</a></p>
<p>coslice, <a href="chapter006.html#p278">278</a></p>
<p>discrete, <a href="chapter005.html#p188">188</a>, <a href="chapter007.html#p301">301</a></p>
<p>equivalence of, <a href="chapter005.html#p236">236</a></p>
<p>free category, <a href="chapter005.html#p187">187</a>, <a href="chapter007.html#p336">336</a></p>
<p>indiscrete, <a href="chapter007.html#p301">301</a></p>
<p>Kleisli, <a href="chapter007.html#p351">351</a></p>
<p>non-example, <a href="chapter005.html#p165">165</a>, <a href="chapter005.html#p166">166</a></p>
<p>of elements, <a href="chapter006.html#p287">287</a></p>
<p>of functors, <a href="chapter005.html#p223">223</a></p>
<p>opposite, <a href="chapter006.html#p285">285</a></p>
<p>presentation, <a href="chapter005.html#p200">200</a></p>
<p>questionable, <a href="chapter005.html#p164">164</a></p>
<p>slice, <a href="chapter006.html#p273">273</a></p>
<p>small, <a href="chapter005.html#p163">163</a></p>
<p>underlying graph of, <a href="chapter005.html#p187">187</a></p>
<p>CCCs, <a href="chapter005.html#p210">210</a></p>
<p>characteristic function, <a href="chapter003.html#p82">82</a></p>
<p>clunky, <a href="chapter003.html#p42">42</a></p>
<p>coequalizer, <a href="chapter003.html#p72">72</a></p>
<p>colimit, <a href="chapter006.html#p278">278</a></p>
<p>closed under, <a href="chapter007.html#p319">319</a></p>
<p>common ground, <a href="chapter007.html#p342">342</a></p>
<p>commuting diagram, <a href="chapter002.html#p21">21</a></p>
<p>component, <a href="chapter005.html#p213">213</a></p>
<p>composition</p>
<p>classical order, <a href="chapter002.html#p15">15</a>, <a href="chapter002.html#p31">31</a></p>
<p>diagrammatic order, <a href="chapter002.html#p15">15</a>, <a href="chapter002.html#p31">31</a></p>
<p>of functions, <a href="chapter002.html#p13">13</a></p>
<p>of morphisms, <a href="chapter005.html#p162">162</a></p>
<p>concatenation</p>
<p>of lists, <a href="chapter004.html#p97">97</a></p>
<p>of paths, <a href="chapter004.html#p126">126</a></p>
<p>cone</p>
<p>left, <a href="chapter006.html#p265">265</a></p>
<p>right, <a href="chapter006.html#p266">266</a></p>
<p>congruence, <a href="chapter004.html#p151">151</a></p>
<p>on a monoid, <a href="chapter004.html#p97">97</a></p>
<p>connected component, <a href="chapter003.html#p67">67</a>, <a href="chapter005.html#p186">186</a></p>
<p>context, <a href="chapter007.html#p344">344</a></p>
<p>coproduct</p>
<p>inclusion functions, <a href="chapter003.html#p43">43</a></p>
<p>coproducts, <a href="chapter006.html#p257">257</a></p>
<p>of sets, <a href="chapter003.html#p43">43</a></p>
<p>universal property for, <a href="chapter003.html#p45">45</a></p>
<p>core, <a href="chapter005.html#p205">205</a>, <a href="chapter005.html#p206">206</a></p>
<p>correspondence</p>
<p>one-to-one, <a href="chapter002.html#p17">17</a></p>
<p>coslice, <a href="chapter006.html#p278">278</a></p>
<p>cospan, <a href="chapter006.html#p260">260</a>, <a href="chapter006.html#p261">261</a>, <a href="chapter006.html#p274">274</a>, <a href="chapter006.html#p293">293</a></p>
<p>currying, <a href="chapter003.html#p74">74</a></p>
<p>as adjunction, <a href="chapter007.html#p301">301</a></p>
<p>via data migration functors, <a href="chapter007.html#p318">318</a></p>
<p>data, <a href="chapter001.html#p6">6</a></p>
<p>valid time, <a href="chapter007.html#p343">343</a></p>
<p>data migration, <a href="chapter007.html#p308">308</a></p>
<p>left pushforward Σ, <a href="chapter007.html#p312">312</a></p>
<p>pullback Δ, <a href="chapter007.html#p309">309</a></p>
<p>right pushforward Π, <a href="chapter007.html#p315">315</a></p>
<p>database</p>
<p>business rules, <a href="chapter004.html#p149">149</a></p>
<p>category of instances on, <a href="chapter005.html#p230">230</a></p>
<p>foreign key, <a href="chapter004.html#p148">148</a></p>
<p>homomorphism, <a href="chapter005.html#p235">235</a></p>
<p>instance, <a href="chapter004.html#p157">157</a>, <a href="chapter005.html#p201">201</a></p>
<p>Kleisli, <a href="chapter007.html#p357">357</a></p>
<p>primary key, <a href="chapter004.html#p148">148</a></p>
<p>schema, <a href="chapter004.html#p149">149</a>, <a href="chapter004.html#p153">153</a></p>
<p>tables, <a href="chapter004.html#p147">147</a></p>
<p>descent data, <a href="chapter007.html#p340">340</a></p>
<p>diagam</p>
<p>commutes, <a href="chapter002.html#p21">21</a></p>
<p>diagram, <a href="chapter006.html#p262">262</a></p>
<p>in <strong>Set</strong>, <a href="chapter002.html#p21">21</a></p>
<p>Dolan, James, <a href="chapter001.html#p5">5</a></p>
<p>dynamical system</p>
<p>continuous, <a href="chapter005.html#p204">204</a></p>
<p>discrete, <a href="chapter004.html#p153">153</a></p>
<p>Eilenberg, Samuel, <a href="chapter001.html#p4">4</a></p>
<p>element, <a href="chapter002.html#p9">9</a></p>
<p>represented by a function, <a href="chapter002.html#p14">14</a></p>
<p>Englishification, <a href="chapter002.html#p33">33</a>, <a href="chapter004.html#p158">158</a>, <a href="chapter006.html#p290">290</a></p>
<p>entry</p>
<p>in list, <a href="chapter004.html#p97">97</a></p>
<p>epimorphism, <a href="chapter007.html#p321">321</a></p>
<p>in <strong>Set</strong>, <a href="chapter003.html#p85">85</a></p>
<p>equalizer, <a href="chapter003.html#p62">62</a>, <a href="chapter006.html#p275">275</a></p>
<p>equivalence relation, <a href="chapter003.html#p63">63</a></p>
<p>as partition, <a href="chapter003.html#p64">64</a></p>
<p>equivalence classes, <a href="chapter003.html#p63">63</a></p>
<p>generated, <a href="chapter003.html#p65">65</a></p>
<p>quotient by, <a href="chapter003.html#p64">64</a></p>
<p>trivial, <a href="chapter003.html#p66">66</a></p>
<p>exceptions, <a href="chapter007.html#p350">350</a></p>
<p>exponentials</p>
<p>evaluation of, <a href="chapter003.html#p75">75</a></p>
<p>exponentials</p>
<p>in <strong>Set</strong>, <a href="chapter003.html#p74">74</a></p>
<p>fiber product, <a href="chapter003.html#p49">49</a></p>
<p>fiber sum, <a href="chapter003.html#p68">68</a></p>
<p>finite state machine, <a href="chapter004.html#p106">106</a>, <a href="chapter006.html#p291">291</a></p>
<p>FQL, <a href="chapter007.html#p309">309</a></p>
<p>function, <a href="chapter002.html#p11">11</a></p>
<p>bijection, <a href="chapter003.html#p83">83</a></p>
<p>codomain, <a href="chapter002.html#p11">11</a></p>
<p>composition, <a href="chapter002.html#p13">13</a></p>
<p>domain, <a href="chapter002.html#p11">11</a></p>
<p>equality of, <a href="chapter002.html#p15">15</a></p>
<p>identity, <a href="chapter002.html#p16">16</a></p>
<p>induced, <a href="chapter003.html#p40">40</a></p>
<p>injection, <a href="chapter003.html#p83">83</a></p>
<p>inverse, <a href="chapter002.html#p17">17</a></p>
<p>isomorphism, <a href="chapter002.html#p16">16</a></p>
<p>representing an element, <a href="chapter002.html#p14">14</a></p>
<p>surjection, <a href="chapter003.html#p83">83</a></p>
<p>functor, <a href="chapter005.html#p174">174</a></p>
<p>adjoint, <a href="chapter007.html#p298">298</a></p>
<p>constant, <a href="chapter005.html#p221">221</a>, <a href="chapter007.html#p306">306</a></p>
<p>contravariant, <a href="chapter006.html#p284">284</a></p>
<p>covariant, <a href="chapter006.html#p284">284</a></p>
<p>faithful, <a href="chapter005.html#p240">240</a></p>
<p>forgetful, <a href="chapter005.html#p176">176</a></p>
<p>full, <a href="chapter005.html#p240">240</a></p>
<p>representable, <a href="chapter007.html#p322">322</a></p>
<p>representing an object, <a href="chapter005.html#p224">224</a></p>
<p>functorial query language, <a href="chapter007.html#p309">309</a></p>
<p>gateway, <a href="chapter006.html#p254">254</a></p>
<p>generators, <a href="chapter004.html#p97">97</a></p>
<p>geography, <a href="chapter004.html#p145">145</a>, <a href="chapter007.html#p336">336</a></p>
<p>graph, <a href="chapter004.html#p119">119</a></p>
<p>as functor, <a href="chapter005.html#p197">197</a></p>
<p>bipartite, <a href="chapter003.html#p61">61</a></p>
<p>chain, <a href="chapter004.html#p122">122</a></p>
<p>converting to a preorder, <a href="chapter004.html#p135">135</a></p>
<p>discrete, <a href="chapter004.html#p122">122</a></p>
<p>free category on, <a href="chapter005.html#p187">187</a>, <a href="chapter007.html#p336">336</a></p>
<p>homomorphism, <a href="chapter004.html#p126">126</a></p>
<p>indiscrete, <a href="chapter004.html#p122">122</a></p>
<p>paths, <a href="chapter004.html#p125">125</a></p>
<p>paths-graph, <a href="chapter005.html#p183">183</a>, <a href="chapter007.html#p351">351</a></p>
<p>symmetric, <a href="chapter005.html#p198">198</a></p>
<p>graph homomorphism</p>
<p>as functor, <a href="chapter005.html#p232">232</a></p>
<p>Grothendieck</p>
<p>construction, <a href="chapter006.html#p286">286</a></p>
<p>expanding universes, <a href="chapter005.html#p163">163</a></p>
<p>in history, <a href="chapter001.html#p4">4</a></p>
<p>group, <a href="chapter004.html#p114">114</a></p>
<p>action, <a href="chapter004.html#p117">117</a></p>
<p>as category, <a href="chapter005.html#p192">192</a></p>
<p>homomorphism, <a href="chapter004.html#p119">119</a></p>
<p>of automorphisms, <a href="chapter005.html#p193">193</a></p>
<p>groupoid, <a href="chapter005.html#p205">205</a></p>
<p>fundamental, <a href="chapter005.html#p206">206</a></p>
<p>of material states, <a href="chapter005.html#p205">205</a></p>
<p>hierarchy, <a href="chapter004.html#p154">154</a></p>
<p>hom-set, <a href="chapter005.html#p162">162</a></p>
<p>homomorphism</p>
<p>database, <a href="chapter005.html#p235">235</a></p>
<p>graph, <a href="chapter004.html#p126">126</a></p>
<p>group, <a href="chapter004.html#p119">119</a></p>
<p>monoid, <a href="chapter004.html#p98">98</a>, <a href="chapter004.html#p110">110</a></p>
<p>iff, <a href="chapter003.html#p67">67</a></p>
<p>image, <a href="chapter002.html#p13">13</a></p>
<p>in olog, <a href="chapter002.html#p34">34</a></p>
<p>inclusion functions, <a href="chapter003.html#p43">43</a></p>
<p>indexed set, <a href="chapter003.html#p90">90</a>, <a href="chapter003.html#p91">91</a></p>
<p>as functor, <a href="chapter005.html#p232">232</a></p>
<p>indexing category, <a href="chapter006.html#p262">262</a></p>
<p>infix notation, <a href="chapter004.html#p95">95</a></p>
<p>information theory, <a href="chapter005.html#p211">211</a></p>
<p>initial object, <a href="chapter006.html#p267">267</a></p>
<p>in C−Set, <a href="chapter007.html#p320">320</a></p>
<p>instance, <a href="chapter004.html#p157">157</a>, <a href="chapter005.html#p201">201</a></p>
<p>Kleisli, <a href="chapter007.html#p357">357</a></p>
<p>isomorphism, <a href="chapter005.html#p169">169</a></p>
<p>of sets, <a href="chapter002.html#p16">16</a></p>
<p>join, <a href="chapter004.html#p139">139</a></p>
<p>Joyal, André, <a href="chapter001.html#p5">5</a></p>
<p>Kan extension</p>
<p>left, <a href="chapter007.html#p312">312</a></p>
<p>right, <a href="chapter007.html#p315">315</a></p>
<p>Kan, Daniel, <a href="chapter001.html#p5">5</a></p>
<p>Kleisli category, <a href="chapter007.html#p351">351</a></p>
<p>labeled null, <a href="chapter007.html#p314">314</a></p>
<p>Lambek, Joachim, <a href="chapter001.html#p5">5</a></p>
<p>laws</p>
<p>category, <a href="chapter005.html#p162">162</a></p>
<p>functor, <a href="chapter005.html#p174">174</a></p>
<p>monad, <a href="chapter007.html#p347">347</a></p>
<p>monoid, <a href="chapter004.html#p94">94</a></p>
<p>monoid action, <a href="chapter004.html#p101">101</a></p>
<p>natural transformation, <a href="chapter005.html#p214">214</a></p>
<p>operad, <a href="chapter007.html#p364">364</a></p>
<p>operad-functor, <a href="chapter007.html#p367">367</a></p>
<p>Lawvere, William, <a href="chapter001.html#p4">4</a></p>
<p>leaf table, <a href="chapter005.html#p201">201</a></p>
<p>limit, <a href="chapter006.html#p273">273</a></p>
<p>closed under, <a href="chapter007.html#p319">319</a></p>
<p>linear order</p>
<p>finite, <a href="chapter004.html#p134">134</a></p>
<p>list, <a href="chapter004.html#p96">96</a>, <a href="chapter007.html#p348">348</a></p>
<p>as functor, <a href="chapter005.html#p181">181</a></p>
<p>concatenation, <a href="chapter004.html#p97">97</a></p>
<p>local-to-global, <a href="chapter001.html#p4">4</a>, <a href="chapter005.html#p211">211</a></p>
<p>Mac Lane, Saunders, <a href="chapter001.html#p4">4</a></p>
<p>Markov chain, <a href="chapter007.html#p359">359</a></p>
<p>materials</p>
<p>force extension curves, <a href="chapter003.html#p74">74</a></p>
<p>force-extension curves, <a href="chapter002.html#p12">12</a></p>
<p>meet, <a href="chapter004.html#p139">139</a></p>
<p>Moggi, Eugenio, <a href="chapter001.html#p5">5</a></p>
<p>monad, <a href="chapter007.html#p344">344</a>, <a href="chapter007.html#p347">347</a></p>
<p>formalizing context, <a href="chapter007.html#p344">344</a></p>
<p>Kleisli category of, <a href="chapter007.html#p351">351</a></p>
<p>on <strong>Grph</strong>, <a href="chapter007.html#p351">351</a></p>
<p>on <strong>Set</strong>, <a href="chapter007.html#p347">347</a></p>
<p>on arbitrary category, <a href="chapter007.html#p361">361</a></p>
<p>monoid, <a href="chapter004.html#p94">94</a></p>
<p>action, <a href="chapter004.html#p101">101</a></p>
<p>additive natural numbers, <a href="chapter004.html#p95">95</a></p>
<p>as category, <a href="chapter005.html#p190">190</a></p>
<p>commutative, <a href="chapter004.html#p96">96</a></p>
<p>cyclic, <a href="chapter004.html#p100">100</a></p>
<p>free, <a href="chapter004.html#p97">97</a>, <a href="chapter005.html#p181">181</a></p>
<p>generators, <a href="chapter004.html#p97">97</a></p>
<p>homomorphism, <a href="chapter004.html#p110">110</a></p>
<p>initial, <a href="chapter006.html#p268">268</a></p>
<p>inverse of an element in, <a href="chapter004.html#p114">114</a></p>
<p>multiplication formula, <a href="chapter004.html#p94">94</a></p>
<p>of endomorphisms, <a href="chapter005.html#p193">193</a></p>
<p>olog of, <a href="chapter004.html#p105">105</a></p>
<p>presented, <a href="chapter004.html#p98">98</a></p>
<p>terminal, <a href="chapter006.html#p268">268</a></p>
<p>trivial, <a href="chapter004.html#p96">96</a></p>
<p>trivial homomorphism, <a href="chapter004.html#p111">111</a></p>
<p>unit element of, <a href="chapter004.html#p94">94</a></p>
<p>monomorphism, <a href="chapter007.html#p321">321</a></p>
<p>in <strong>Set</strong>, <a href="chapter003.html#p85">85</a></p>
<p>morphism, <a href="chapter005.html#p162">162</a></p>
<p>inverse, <a href="chapter005.html#p169">169</a></p>
<p>multicategory, <a href="chapter007.html#p362">362</a></p>
<p>multiset, <a href="chapter003.html#p88">88</a></p>
<p>natural isomorphism, <a href="chapter005.html#p225">225</a></p>
<p>natural transformation, <a href="chapter005.html#p213">213</a></p>
<p>as functor, <a href="chapter006.html#p276">276</a></p>
<p>as refinement of model, <a href="chapter005.html#p218">218</a></p>
<p>for adding functionality, <a href="chapter005.html#p227">227</a></p>
<p>horizontal composition of, <a href="chapter005.html#p228">228</a></p>
<p>interchange, <a href="chapter005.html#p229">229</a></p>
<p>questionable, <a href="chapter005.html#p214">214</a></p>
<p>vertical composition of, <a href="chapter005.html#p223">223</a></p>
<p>whiskering of, <a href="chapter005.html#p228">228</a></p>
<p>object</p>
<p>represented by a functor, <a href="chapter005.html#p224">224</a></p>
<p>olog, <a href="chapter002.html#p22">22</a></p>
<p>as database schema, <a href="chapter004.html#p155">155</a></p>
<p>aspects, <a href="chapter002.html#p25">25</a></p>
<p>facts, <a href="chapter002.html#p30">30</a></p>
<p>facts in English, <a href="chapter002.html#p32">32</a></p>
<p>images, <a href="chapter002.html#p34">34</a></p>
<p>invalid aspects, <a href="chapter002.html#p25">25</a></p>
<p>path in, <a href="chapter002.html#p30">30</a></p>
<p>relational, <a href="chapter007.html#p357">357</a></p>
<p>rules, <a href="chapter002.html#p24">24</a>, <a href="chapter002.html#p29">29</a>, <a href="chapter004.html#p153">153</a></p>
<p>sheaf of, <a href="chapter007.html#p341">341</a></p>
<p>types, <a href="chapter002.html#p23">23</a></p>
<p>underlying graph, <a href="chapter004.html#p120">120</a></p>
<p>one-to-one correspondence, <a href="chapter002.html#p17">17</a></p>
<p>open cover, <a href="chapter007.html#p339">339</a></p>
<p>operad</p>
<p>algebra of, <a href="chapter007.html#p368">368</a></p>
<p>colored, <a href="chapter007.html#p362">362</a></p>
<p>morphism of, <a href="chapter007.html#p367">367</a></p>
<p>orbit, <a href="chapter004.html#p118">118</a></p>
<p>rotating earth, <a href="chapter004.html#p117">117</a></p>
<p>order, <a href="chapter004.html#p132">132</a></p>
<p>linear order, <a href="chapter004.html#p132">132</a></p>
<p>morphism, <a href="chapter004.html#p142">142</a></p>
<p>opposite, <a href="chapter004.html#p141">141</a></p>
<p>partial order, <a href="chapter004.html#p132">132</a></p>
<p>preorder, <a href="chapter004.html#p132">132</a></p>
<p>tree, <a href="chapter004.html#p140">140</a></p>
<p>partial function, <a href="chapter007.html#p345">345</a></p>
<p>partial functions, <a href="chapter007.html#p345">345</a></p>
<p>path, <a href="chapter004.html#p125">125</a></p>
<p>PED, <a href="chapter004.html#p151">151</a></p>
<p>permutation, <a href="chapter004.html#p116">116</a></p>
<p>power-set, <a href="chapter003.html#p78">78</a></p>
<p>as poset, <a href="chapter004.html#p136">136</a></p>
<p>preimage, <a href="chapter003.html#p54">54</a>, <a href="chapter007.html#p303">303</a></p>
<p>preorder</p>
<p>as category, <a href="chapter005.html#p194">194</a></p>
<p>clique in, <a href="chapter004.html#p137">137</a></p>
<p>converting to graph, <a href="chapter004.html#p134">134</a></p>
<p>discrete, <a href="chapter004.html#p142">142</a></p>
<p>generated, <a href="chapter004.html#p137">137</a></p>
<p>indiscrete, <a href="chapter004.html#p142">142</a></p>
<p>join, <a href="chapter004.html#p139">139</a></p>
<p>meet, <a href="chapter004.html#p139">139</a></p>
<p>presheaf, <a href="chapter007.html#p338">338</a></p>
<p>product</p>
<p>as grid, <a href="chapter003.html#p38">38</a></p>
<p>projection functions, <a href="chapter003.html#p38">38</a></p>
<p>products, <a href="chapter006.html#p250">250</a>, <a href="chapter006.html#p254">254</a>, <a href="chapter006.html#p271">271</a></p>
<p>as not always existing, <a href="chapter006.html#p255">255</a></p>
<p>of sets, <a href="chapter003.html#p37">37</a></p>
<p>universal property for, <a href="chapter003.html#p40">40</a></p>
<p>projection functions, <a href="chapter003.html#p38">38</a></p>
<p>pullback, <a href="chapter006.html#p274">274</a></p>
<p>of sets, <a href="chapter003.html#p49">49</a></p>
<p>pushout, <a href="chapter006.html#p278">278</a></p>
<p>of topological spaces, <a href="chapter006.html#p282">282</a></p>
<p>RDF, <a href="chapter006.html#p286">286</a></p>
<p>as category of elements, <a href="chapter006.html#p288">288</a></p>
<p>relation</p>
<p>binary, <a href="chapter004.html#p129">129</a></p>
<p>equivalence, <a href="chapter003.html#p63">63</a></p>
<p>graph of, <a href="chapter004.html#p130">130</a></p>
<p>relative set, <a href="chapter003.html#p89">89</a>, <a href="chapter003.html#p90">90</a></p>
<p>as slice category, <a href="chapter006.html#p277">277</a></p>
<p>representable functor, <a href="chapter007.html#p322">322</a></p>
<p>representation theory, <a href="chapter007.html#p335">335</a></p>
<p>representative</p>
<p>of an equivalence class, <a href="chapter003.html#p64">64</a></p>
<p>restriction of scalars, <a href="chapter004.html#p113">113</a></p>
<p>retraction, <a href="chapter003.html#p73">73</a></p>
<p>RNA transcription, <a href="chapter002.html#p17">17</a></p>
<p>schema, <a href="chapter004.html#p153">153</a></p>
<p>as category presentation, <a href="chapter005.html#p199">199</a>, <a href="chapter005.html#p200">200</a></p>
<p>as equivalent to category, <a href="chapter005.html#p241">241</a></p>
<p>as syntax, <a href="chapter005.html#p199">199</a></p>
<p>congruence, <a href="chapter004.html#p151">151</a></p>
<p>fact table, <a href="chapter007.html#p310">310</a></p>
<p>leaf table, <a href="chapter004.html#p150">150</a>, <a href="chapter007.html#p310">310</a></p>
<p>morphism, <a href="chapter005.html#p243">243</a></p>
<p>of a database, <a href="chapter004.html#p149">149</a></p>
<p>Path equivalence declaration (PED), <a href="chapter004.html#p151">151</a></p>
<p>schematically implied reference spread, <a href="chapter007.html#p323">323</a></p>
<p>security, <a href="chapter004.html#p144">144</a></p>
<p>set, <a href="chapter002.html#p9">9</a></p>
<p>arithmetic of, <a href="chapter003.html#p76">76</a></p>
<p>Lawvere is description of, <a href="chapter005.html#p210">210</a></p>
<p>numeral, <a href="chapter002.html#p20">20</a></p>
<p>permutation of, <a href="chapter004.html#p116">116</a></p>
<p>set builder notation, <a href="chapter002.html#p10">10</a></p>
<p>sheaf</p>
<p>condition, <a href="chapter007.html#p339">339</a></p>
<p>descent data, <a href="chapter007.html#p340">340</a></p>
<p>sheaves, <a href="chapter007.html#p337">337</a></p>
<p>simplex, <a href="chapter003.html#p79">79</a></p>
<p>simplicial complex, <a href="chapter003.html#p79">79</a>, <a href="chapter007.html#p342">342</a></p>
<p>simplicial set, <a href="chapter006.html#p286">286</a></p>
<p>Skolem, <a href="chapter007.html#p323">323</a></p>
<p>Skolem variable, <a href="chapter007.html#p314">314</a></p>
<p>slice, <a href="chapter006.html#p273">273</a></p>
<p>space, <a href="chapter004.html#p145">145</a>, <a href="chapter005.html#p202">202</a></p>
<p>topological, <a href="chapter005.html#p202">202</a></p>
<p>space group, <a href="chapter004.html#p116">116</a></p>
<p>span, <a href="chapter003.html#p58">58</a></p>
<p>composite, <a href="chapter003.html#p59">59</a></p>
<p>stereotype, <a href="chapter002.html#p26">26</a></p>
<p>subcategory</p>
<p>full, <a href="chapter005.html#p166">166</a>, <a href="chapter006.html#p291">291</a></p>
<p>subobject classifier</p>
<p>in C−Set, <a href="chapter007.html#p331">331</a></p>
<p>in <strong>Set</strong>, <a href="chapter003.html#p81">81</a></p>
<p>subset, <a href="chapter002.html#p10">10</a></p>
<p>as function, <a href="chapter002.html#p12">12</a></p>
<p>characteristic function of, <a href="chapter003.html#p82">82</a></p>
<p>complement, <a href="chapter003.html#p82">82</a></p>
<p>subway, <a href="chapter006.html#p283">283</a></p>
<p>symmetry, <a href="chapter004.html#p115">115</a></p>
<p>terminal object, <a href="chapter006.html#p267">267</a></p>
<p>in C−Set, <a href="chapter007.html#p320">320</a></p>
<p>in <strong>Set</strong>, <a href="chapter003.html#p62">62</a></p>
<p>topological space, <a href="chapter005.html#p203">203</a></p>
<p>topology, <a href="chapter005.html#p202">202</a></p>
<p>topos, <a href="chapter007.html#p331">331</a></p>
<p>tree, <a href="chapter004.html#p140">140</a></p>
<p>root, <a href="chapter004.html#p140">140</a></p>
<p>trivial homomorphism</p>
<p>of monoids, <a href="chapter004.html#p111">111</a></p>
<p>universal property, <a href="chapter006.html#p254">254</a></p>
<p>products, <a href="chapter003.html#p40">40</a></p>
<p>pullback, <a href="chapter006.html#p274">274</a></p>
<p>vector field, <a href="chapter005.html#p168">168</a>, <a href="chapter005.html#p207">207</a></p>
<p>conservative, <a href="chapter005.html#p207">207</a></p>
<p>vector space, <a href="chapter005.html#p204">204</a>, <a href="chapter007.html#p335">335</a></p>
<p>vertex, <a href="chapter004.html#p119">119</a></p>
<p>wiring diagram, <a href="chapter007.html#p372">372</a></p>
<p>Yoneda’s lemma, <a href="chapter007.html#p327">327</a></p>
<p></p>
<p>[Go to <a href="index.html">first</a>, <a href="reference.html">previous</a>, next page;   <a href="toc.html">contents</a>;   index]</p>
